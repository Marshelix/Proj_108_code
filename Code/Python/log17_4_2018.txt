[2018-04-17 14:06:39.570713]: Starting
[2018-04-17 14:06:39.574724]: OS detected: Windows
[2018-04-17 14:06:39.580741]: Using G:\Data\map_data\ as file path
[2018-04-17 14:06:39.585753]: Using CUDA: True
[2018-04-17 14:06:40.743331]: Raw Data loaded. Turning to batches
[2018-04-17 14:06:40.764888]: Batches generated
[2018-04-17 14:06:40.769401]: Generating 25 string maps per stringless one.
[2018-04-17 14:06:40.770403]: Estimated time till completion of map generation: 0:37:30
[2018-04-17 14:06:40.774414]: Estimated time of completion of map generation: 2018-04-17 14:44:10.773912
[2018-04-17 14:06:40.778424]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:20:27.524040]: Starting
[2018-04-17 14:20:27.529054]: OS detected: Windows
[2018-04-17 14:20:27.534569]: Using G:\Data\map_data\ as file path
[2018-04-17 14:20:27.751144]: Using CUDA: True
[2018-04-17 14:20:28.491615]: Raw Data loaded. Turning to batches
[2018-04-17 14:20:28.496627]: Batches generated
[2018-04-17 14:20:28.502141]: Generating 25 string maps per stringless one.
[2018-04-17 14:20:28.508157]: Estimated time till completion of map generation: 0:37:30
[2018-04-17 14:20:28.514682]: Estimated time of completion of map generation: 2018-04-17 14:57:58.514682
[2018-04-17 14:20:28.520190]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:20:58.551682]: Starting
[2018-04-17 14:20:58.555692]: OS detected: Windows
[2018-04-17 14:20:58.561708]: Using G:\Data\map_data\ as file path
[2018-04-17 14:20:58.566722]: Using CUDA: True
[2018-04-17 14:20:59.398935]: Raw Data loaded. Turning to batches
[2018-04-17 14:20:59.414476]: Batches generated
[2018-04-17 14:20:59.419993]: Generating 1 string maps per stringless one.
[2018-04-17 14:20:59.425005]: Estimated time till completion of map generation: 0:01:30
[2018-04-17 14:20:59.431020]: Estimated time of completion of map generation: 2018-04-17 14:22:29.431020
[2018-04-17 14:20:59.436033]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:22:00.757313]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 14:22:00.761322]: 10 elements per train batch.
[2018-04-17 14:22:21.044256]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 14:22:21.048767]: 10 elements per test batch.
[2018-04-17 14:22:23.503794]: Network and optimizers created
[2018-04-17 14:22:23.508307]: Projected finishing time = 2018-04-17 14:22:32.508307
[2018-04-17 14:22:23.512819]: Projected time to completion = 0:00:09
[2018-04-17 14:22:24.736074]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7473229169845581
[2018-04-17 14:22:24.928582]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 14.875834584236145
[2018-04-17 14:22:25.121596]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 28.78532701730728
[2018-04-17 14:22:25.711777]: Test set accuracy: 40.0% ,loss = 17.693206667900085
[2018-04-17 14:22:26.476309]: ====================
[2018-04-17 14:22:26.480822]: Elapsed time since starting training: 0:00:02.972515
[2018-04-17 14:22:26.485334]: ====================
[2018-04-17 14:22:26.498368]: [Epoch: 1(100.0%): Data: 0.0%]:Running loss: 0.7077282667160034
[2018-04-17 14:22:26.685366]: [Epoch: 1(100.0%): Data: 25.333333333333336%]:Running loss: 14.082907736301422
[2018-04-17 14:22:26.891413]: [Epoch: 1(100.0%): Data: 50.66666666666667%]:Running loss: 27.340845048427582
[2018-04-17 14:22:27.429344]: Test set accuracy: 60.0% ,loss = 17.18640923500061
[2018-04-17 14:22:27.671488]: ====================
[2018-04-17 14:22:27.676000]: Elapsed time since starting training: 0:00:04.167693
[2018-04-17 14:22:27.681515]: ====================
[2018-04-17 14:22:27.687030]: Elapsed time on training: 0:00:04.178221
[2018-04-17 14:22:27.857993]: Test set accuracy: 60.0% ,loss = 17.18640923500061
[2018-04-17 14:23:32.607326]: Starting
[2018-04-17 14:23:32.611838]: OS detected: Windows
[2018-04-17 14:23:32.618355]: Using G:\Data\map_data\ as file path
[2018-04-17 14:23:32.624872]: Using CUDA: True
[2018-04-17 14:23:33.460093]: Raw Data loaded. Turning to batches
[2018-04-17 14:23:33.475134]: Batches generated
[2018-04-17 14:23:33.482153]: Generating 1 string maps per stringless one.
[2018-04-17 14:23:33.488168]: Estimated time till completion of map generation: 0:01:30
[2018-04-17 14:23:33.492681]: Estimated time of completion of map generation: 2018-04-17 14:25:03.492178
[2018-04-17 14:23:33.498194]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:24:36.473682]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 14:24:36.478694]: 10 elements per train batch.
[2018-04-17 14:24:58.393486]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 14:24:58.398499]: 10 elements per test batch.
[2018-04-17 14:24:58.405017]: Network and optimizers created
[2018-04-17 14:24:58.412539]: Projected finishing time = 2018-04-17 14:25:20.912539
[2018-04-17 14:24:58.417062]: Projected time to completion = 0:00:22.500000
[2018-04-17 14:24:58.489240]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.6831448674201965
[2018-04-17 14:24:58.685262]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 13.652949690818787
[2018-04-17 14:24:58.874766]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 26.59519749879837
[2018-04-17 14:24:59.389651]: Test set accuracy: 60.0% ,loss = 16.950202584266663
[2018-04-17 14:24:59.954652]: ====================
[2018-04-17 14:24:59.959666]: Elapsed time since starting training: 0:00:01.547127
[2018-04-17 14:24:59.963676]: ====================
[2018-04-17 14:24:59.976209]: [Epoch: 1(25.0%): Data: 0.0%]:Running loss: 0.6779196858406067
[2018-04-17 14:25:00.142151]: [Epoch: 1(25.0%): Data: 25.333333333333336%]:Running loss: 13.550330936908722
[2018-04-17 14:25:00.324135]: [Epoch: 1(25.0%): Data: 50.66666666666667%]:Running loss: 26.406319975852966
[2018-04-17 14:25:00.848541]: Test set accuracy: 60.0% ,loss = 16.880371034145355
[2018-04-17 14:25:00.980881]: ====================
[2018-04-17 14:25:00.985896]: Elapsed time since starting training: 0:00:02.572854
[2018-04-17 14:25:00.992913]: ====================
[2018-04-17 14:25:01.007452]: [Epoch: 2(50.0%): Data: 0.0%]:Running loss: 0.6752198934555054
[2018-04-17 14:25:01.171889]: [Epoch: 2(50.0%): Data: 25.333333333333336%]:Running loss: 13.499997556209564
[2018-04-17 14:25:01.357382]: [Epoch: 2(50.0%): Data: 50.66666666666667%]:Running loss: 26.317103505134583
[2018-04-17 14:25:01.891302]: Test set accuracy: 60.0% ,loss = 16.849451899528503
[2018-04-17 14:25:02.015632]: ====================
[2018-04-17 14:25:02.020145]: Elapsed time since starting training: 0:00:03.607104
[2018-04-17 14:25:02.025158]: ====================
[2018-04-17 14:25:02.039195]: [Epoch: 3(75.0%): Data: 0.0%]:Running loss: 0.6739457845687866
[2018-04-17 14:25:02.215163]: [Epoch: 3(75.0%): Data: 25.333333333333336%]:Running loss: 13.476957321166992
[2018-04-17 14:25:02.395642]: [Epoch: 3(75.0%): Data: 50.66666666666667%]:Running loss: 26.2773340344429
[2018-04-17 14:25:02.918538]: Test set accuracy: 60.0% ,loss = 16.83591777086258
[2018-04-17 14:25:03.032336]: ====================
[2018-04-17 14:25:03.037349]: Elapsed time since starting training: 0:00:04.624309
[2018-04-17 14:25:03.042362]: ====================
[2018-04-17 14:25:03.055898]: [Epoch: 4(100.0%): Data: 0.0%]:Running loss: 0.6733037233352661
[2018-04-17 14:25:03.222341]: [Epoch: 4(100.0%): Data: 25.333333333333336%]:Running loss: 13.467289626598358
[2018-04-17 14:25:03.410842]: [Epoch: 4(100.0%): Data: 50.66666666666667%]:Running loss: 26.26007843017578
[2018-04-17 14:25:03.941754]: Test set accuracy: 60.0% ,loss = 16.83003294467926
[2018-04-17 14:25:04.059065]: ====================
[2018-04-17 14:25:04.063578]: Elapsed time since starting training: 0:00:05.650538
[2018-04-17 14:25:04.068604]: ====================
[2018-04-17 14:25:04.073605]: Elapsed time on training: 0:00:05.661066
[2018-04-17 14:25:04.226010]: Test set accuracy: 60.0% ,loss = 16.83003294467926
[2018-04-17 14:26:39.475996]: Starting
[2018-04-17 14:26:39.482514]: OS detected: Windows
[2018-04-17 14:26:39.488028]: Using G:\Data\map_data\ as file path
[2018-04-17 14:26:39.493543]: Using CUDA: True
[2018-04-17 14:26:40.480667]: Raw Data loaded. Turning to batches
[2018-04-17 14:26:40.491196]: Batches generated
[2018-04-17 14:26:40.496209]: Generating 1 string maps per stringless one.
[2018-04-17 14:26:40.500721]: Estimated time till completion of map generation: 0:01:30
[2018-04-17 14:26:40.505736]: Estimated time of completion of map generation: 2018-04-17 14:28:10.505233
[2018-04-17 14:26:40.511751]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:27:43.857755]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 14:27:43.864774]: 10 elements per train batch.
[2018-04-17 14:28:04.021396]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 14:28:04.026409]: 10 elements per test batch.
[2018-04-17 14:28:04.030921]: Network and optimizers created
[2018-04-17 14:28:04.036435]: Projected finishing time = 2018-04-17 14:28:49.036435
[2018-04-17 14:28:04.041448]: Projected time to completion = 0:00:45
[2018-04-17 14:28:04.127177]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7076665163040161
[2018-04-17 14:28:04.308658]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 14.12019556760788
[2018-04-17 14:28:04.475101]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 27.43018490076065
[2018-04-17 14:28:04.968414]: Test set accuracy: 60.0% ,loss = 17.229653894901276
[2018-04-17 14:28:05.364967]: ====================
[2018-04-17 14:28:05.369981]: Elapsed time since starting training: 0:00:01.333546
[2018-04-17 14:28:05.374493]: ====================
[2018-04-17 14:28:05.387026]: [Epoch: 1(11.11111111111111%): Data: 0.0%]:Running loss: 0.689186155796051
[2018-04-17 14:28:05.547954]: [Epoch: 1(11.11111111111111%): Data: 25.333333333333336%]:Running loss: 13.750463962554932
[2018-04-17 14:28:05.725927]: [Epoch: 1(11.11111111111111%): Data: 50.66666666666667%]:Running loss: 26.757340013980865
[2018-04-17 14:28:06.203698]: Test set accuracy: 60.0% ,loss = 16.994401812553406
[2018-04-17 14:28:06.326023]: ====================
[2018-04-17 14:28:06.331538]: Elapsed time since starting training: 0:00:02.295103
[2018-04-17 14:28:06.336551]: ====================
[2018-04-17 14:28:06.349084]: [Epoch: 2(22.22222222222222%): Data: 0.0%]:Running loss: 0.6797760725021362
[2018-04-17 14:28:06.503996]: [Epoch: 2(22.22222222222222%): Data: 25.333333333333336%]:Running loss: 13.581709682941437
[2018-04-17 14:28:06.684978]: [Epoch: 2(22.22222222222222%): Data: 50.66666666666667%]:Running loss: 26.46103549003601
[2018-04-17 14:28:07.171772]: Test set accuracy: 60.0% ,loss = 16.896505653858185
[2018-04-17 14:28:07.287580]: ====================
[2018-04-17 14:28:07.292593]: Elapsed time since starting training: 0:00:03.255657
[2018-04-17 14:28:07.297606]: ====================
[2018-04-17 14:28:07.310641]: [Epoch: 3(33.33333333333333%): Data: 0.0%]:Running loss: 0.6758602261543274
[2018-04-17 14:28:07.474577]: [Epoch: 3(33.33333333333333%): Data: 25.333333333333336%]:Running loss: 13.511429488658905
[2018-04-17 14:28:07.647537]: [Epoch: 3(33.33333333333333%): Data: 50.66666666666667%]:Running loss: 26.337531626224518
[2018-04-17 14:28:08.124806]: Test set accuracy: 60.0% ,loss = 16.855457425117493
[2018-04-17 14:28:08.225073]: ====================
[2018-04-17 14:28:08.230086]: Elapsed time since starting training: 0:00:04.193651
[2018-04-17 14:28:08.235601]: ====================
[2018-04-17 14:28:08.250139]: [Epoch: 4(44.44444444444444%): Data: 0.0%]:Running loss: 0.6742182970046997
[2018-04-17 14:28:08.416080]: [Epoch: 4(44.44444444444444%): Data: 25.333333333333336%]:Running loss: 13.481932938098907
[2018-04-17 14:28:08.567984]: [Epoch: 4(44.44444444444444%): Data: 50.66666666666667%]:Running loss: 26.285654604434967
[2018-04-17 14:28:09.051270]: Test set accuracy: 60.0% ,loss = 16.83812439441681
[2018-04-17 14:28:09.160560]: ====================
[2018-04-17 14:28:09.165573]: Elapsed time since starting training: 0:00:05.129138
[2018-04-17 14:28:09.170587]: ====================
[2018-04-17 14:28:09.185627]: [Epoch: 5(55.55555555555556%): Data: 0.0%]:Running loss: 0.6735249757766724
[2018-04-17 14:28:09.360101]: [Epoch: 5(55.55555555555556%): Data: 25.333333333333336%]:Running loss: 13.469469785690308
[2018-04-17 14:28:09.525540]: [Epoch: 5(55.55555555555556%): Data: 50.66666666666667%]:Running loss: 26.263721227645874
[2018-04-17 14:28:10.014341]: Test set accuracy: 60.0% ,loss = 16.830769181251526
[2018-04-17 14:28:10.115108]: ====================
[2018-04-17 14:28:10.120121]: Elapsed time since starting training: 0:00:06.083686
[2018-04-17 14:28:10.125135]: ====================
[2018-04-17 14:28:10.138671]: [Epoch: 6(66.66666666666666%): Data: 0.0%]:Running loss: 0.673230767250061
[2018-04-17 14:28:10.316644]: [Epoch: 6(66.66666666666666%): Data: 25.333333333333336%]:Running loss: 13.46417623758316
[2018-04-17 14:28:10.472057]: [Epoch: 6(66.66666666666666%): Data: 50.66666666666667%]:Running loss: 26.254400670528412
[2018-04-17 14:28:10.942323]: Test set accuracy: 60.0% ,loss = 16.82763397693634
[2018-04-17 14:28:11.044094]: ====================
[2018-04-17 14:28:11.049107]: Elapsed time since starting training: 0:00:07.012672
[2018-04-17 14:28:11.054622]: ====================
[2018-04-17 14:28:11.069161]: [Epoch: 7(77.77777777777779%): Data: 0.0%]:Running loss: 0.6731053590774536
[2018-04-17 14:28:11.244627]: [Epoch: 7(77.77777777777779%): Data: 25.333333333333336%]:Running loss: 13.461919367313385
[2018-04-17 14:28:11.407560]: [Epoch: 7(77.77777777777779%): Data: 50.66666666666667%]:Running loss: 26.2504261136055
[2018-04-17 14:28:11.873801]: Test set accuracy: 60.0% ,loss = 16.826295852661133
[2018-04-17 14:28:11.976072]: ====================
[2018-04-17 14:28:11.981587]: Elapsed time since starting training: 0:00:07.945152
[2018-04-17 14:28:11.986605]: ====================
[2018-04-17 14:28:12.002144]: [Epoch: 8(88.88888888888889%): Data: 0.0%]:Running loss: 0.6730518341064453
[2018-04-17 14:28:12.180115]: [Epoch: 8(88.88888888888889%): Data: 25.333333333333336%]:Running loss: 13.460955202579498
[2018-04-17 14:28:12.353576]: [Epoch: 8(88.88888888888889%): Data: 50.66666666666667%]:Running loss: 26.248726963996887
[2018-04-17 14:28:12.818813]: Test set accuracy: 60.0% ,loss = 16.82571917772293
[2018-04-17 14:28:12.929608]: ====================
[2018-04-17 14:28:12.935123]: Elapsed time since starting training: 0:00:08.898186
[2018-04-17 14:28:12.940637]: ====================
[2018-04-17 14:28:12.958183]: [Epoch: 9(100.0%): Data: 0.0%]:Running loss: 0.6730287671089172
[2018-04-17 14:28:13.145682]: [Epoch: 9(100.0%): Data: 25.333333333333336%]:Running loss: 13.460542917251587
[2018-04-17 14:28:13.320647]: [Epoch: 9(100.0%): Data: 50.66666666666667%]:Running loss: 26.248001039028168
[2018-04-17 14:28:13.790397]: Test set accuracy: 60.0% ,loss = 16.825474798679352
[2018-04-17 14:28:13.883644]: ====================
[2018-04-17 14:28:13.889159]: Elapsed time since starting training: 0:00:09.852724
[2018-04-17 14:28:13.894172]: ====================
[2018-04-17 14:28:13.899687]: Elapsed time on training: 0:00:09.863252
[2018-04-17 14:28:14.051591]: Test set accuracy: 60.0% ,loss = 16.825474798679352
[2018-04-17 14:29:16.645914]: Starting
[2018-04-17 14:29:16.651429]: OS detected: Windows
[2018-04-17 14:29:16.658949]: Using G:\Data\map_data\ as file path
[2018-04-17 14:29:16.665466]: Using CUDA: True
[2018-04-17 14:29:17.523248]: Raw Data loaded. Turning to batches
[2018-04-17 14:29:17.531771]: Batches generated
[2018-04-17 14:29:17.537284]: Generating 5 string maps per stringless one.
[2018-04-17 14:29:17.542298]: Estimated time till completion of map generation: 0:07:30
[2018-04-17 14:29:17.547311]: Estimated time of completion of map generation: 2018-04-17 14:36:47.547311
[2018-04-17 14:29:17.552826]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:34:20.190865]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 14:34:20.195878]: 26 elements per train batch.
[2018-04-17 14:35:56.191272]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 14:35:56.196285]: 26 elements per test batch.
[2018-04-17 14:35:56.203304]: Network and optimizers created
[2018-04-17 14:35:56.208819]: Projected finishing time = 2018-04-17 14:36:41.208819
[2018-04-17 14:35:56.214333]: Projected time to completion = 0:00:45
[2018-04-17 14:35:56.297053]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7616516947746277
[2018-04-17 14:35:56.701629]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 15.028255820274353
[2018-04-17 14:35:57.076626]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 28.660891234874725
[2018-04-17 14:35:58.084309]: Test set accuracy: 76.92307692307692% ,loss = 16.184161603450775
[2018-04-17 14:35:58.916017]: ====================
[2018-04-17 14:35:58.921031]: Elapsed time since starting training: 0:00:02.712212
[2018-04-17 14:35:58.926044]: ====================
[2018-04-17 14:35:58.949606]: [Epoch: 1(11.11111111111111%): Data: 0.0%]:Running loss: 0.647366464138031
[2018-04-17 14:35:59.296027]: [Epoch: 1(11.11111111111111%): Data: 25.333333333333336%]:Running loss: 12.741319417953491
[2018-04-17 14:35:59.661499]: [Epoch: 1(11.11111111111111%): Data: 50.66666666666667%]:Running loss: 24.497633159160614
[2018-04-17 14:36:00.653641]: Test set accuracy: 76.92307692307692% ,loss = 14.717386662960052
[2018-04-17 14:36:01.011599]: ====================
[2018-04-17 14:36:01.017605]: Elapsed time since starting training: 0:00:04.808786
[2018-04-17 14:36:01.023621]: ====================
[2018-04-17 14:36:01.047685]: [Epoch: 2(22.22222222222222%): Data: 0.0%]:Running loss: 0.5886954665184021
[2018-04-17 14:36:01.374053]: [Epoch: 2(22.22222222222222%): Data: 25.333333333333336%]:Running loss: 11.685905873775482
[2018-04-17 14:36:01.737519]: [Epoch: 2(22.22222222222222%): Data: 50.66666666666667%]:Running loss: 22.637701094150543
[2018-04-17 14:36:02.722639]: Test set accuracy: 76.92307692307692% ,loss = 14.079545438289642
[2018-04-17 14:36:02.833433]: ====================
[2018-04-17 14:36:02.838948]: Elapsed time since starting training: 0:00:06.629628
[2018-04-17 14:36:02.843962]: ====================
[2018-04-17 14:36:02.869530]: [Epoch: 3(33.33333333333333%): Data: 0.0%]:Running loss: 0.5631818175315857
[2018-04-17 14:36:03.235001]: [Epoch: 3(33.33333333333333%): Data: 25.333333333333336%]:Running loss: 11.224017918109894
[2018-04-17 14:36:03.591963]: [Epoch: 3(33.33333333333333%): Data: 50.66666666666667%]:Running loss: 21.818825840950012
[2018-04-17 14:36:04.554510]: Test set accuracy: 76.92307692307692% ,loss = 13.787338137626648
[2018-04-17 14:36:04.660292]: ====================
[2018-04-17 14:36:04.665304]: Elapsed time since starting training: 0:00:08.456485
[2018-04-17 14:36:04.670318]: ====================
[2018-04-17 14:36:04.692878]: [Epoch: 4(44.44444444444444%): Data: 0.0%]:Running loss: 0.5514935255050659
[2018-04-17 14:36:05.065870]: [Epoch: 4(44.44444444444444%): Data: 25.333333333333336%]:Running loss: 11.011168777942657
[2018-04-17 14:36:05.412290]: [Epoch: 4(44.44444444444444%): Data: 50.66666666666667%]:Running loss: 21.439461588859558
[2018-04-17 14:36:06.391895]: Test set accuracy: 76.92307692307692% ,loss = 13.647477328777313
[2018-04-17 14:36:06.498679]: ====================
[2018-04-17 14:36:06.504195]: Elapsed time since starting training: 0:00:10.295376
[2018-04-17 14:36:06.509709]: ====================
[2018-04-17 14:36:06.535778]: [Epoch: 5(55.55555555555556%): Data: 0.0%]:Running loss: 0.5458990931510925
[2018-04-17 14:36:06.901751]: [Epoch: 5(55.55555555555556%): Data: 25.333333333333336%]:Running loss: 10.90883320569992
[2018-04-17 14:36:07.260705]: [Epoch: 5(55.55555555555556%): Data: 50.66666666666667%]:Running loss: 21.256323516368866
[2018-04-17 14:36:08.211757]: Test set accuracy: 76.92307692307692% ,loss = 13.578318059444427
[2018-04-17 14:36:08.302487]: ====================
[2018-04-17 14:36:08.307500]: Elapsed time since starting training: 0:00:12.098681
[2018-04-17 14:36:08.312012]: ====================
[2018-04-17 14:36:08.335073]: [Epoch: 6(66.66666666666666%): Data: 0.0%]:Running loss: 0.5431327223777771
[2018-04-17 14:36:08.694538]: [Epoch: 6(66.66666666666666%): Data: 25.333333333333336%]:Running loss: 10.858041942119598
[2018-04-17 14:36:09.065802]: [Epoch: 6(66.66666666666666%): Data: 50.66666666666667%]:Running loss: 21.165155351161957
[2018-04-17 14:36:10.010314]: Test set accuracy: 76.92307692307692% ,loss = 13.54326456785202
[2018-04-17 14:36:10.108575]: ====================
[2018-04-17 14:36:10.113589]: Elapsed time since starting training: 0:00:13.904269
[2018-04-17 14:36:10.118101]: ====================
[2018-04-17 14:36:10.142165]: [Epoch: 7(77.77777777777779%): Data: 0.0%]:Running loss: 0.5417305827140808
[2018-04-17 14:36:10.468532]: [Epoch: 7(77.77777777777779%): Data: 25.333333333333336%]:Running loss: 10.832244992256165
[2018-04-17 14:36:10.834005]: [Epoch: 7(77.77777777777779%): Data: 50.66666666666667%]:Running loss: 21.11875146627426
[2018-04-17 14:36:11.806590]: Test set accuracy: 76.92307692307692% ,loss = 13.525182008743286
[2018-04-17 14:36:11.909364]: ====================
[2018-04-17 14:36:11.913876]: Elapsed time since starting training: 0:00:15.705057
[2018-04-17 14:36:11.918889]: ====================
[2018-04-17 14:36:11.942953]: [Epoch: 8(88.88888888888889%): Data: 0.0%]:Running loss: 0.5410072803497314
[2018-04-17 14:36:12.305417]: [Epoch: 8(88.88888888888889%): Data: 25.333333333333336%]:Running loss: 10.81892079114914
[2018-04-17 14:36:12.658355]: [Epoch: 8(88.88888888888889%): Data: 50.66666666666667%]:Running loss: 21.094745993614197
[2018-04-17 14:36:13.633448]: Test set accuracy: 76.92307692307692% ,loss = 13.515737652778625
[2018-04-17 14:36:13.740733]: ====================
[2018-04-17 14:36:13.745746]: Elapsed time since starting training: 0:00:17.536927
[2018-04-17 14:36:13.750259]: ====================
[2018-04-17 14:36:13.775325]: [Epoch: 9(100.0%): Data: 0.0%]:Running loss: 0.540629506111145
[2018-04-17 14:36:14.136285]: [Epoch: 9(100.0%): Data: 25.333333333333336%]:Running loss: 10.811951279640198
[2018-04-17 14:36:14.487218]: [Epoch: 9(100.0%): Data: 50.66666666666667%]:Running loss: 21.082176089286804
[2018-04-17 14:36:15.473340]: Test set accuracy: 76.92307692307692% ,loss = 13.510774075984955
[2018-04-17 14:36:15.561576]: ====================
[2018-04-17 14:36:15.566588]: Elapsed time since starting training: 0:00:19.357769
[2018-04-17 14:36:15.571601]: ====================
[2018-04-17 14:36:15.576617]: Elapsed time on training: 0:00:19.367798
[2018-04-17 14:36:15.916019]: Test set accuracy: 76.92307692307692% ,loss = 13.510774075984955
[2018-04-17 14:43:37.505422]: Starting
[2018-04-17 14:43:37.510436]: OS detected: Windows
[2018-04-17 14:43:37.517454]: Using G:\Data\map_data\ as file path
[2018-04-17 14:43:37.521967]: Using CUDA: True
[2018-04-17 14:43:38.305549]: Raw Data loaded. Turning to batches
[2018-04-17 14:43:38.314072]: Batches generated
[2018-04-17 14:43:38.319085]: Generating 5 string maps per stringless one.
[2018-04-17 14:43:38.324099]: Estimated time till completion of map generation: 0:07:30
[2018-04-17 14:43:38.328109]: Estimated time of completion of map generation: 2018-04-17 14:51:08.328109
[2018-04-17 14:43:38.333123]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 14:48:33.940643]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 14:48:33.946145]: 26 elements per train batch.
[2018-04-17 14:50:10.426410]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 14:50:10.430922]: 26 elements per test batch.
[2018-04-17 14:50:10.437940]: Network and optimizers created
[2018-04-17 14:50:10.442954]: Projected finishing time = 2018-04-17 14:50:55.442452
[2018-04-17 14:50:10.447968]: Projected time to completion = 0:00:45
[2018-04-17 14:50:10.533193]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7018615007400513
[2018-04-17 14:50:10.908203]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 12.900617718696594
[2018-04-17 14:50:11.281727]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 23.417788445949554
[2018-04-17 14:50:12.278377]: Test set accuracy: 76.92307692307692% ,loss = 13.506655395030975
[2018-04-17 14:50:12.764669]: ====================
[2018-04-17 14:50:12.769181]: Elapsed time since starting training: 0:00:02.326729
[2018-04-17 14:50:12.773693]: ====================
[2018-04-17 14:50:12.798259]: [Epoch: 1(11.11111111111111%): Data: 0.0%]:Running loss: 0.540266215801239
[2018-04-17 14:50:13.158719]: [Epoch: 1(11.11111111111111%): Data: 25.333333333333336%]:Running loss: 10.804849088191986
[2018-04-17 14:50:13.505639]: [Epoch: 1(11.11111111111111%): Data: 50.66666666666667%]:Running loss: 21.068849444389343
[2018-04-17 14:50:14.477224]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:14.698812]: ====================
[2018-04-17 14:50:14.706332]: Elapsed time since starting training: 0:00:04.263880
[2018-04-17 14:50:14.711345]: ====================
[2018-04-17 14:50:14.736915]: [Epoch: 2(22.22222222222222%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:15.085841]: [Epoch: 2(22.22222222222222%): Data: 25.333333333333336%]:Running loss: 10.804083168506622
[2018-04-17 14:50:15.451322]: [Epoch: 2(22.22222222222222%): Data: 50.66666666666667%]:Running loss: 21.067961037158966
[2018-04-17 14:50:16.427409]: Test set accuracy: 76.92307692307692% ,loss = 13.50509375333786
[2018-04-17 14:50:16.539208]: ====================
[2018-04-17 14:50:16.544221]: Elapsed time since starting training: 0:00:06.101769
[2018-04-17 14:50:16.549232]: ====================
[2018-04-17 14:50:16.574299]: [Epoch: 3(33.33333333333333%): Data: 0.0%]:Running loss: 0.5402037501335144
[2018-04-17 14:50:16.919718]: [Epoch: 3(33.33333333333333%): Data: 25.333333333333336%]:Running loss: 10.804081320762634
[2018-04-17 14:50:17.278170]: [Epoch: 3(33.33333333333333%): Data: 50.66666666666667%]:Running loss: 21.06795710325241
[2018-04-17 14:50:18.238726]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:18.344005]: ====================
[2018-04-17 14:50:18.349521]: Elapsed time since starting training: 0:00:07.907069
[2018-04-17 14:50:18.354532]: ====================
[2018-04-17 14:50:18.378095]: [Epoch: 4(44.44444444444444%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:18.736549]: [Epoch: 4(44.44444444444444%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:19.089487]: [Epoch: 4(44.44444444444444%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:20.065093]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:20.176377]: ====================
[2018-04-17 14:50:20.180889]: Elapsed time since starting training: 0:00:09.738437
[2018-04-17 14:50:20.186404]: ====================
[2018-04-17 14:50:20.209966]: [Epoch: 5(55.55555555555556%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:20.582457]: [Epoch: 5(55.55555555555556%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:20.927374]: [Epoch: 5(55.55555555555556%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:21.915000]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:22.019779]: ====================
[2018-04-17 14:50:22.024792]: Elapsed time since starting training: 0:00:11.582340
[2018-04-17 14:50:22.029806]: ====================
[2018-04-17 14:50:22.054378]: [Epoch: 6(66.66666666666666%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:22.431874]: [Epoch: 6(66.66666666666666%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:22.797847]: [Epoch: 6(66.66666666666666%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:23.779958]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:23.877218]: ====================
[2018-04-17 14:50:23.882231]: Elapsed time since starting training: 0:00:13.439278
[2018-04-17 14:50:23.888247]: ====================
[2018-04-17 14:50:23.910807]: [Epoch: 7(77.77777777777779%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:24.280791]: [Epoch: 7(77.77777777777779%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:24.649270]: [Epoch: 7(77.77777777777779%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:25.623863]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:25.731648]: ====================
[2018-04-17 14:50:25.736161]: Elapsed time since starting training: 0:00:15.293709
[2018-04-17 14:50:25.740672]: ====================
[2018-04-17 14:50:25.761728]: [Epoch: 8(88.88888888888889%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:26.109153]: [Epoch: 8(88.88888888888889%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:26.473621]: [Epoch: 8(88.88888888888889%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:27.462315]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:27.569601]: ====================
[2018-04-17 14:50:27.574614]: Elapsed time since starting training: 0:00:17.131661
[2018-04-17 14:50:27.579127]: ====================
[2018-04-17 14:50:27.601686]: [Epoch: 9(100.0%): Data: 0.0%]:Running loss: 0.5402042865753174
[2018-04-17 14:50:27.954629]: [Epoch: 9(100.0%): Data: 25.333333333333336%]:Running loss: 10.804085731506348
[2018-04-17 14:50:28.307082]: [Epoch: 9(100.0%): Data: 50.66666666666667%]:Running loss: 21.067967176437378
[2018-04-17 14:50:29.276167]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 14:50:29.378926]: ====================
[2018-04-17 14:50:29.383940]: Elapsed time since starting training: 0:00:18.941488
[2018-04-17 14:50:29.389455]: ====================
[2018-04-17 14:50:29.394468]: Elapsed time on training: 0:00:18.951514
[2018-04-17 14:50:29.741891]: Test set accuracy: 76.92307692307692% ,loss = 13.505107164382935
[2018-04-17 15:01:26.626836]: Starting
[2018-04-17 15:01:26.631348]: OS detected: Windows
[2018-04-17 15:01:26.638367]: Using G:\Data\map_data\ as file path
[2018-04-17 15:01:26.643380]: Using CUDA: True
[2018-04-17 15:01:27.565331]: Raw Data loaded. Turning to batches
[2018-04-17 15:01:27.578379]: Batches generated
[2018-04-17 15:01:27.583881]: Generating 5 string maps per stringless one.
[2018-04-17 15:01:27.588895]: Estimated time till completion of map generation: 0:07:30
[2018-04-17 15:01:27.594409]: Estimated time of completion of map generation: 2018-04-17 15:08:57.593908
[2018-04-17 15:01:27.598921]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 15:06:35.685360]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 15:06:35.690375]: 26 elements per train batch.
[2018-04-17 15:08:19.769516]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 15:08:19.775031]: 26 elements per test batch.
[2018-04-17 15:08:19.782551]: Network and optimizers created
[2018-04-17 15:08:19.788567]: Projected finishing time = 2018-04-17 15:15:49.788066
[2018-04-17 15:08:19.794082]: Projected time to completion = 0:07:30
[2018-04-17 15:08:19.888834]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7916135191917419
[2018-04-17 15:08:20.293409]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 15.78140652179718
[2018-04-17 15:08:20.684449]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 30.675913870334625
[2018-04-17 15:08:21.742274]: Test set accuracy: 23.076923076923077% ,loss = 19.304916262626648
[2018-04-17 15:08:22.659713]: ====================
[2018-04-17 15:08:22.665228]: Elapsed time since starting training: 0:00:02.876661
[2018-04-17 15:08:22.671245]: ====================
[2018-04-17 15:08:22.697314]: [Epoch: 1(1.0101010101010102%): Data: 0.0%]:Running loss: 0.7721966505050659
[2018-04-17 15:08:23.051255]: [Epoch: 1(1.0101010101010102%): Data: 25.333333333333336%]:Running loss: 15.397061705589294
[2018-04-17 15:08:23.419734]: [Epoch: 1(1.0101010101010102%): Data: 50.66666666666667%]:Running loss: 29.934123873710632
[2018-04-17 15:08:24.422902]: Test set accuracy: 23.076923076923077% ,loss = 18.85768324136734
[2018-04-17 15:08:24.809429]: ====================
[2018-04-17 15:08:24.814443]: Elapsed time since starting training: 0:00:05.026377
[2018-04-17 15:08:24.819958]: ====================
[2018-04-17 15:08:24.844022]: [Epoch: 2(2.0202020202020203%): Data: 0.0%]:Running loss: 0.7543073296546936
[2018-04-17 15:08:25.209493]: [Epoch: 2(2.0202020202020203%): Data: 25.333333333333336%]:Running loss: 15.042976021766663
[2018-04-17 15:08:25.550901]: [Epoch: 2(2.0202020202020203%): Data: 50.66666666666667%]:Running loss: 29.25078296661377
[2018-04-17 15:08:26.543541]: Test set accuracy: 23.076923076923077% ,loss = 18.44584345817566
[2018-04-17 15:08:26.662858]: ====================
[2018-04-17 15:08:26.667871]: Elapsed time since starting training: 0:00:06.879805
[2018-04-17 15:08:26.673396]: ====================
[2018-04-17 15:08:26.696447]: [Epoch: 3(3.0303030303030303%): Data: 0.0%]:Running loss: 0.7378337383270264
[2018-04-17 15:08:27.036351]: [Epoch: 3(3.0303030303030303%): Data: 25.333333333333336%]:Running loss: 14.716931521892548
[2018-04-17 15:08:27.391795]: [Epoch: 3(3.0303030303030303%): Data: 50.66666666666667%]:Running loss: 28.621591866016388
[2018-04-17 15:08:28.386441]: Test set accuracy: 23.076923076923077% ,loss = 18.066750466823578
[2018-04-17 15:08:28.497235]: ====================
[2018-04-17 15:08:28.502249]: Elapsed time since starting training: 0:00:08.713686
[2018-04-17 15:08:28.507262]: ====================
[2018-04-17 15:08:28.531336]: [Epoch: 4(4.040404040404041%): Data: 0.0%]:Running loss: 0.7226700186729431
[2018-04-17 15:08:28.897800]: [Epoch: 4(4.040404040404041%): Data: 25.333333333333336%]:Running loss: 14.416824400424957
[2018-04-17 15:08:29.249736]: [Epoch: 4(4.040404040404041%): Data: 50.66666666666667%]:Running loss: 28.042473077774048
[2018-04-17 15:08:30.225330]: Test set accuracy: 23.076923076923077% ,loss = 17.717888951301575
[2018-04-17 15:08:30.341640]: ====================
[2018-04-17 15:08:30.346151]: Elapsed time since starting training: 0:00:10.558085
[2018-04-17 15:08:30.350663]: ====================
[2018-04-17 15:08:30.375229]: [Epoch: 5(5.05050505050505%): Data: 0.0%]:Running loss: 0.708715558052063
[2018-04-17 15:08:30.722176]: [Epoch: 5(5.05050505050505%): Data: 25.333333333333336%]:Running loss: 14.140657186508179
[2018-04-17 15:08:31.084640]: [Epoch: 5(5.05050505050505%): Data: 50.66666666666667%]:Running loss: 27.509566247463226
[2018-04-17 15:08:32.057226]: Test set accuracy: 23.076923076923077% ,loss = 17.3969104886055
[2018-04-17 15:08:32.168523]: ====================
[2018-04-17 15:08:32.173536]: Elapsed time since starting training: 0:00:12.385470
[2018-04-17 15:08:32.179051]: ====================
[2018-04-17 15:08:32.201610]: [Epoch: 6(6.0606060606060606%): Data: 0.0%]:Running loss: 0.69587641954422
[2018-04-17 15:08:32.546527]: [Epoch: 6(6.0606060606060606%): Data: 25.333333333333336%]:Running loss: 13.886562705039978
[2018-04-17 15:08:32.903978]: [Epoch: 6(6.0606060606060606%): Data: 50.66666666666667%]:Running loss: 27.019256353378296
[2018-04-17 15:08:33.891604]: Test set accuracy: 76.92307692307692% ,loss = 17.10159480571747
[2018-04-17 15:08:34.001396]: ====================
[2018-04-17 15:08:34.007913]: Elapsed time since starting training: 0:00:14.219346
[2018-04-17 15:08:34.012927]: ====================
[2018-04-17 15:08:34.037492]: [Epoch: 7(7.07070707070707%): Data: 0.0%]:Running loss: 0.6840637922286987
[2018-04-17 15:08:34.394440]: [Epoch: 7(7.07070707070707%): Data: 25.333333333333336%]:Running loss: 13.652786612510681
[2018-04-17 15:08:34.738857]: [Epoch: 7(7.07070707070707%): Data: 50.66666666666667%]:Running loss: 26.56815403699875
[2018-04-17 15:08:35.742526]: Test set accuracy: 76.92307692307692% ,loss = 16.829897463321686
[2018-04-17 15:08:35.853822]: ====================
[2018-04-17 15:08:35.859337]: Elapsed time since starting training: 0:00:16.070770
[2018-04-17 15:08:35.863848]: ====================
[2018-04-17 15:08:35.888414]: [Epoch: 8(8.080808080808081%): Data: 0.0%]:Running loss: 0.6731958985328674
[2018-04-17 15:08:36.252883]: [Epoch: 8(8.080808080808081%): Data: 25.333333333333336%]:Running loss: 13.437699615955353
[2018-04-17 15:08:36.588776]: [Epoch: 8(8.080808080808081%): Data: 50.66666666666667%]:Running loss: 26.153112173080444
[2018-04-17 15:08:37.559858]: Test set accuracy: 76.92307692307692% ,loss = 16.57988727092743
[2018-04-17 15:08:37.668648]: ====================
[2018-04-17 15:08:37.674162]: Elapsed time since starting training: 0:00:17.885595
[2018-04-17 15:08:37.679175]: ====================
[2018-04-17 15:08:37.704242]: [Epoch: 9(9.090909090909092%): Data: 0.0%]:Running loss: 0.6631954908370972
[2018-04-17 15:08:38.065201]: [Epoch: 9(9.090909090909092%): Data: 25.333333333333336%]:Running loss: 13.239786446094513
[2018-04-17 15:08:38.420146]: [Epoch: 9(9.090909090909092%): Data: 50.66666666666667%]:Running loss: 25.771201074123383
[2018-04-17 15:08:39.401279]: Test set accuracy: 76.92307692307692% ,loss = 16.349805891513824
[2018-04-17 15:08:39.497034]: ====================
[2018-04-17 15:08:39.502549]: Elapsed time since starting training: 0:00:19.713981
[2018-04-17 15:08:39.509066]: ====================
[2018-04-17 15:08:39.531626]: [Epoch: 10(10.1010101010101%): Data: 0.0%]:Running loss: 0.653992235660553
[2018-04-17 15:08:39.878047]: [Epoch: 10(10.1010101010101%): Data: 25.333333333333336%]:Running loss: 13.057645916938782
[2018-04-17 15:08:40.234996]: [Epoch: 10(10.1010101010101%): Data: 50.66666666666667%]:Running loss: 25.419713973999023
[2018-04-17 15:08:41.234153]: Test set accuracy: 76.92307692307692% ,loss = 16.138018667697906
[2018-04-17 15:08:41.339433]: ====================
[2018-04-17 15:08:41.344948]: Elapsed time since starting training: 0:00:21.556882
[2018-04-17 15:08:41.350964]: ====================
[2018-04-17 15:08:41.377534]: [Epoch: 11(11.11111111111111%): Data: 0.0%]:Running loss: 0.6455207467079163
[2018-04-17 15:08:41.741502]: [Epoch: 11(11.11111111111111%): Data: 25.333333333333336%]:Running loss: 12.889978885650635
[2018-04-17 15:08:42.096947]: [Epoch: 11(11.11111111111111%): Data: 50.66666666666667%]:Running loss: 25.096151173114777
[2018-04-17 15:08:43.076552]: Test set accuracy: 76.92307692307692% ,loss = 15.943020582199097
[2018-04-17 15:08:43.179325]: ====================
[2018-04-17 15:08:43.185843]: Elapsed time since starting training: 0:00:23.397275
[2018-04-17 15:08:43.191860]: ====================
[2018-04-17 15:08:43.216925]: [Epoch: 12(12.121212121212121%): Data: 0.0%]:Running loss: 0.6377208232879639
[2018-04-17 15:08:43.563848]: [Epoch: 12(12.121212121212121%): Data: 25.333333333333336%]:Running loss: 12.735593676567078
[2018-04-17 15:08:43.915784]: [Epoch: 12(12.121212121212121%): Data: 50.66666666666667%]:Running loss: 24.798207700252533
[2018-04-17 15:08:44.896892]: Test set accuracy: 76.92307692307692% ,loss = 15.763415396213531
[2018-04-17 15:08:45.014205]: ====================
[2018-04-17 15:08:45.020722]: Elapsed time since starting training: 0:00:25.232154
[2018-04-17 15:08:45.026737]: ====================
[2018-04-17 15:08:45.050300]: [Epoch: 13(13.131313131313133%): Data: 0.0%]:Running loss: 0.6305366158485413
[2018-04-17 15:08:45.407250]: [Epoch: 13(13.131313131313133%): Data: 25.333333333333336%]:Running loss: 12.593396067619324
[2018-04-17 15:08:45.768209]: [Epoch: 13(13.131313131313133%): Data: 50.66666666666667%]:Running loss: 24.52377140522003
[2018-04-17 15:08:46.761350]: Test set accuracy: 76.92307692307692% ,loss = 15.597942471504211
[2018-04-17 15:08:46.857104]: ====================
[2018-04-17 15:08:46.863121]: Elapsed time since starting training: 0:00:27.075055
[2018-04-17 15:08:46.869136]: ====================
[2018-04-17 15:08:46.892711]: [Epoch: 14(14.14141414141414%): Data: 0.0%]:Running loss: 0.6239176988601685
[2018-04-17 15:08:47.260678]: [Epoch: 14(14.14141414141414%): Data: 25.333333333333336%]:Running loss: 12.462373495101929
[2018-04-17 15:08:47.634681]: [Epoch: 14(14.14141414141414%): Data: 50.66666666666667%]:Running loss: 24.27089250087738
[2018-04-17 15:08:48.618799]: Test set accuracy: 76.92307692307692% ,loss = 15.445421636104584
[2018-04-17 15:08:48.730096]: ====================
[2018-04-17 15:08:48.736111]: Elapsed time since starting training: 0:00:28.947543
[2018-04-17 15:08:48.741625]: ====================
[2018-04-17 15:08:48.767694]: [Epoch: 15(15.151515151515152%): Data: 0.0%]:Running loss: 0.6178168654441833
[2018-04-17 15:08:49.127652]: [Epoch: 15(15.151515151515152%): Data: 25.333333333333336%]:Running loss: 12.341605961322784
[2018-04-17 15:08:49.481091]: [Epoch: 15(15.151515151515152%): Data: 50.66666666666667%]:Running loss: 24.03779250383377
[2018-04-17 15:08:50.493289]: Test set accuracy: 76.92307692307692% ,loss = 15.304788947105408
[2018-04-17 15:08:50.604083]: ====================
[2018-04-17 15:08:50.610601]: Elapsed time since starting training: 0:00:30.822033
[2018-04-17 15:08:50.615114]: ====================
[2018-04-17 15:08:50.638675]: [Epoch: 16(16.161616161616163%): Data: 0.0%]:Running loss: 0.6121915578842163
[2018-04-17 15:08:51.007656]: [Epoch: 16(16.161616161616163%): Data: 25.333333333333336%]:Running loss: 12.230239689350128
[2018-04-17 15:08:51.377138]: [Epoch: 16(16.161616161616163%): Data: 50.66666666666667%]:Running loss: 23.822830855846405
[2018-04-17 15:08:52.408380]: Test set accuracy: 76.92307692307692% ,loss = 15.175047516822815
[2018-04-17 15:08:52.530204]: ====================
[2018-04-17 15:08:52.535719]: Elapsed time since starting training: 0:00:32.747152
[2018-04-17 15:08:52.541734]: ====================
[2018-04-17 15:08:52.564796]: [Epoch: 17(17.17171717171717%): Data: 0.0%]:Running loss: 0.6070019006729126
[2018-04-17 15:08:52.936284]: [Epoch: 17(17.17171717171717%): Data: 25.333333333333336%]:Running loss: 12.127505481243134
[2018-04-17 15:08:53.316795]: [Epoch: 17(17.17171717171717%): Data: 50.66666666666667%]:Running loss: 23.624516189098358
[2018-04-17 15:08:54.328486]: Test set accuracy: 76.92307692307692% ,loss = 15.055328607559204
[2018-04-17 15:08:54.442790]: ====================
[2018-04-17 15:08:54.447803]: Elapsed time since starting training: 0:00:34.659737
[2018-04-17 15:08:54.453825]: ====================
[2018-04-17 15:08:54.478885]: [Epoch: 18(18.181818181818183%): Data: 0.0%]:Running loss: 0.6022131443023682
[2018-04-17 15:08:54.817787]: [Epoch: 18(18.181818181818183%): Data: 25.333333333333336%]:Running loss: 12.032687664031982
[2018-04-17 15:08:55.187269]: [Epoch: 18(18.181818181818183%): Data: 50.66666666666667%]:Running loss: 23.441474735736847
[2018-04-17 15:08:56.188943]: Test set accuracy: 76.92307692307692% ,loss = 14.944782853126526
[2018-04-17 15:08:56.302234]: ====================
[2018-04-17 15:08:56.307749]: Elapsed time since starting training: 0:00:36.519181
[2018-04-17 15:08:56.312261]: ====================
[2018-04-17 15:08:56.337828]: [Epoch: 19(19.19191919191919%): Data: 0.0%]:Running loss: 0.597791314125061
[2018-04-17 15:08:56.699290]: [Epoch: 19(19.19191919191919%): Data: 25.333333333333336%]:Running loss: 11.945140361785889
[2018-04-17 15:08:57.035183]: [Epoch: 19(19.19191919191919%): Data: 50.66666666666667%]:Running loss: 23.272458493709564
[2018-04-17 15:08:58.051886]: Test set accuracy: 76.92307692307692% ,loss = 14.84268307685852
[2018-04-17 15:08:58.161678]: ====================
[2018-04-17 15:08:58.166691]: Elapsed time since starting training: 0:00:38.378625
[2018-04-17 15:08:58.172207]: ====================
[2018-04-17 15:08:58.195769]: [Epoch: 20(20.2020202020202%): Data: 0.0%]:Running loss: 0.5937073230743408
[2018-04-17 15:08:58.557731]: [Epoch: 20(20.2020202020202%): Data: 25.333333333333336%]:Running loss: 11.86426717042923
[2018-04-17 15:08:58.915683]: [Epoch: 20(20.2020202020202%): Data: 50.66666666666667%]:Running loss: 23.116315960884094
[2018-04-17 15:08:59.909326]: Test set accuracy: 76.92307692307692% ,loss = 14.748312532901764
[2018-04-17 15:09:00.035660]: ====================
[2018-04-17 15:09:00.041183]: Elapsed time since starting training: 0:00:40.253117
[2018-04-17 15:09:00.046189]: ====================
[2018-04-17 15:09:00.071757]: [Epoch: 21(21.21212121212121%): Data: 0.0%]:Running loss: 0.5899325013160706
[2018-04-17 15:09:00.425698]: [Epoch: 21(21.21212121212121%): Data: 25.333333333333336%]:Running loss: 11.789521098136902
[2018-04-17 15:09:00.786657]: [Epoch: 21(21.21212121212121%): Data: 50.66666666666667%]:Running loss: 22.971998929977417
[2018-04-17 15:09:01.816396]: Test set accuracy: 76.92307692307692% ,loss = 14.661075174808502
[2018-04-17 15:09:01.918668]: ====================
[2018-04-17 15:09:01.924183]: Elapsed time since starting training: 0:00:42.136117
[2018-04-17 15:09:01.929196]: ====================
[2018-04-17 15:09:01.954263]: [Epoch: 22(22.22222222222222%): Data: 0.0%]:Running loss: 0.5864430069923401
[2018-04-17 15:09:02.337281]: [Epoch: 22(22.22222222222222%): Data: 25.333333333333336%]:Running loss: 11.720410823822021
[2018-04-17 15:09:02.701750]: [Epoch: 22(22.22222222222222%): Data: 50.66666666666667%]:Running loss: 22.83855402469635
[2018-04-17 15:09:03.705419]: Test set accuracy: 76.92307692307692% ,loss = 14.580373466014862
[2018-04-17 15:09:03.806187]: ====================
[2018-04-17 15:09:03.810699]: Elapsed time since starting training: 0:00:44.022633
[2018-04-17 15:09:03.816213]: ====================
[2018-04-17 15:09:03.841280]: [Epoch: 23(23.232323232323232%): Data: 0.0%]:Running loss: 0.5832149386405945
[2018-04-17 15:09:04.189211]: [Epoch: 23(23.232323232323232%): Data: 25.333333333333336%]:Running loss: 11.656481742858887
[2018-04-17 15:09:04.559189]: [Epoch: 23(23.232323232323232%): Data: 50.66666666666667%]:Running loss: 22.71510374546051
[2018-04-17 15:09:05.562874]: Test set accuracy: 76.92307692307692% ,loss = 14.505678415298462
[2018-04-17 15:09:05.662137]: ====================
[2018-04-17 15:09:05.667152]: Elapsed time since starting training: 0:00:45.879086
[2018-04-17 15:09:05.672164]: ====================
[2018-04-17 15:09:05.696228]: [Epoch: 24(24.242424242424242%): Data: 0.0%]:Running loss: 0.5802271366119385
[2018-04-17 15:09:06.051674]: [Epoch: 24(24.242424242424242%): Data: 25.333333333333336%]:Running loss: 11.597312033176422
[2018-04-17 15:09:06.415140]: [Epoch: 24(24.242424242424242%): Data: 50.66666666666667%]:Running loss: 22.60083770751953
[2018-04-17 15:09:07.433850]: Test set accuracy: 76.92307692307692% ,loss = 14.43653255701065
[2018-04-17 15:09:07.545646]: ====================
[2018-04-17 15:09:07.550158]: Elapsed time since starting training: 0:00:47.762092
[2018-04-17 15:09:07.556676]: ====================
[2018-04-17 15:09:07.580739]: [Epoch: 25(25.252525252525253%): Data: 0.0%]:Running loss: 0.577461302280426
[2018-04-17 15:09:07.963757]: [Epoch: 25(25.252525252525253%): Data: 25.333333333333336%]:Running loss: 11.54252803325653
[2018-04-17 15:09:08.322217]: [Epoch: 25(25.252525252525253%): Data: 50.66666666666667%]:Running loss: 22.49503469467163
[2018-04-17 15:09:09.322370]: Test set accuracy: 76.92307692307692% ,loss = 14.372482895851135
[2018-04-17 15:09:09.426146]: ====================
[2018-04-17 15:09:09.431160]: Elapsed time since starting training: 0:00:49.643094
[2018-04-17 15:09:09.436179]: ====================
[2018-04-17 15:09:09.461741]: [Epoch: 26(26.262626262626267%): Data: 0.0%]:Running loss: 0.5748993158340454
[2018-04-17 15:09:09.840247]: [Epoch: 26(26.262626262626267%): Data: 25.333333333333336%]:Running loss: 11.491776943206787
[2018-04-17 15:09:10.213239]: [Epoch: 26(26.262626262626267%): Data: 50.66666666666667%]:Running loss: 22.397015810012817
[2018-04-17 15:09:11.246486]: Test set accuracy: 76.92307692307692% ,loss = 14.313119649887085
[2018-04-17 15:09:11.346753]: ====================
[2018-04-17 15:09:11.351767]: Elapsed time since starting training: 0:00:51.563199
[2018-04-17 15:09:11.358284]: ====================
[2018-04-17 15:09:11.380844]: [Epoch: 27(27.27272727272727%): Data: 0.0%]:Running loss: 0.5725247859954834
[2018-04-17 15:09:11.743809]: [Epoch: 27(27.27272727272727%): Data: 25.333333333333336%]:Running loss: 11.444739639759064
[2018-04-17 15:09:12.131845]: [Epoch: 27(27.27272727272727%): Data: 50.66666666666667%]:Running loss: 22.306166112422943
[2018-04-17 15:09:13.129493]: Test set accuracy: 76.92307692307692% ,loss = 14.25808072090149
[2018-04-17 15:09:13.288416]: ====================
[2018-04-17 15:09:13.293429]: Elapsed time since starting training: 0:00:53.505363
[2018-04-17 15:09:13.298443]: ====================
[2018-04-17 15:09:13.323008]: [Epoch: 28(28.28282828282828%): Data: 0.0%]:Running loss: 0.5703232288360596
[2018-04-17 15:09:13.652885]: [Epoch: 28(28.28282828282828%): Data: 25.333333333333336%]:Running loss: 11.40112817287445
[2018-04-17 15:09:14.028885]: [Epoch: 28(28.28282828282828%): Data: 50.66666666666667%]:Running loss: 22.221927106380463
[2018-04-17 15:09:15.015518]: Test set accuracy: 76.92307692307692% ,loss = 14.207024872303009
[2018-04-17 15:09:15.122793]: ====================
[2018-04-17 15:09:15.128809]: Elapsed time since starting training: 0:00:55.340743
[2018-04-17 15:09:15.134825]: ====================
[2018-04-17 15:09:15.158889]: [Epoch: 29(29.292929292929294%): Data: 0.0%]:Running loss: 0.5682809948921204
[2018-04-17 15:09:15.529375]: [Epoch: 29(29.292929292929294%): Data: 25.333333333333336%]:Running loss: 11.36067271232605
[2018-04-17 15:09:15.857246]: [Epoch: 29(29.292929292929294%): Data: 50.66666666666667%]:Running loss: 22.14378249645233
[2018-04-17 15:09:16.855400]: Test set accuracy: 76.92307692307692% ,loss = 14.159658551216125
[2018-04-17 15:09:16.962686]: ====================
[2018-04-17 15:09:16.968702]: Elapsed time since starting training: 0:00:57.180134
[2018-04-17 15:09:16.974727]: ====================
[2018-04-17 15:09:17.005299]: [Epoch: 30(30.303030303030305%): Data: 0.0%]:Running loss: 0.566386342048645
[2018-04-17 15:09:17.374781]: [Epoch: 30(30.303030303030305%): Data: 25.333333333333336%]:Running loss: 11.32313185930252
[2018-04-17 15:09:17.737245]: [Epoch: 30(30.303030303030305%): Data: 50.66666666666667%]:Running loss: 22.07125961780548
[2018-04-17 15:09:18.722866]: Test set accuracy: 76.92307692307692% ,loss = 14.115683734416962
[2018-04-17 15:09:18.832156]: ====================
[2018-04-17 15:09:18.839175]: Elapsed time since starting training: 0:00:59.050608
[2018-04-17 15:09:18.845199]: ====================
[2018-04-17 15:09:18.868754]: [Epoch: 31(31.313131313131315%): Data: 0.0%]:Running loss: 0.5646273493766785
[2018-04-17 15:09:19.224700]: [Epoch: 31(31.313131313131315%): Data: 25.333333333333336%]:Running loss: 11.288275837898254
[2018-04-17 15:09:19.578654]: [Epoch: 31(31.313131313131315%): Data: 50.66666666666667%]:Running loss: 22.003921270370483
[2018-04-17 15:09:20.581750]: Test set accuracy: 76.92307692307692% ,loss = 14.074830710887909
[2018-04-17 15:09:20.689535]: ====================
[2018-04-17 15:09:20.695552]: Elapsed time since starting training: 0:01:00.907486
[2018-04-17 15:09:20.701568]: ====================
[2018-04-17 15:09:20.726634]: [Epoch: 32(32.323232323232325%): Data: 0.0%]:Running loss: 0.5629932284355164
[2018-04-17 15:09:21.085589]: [Epoch: 32(32.323232323232325%): Data: 25.333333333333336%]:Running loss: 11.255901634693146
[2018-04-17 15:09:21.443039]: [Epoch: 32(32.323232323232325%): Data: 50.66666666666667%]:Running loss: 21.941375255584717
[2018-04-17 15:09:22.421642]: Test set accuracy: 76.92307692307692% ,loss = 14.036880433559418
[2018-04-17 15:09:22.531935]: ====================
[2018-04-17 15:09:22.538954]: Elapsed time since starting training: 0:01:02.750388
[2018-04-17 15:09:22.544969]: ====================
[2018-04-17 15:09:22.570036]: [Epoch: 33(33.33333333333333%): Data: 0.0%]:Running loss: 0.5614752173423767
[2018-04-17 15:09:22.923476]: [Epoch: 33(33.33333333333333%): Data: 25.333333333333336%]:Running loss: 11.225820362567902
[2018-04-17 15:09:23.286441]: [Epoch: 33(33.33333333333333%): Data: 50.66666666666667%]:Running loss: 21.883255422115326
[2018-04-17 15:09:24.271601]: Test set accuracy: 76.92307692307692% ,loss = 14.001598954200745
[2018-04-17 15:09:24.378885]: ====================
[2018-04-17 15:09:24.385404]: Elapsed time since starting training: 0:01:04.596835
[2018-04-17 15:09:24.391920]: ====================
[2018-04-17 15:09:24.417989]: [Epoch: 34(34.34343434343434%): Data: 0.0%]:Running loss: 0.5600639581680298
[2018-04-17 15:09:24.793488]: [Epoch: 34(34.34343434343434%): Data: 25.333333333333336%]:Running loss: 11.197857737541199
[2018-04-17 15:09:25.157456]: [Epoch: 34(34.34343434343434%): Data: 50.66666666666667%]:Running loss: 21.829226672649384
[2018-04-17 15:09:26.174160]: Test set accuracy: 76.92307692307692% ,loss = 13.968804478645325
[2018-04-17 15:09:26.291471]: ====================
[2018-04-17 15:09:26.296985]: Elapsed time since starting training: 0:01:06.508919
[2018-04-17 15:09:26.301999]: ====================
[2018-04-17 15:09:26.325060]: [Epoch: 35(35.35353535353536%): Data: 0.0%]:Running loss: 0.558752179145813
[2018-04-17 15:09:26.666468]: [Epoch: 35(35.35353535353536%): Data: 25.333333333333336%]:Running loss: 11.171853840351105
[2018-04-17 15:09:27.033945]: [Epoch: 35(35.35353535353536%): Data: 50.66666666666667%]:Running loss: 21.77897870540619
[2018-04-17 15:09:28.023576]: Test set accuracy: 76.92307692307692% ,loss = 13.938282430171967
[2018-04-17 15:09:28.135875]: ====================
[2018-04-17 15:09:28.141389]: Elapsed time since starting training: 0:01:08.353323
[2018-04-17 15:09:28.147405]: ====================
[2018-04-17 15:09:28.173474]: [Epoch: 36(36.36363636363637%): Data: 0.0%]:Running loss: 0.5575312972068787
[2018-04-17 15:09:28.551480]: [Epoch: 36(36.36363636363637%): Data: 25.333333333333336%]:Running loss: 11.147661328315735
[2018-04-17 15:09:28.918005]: [Epoch: 36(36.36363636363637%): Data: 50.66666666666667%]:Running loss: 21.732232093811035
[2018-04-17 15:09:29.907135]: Test set accuracy: 76.92307692307692% ,loss = 13.909880816936493
[2018-04-17 15:09:30.026954]: ====================
[2018-04-17 15:09:30.032969]: Elapsed time since starting training: 0:01:10.244402
[2018-04-17 15:09:30.038484]: ====================
[2018-04-17 15:09:30.063551]: [Epoch: 37(37.37373737373738%): Data: 0.0%]:Running loss: 0.5563952326774597
[2018-04-17 15:09:30.409056]: [Epoch: 37(37.37373737373738%): Data: 25.333333333333336%]:Running loss: 11.125148832798004
[2018-04-17 15:09:30.769514]: [Epoch: 37(37.37373737373738%): Data: 50.66666666666667%]:Running loss: 21.688724637031555
[2018-04-17 15:09:31.759648]: Test set accuracy: 76.92307692307692% ,loss = 13.883453607559204
[2018-04-17 15:09:31.874955]: ====================
[2018-04-17 15:09:31.880971]: Elapsed time since starting training: 0:01:12.092403
[2018-04-17 15:09:31.886492]: ====================
[2018-04-17 15:09:31.911551]: [Epoch: 38(38.38383838383838%): Data: 0.0%]:Running loss: 0.5553381443023682
[2018-04-17 15:09:32.270506]: [Epoch: 38(38.38383838383838%): Data: 25.333333333333336%]:Running loss: 11.104188323020935
[2018-04-17 15:09:32.636980]: [Epoch: 38(38.38383838383838%): Data: 50.66666666666667%]:Running loss: 21.64822030067444
[2018-04-17 15:09:33.619593]: Test set accuracy: 76.92307692307692% ,loss = 13.85883241891861
[2018-04-17 15:09:33.733897]: ====================
[2018-04-17 15:09:33.739914]: Elapsed time since starting training: 0:01:13.951346
[2018-04-17 15:09:33.744926]: ====================
[2018-04-17 15:09:33.773503]: [Epoch: 39(39.39393939393939%): Data: 0.0%]:Running loss: 0.5543532967567444
[2018-04-17 15:09:34.125438]: [Epoch: 39(39.39393939393939%): Data: 25.333333333333336%]:Running loss: 11.08466899394989
[2018-04-17 15:09:34.476371]: [Epoch: 39(39.39393939393939%): Data: 50.66666666666667%]:Running loss: 21.610493063926697
[2018-04-17 15:09:35.462995]: Test set accuracy: 76.92307692307692% ,loss = 13.835886120796204
[2018-04-17 15:09:35.579806]: ====================
[2018-04-17 15:09:35.584819]: Elapsed time since starting training: 0:01:15.796753
[2018-04-17 15:09:35.590834]: ====================
[2018-04-17 15:09:35.615400]: [Epoch: 40(40.4040404040404%): Data: 0.0%]:Running loss: 0.5534354448318481
[2018-04-17 15:09:35.971848]: [Epoch: 40(40.4040404040404%): Data: 25.333333333333336%]:Running loss: 11.066483795642853
[2018-04-17 15:09:36.333318]: [Epoch: 40(40.4040404040404%): Data: 50.66666666666667%]:Running loss: 21.57534748315811
[2018-04-17 15:09:37.331964]: Test set accuracy: 76.92307692307692% ,loss = 13.814517855644226
[2018-04-17 15:09:37.449778]: ====================
[2018-04-17 15:09:37.457297]: Elapsed time since starting training: 0:01:17.669231
[2018-04-17 15:09:37.462823]: ====================
[2018-04-17 15:09:37.485874]: [Epoch: 41(41.41414141414141%): Data: 0.0%]:Running loss: 0.552580714225769
[2018-04-17 15:09:37.824274]: [Epoch: 41(41.41414141414141%): Data: 25.333333333333336%]:Running loss: 11.049533009529114
[2018-04-17 15:09:38.181724]: [Epoch: 41(41.41414141414141%): Data: 50.66666666666667%]:Running loss: 21.542585909366608
[2018-04-17 15:09:39.137766]: Test set accuracy: 76.92307692307692% ,loss = 13.794590532779694
[2018-04-17 15:09:39.239537]: ====================
[2018-04-17 15:09:39.245552]: Elapsed time since starting training: 0:01:19.456985
[2018-04-17 15:09:39.250566]: ====================
[2018-04-17 15:09:39.276635]: [Epoch: 42(42.42424242424242%): Data: 0.0%]:Running loss: 0.5517836213111877
[2018-04-17 15:09:39.644112]: [Epoch: 42(42.42424242424242%): Data: 25.333333333333336%]:Running loss: 11.033732533454895
[2018-04-17 15:09:40.011088]: [Epoch: 42(42.42424242424242%): Data: 50.66666666666667%]:Running loss: 21.512045443058014
[2018-04-17 15:09:40.989189]: Test set accuracy: 76.92307692307692% ,loss = 13.776005804538727
[2018-04-17 15:09:41.096474]: ====================
[2018-04-17 15:09:41.102490]: Elapsed time since starting training: 0:01:21.314424
[2018-04-17 15:09:41.109509]: ====================
[2018-04-17 15:09:41.132570]: [Epoch: 43(43.43434343434344%): Data: 0.0%]:Running loss: 0.5510402321815491
[2018-04-17 15:09:41.484004]: [Epoch: 43(43.43434343434344%): Data: 25.333333333333336%]:Running loss: 11.018997192382812
[2018-04-17 15:09:41.813882]: [Epoch: 43(43.43434343434344%): Data: 50.66666666666667%]:Running loss: 21.483561754226685
[2018-04-17 15:09:42.793997]: Test set accuracy: 76.92307692307692% ,loss = 13.758677244186401
[2018-04-17 15:09:42.890745]: ====================
[2018-04-17 15:09:42.896762]: Elapsed time since starting training: 0:01:23.108194
[2018-04-17 15:09:42.901775]: ====================
[2018-04-17 15:09:42.927342]: [Epoch: 44(44.44444444444444%): Data: 0.0%]:Running loss: 0.550347089767456
[2018-04-17 15:09:43.293821]: [Epoch: 44(44.44444444444444%): Data: 25.333333333333336%]:Running loss: 11.005253791809082
[2018-04-17 15:09:43.656786]: [Epoch: 44(44.44444444444444%): Data: 50.66666666666667%]:Running loss: 21.456993520259857
[2018-04-17 15:09:44.616839]: Test set accuracy: 76.92307692307692% ,loss = 13.742491602897644
[2018-04-17 15:09:44.720615]: ====================
[2018-04-17 15:09:44.727132]: Elapsed time since starting training: 0:01:24.939066
[2018-04-17 15:09:44.732647]: ====================
[2018-04-17 15:09:44.757212]: [Epoch: 45(45.45454545454545%): Data: 0.0%]:Running loss: 0.5496996641159058
[2018-04-17 15:09:45.124188]: [Epoch: 45(45.45454545454545%): Data: 25.333333333333336%]:Running loss: 10.992424666881561
[2018-04-17 15:09:45.486150]: [Epoch: 45(45.45454545454545%): Data: 50.66666666666667%]:Running loss: 21.43219530582428
[2018-04-17 15:09:46.458235]: Test set accuracy: 76.92307692307692% ,loss = 13.727393746376038
[2018-04-17 15:09:46.560507]: ====================
[2018-04-17 15:09:46.566523]: Elapsed time since starting training: 0:01:26.778457
[2018-04-17 15:09:46.572038]: ====================
[2018-04-17 15:09:46.594597]: [Epoch: 46(46.464646464646464%): Data: 0.0%]:Running loss: 0.5490957498550415
[2018-04-17 15:09:46.940016]: [Epoch: 46(46.464646464646464%): Data: 25.333333333333336%]:Running loss: 10.98045164346695
[2018-04-17 15:09:47.295461]: [Epoch: 46(46.464646464646464%): Data: 50.66666666666667%]:Running loss: 21.409047484397888
[2018-04-17 15:09:48.288100]: Test set accuracy: 76.92307692307692% ,loss = 13.713300228118896
[2018-04-17 15:09:48.386370]: ====================
[2018-04-17 15:09:48.392380]: Elapsed time since starting training: 0:01:28.603810
[2018-04-17 15:09:48.397893]: ====================
[2018-04-17 15:09:48.422458]: [Epoch: 47(47.474747474747474%): Data: 0.0%]:Running loss: 0.5485320091247559
[2018-04-17 15:09:48.787942]: [Epoch: 47(47.474747474747474%): Data: 25.333333333333336%]:Running loss: 10.96927124261856
[2018-04-17 15:09:49.153401]: [Epoch: 47(47.474747474747474%): Data: 50.66666666666667%]:Running loss: 21.387434124946594
[2018-04-17 15:09:50.120974]: Test set accuracy: 76.92307692307692% ,loss = 13.70013952255249
[2018-04-17 15:09:50.219738]: ====================
[2018-04-17 15:09:50.226254]: Elapsed time since starting training: 0:01:30.438188
[2018-04-17 15:09:50.231267]: ====================
[2018-04-17 15:09:50.254328]: [Epoch: 48(48.484848484848484%): Data: 0.0%]:Running loss: 0.5480055809020996
[2018-04-17 15:09:50.608270]: [Epoch: 48(48.484848484848484%): Data: 25.333333333333336%]:Running loss: 10.958829581737518
[2018-04-17 15:09:50.962713]: [Epoch: 48(48.484848484848484%): Data: 50.66666666666667%]:Running loss: 21.367247939109802
[2018-04-17 15:09:51.965880]: Test set accuracy: 76.92307692307692% ,loss = 13.687840104103088
[2018-04-17 15:09:52.076181]: ====================
[2018-04-17 15:09:52.081688]: Elapsed time since starting training: 0:01:32.293622
[2018-04-17 15:09:52.088205]: ====================
[2018-04-17 15:09:52.113272]: [Epoch: 49(49.494949494949495%): Data: 0.0%]:Running loss: 0.5475136041641235
[2018-04-17 15:09:52.474767]: [Epoch: 49(49.494949494949495%): Data: 25.333333333333336%]:Running loss: 10.949076473712921
[2018-04-17 15:09:52.837732]: [Epoch: 49(49.494949494949495%): Data: 50.66666666666667%]:Running loss: 21.348390460014343
[2018-04-17 15:09:53.817838]: Test set accuracy: 76.92307692307692% ,loss = 13.676352798938751
[2018-04-17 15:09:53.924622]: ====================
[2018-04-17 15:09:53.931641]: Elapsed time since starting training: 0:01:34.143073
[2018-04-17 15:09:53.937155]: ====================
[2018-04-17 15:09:53.958211]: [Epoch: 50(50.505050505050505%): Data: 0.0%]:Running loss: 0.54705411195755
[2018-04-17 15:09:54.302627]: [Epoch: 50(50.505050505050505%): Data: 25.333333333333336%]:Running loss: 10.939961671829224
[2018-04-17 15:09:54.663587]: [Epoch: 50(50.505050505050505%): Data: 50.66666666666667%]:Running loss: 21.33076786994934
[2018-04-17 15:09:55.643702]: Test set accuracy: 76.92307692307692% ,loss = 13.665615022182465
[2018-04-17 15:09:55.750485]: ====================
[2018-04-17 15:09:55.756501]: Elapsed time since starting training: 0:01:35.968435
[2018-04-17 15:09:55.762016]: ====================
[2018-04-17 15:09:55.786581]: [Epoch: 51(51.515151515151516%): Data: 0.0%]:Running loss: 0.5466246008872986
[2018-04-17 15:09:56.157568]: [Epoch: 51(51.515151515151516%): Data: 25.333333333333336%]:Running loss: 10.931442141532898
[2018-04-17 15:09:56.508500]: [Epoch: 51(51.515151515151516%): Data: 50.66666666666667%]:Running loss: 21.314295411109924
[2018-04-17 15:09:57.499136]: Test set accuracy: 76.92307692307692% ,loss = 13.655559718608856
[2018-04-17 15:09:57.600906]: ====================
[2018-04-17 15:09:57.606922]: Elapsed time since starting training: 0:01:37.818355
[2018-04-17 15:09:57.612438]: ====================
[2018-04-17 15:09:57.637002]: [Epoch: 52(52.52525252525253%): Data: 0.0%]:Running loss: 0.5462223887443542
[2018-04-17 15:09:58.005492]: [Epoch: 52(52.52525252525253%): Data: 25.333333333333336%]:Running loss: 10.923475921154022
[2018-04-17 15:09:58.360926]: [Epoch: 52(52.52525252525253%): Data: 50.66666666666667%]:Running loss: 21.298892617225647
[2018-04-17 15:09:59.350057]: Test set accuracy: 76.92307692307692% ,loss = 13.64617794752121
[2018-04-17 15:09:59.460349]: ====================
[2018-04-17 15:09:59.465864]: Elapsed time since starting training: 0:01:39.677297
[2018-04-17 15:09:59.470877]: ====================
[2018-04-17 15:09:59.495443]: [Epoch: 53(53.535353535353536%): Data: 0.0%]:Running loss: 0.5458471179008484
[2018-04-17 15:09:59.856904]: [Epoch: 53(53.535353535353536%): Data: 25.333333333333336%]:Running loss: 10.916027665138245
[2018-04-17 15:10:00.188285]: [Epoch: 53(53.535353535353536%): Data: 50.66666666666667%]:Running loss: 21.284490883350372
[2018-04-17 15:10:01.208498]: Test set accuracy: 76.92307692307692% ,loss = 13.637396693229675
[2018-04-17 15:10:01.306773]: ====================
[2018-04-17 15:10:01.312274]: Elapsed time since starting training: 0:01:41.524208
[2018-04-17 15:10:01.317796]: ====================
[2018-04-17 15:10:01.341852]: [Epoch: 54(54.54545454545454%): Data: 0.0%]:Running loss: 0.545495867729187
[2018-04-17 15:10:01.708327]: [Epoch: 54(54.54545454545454%): Data: 25.333333333333336%]:Running loss: 10.909060895442963
[2018-04-17 15:10:02.079815]: [Epoch: 54(54.54545454545454%): Data: 50.66666666666667%]:Running loss: 21.271019339561462
[2018-04-17 15:10:03.066444]: Test set accuracy: 76.92307692307692% ,loss = 13.62917572259903
[2018-04-17 15:10:03.170716]: ====================
[2018-04-17 15:10:03.176732]: Elapsed time since starting training: 0:01:43.388666
[2018-04-17 15:10:03.182246]: ====================
[2018-04-17 15:10:03.206310]: [Epoch: 55(55.55555555555556%): Data: 0.0%]:Running loss: 0.5451670289039612
[2018-04-17 15:10:03.553757]: [Epoch: 55(55.55555555555556%): Data: 25.333333333333336%]:Running loss: 10.902542173862457
[2018-04-17 15:10:03.923239]: [Epoch: 55(55.55555555555556%): Data: 50.66666666666667%]:Running loss: 21.258412659168243
[2018-04-17 15:10:04.948967]: Test set accuracy: 76.92307692307692% ,loss = 13.621488213539124
[2018-04-17 15:10:05.056252]: ====================
[2018-04-17 15:10:05.061767]: Elapsed time since starting training: 0:01:45.273701
[2018-04-17 15:10:05.067282]: ====================
[2018-04-17 15:10:05.092348]: [Epoch: 56(56.56565656565656%): Data: 0.0%]:Running loss: 0.5448595285415649
[2018-04-17 15:10:05.463835]: [Epoch: 56(56.56565656565656%): Data: 25.333333333333336%]:Running loss: 10.896443784236908
[2018-04-17 15:10:05.821788]: [Epoch: 56(56.56565656565656%): Data: 50.66666666666667%]:Running loss: 21.246618270874023
[2018-04-17 15:10:06.814427]: Test set accuracy: 76.92307692307692% ,loss = 13.614292442798615
[2018-04-17 15:10:06.916199]: ====================
[2018-04-17 15:10:06.921712]: Elapsed time since starting training: 0:01:47.133145
[2018-04-17 15:10:06.931739]: ====================
[2018-04-17 15:10:06.953804]: [Epoch: 57(57.57575757575758%): Data: 0.0%]:Running loss: 0.5445716977119446
[2018-04-17 15:10:07.321275]: [Epoch: 57(57.57575757575758%): Data: 25.333333333333336%]:Running loss: 10.89073133468628
[2018-04-17 15:10:07.686246]: [Epoch: 57(57.57575757575758%): Data: 50.66666666666667%]:Running loss: 21.23557549715042
[2018-04-17 15:10:08.656325]: Test set accuracy: 76.92307692307692% ,loss = 13.607561588287354
[2018-04-17 15:10:08.761103]: ====================
[2018-04-17 15:10:08.767120]: Elapsed time since starting training: 0:01:48.978552
[2018-04-17 15:10:08.772634]: ====================
[2018-04-17 15:10:08.797199]: [Epoch: 58(58.58585858585859%): Data: 0.0%]:Running loss: 0.5443024635314941
[2018-04-17 15:10:09.148576]: [Epoch: 58(58.58585858585859%): Data: 25.333333333333336%]:Running loss: 10.88538783788681
[2018-04-17 15:10:09.494486]: [Epoch: 58(58.58585858585859%): Data: 50.66666666666667%]:Running loss: 21.22523957490921
[2018-04-17 15:10:10.487633]: Test set accuracy: 76.92307692307692% ,loss = 13.601252436637878
[2018-04-17 15:10:10.663094]: ====================
[2018-04-17 15:10:10.669110]: Elapsed time since starting training: 0:01:50.881044
[2018-04-17 15:10:10.675129]: ====================
[2018-04-17 15:10:10.701707]: [Epoch: 59(59.59595959595959%): Data: 0.0%]:Running loss: 0.5440500974655151
[2018-04-17 15:10:11.068672]: [Epoch: 59(59.59595959595959%): Data: 25.333333333333336%]:Running loss: 10.880383372306824
[2018-04-17 15:10:11.424117]: [Epoch: 59(59.59595959595959%): Data: 50.66666666666667%]:Running loss: 21.215559363365173
[2018-04-17 15:10:12.417258]: Test set accuracy: 76.92307692307692% ,loss = 13.595336675643921
[2018-04-17 15:10:12.540587]: ====================
[2018-04-17 15:10:12.546602]: Elapsed time since starting training: 0:01:52.758536
[2018-04-17 15:10:12.551615]: ====================
[2018-04-17 15:10:12.575679]: [Epoch: 60(60.60606060606061%): Data: 0.0%]:Running loss: 0.5438134670257568
[2018-04-17 15:10:12.938143]: [Epoch: 60(60.60606060606061%): Data: 25.333333333333336%]:Running loss: 10.875697016716003
[2018-04-17 15:10:13.312639]: [Epoch: 60(60.60606060606061%): Data: 50.66666666666667%]:Running loss: 21.206495761871338
[2018-04-17 15:10:14.296255]: Test set accuracy: 76.92307692307692% ,loss = 13.589802384376526
[2018-04-17 15:10:14.403539]: ====================
[2018-04-17 15:10:14.409556]: Elapsed time since starting training: 0:01:54.621490
[2018-04-17 15:10:14.415071]: ====================
[2018-04-17 15:10:14.438633]: [Epoch: 61(61.61616161616161%): Data: 0.0%]:Running loss: 0.543592095375061
[2018-04-17 15:10:14.785054]: [Epoch: 61(61.61616161616161%): Data: 25.333333333333336%]:Running loss: 10.871304094791412
[2018-04-17 15:10:15.154035]: [Epoch: 61(61.61616161616161%): Data: 50.66666666666667%]:Running loss: 21.19800466299057
[2018-04-17 15:10:16.152690]: Test set accuracy: 76.92307692307692% ,loss = 13.584622740745544
[2018-04-17 15:10:16.264990]: ====================
[2018-04-17 15:10:16.271005]: Elapsed time since starting training: 0:01:56.482939
[2018-04-17 15:10:16.277523]: ====================
[2018-04-17 15:10:16.303090]: [Epoch: 62(62.62626262626263%): Data: 0.0%]:Running loss: 0.5433849096298218
[2018-04-17 15:10:16.673074]: [Epoch: 62(62.62626262626263%): Data: 25.333333333333336%]:Running loss: 10.867189645767212
[2018-04-17 15:10:17.005458]: [Epoch: 62(62.62626262626263%): Data: 50.66666666666667%]:Running loss: 21.19004487991333
[2018-04-17 15:10:17.999100]: Test set accuracy: 76.92307692307692% ,loss = 13.579761981964111
[2018-04-17 15:10:18.103879]: ====================
[2018-04-17 15:10:18.109895]: Elapsed time since starting training: 0:01:58.321829
[2018-04-17 15:10:18.114909]: ====================
[2018-04-17 15:10:18.139975]: [Epoch: 63(63.63636363636363%): Data: 0.0%]:Running loss: 0.5431904792785645
[2018-04-17 15:10:18.508455]: [Epoch: 63(63.63636363636363%): Data: 25.333333333333336%]:Running loss: 10.863336443901062
[2018-04-17 15:10:18.872433]: [Epoch: 63(63.63636363636363%): Data: 50.66666666666667%]:Running loss: 21.182590663433075
[2018-04-17 15:10:19.873446]: Test set accuracy: 76.92307692307692% ,loss = 13.575197756290436
[2018-04-17 15:10:19.996273]: ====================
[2018-04-17 15:10:20.001285]: Elapsed time since starting training: 0:02:00.213219
[2018-04-17 15:10:20.006801]: ====================
[2018-04-17 15:10:20.032870]: [Epoch: 64(64.64646464646465%): Data: 0.0%]:Running loss: 0.5430079102516174
[2018-04-17 15:10:20.387312]: [Epoch: 64(64.64646464646465%): Data: 25.333333333333336%]:Running loss: 10.859722435474396
[2018-04-17 15:10:20.734736]: [Epoch: 64(64.64646464646465%): Data: 50.66666666666667%]:Running loss: 21.175601601600647
[2018-04-17 15:10:21.740913]: Test set accuracy: 76.92307692307692% ,loss = 13.570944964885712
[2018-04-17 15:10:21.854714]: ====================
[2018-04-17 15:10:21.862235]: Elapsed time since starting training: 0:02:02.074169
[2018-04-17 15:10:21.867749]: ====================
[2018-04-17 15:10:21.892816]: [Epoch: 65(65.65656565656566%): Data: 0.0%]:Running loss: 0.5428377985954285
[2018-04-17 15:10:22.266823]: [Epoch: 65(65.65656565656566%): Data: 25.333333333333336%]:Running loss: 10.856335639953613
[2018-04-17 15:10:22.633284]: [Epoch: 65(65.65656565656566%): Data: 50.66666666666667%]:Running loss: 21.169051110744476
[2018-04-17 15:10:23.634446]: Test set accuracy: 76.92307692307692% ,loss = 13.566938042640686
[2018-04-17 15:10:23.740228]: ====================
[2018-04-17 15:10:23.746244]: Elapsed time since starting training: 0:02:03.957677
[2018-04-17 15:10:23.752260]: ====================
[2018-04-17 15:10:23.777327]: [Epoch: 66(66.66666666666666%): Data: 0.0%]:Running loss: 0.5426775217056274
[2018-04-17 15:10:24.123246]: [Epoch: 66(66.66666666666666%): Data: 25.333333333333336%]:Running loss: 10.853159844875336
[2018-04-17 15:10:24.464654]: [Epoch: 66(66.66666666666666%): Data: 50.66666666666667%]:Running loss: 21.162908673286438
[2018-04-17 15:10:25.489379]: Test set accuracy: 76.92307692307692% ,loss = 13.563182950019836
[2018-04-17 15:10:25.611704]: ====================
[2018-04-17 15:10:25.617720]: Elapsed time since starting training: 0:02:05.829153
[2018-04-17 15:10:25.623235]: ====================
[2018-04-17 15:10:25.648301]: [Epoch: 67(67.67676767676768%): Data: 0.0%]:Running loss: 0.5425273180007935
[2018-04-17 15:10:26.016280]: [Epoch: 67(67.67676767676768%): Data: 25.333333333333336%]:Running loss: 10.850181996822357
[2018-04-17 15:10:26.360198]: [Epoch: 67(67.67676767676768%): Data: 50.66666666666667%]:Running loss: 21.157149732112885
[2018-04-17 15:10:27.352834]: Test set accuracy: 76.92307692307692% ,loss = 13.559658825397491
[2018-04-17 15:10:27.458615]: ====================
[2018-04-17 15:10:27.464130]: Elapsed time since starting training: 0:02:07.676064
[2018-04-17 15:10:27.469645]: ====================
[2018-04-17 15:10:27.492706]: [Epoch: 68(68.68686868686868%): Data: 0.0%]:Running loss: 0.5423863530158997
[2018-04-17 15:10:27.855169]: [Epoch: 68(68.68686868686868%): Data: 25.333333333333336%]:Running loss: 10.847389101982117
[2018-04-17 15:10:28.225154]: [Epoch: 68(68.68686868686868%): Data: 50.66666666666667%]:Running loss: 21.151745438575745
[2018-04-17 15:10:29.193227]: Test set accuracy: 76.92307692307692% ,loss = 13.55636864900589
[2018-04-17 15:10:29.310539]: ====================
[2018-04-17 15:10:29.316054]: Elapsed time since starting training: 0:02:09.527988
[2018-04-17 15:10:29.322070]: ====================
[2018-04-17 15:10:29.344630]: [Epoch: 69(69.6969696969697%): Data: 0.0%]:Running loss: 0.5422547459602356
[2018-04-17 15:10:29.694560]: [Epoch: 69(69.6969696969697%): Data: 25.333333333333336%]:Running loss: 10.844769716262817
[2018-04-17 15:10:30.059531]: [Epoch: 69(69.6969696969697%): Data: 50.66666666666667%]:Running loss: 21.146680653095245
[2018-04-17 15:10:31.047157]: Test set accuracy: 76.92307692307692% ,loss = 13.553258776664734
[2018-04-17 15:10:31.163968]: ====================
[2018-04-17 15:10:31.169984]: Elapsed time since starting training: 0:02:11.381416
[2018-04-17 15:10:31.175999]: ====================
[2018-04-17 15:10:31.198058]: [Epoch: 70(70.70707070707071%): Data: 0.0%]:Running loss: 0.5421303510665894
[2018-04-17 15:10:31.561524]: [Epoch: 70(70.70707070707071%): Data: 25.333333333333336%]:Running loss: 10.842313826084137
[2018-04-17 15:10:31.894911]: [Epoch: 70(70.70707070707071%): Data: 50.66666666666667%]:Running loss: 21.14192843437195
[2018-04-17 15:10:32.902591]: Test set accuracy: 76.92307692307692% ,loss = 13.550370931625366
[2018-04-17 15:10:33.015391]: ====================
[2018-04-17 15:10:33.020905]: Elapsed time since starting training: 0:02:13.232839
[2018-04-17 15:10:33.027423]: ====================
[2018-04-17 15:10:33.051487]: [Epoch: 71(71.71717171717171%): Data: 0.0%]:Running loss: 0.5420148372650146
[2018-04-17 15:10:33.415956]: [Epoch: 71(71.71717171717171%): Data: 25.333333333333336%]:Running loss: 10.840008318424225
[2018-04-17 15:10:33.773407]: [Epoch: 71(71.71717171717171%): Data: 50.66666666666667%]:Running loss: 21.1374688744545
[2018-04-17 15:10:34.763539]: Test set accuracy: 76.92307692307692% ,loss = 13.547644019126892
[2018-04-17 15:10:34.874333]: ====================
[2018-04-17 15:10:34.879848]: Elapsed time since starting training: 0:02:15.091782
[2018-04-17 15:10:34.885363]: ====================
[2018-04-17 15:10:34.906920]: [Epoch: 72(72.72727272727273%): Data: 0.0%]:Running loss: 0.5419057607650757
[2018-04-17 15:10:35.270387]: [Epoch: 72(72.72727272727273%): Data: 25.333333333333336%]:Running loss: 10.837847232818604
[2018-04-17 15:10:35.627837]: [Epoch: 72(72.72727272727273%): Data: 50.66666666666667%]:Running loss: 21.13328605890274
[2018-04-17 15:10:36.611057]: Test set accuracy: 76.92307692307692% ,loss = 13.54508101940155
[2018-04-17 15:10:36.723858]: ====================
[2018-04-17 15:10:36.729886]: Elapsed time since starting training: 0:02:16.941820
[2018-04-17 15:10:36.735387]: ====================
[2018-04-17 15:10:36.758950]: [Epoch: 73(73.73737373737373%): Data: 0.0%]:Running loss: 0.541803240776062
[2018-04-17 15:10:37.130939]: [Epoch: 73(73.73737373737373%): Data: 25.333333333333336%]:Running loss: 10.835813820362091
[2018-04-17 15:10:37.485393]: [Epoch: 73(73.73737373737373%): Data: 50.66666666666667%]:Running loss: 21.129356622695923
[2018-04-17 15:10:38.517137]: Test set accuracy: 76.92307692307692% ,loss = 13.542678952217102
[2018-04-17 15:10:38.626929]: ====================
[2018-04-17 15:10:38.632444]: Elapsed time since starting training: 0:02:18.844378
[2018-04-17 15:10:38.637968]: ====================
[2018-04-17 15:10:38.659015]: [Epoch: 74(74.74747474747475%): Data: 0.0%]:Running loss: 0.5417071580886841
[2018-04-17 15:10:39.017467]: [Epoch: 74(74.74747474747475%): Data: 25.333333333333336%]:Running loss: 10.83390748500824
[2018-04-17 15:10:39.373915]: [Epoch: 74(74.74747474747475%): Data: 50.66666666666667%]:Running loss: 21.125667989253998
[2018-04-17 15:10:40.381094]: Test set accuracy: 76.92307692307692% ,loss = 13.540434837341309
[2018-04-17 15:10:40.509937]: ====================
[2018-04-17 15:10:40.514949]: Elapsed time since starting training: 0:02:20.726883
[2018-04-17 15:10:40.521468]: ====================
[2018-04-17 15:10:40.548037]: [Epoch: 75(75.75757575757575%): Data: 0.0%]:Running loss: 0.5416173934936523
[2018-04-17 15:10:40.920030]: [Epoch: 75(75.75757575757575%): Data: 25.333333333333336%]:Running loss: 10.83212012052536
[2018-04-17 15:10:41.280990]: [Epoch: 75(75.75757575757575%): Data: 50.66666666666667%]:Running loss: 21.122209548950195
[2018-04-17 15:10:42.269118]: Test set accuracy: 76.92307692307692% ,loss = 13.538312911987305
[2018-04-17 15:10:42.412499]: ====================
[2018-04-17 15:10:42.418013]: Elapsed time since starting training: 0:02:22.629947
[2018-04-17 15:10:42.423528]: ====================
[2018-04-17 15:10:42.447592]: [Epoch: 76(76.76767676767676%): Data: 0.0%]:Running loss: 0.5415325164794922
[2018-04-17 15:10:42.800030]: [Epoch: 76(76.76767676767676%): Data: 25.333333333333336%]:Running loss: 10.83043658733368
[2018-04-17 15:10:43.168008]: [Epoch: 76(76.76767676767676%): Data: 50.66666666666667%]:Running loss: 21.11895775794983
[2018-04-17 15:10:44.148616]: Test set accuracy: 76.92307692307692% ,loss = 13.536328077316284
[2018-04-17 15:10:44.265927]: ====================
[2018-04-17 15:10:44.270940]: Elapsed time since starting training: 0:02:24.482874
[2018-04-17 15:10:44.276956]: ====================
[2018-04-17 15:10:44.301020]: [Epoch: 77(77.77777777777779%): Data: 0.0%]:Running loss: 0.5414531230926514
[2018-04-17 15:10:44.642429]: [Epoch: 77(77.77777777777779%): Data: 25.333333333333336%]:Running loss: 10.828863441944122
[2018-04-17 15:10:45.011919]: [Epoch: 77(77.77777777777779%): Data: 50.66666666666667%]:Running loss: 21.115910351276398
[2018-04-17 15:10:46.022598]: Test set accuracy: 76.92307692307692% ,loss = 13.534456491470337
[2018-04-17 15:10:46.140411]: ====================
[2018-04-17 15:10:46.146930]: Elapsed time since starting training: 0:02:26.358864
[2018-04-17 15:10:46.152444]: ====================
[2018-04-17 15:10:46.175004]: [Epoch: 78(78.78787878787878%): Data: 0.0%]:Running loss: 0.5413782596588135
[2018-04-17 15:10:46.512902]: [Epoch: 78(78.78787878787878%): Data: 25.333333333333336%]:Running loss: 10.827383279800415
[2018-04-17 15:10:46.878374]: [Epoch: 78(78.78787878787878%): Data: 50.66666666666667%]:Running loss: 21.11304545402527
[2018-04-17 15:10:47.868021]: Test set accuracy: 76.92307692307692% ,loss = 13.532698154449463
[2018-04-17 15:10:47.985834]: ====================
[2018-04-17 15:10:47.992353]: Elapsed time since starting training: 0:02:28.204287
[2018-04-17 15:10:47.997866]: ====================
[2018-04-17 15:10:48.021429]: [Epoch: 79(79.7979797979798%): Data: 0.0%]:Running loss: 0.5413079261779785
[2018-04-17 15:10:48.384895]: [Epoch: 79(79.7979797979798%): Data: 25.333333333333336%]:Running loss: 10.82599264383316
[2018-04-17 15:10:48.730314]: [Epoch: 79(79.7979797979798%): Data: 50.66666666666667%]:Running loss: 21.11035466194153
[2018-04-17 15:10:49.711924]: Test set accuracy: 76.92307692307692% ,loss = 13.531063497066498
[2018-04-17 15:10:49.829236]: ====================
[2018-04-17 15:10:49.834751]: Elapsed time since starting training: 0:02:30.046183
[2018-04-17 15:10:49.840265]: ====================
[2018-04-17 15:10:49.864329]: [Epoch: 80(80.8080808080808%): Data: 0.0%]:Running loss: 0.5412425398826599
[2018-04-17 15:10:50.224286]: [Epoch: 80(80.8080808080808%): Data: 25.333333333333336%]:Running loss: 10.824685335159302
[2018-04-17 15:10:50.587252]: [Epoch: 80(80.8080808080808%): Data: 50.66666666666667%]:Running loss: 21.107826948165894
[2018-04-17 15:10:51.569363]: Test set accuracy: 76.92307692307692% ,loss = 13.529513776302338
[2018-04-17 15:10:51.683165]: ====================
[2018-04-17 15:10:51.688680]: Elapsed time since starting training: 0:02:31.900614
[2018-04-17 15:10:51.694195]: ====================
[2018-04-17 15:10:51.715752]: [Epoch: 81(81.81818181818183%): Data: 0.0%]:Running loss: 0.5411805510520935
[2018-04-17 15:10:52.054653]: [Epoch: 81(81.81818181818183%): Data: 25.333333333333336%]:Running loss: 10.823460280895233
[2018-04-17 15:10:52.422131]: [Epoch: 81(81.81818181818183%): Data: 50.66666666666667%]:Running loss: 21.105453670024872
[2018-04-17 15:10:53.414779]: Test set accuracy: 76.92307692307692% ,loss = 13.528060913085938
[2018-04-17 15:10:53.530579]: ====================
[2018-04-17 15:10:53.536594]: Elapsed time since starting training: 0:02:33.748027
[2018-04-17 15:10:53.541608]: ====================
[2018-04-17 15:10:53.566674]: [Epoch: 82(82.82828282828282%): Data: 0.0%]:Running loss: 0.5411224365234375
[2018-04-17 15:10:53.917105]: [Epoch: 82(82.82828282828282%): Data: 25.333333333333336%]:Running loss: 10.82230532169342
[2018-04-17 15:10:54.269041]: [Epoch: 82(82.82828282828282%): Data: 50.66666666666667%]:Running loss: 21.103220641613007
[2018-04-17 15:10:55.254162]: Test set accuracy: 76.92307692307692% ,loss = 13.5266974568367
[2018-04-17 15:10:55.359443]: ====================
[2018-04-17 15:10:55.364956]: Elapsed time since starting training: 0:02:35.576388
[2018-04-17 15:10:55.370471]: ====================
[2018-04-17 15:10:55.396539]: [Epoch: 83(83.83838383838383%): Data: 0.0%]:Running loss: 0.541067898273468
[2018-04-17 15:10:55.767024]: [Epoch: 83(83.83838383838383%): Data: 25.333333333333336%]:Running loss: 10.82122266292572
[2018-04-17 15:10:56.127483]: [Epoch: 83(83.83838383838383%): Data: 50.66666666666667%]:Running loss: 21.101127088069916
[2018-04-17 15:10:57.112602]: Test set accuracy: 76.92307692307692% ,loss = 13.525404036045074
[2018-04-17 15:10:57.209360]: ====================
[2018-04-17 15:10:57.214883]: Elapsed time since starting training: 0:02:37.426307
[2018-04-17 15:10:57.220390]: ====================
[2018-04-17 15:10:57.246458]: [Epoch: 84(84.84848484848484%): Data: 0.0%]:Running loss: 0.541016161441803
[2018-04-17 15:10:57.601904]: [Epoch: 84(84.84848484848484%): Data: 25.333333333333336%]:Running loss: 10.82020616531372
[2018-04-17 15:10:57.946820]: [Epoch: 84(84.84848484848484%): Data: 50.66666666666667%]:Running loss: 21.099158823490143
[2018-04-17 15:10:58.979065]: Test set accuracy: 76.92307692307692% ,loss = 13.52420449256897
[2018-04-17 15:10:59.094371]: ====================
[2018-04-17 15:10:59.099886]: Elapsed time since starting training: 0:02:39.311820
[2018-04-17 15:10:59.106905]: ====================
[2018-04-17 15:10:59.129966]: [Epoch: 85(85.85858585858585%): Data: 0.0%]:Running loss: 0.5409681797027588
[2018-04-17 15:10:59.474883]: [Epoch: 85(85.85858585858585%): Data: 25.333333333333336%]:Running loss: 10.81924819946289
[2018-04-17 15:10:59.838350]: [Epoch: 85(85.85858585858585%): Data: 50.66666666666667%]:Running loss: 21.09730637073517
[2018-04-17 15:11:00.848035]: Test set accuracy: 76.92307692307692% ,loss = 13.523080945014954
[2018-04-17 15:11:00.946296]: ====================
[2018-04-17 15:11:00.951810]: Elapsed time since starting training: 0:02:41.163744
[2018-04-17 15:11:00.957827]: ====================
[2018-04-17 15:11:00.983394]: [Epoch: 86(86.86868686868688%): Data: 0.0%]:Running loss: 0.5409232378005981
[2018-04-17 15:11:01.356387]: [Epoch: 86(86.86868686868688%): Data: 25.333333333333336%]:Running loss: 10.818348228931427
[2018-04-17 15:11:01.712333]: [Epoch: 86(86.86868686868688%): Data: 50.66666666666667%]:Running loss: 21.095567226409912
[2018-04-17 15:11:02.693442]: Test set accuracy: 76.92307692307692% ,loss = 13.522003591060638
[2018-04-17 15:11:02.799724]: ====================
[2018-04-17 15:11:02.805239]: Elapsed time since starting training: 0:02:43.017173
[2018-04-17 15:11:02.811255]: ====================
[2018-04-17 15:11:02.836823]: [Epoch: 87(87.87878787878788%): Data: 0.0%]:Running loss: 0.5408801436424255
[2018-04-17 15:11:03.198284]: [Epoch: 87(87.87878787878788%): Data: 25.333333333333336%]:Running loss: 10.817499995231628
[2018-04-17 15:11:03.550721]: [Epoch: 87(87.87878787878788%): Data: 50.66666666666667%]:Running loss: 21.093929648399353
[2018-04-17 15:11:04.532833]: Test set accuracy: 76.92307692307692% ,loss = 13.521017134189606
[2018-04-17 15:11:04.630091]: ====================
[2018-04-17 15:11:04.635606]: Elapsed time since starting training: 0:02:44.847540
[2018-04-17 15:11:04.640620]: ====================
[2018-04-17 15:11:04.665686]: [Epoch: 88(88.88888888888889%): Data: 0.0%]:Running loss: 0.5408406853675842
[2018-04-17 15:11:05.033163]: [Epoch: 88(88.88888888888889%): Data: 25.333333333333336%]:Running loss: 10.81671017408371
[2018-04-17 15:11:05.383093]: [Epoch: 88(88.88888888888889%): Data: 50.66666666666667%]:Running loss: 21.092397272586823
[2018-04-17 15:11:06.395787]: Test set accuracy: 76.92307692307692% ,loss = 13.520064949989319
[2018-04-17 15:11:06.491547]: ====================
[2018-04-17 15:11:06.497557]: Elapsed time since starting training: 0:02:46.708990
[2018-04-17 15:11:06.502570]: ====================
[2018-04-17 15:11:06.526134]: [Epoch: 89(89.8989898989899%): Data: 0.0%]:Running loss: 0.5408025979995728
[2018-04-17 15:11:06.877567]: [Epoch: 89(89.8989898989899%): Data: 25.333333333333336%]:Running loss: 10.815963387489319
[2018-04-17 15:11:07.239540]: [Epoch: 89(89.8989898989899%): Data: 50.66666666666667%]:Running loss: 21.09095150232315
[2018-04-17 15:11:08.238204]: Test set accuracy: 76.92307692307692% ,loss = 13.51919174194336
[2018-04-17 15:11:08.335476]: ====================
[2018-04-17 15:11:08.340977]: Elapsed time since starting training: 0:02:48.552911
[2018-04-17 15:11:08.347495]: ====================
[2018-04-17 15:11:08.372561]: [Epoch: 90(90.9090909090909%): Data: 0.0%]:Running loss: 0.5407676696777344
[2018-04-17 15:11:08.736529]: [Epoch: 90(90.9090909090909%): Data: 25.333333333333336%]:Running loss: 10.815262377262115
[2018-04-17 15:11:09.103552]: [Epoch: 90(90.9090909090909%): Data: 50.66666666666667%]:Running loss: 21.089593410491943
[2018-04-17 15:11:10.072136]: Test set accuracy: 76.92307692307692% ,loss = 13.518351316452026
[2018-04-17 15:11:10.250101]: ====================
[2018-04-17 15:11:10.257634]: Elapsed time since starting training: 0:02:50.469568
[2018-04-17 15:11:10.267147]: ====================
[2018-04-17 15:11:10.292213]: [Epoch: 91(91.91919191919192%): Data: 0.0%]:Running loss: 0.540734052658081
[2018-04-17 15:11:10.635125]: [Epoch: 91(91.91919191919192%): Data: 25.333333333333336%]:Running loss: 10.814602196216583
[2018-04-17 15:11:11.002602]: [Epoch: 91(91.91919191919192%): Data: 50.66666666666667%]:Running loss: 21.08831775188446
[2018-04-17 15:11:11.994741]: Test set accuracy: 76.92307692307692% ,loss = 13.517573475837708
[2018-04-17 15:11:12.094505]: ====================
[2018-04-17 15:11:12.102026]: Elapsed time since starting training: 0:02:52.313960
[2018-04-17 15:11:12.110047]: ====================
[2018-04-17 15:11:12.136116]: [Epoch: 92(92.92929292929293%): Data: 0.0%]:Running loss: 0.5407029390335083
[2018-04-17 15:11:12.494569]: [Epoch: 92(92.92929292929293%): Data: 25.333333333333336%]:Running loss: 10.813982546329498
[2018-04-17 15:11:12.829460]: [Epoch: 92(92.92929292929293%): Data: 50.66666666666667%]:Running loss: 21.087118446826935
[2018-04-17 15:11:13.815581]: Test set accuracy: 76.92307692307692% ,loss = 13.516846299171448
[2018-04-17 15:11:13.914846]: ====================
[2018-04-17 15:11:13.922869]: Elapsed time since starting training: 0:02:54.134803
[2018-04-17 15:11:13.930888]: ====================
[2018-04-17 15:11:13.956957]: [Epoch: 93(93.93939393939394%): Data: 0.0%]:Running loss: 0.5406738519668579
[2018-04-17 15:11:14.327944]: [Epoch: 93(93.93939393939394%): Data: 25.333333333333336%]:Running loss: 10.81339830160141
[2018-04-17 15:11:14.697427]: [Epoch: 93(93.93939393939394%): Data: 50.66666666666667%]:Running loss: 21.085989117622375
[2018-04-17 15:11:15.688612]: Test set accuracy: 76.92307692307692% ,loss = 13.516144454479218
[2018-04-17 15:11:15.790383]: ====================
[2018-04-17 15:11:15.798405]: Elapsed time since starting training: 0:02:56.010339
[2018-04-17 15:11:15.806425]: ====================
[2018-04-17 15:11:15.835502]: [Epoch: 94(94.94949494949495%): Data: 0.0%]:Running loss: 0.5406457781791687
[2018-04-17 15:11:16.187950]: [Epoch: 94(94.94949494949495%): Data: 25.333333333333336%]:Running loss: 10.812849223613739
[2018-04-17 15:11:16.545902]: [Epoch: 94(94.94949494949495%): Data: 50.66666666666667%]:Running loss: 21.08492523431778
[2018-04-17 15:11:17.532525]: Test set accuracy: 76.92307692307692% ,loss = 13.515493273735046
[2018-04-17 15:11:17.634296]: ====================
[2018-04-17 15:11:17.641816]: Elapsed time since starting training: 0:02:57.853750
[2018-04-17 15:11:17.649848]: ====================
[2018-04-17 15:11:17.676407]: [Epoch: 95(95.95959595959596%): Data: 0.0%]:Running loss: 0.5406197309494019
[2018-04-17 15:11:18.039874]: [Epoch: 95(95.95959595959596%): Data: 25.333333333333336%]:Running loss: 10.812333464622498
[2018-04-17 15:11:18.403340]: [Epoch: 95(95.95959595959596%): Data: 50.66666666666667%]:Running loss: 21.083929240703583
[2018-04-17 15:11:19.388961]: Test set accuracy: 76.92307692307692% ,loss = 13.514885306358337
[2018-04-17 15:11:19.500759]: ====================
[2018-04-17 15:11:19.509282]: Elapsed time since starting training: 0:02:59.720715
[2018-04-17 15:11:19.517804]: ====================
[2018-04-17 15:11:19.542369]: [Epoch: 96(96.96969696969697%): Data: 0.0%]:Running loss: 0.5405954122543335
[2018-04-17 15:11:19.888791]: [Epoch: 96(96.96969696969697%): Data: 25.333333333333336%]:Running loss: 10.811849236488342
[2018-04-17 15:11:20.255265]: [Epoch: 96(96.96969696969697%): Data: 50.66666666666667%]:Running loss: 21.082989990711212
[2018-04-17 15:11:21.242389]: Test set accuracy: 76.92307692307692% ,loss = 13.514307141304016
[2018-04-17 15:11:21.352182]: ====================
[2018-04-17 15:11:21.361715]: Elapsed time since starting training: 0:03:01.573649
[2018-04-17 15:11:21.367221]: ====================
[2018-04-17 15:11:21.389782]: [Epoch: 97(97.97979797979798%): Data: 0.0%]:Running loss: 0.5405722856521606
[2018-04-17 15:11:21.764278]: [Epoch: 97(97.97979797979798%): Data: 25.333333333333336%]:Running loss: 10.811394572257996
[2018-04-17 15:11:22.119222]: [Epoch: 97(97.97979797979798%): Data: 50.66666666666667%]:Running loss: 21.082109570503235
[2018-04-17 15:11:23.121887]: Test set accuracy: 76.92307692307692% ,loss = 13.513769209384918
[2018-04-17 15:11:23.233184]: ====================
[2018-04-17 15:11:23.238699]: Elapsed time since starting training: 0:03:03.450131
[2018-04-17 15:11:23.244714]: ====================
[2018-04-17 15:11:23.270783]: [Epoch: 98(98.98989898989899%): Data: 0.0%]:Running loss: 0.5405507683753967
[2018-04-17 15:11:23.612692]: [Epoch: 98(98.98989898989899%): Data: 25.333333333333336%]:Running loss: 10.8109632730484
[2018-04-17 15:11:23.970644]: [Epoch: 98(98.98989898989899%): Data: 50.66666666666667%]:Running loss: 21.0812771320343
[2018-04-17 15:11:24.947241]: Test set accuracy: 76.92307692307692% ,loss = 13.513261079788208
[2018-04-17 15:11:25.050015]: ====================
[2018-04-17 15:11:25.056531]: Elapsed time since starting training: 0:03:05.268465
[2018-04-17 15:11:25.062547]: ====================
[2018-04-17 15:11:25.088115]: [Epoch: 99(100.0%): Data: 0.0%]:Running loss: 0.5405304431915283
[2018-04-17 15:11:25.447571]: [Epoch: 99(100.0%): Data: 25.333333333333336%]:Running loss: 10.810559332370758
[2018-04-17 15:11:25.809032]: [Epoch: 99(100.0%): Data: 50.66666666666667%]:Running loss: 21.080494225025177
[2018-04-17 15:11:26.802173]: Test set accuracy: 76.92307692307692% ,loss = 13.512787222862244
[2018-04-17 15:11:26.908957]: ====================
[2018-04-17 15:11:26.914973]: Elapsed time since starting training: 0:03:07.126907
[2018-04-17 15:11:26.920990]: ====================
[2018-04-17 15:11:26.927005]: Elapsed time on training: 0:03:07.138438
[2018-04-17 15:11:27.279442]: Test set accuracy: 76.92307692307692% ,loss = 13.512787222862244
[2018-04-17 15:16:43.225419]: Starting
[2018-04-17 15:16:43.231434]: OS detected: Windows
[2018-04-17 15:16:43.238955]: Using G:\Data\map_data\ as file path
[2018-04-17 15:16:43.245973]: Using CUDA: True
[2018-04-17 15:16:44.164916]: Raw Data loaded. Turning to batches
[2018-04-17 15:16:44.177951]: Batches generated
[2018-04-17 15:16:44.183975]: Generating 25 string maps per stringless one.
[2018-04-17 15:16:44.189983]: Estimated time till completion of map generation: 0:37:30
[2018-04-17 15:16:44.197005]: Estimated time of completion of map generation: 2018-04-17 15:54:14.196501
[2018-04-17 15:16:44.202521]: Values for string maps: (G_mu,v,A):(1e-06,1,1e-06)
[2018-04-17 15:44:37.670209]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 15:44:37.676726]: 106 elements per train batch.
[2018-04-17 15:55:14.580238]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 15:55:14.588260]: 106 elements per test batch.
[2018-04-17 15:55:14.598285]: Network and optimizers created
[2018-04-17 15:55:14.603801]: Projected finishing time = 2018-04-17 17:47:44.603801
[2018-04-17 15:55:14.611320]: Projected time to completion = 1:52:30
[2018-04-17 15:55:14.774755]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.6627141237258911
[2018-04-17 15:55:16.186028]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 13.178223073482513
[2018-04-17 15:55:17.584746]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 25.55128562450409
[2018-04-17 15:55:21.545328]: Test set accuracy: 94.33962264150944% ,loss = 15.842431783676147
[2018-04-17 15:55:27.644020]: ====================
[2018-04-17 15:55:27.650536]: Elapsed time since starting training: 0:00:13.046234
[2018-04-17 15:55:27.656552]: ====================
[2018-04-17 15:55:27.731752]: [Epoch: 1(0.06671114076050699%): Data: 0.0%]:Running loss: 0.6336972713470459
[2018-04-17 15:55:29.060285]: [Epoch: 1(0.06671114076050699%): Data: 25.333333333333336%]:Running loss: 12.603954076766968
[2018-04-17 15:55:30.377828]: [Epoch: 1(0.06671114076050699%): Data: 50.66666666666667%]:Running loss: 24.44311511516571
[2018-04-17 15:55:34.088712]: Test set accuracy: 94.33962264150944% ,loss = 15.174761414527893
[2018-04-17 15:55:36.665063]: ====================
[2018-04-17 15:55:36.671078]: Elapsed time since starting training: 0:00:22.067277
[2018-04-17 15:55:36.678097]: ====================
[2018-04-17 15:55:36.751304]: [Epoch: 2(0.13342228152101399%): Data: 0.0%]:Running loss: 0.6069904565811157
[2018-04-17 15:55:38.106395]: [Epoch: 2(0.13342228152101399%): Data: 25.333333333333336%]:Running loss: 12.075367391109467
[2018-04-17 15:55:39.428917]: [Epoch: 2(0.13342228152101399%): Data: 50.66666666666667%]:Running loss: 23.42304164171219
[2018-04-17 15:55:43.150813]: Test set accuracy: 94.33962264150944% ,loss = 14.5599365234375
[2018-04-17 15:55:43.294706]: ====================
[2018-04-17 15:55:43.301715]: Elapsed time since starting training: 0:00:28.697914
[2018-04-17 15:55:43.309235]: ====================
[2018-04-17 15:55:43.396968]: [Epoch: 3(0.20013342228152103%): Data: 0.0%]:Running loss: 0.5823974609375
[2018-04-17 15:55:44.695922]: [Epoch: 3(0.20013342228152103%): Data: 25.333333333333336%]:Running loss: 11.588588833808899
[2018-04-17 15:55:46.024455]: [Epoch: 3(0.20013342228152103%): Data: 50.66666666666667%]:Running loss: 22.48358178138733
[2018-04-17 15:55:49.672153]: Test set accuracy: 94.33962264150944% ,loss = 13.99342566728592
[2018-04-17 15:55:49.788465]: ====================
[2018-04-17 15:55:49.794980]: Elapsed time since starting training: 0:00:35.191179
[2018-04-17 15:55:49.800997]: ====================
[2018-04-17 15:55:49.874694]: [Epoch: 4(0.26684456304202797%): Data: 0.0%]:Running loss: 0.5597370266914368
[2018-04-17 15:55:51.250851]: [Epoch: 4(0.26684456304202797%): Data: 25.333333333333336%]:Running loss: 11.140026271343231
[2018-04-17 15:55:52.606957]: [Epoch: 4(0.26684456304202797%): Data: 50.66666666666667%]:Running loss: 21.617799401283264
[2018-04-17 15:55:56.355461]: Test set accuracy: 94.33962264150944% ,loss = 13.471059501171112
[2018-04-17 15:55:56.479290]: ====================
[2018-04-17 15:55:56.485808]: Elapsed time since starting training: 0:00:41.882007
[2018-04-17 15:55:56.491824]: ====================
[2018-04-17 15:55:56.570534]: [Epoch: 5(0.333555703802535%): Data: 0.0%]:Running loss: 0.5388423800468445
[2018-04-17 15:55:57.921625]: [Epoch: 5(0.333555703802535%): Data: 25.333333333333336%]:Running loss: 10.7263662815094
[2018-04-17 15:55:59.264697]: [Epoch: 5(0.333555703802535%): Data: 50.66666666666667%]:Running loss: 20.819299161434174
[2018-04-17 15:56:03.037730]: Test set accuracy: 94.33962264150944% ,loss = 12.988969683647156
[2018-04-17 15:56:03.154038]: ====================
[2018-04-17 15:56:03.160054]: Elapsed time since starting training: 0:00:48.556253
[2018-04-17 15:56:03.166070]: ====================
[2018-04-17 15:56:03.242774]: [Epoch: 6(0.40026684456304207%): Data: 0.0%]:Running loss: 0.5195587873458862
[2018-04-17 15:56:04.602897]: [Epoch: 6(0.40026684456304207%): Data: 25.333333333333336%]:Running loss: 10.344562590122223
[2018-04-17 15:56:05.929919]: [Epoch: 6(0.40026684456304207%): Data: 50.66666666666667%]:Running loss: 20.082209050655365
[2018-04-17 15:56:09.635773]: Test set accuracy: 94.33962264150944% ,loss = 12.543636560440063
[2018-04-17 15:56:09.747069]: ====================
[2018-04-17 15:56:09.752584]: Elapsed time since starting training: 0:00:55.148783
[2018-04-17 15:56:09.758600]: ====================
[2018-04-17 15:56:09.836809]: [Epoch: 7(0.46697798532354906%): Data: 0.0%]:Running loss: 0.5017454624176025
[2018-04-17 15:56:11.191471]: [Epoch: 7(0.46697798532354906%): Data: 25.333333333333336%]:Running loss: 9.991830319166183
[2018-04-17 15:56:12.552633]: [Epoch: 7(0.46697798532354906%): Data: 50.66666666666667%]:Running loss: 19.4011589884758
[2018-04-17 15:56:16.297105]: Test set accuracy: 94.33962264150944% ,loss = 12.131869792938232
[2018-04-17 15:56:16.424444]: ====================
[2018-04-17 15:56:16.431965]: Elapsed time since starting training: 0:01:01.827662
[2018-04-17 15:56:16.437981]: ====================
[2018-04-17 15:56:16.516193]: [Epoch: 8(0.5336891260840559%): Data: 0.0%]:Running loss: 0.4852747917175293
[2018-04-17 15:56:17.875826]: [Epoch: 8(0.5336891260840559%): Data: 25.333333333333336%]:Running loss: 9.66563105583191
[2018-04-17 15:56:19.241457]: [Epoch: 8(0.5336891260840559%): Data: 50.66666666666667%]:Running loss: 18.771254301071167
[2018-04-17 15:56:23.059130]: Test set accuracy: 94.33962264150944% ,loss = 11.750701814889908
[2018-04-17 15:56:23.194487]: ====================
[2018-04-17 15:56:23.200503]: Elapsed time since starting training: 0:01:08.596702
[2018-04-17 15:56:23.207021]: ====================
[2018-04-17 15:56:23.279212]: [Epoch: 9(0.600400266844563%): Data: 0.0%]:Running loss: 0.4700280725955963
[2018-04-17 15:56:24.643857]: [Epoch: 9(0.600400266844563%): Data: 25.333333333333336%]:Running loss: 9.363644570112228
[2018-04-17 15:56:26.032048]: [Epoch: 9(0.600400266844563%): Data: 50.66666666666667%]:Running loss: 18.18802872300148
[2018-04-17 15:56:29.803576]: Test set accuracy: 94.33962264150944% ,loss = 11.397507786750793
[2018-04-17 15:56:29.908857]: ====================
[2018-04-17 15:56:29.915875]: Elapsed time since starting training: 0:01:15.312074
[2018-04-17 15:56:29.921891]: ====================
[2018-04-17 15:56:29.999097]: [Epoch: 10(0.66711140760507%): Data: 0.0%]:Running loss: 0.45590031147003174
[2018-04-17 15:56:31.318104]: [Epoch: 10(0.66711140760507%): Data: 25.333333333333336%]:Running loss: 9.083772450685501
[2018-04-17 15:56:32.661677]: [Epoch: 10(0.66711140760507%): Data: 50.66666666666667%]:Running loss: 17.647436320781708
[2018-04-17 15:56:36.401147]: Test set accuracy: 94.33962264150944% ,loss = 11.069857329130173
[2018-04-17 15:56:36.518960]: ====================
[2018-04-17 15:56:36.524976]: Elapsed time since starting training: 0:01:21.921175
[2018-04-17 15:56:36.531502]: ====================
[2018-04-17 15:56:36.604187]: [Epoch: 11(0.733822548365577%): Data: 0.0%]:Running loss: 0.4427942931652069
[2018-04-17 15:56:37.891109]: [Epoch: 11(0.733822548365577%): Data: 25.333333333333336%]:Running loss: 8.82410341501236
[2018-04-17 15:56:39.180538]: [Epoch: 11(0.733822548365577%): Data: 50.66666666666667%]:Running loss: 17.14579537510872
[2018-04-17 15:56:42.830753]: Test set accuracy: 94.33962264150944% ,loss = 10.765551030635834
[2018-04-17 15:56:42.936032]: ====================
[2018-04-17 15:56:42.942049]: Elapsed time since starting training: 0:01:28.337747
[2018-04-17 15:56:42.948566]: ====================
[2018-04-17 15:56:43.024268]: [Epoch: 12(0.8005336891260841%): Data: 0.0%]:Running loss: 0.43062204122543335
[2018-04-17 15:56:44.364850]: [Epoch: 12(0.8005336891260841%): Data: 25.333333333333336%]:Running loss: 8.58290308713913
[2018-04-17 15:56:45.657298]: [Epoch: 12(0.8005336891260841%): Data: 50.66666666666667%]:Running loss: 16.67976665496826
[2018-04-17 15:56:49.261370]: Test set accuracy: 94.33962264150944% ,loss = 10.482610017061234
[2018-04-17 15:56:49.377679]: ====================
[2018-04-17 15:56:49.384196]: Elapsed time since starting training: 0:01:34.780395
[2018-04-17 15:56:49.389711]: ====================
[2018-04-17 15:56:49.460901]: [Epoch: 13(0.867244829886591%): Data: 0.0%]:Running loss: 0.41930440068244934
[2018-04-17 15:56:50.767962]: [Epoch: 13(0.867244829886591%): Data: 25.333333333333336%]:Running loss: 8.358602821826935
[2018-04-17 15:56:52.033335]: [Epoch: 13(0.867244829886591%): Data: 50.66666666666667%]:Running loss: 16.24633029103279
[2018-04-17 15:56:55.566313]: Test set accuracy: 94.33962264150944% ,loss = 10.21922305226326
[2018-04-17 15:56:55.675604]: ====================
[2018-04-17 15:56:55.681620]: Elapsed time since starting training: 0:01:41.077819
[2018-04-17 15:56:55.687135]: ====================
[2018-04-17 15:56:55.759828]: [Epoch: 14(0.9339559706470981%): Data: 0.0%]:Running loss: 0.4087689220905304
[2018-04-17 15:56:57.021182]: [Epoch: 14(0.9339559706470981%): Data: 25.333333333333336%]:Running loss: 8.149781346321106
[2018-04-17 15:56:58.275015]: [Epoch: 14(0.9339559706470981%): Data: 50.66666666666667%]:Running loss: 15.842744499444962
[2018-04-17 15:57:01.831973]: Test set accuracy: 94.33962264150944% ,loss = 9.97377261519432
[2018-04-17 15:57:01.946278]: ====================
[2018-04-17 15:57:01.952795]: Elapsed time since starting training: 0:01:47.348492
[2018-04-17 15:57:01.958310]: ====================
[2018-04-17 15:57:02.033509]: [Epoch: 15(1.0006671114076051%): Data: 0.0%]:Running loss: 0.3989509046077728
[2018-04-17 15:57:03.301883]: [Epoch: 15(1.0006671114076051%): Data: 25.333333333333336%]:Running loss: 7.955144703388214
[2018-04-17 15:57:04.568249]: [Epoch: 15(1.0006671114076051%): Data: 50.66666666666667%]:Running loss: 15.466522365808487
[2018-04-17 15:57:08.099139]: Test set accuracy: 94.33962264150944% ,loss = 9.744767099618912
[2018-04-17 15:57:08.229986]: ====================
[2018-04-17 15:57:08.236007]: Elapsed time since starting training: 0:01:53.632206
[2018-04-17 15:57:08.242520]: ====================
[2018-04-17 15:57:08.320226]: [Epoch: 16(1.0673782521681119%): Data: 0.0%]:Running loss: 0.38979068398475647
[2018-04-17 15:57:09.634221]: [Epoch: 16(1.0673782521681119%): Data: 25.333333333333336%]:Running loss: 7.773525953292847
[2018-04-17 15:57:10.995918]: [Epoch: 16(1.0673782521681119%): Data: 50.66666666666667%]:Running loss: 15.115411072969437
[2018-04-17 15:57:14.846656]: Test set accuracy: 94.33962264150944% ,loss = 9.530869126319885
[2018-04-17 15:57:14.976502]: ====================
[2018-04-17 15:57:14.983520]: Elapsed time since starting training: 0:02:00.379719
[2018-04-17 15:57:14.989536]: ====================
[2018-04-17 15:57:15.069248]: [Epoch: 17(1.134089392928619%): Data: 0.0%]:Running loss: 0.3812347650527954
[2018-04-17 15:57:16.441902]: [Epoch: 17(1.134089392928619%): Data: 25.333333333333336%]:Running loss: 7.603862226009369
[2018-04-17 15:57:17.796521]: [Epoch: 17(1.134089392928619%): Data: 50.66666666666667%]:Running loss: 14.787367194890976
[2018-04-17 15:57:21.574112]: Test set accuracy: 94.33962264150944% ,loss = 9.330853074789047
[2018-04-17 15:57:21.696938]: ====================
[2018-04-17 15:57:21.702955]: Elapsed time since starting training: 0:02:07.099154
[2018-04-17 15:57:21.709472]: ====================
[2018-04-17 15:57:21.784685]: [Epoch: 18(1.200800533689126%): Data: 0.0%]:Running loss: 0.3732341229915619
[2018-04-17 15:57:23.093151]: [Epoch: 18(1.200800533689126%): Data: 25.333333333333336%]:Running loss: 7.445191651582718
[2018-04-17 15:57:24.472820]: [Epoch: 18(1.200800533689126%): Data: 50.66666666666667%]:Running loss: 14.48053702712059
[2018-04-17 15:57:28.215796]: Test set accuracy: 94.33962264150944% ,loss = 9.143628180027008
[2018-04-17 15:57:28.336117]: ====================
[2018-04-17 15:57:28.341643]: Elapsed time since starting training: 0:02:13.737842
[2018-04-17 15:57:28.348147]: ====================
[2018-04-17 15:57:28.425855]: [Epoch: 19(1.267511674449633%): Data: 0.0%]:Running loss: 0.3657451272010803
[2018-04-17 15:57:29.750376]: [Epoch: 19(1.267511674449633%): Data: 25.333333333333336%]:Running loss: 7.29664158821106
[2018-04-17 15:57:31.075906]: [Epoch: 19(1.267511674449633%): Data: 50.66666666666667%]:Running loss: 14.193235516548157
[2018-04-17 15:57:34.827381]: Test set accuracy: 94.33962264150944% ,loss = 8.96816998720169
[2018-04-17 15:57:34.948706]: ====================
[2018-04-17 15:57:34.954720]: Elapsed time since starting training: 0:02:20.350919
[2018-04-17 15:57:34.960736]: ====================
[2018-04-17 15:57:35.034933]: [Epoch: 20(1.33422281521014%): Data: 0.0%]:Running loss: 0.3587267994880676
[2018-04-17 15:57:36.382580]: [Epoch: 20(1.33422281521014%): Data: 25.333333333333336%]:Running loss: 7.1574163138866425
[2018-04-17 15:57:37.729674]: [Epoch: 20(1.33422281521014%): Data: 50.66666666666667%]:Running loss: 13.923936486244202
[2018-04-17 15:57:41.498935]: Test set accuracy: 94.33962264150944% ,loss = 8.803584426641464
[2018-04-17 15:57:41.619255]: ====================
[2018-04-17 15:57:41.625272]: Elapsed time since starting training: 0:02:27.021471
[2018-04-17 15:57:41.631789]: ====================
[2018-04-17 15:57:41.708493]: [Epoch: 21(1.400933955970647%): Data: 0.0%]:Running loss: 0.35214337706565857
[2018-04-17 15:57:43.049589]: [Epoch: 21(1.400933955970647%): Data: 25.333333333333336%]:Running loss: 7.026795595884323
[2018-04-17 15:57:44.423743]: [Epoch: 21(1.400933955970647%): Data: 50.66666666666667%]:Running loss: 13.671245992183685
[2018-04-17 15:57:48.160692]: Test set accuracy: 94.33962264150944% ,loss = 8.649025857448578
[2018-04-17 15:57:48.268968]: ====================
[2018-04-17 15:57:48.275485]: Elapsed time since starting training: 0:02:33.671684
[2018-04-17 15:57:48.281501]: ====================
[2018-04-17 15:57:48.354695]: [Epoch: 22(1.467645096731154%): Data: 0.0%]:Running loss: 0.3459610342979431
[2018-04-17 15:57:49.694269]: [Epoch: 22(1.467645096731154%): Data: 25.333333333333336%]:Running loss: 6.904120147228241
[2018-04-17 15:57:51.030823]: [Epoch: 22(1.467645096731154%): Data: 50.66666666666667%]:Running loss: 13.433896154165268
[2018-04-17 15:57:54.771826]: Test set accuracy: 94.33962264150944% ,loss = 8.503738790750504
[2018-04-17 15:57:54.882119]: ====================
[2018-04-17 15:57:54.888147]: Elapsed time since starting training: 0:02:40.284346
[2018-04-17 15:57:54.894652]: ====================
[2018-04-17 15:57:54.972870]: [Epoch: 23(1.534356237491661%): Data: 0.0%]:Running loss: 0.34014955163002014
[2018-04-17 15:57:56.342503]: [Epoch: 23(1.534356237491661%): Data: 25.333333333333336%]:Running loss: 6.788791805505753
[2018-04-17 15:57:57.701616]: [Epoch: 23(1.534356237491661%): Data: 50.66666666666667%]:Running loss: 13.21073368191719
[2018-04-17 15:58:01.512276]: Test set accuracy: 94.33962264150944% ,loss = 8.367040753364563
[2018-04-17 15:58:01.622605]: ====================
[2018-04-17 15:58:01.628621]: Elapsed time since starting training: 0:02:47.024820
[2018-04-17 15:58:01.635137]: ====================
[2018-04-17 15:58:01.708346]: [Epoch: 24(1.6010673782521683%): Data: 0.0%]:Running loss: 0.3346816301345825
[2018-04-17 15:58:03.030849]: [Epoch: 24(1.6010673782521683%): Data: 25.333333333333336%]:Running loss: 6.680264234542847
[2018-04-17 15:58:04.379435]: [Epoch: 24(1.6010673782521683%): Data: 50.66666666666667%]:Running loss: 13.00070545077324
[2018-04-17 15:58:08.112382]: Test set accuracy: 94.33962264150944% ,loss = 8.238299190998077
[2018-04-17 15:58:08.232201]: ====================
[2018-04-17 15:58:08.238217]: Elapsed time since starting training: 0:02:53.634416
[2018-04-17 15:58:08.243230]: ====================
[2018-04-17 15:58:08.322943]: [Epoch: 25(1.6677785190126753%): Data: 0.0%]:Running loss: 0.3295319676399231
[2018-04-17 15:58:09.668521]: [Epoch: 25(1.6677785190126753%): Data: 25.333333333333336%]:Running loss: 6.578039914369583
[2018-04-17 15:58:11.052706]: [Epoch: 25(1.6677785190126753%): Data: 50.66666666666667%]:Running loss: 12.802852541208267
[2018-04-17 15:58:14.880886]: Test set accuracy: 94.33962264150944% ,loss = 8.116935938596725
[2018-04-17 15:58:14.999702]: ====================
[2018-04-17 15:58:15.006220]: Elapsed time since starting training: 0:03:00.401918
[2018-04-17 15:58:15.012235]: ====================
[2018-04-17 15:58:15.086934]: [Epoch: 26(1.734489659773182%): Data: 0.0%]:Running loss: 0.324677437543869
[2018-04-17 15:58:16.410954]: [Epoch: 26(1.734489659773182%): Data: 25.333333333333336%]:Running loss: 6.481661409139633
[2018-04-17 15:58:17.795508]: [Epoch: 26(1.734489659773182%): Data: 50.66666666666667%]:Running loss: 12.616293787956238
[2018-04-17 15:58:21.417676]: Test set accuracy: 94.33962264150944% ,loss = 8.002416789531708
[2018-04-17 15:58:21.530477]: ====================
[2018-04-17 15:58:21.537496]: Elapsed time since starting training: 0:03:06.933194
[2018-04-17 15:58:21.543511]: ====================
[2018-04-17 15:58:21.614701]: [Epoch: 27(1.801200800533689%): Data: 0.0%]:Running loss: 0.3200966715812683
[2018-04-17 15:58:22.938220]: [Epoch: 27(1.801200800533689%): Data: 25.333333333333336%]:Running loss: 6.390712797641754
[2018-04-17 15:58:24.242202]: [Epoch: 27(1.801200800533689%): Data: 50.66666666666667%]:Running loss: 12.440223604440689
[2018-04-17 15:58:27.830783]: Test set accuracy: 94.33962264150944% ,loss = 7.894257456064224
[2018-04-17 15:58:27.956619]: ====================
[2018-04-17 15:58:27.964137]: Elapsed time since starting training: 0:03:13.360336
[2018-04-17 15:58:27.970153]: ====================
[2018-04-17 15:58:28.041342]: [Epoch: 28(1.8679119412941962%): Data: 0.0%]:Running loss: 0.31577029824256897
[2018-04-17 15:58:29.335784]: [Epoch: 28(1.8679119412941962%): Data: 25.333333333333336%]:Running loss: 6.304809272289276
[2018-04-17 15:58:30.627218]: [Epoch: 28(1.8679119412941962%): Data: 50.66666666666667%]:Running loss: 12.27390143275261
[2018-04-17 15:58:34.157617]: Test set accuracy: 94.33962264150944% ,loss = 7.792040705680847
[2018-04-17 15:58:34.258385]: ====================
[2018-04-17 15:58:34.264401]: Elapsed time since starting training: 0:03:19.660099
[2018-04-17 15:58:34.271419]: ====================
[2018-04-17 15:58:34.351132]: [Epoch: 29(1.9346230820547032%): Data: 0.0%]:Running loss: 0.3116816282272339
[2018-04-17 15:58:35.653093]: [Epoch: 29(1.9346230820547032%): Data: 25.333333333333336%]:Running loss: 6.22360622882843
[2018-04-17 15:58:36.970094]: [Epoch: 29(1.9346230820547032%): Data: 50.66666666666667%]:Running loss: 12.116666793823242
[2018-04-17 15:58:40.449347]: Test set accuracy: 94.33962264150944% ,loss = 7.695335894823074
[2018-04-17 15:58:40.552121]: ====================
[2018-04-17 15:58:40.558136]: Elapsed time since starting training: 0:03:25.953833
[2018-04-17 15:58:40.564655]: ====================
[2018-04-17 15:58:40.646370]: [Epoch: 30(2.0013342228152102%): Data: 0.0%]:Running loss: 0.307813435792923
[2018-04-17 15:58:41.949835]: [Epoch: 30(2.0013342228152102%): Data: 25.333333333333336%]:Running loss: 6.14678218960762
[2018-04-17 15:58:43.185120]: [Epoch: 30(2.0013342228152102%): Data: 50.66666666666667%]:Running loss: 11.96789437532425
[2018-04-17 15:58:46.691945]: Test set accuracy: 94.33962264150944% ,loss = 7.603788375854492
[2018-04-17 15:58:46.797728]: ====================
[2018-04-17 15:58:46.803742]: Elapsed time since starting training: 0:03:32.199941
[2018-04-17 15:58:46.810260]: ====================
[2018-04-17 15:58:46.882451]: [Epoch: 31(2.068045363575717%): Data: 0.0%]:Running loss: 0.3041515350341797
[2018-04-17 15:58:48.174386]: [Epoch: 31(2.068045363575717%): Data: 25.333333333333336%]:Running loss: 6.074040025472641
[2018-04-17 15:58:49.443762]: [Epoch: 31(2.068045363575717%): Data: 50.66666666666667%]:Running loss: 11.827013731002808
[2018-04-17 15:58:52.941088]: Test set accuracy: 94.33962264150944% ,loss = 7.517038285732269
[2018-04-17 15:58:53.113045]: ====================
[2018-04-17 15:58:53.118559]: Elapsed time since starting training: 0:03:38.514758
[2018-04-17 15:58:53.124074]: ====================
[2018-04-17 15:58:53.197269]: [Epoch: 32(2.1347565043362238%): Data: 0.0%]:Running loss: 0.30068153142929077
[2018-04-17 15:58:54.526804]: [Epoch: 32(2.1347565043362238%): Data: 25.333333333333336%]:Running loss: 6.005110740661621
[2018-04-17 15:58:55.802696]: [Epoch: 32(2.1347565043362238%): Data: 50.66666666666667%]:Running loss: 11.693502843379974
[2018-04-17 15:58:59.336236]: Test set accuracy: 94.33962264150944% ,loss = 7.4347831308841705
[2018-04-17 15:58:59.444525]: ====================
[2018-04-17 15:58:59.450039]: Elapsed time since starting training: 0:03:44.845737
[2018-04-17 15:58:59.455554]: ====================
[2018-04-17 15:58:59.529751]: [Epoch: 33(2.201467645096731%): Data: 0.0%]:Running loss: 0.2973913252353668
[2018-04-17 15:59:00.851841]: [Epoch: 33(2.201467645096731%): Data: 25.333333333333336%]:Running loss: 5.939742058515549
[2018-04-17 15:59:02.171851]: [Epoch: 33(2.201467645096731%): Data: 50.66666666666667%]:Running loss: 11.56687730550766
[2018-04-17 15:59:05.738861]: Test set accuracy: 94.33962264150944% ,loss = 7.356716692447662
[2018-04-17 15:59:05.839128]: ====================
[2018-04-17 15:59:05.844643]: Elapsed time since starting training: 0:03:51.240842
[2018-04-17 15:59:05.850157]: ====================
[2018-04-17 15:59:05.919342]: [Epoch: 34(2.268178785857238%): Data: 0.0%]:Running loss: 0.2942686676979065
[2018-04-17 15:59:07.211276]: [Epoch: 34(2.268178785857238%): Data: 25.333333333333336%]:Running loss: 5.877703309059143
[2018-04-17 15:59:08.517751]: [Epoch: 34(2.268178785857238%): Data: 50.66666666666667%]:Running loss: 11.446689993143082
[2018-04-17 15:59:12.078719]: Test set accuracy: 94.33962264150944% ,loss = 7.282587885856628
[2018-04-17 15:59:12.193024]: ====================
[2018-04-17 15:59:12.199041]: Elapsed time since starting training: 0:03:57.595240
[2018-04-17 15:59:12.205056]: ====================
[2018-04-17 15:59:12.281259]: [Epoch: 35(2.334889926617745%): Data: 0.0%]:Running loss: 0.29130351543426514
[2018-04-17 15:59:13.592509]: [Epoch: 35(2.334889926617745%): Data: 25.333333333333336%]:Running loss: 5.81878325343132
[2018-04-17 15:59:14.852860]: [Epoch: 35(2.334889926617745%): Data: 50.66666666666667%]:Running loss: 11.332536071538925
[2018-04-17 15:59:18.389586]: Test set accuracy: 94.33962264150944% ,loss = 7.2121478617191315
[2018-04-17 15:59:18.569460]: ====================
[2018-04-17 15:59:18.578484]: Elapsed time since starting training: 0:04:03.974683
[2018-04-17 15:59:18.586004]: ====================
[2018-04-17 15:59:18.664713]: [Epoch: 36(2.401601067378252%): Data: 0.0%]:Running loss: 0.28848591446876526
[2018-04-17 15:59:19.961259]: [Epoch: 36(2.401601067378252%): Data: 25.333333333333336%]:Running loss: 5.762785911560059
[2018-04-17 15:59:21.278795]: [Epoch: 36(2.401601067378252%): Data: 50.66666666666667%]:Running loss: 11.224034458398819
[2018-04-17 15:59:24.981708]: Test set accuracy: 94.33962264150944% ,loss = 7.145149260759354
[2018-04-17 15:59:25.108545]: ====================
[2018-04-17 15:59:25.114562]: Elapsed time since starting training: 0:04:10.510761
[2018-04-17 15:59:25.121580]: ====================
[2018-04-17 15:59:25.197281]: [Epoch: 37(2.468312208138759%): Data: 0.0%]:Running loss: 0.28580597043037415
[2018-04-17 15:59:26.534844]: [Epoch: 37(2.468312208138759%): Data: 25.333333333333336%]:Running loss: 5.709528625011444
[2018-04-17 15:59:27.816245]: [Epoch: 37(2.468312208138759%): Data: 50.66666666666667%]:Running loss: 11.120832622051239
[2018-04-17 15:59:31.585769]: Test set accuracy: 94.33962264150944% ,loss = 7.081403583288193
[2018-04-17 15:59:31.715614]: ====================
[2018-04-17 15:59:31.722131]: Elapsed time since starting training: 0:04:17.117828
[2018-04-17 15:59:31.728648]: ====================
[2018-04-17 15:59:31.805352]: [Epoch: 38(2.535023348899266%): Data: 0.0%]:Running loss: 0.2832561433315277
[2018-04-17 15:59:33.148925]: [Epoch: 38(2.535023348899266%): Data: 25.333333333333336%]:Running loss: 5.658846706151962
[2018-04-17 15:59:34.447389]: [Epoch: 38(2.535023348899266%): Data: 50.66666666666667%]:Running loss: 11.022611618041992
[2018-04-17 15:59:38.122190]: Test set accuracy: 94.33962264150944% ,loss = 7.0207007229328156
[2018-04-17 15:59:38.242511]: ====================
[2018-04-17 15:59:38.248526]: Elapsed time since starting training: 0:04:23.644725
[2018-04-17 15:59:38.256047]: ====================
[2018-04-17 15:59:38.334755]: [Epoch: 39(2.601734489659773%): Data: 0.0%]:Running loss: 0.2808280289173126
[2018-04-17 15:59:39.655768]: [Epoch: 39(2.601734489659773%): Data: 25.333333333333336%]:Running loss: 5.6105799078941345
[2018-04-17 15:59:40.936678]: [Epoch: 39(2.601734489659773%): Data: 50.66666666666667%]:Running loss: 10.92906665802002
[2018-04-17 15:59:44.630509]: Test set accuracy: 94.33962264150944% ,loss = 6.962854415178299
[2018-04-17 15:59:44.774392]: ====================
[2018-04-17 15:59:44.780908]: Elapsed time since starting training: 0:04:30.177107
[2018-04-17 15:59:44.787436]: ====================
[2018-04-17 15:59:44.860119]: [Epoch: 40(2.66844563042028%): Data: 0.0%]:Running loss: 0.27851417660713196
[2018-04-17 15:59:46.173110]: [Epoch: 40(2.66844563042028%): Data: 25.333333333333336%]:Running loss: 5.564585208892822
[2018-04-17 15:59:47.485099]: [Epoch: 40(2.66844563042028%): Data: 50.66666666666667%]:Running loss: 10.839919239282608
[2018-04-17 15:59:51.242103]: Test set accuracy: 94.33962264150944% ,loss = 6.907704472541809
[2018-04-17 15:59:51.377964]: ====================
[2018-04-17 15:59:51.383992]: Elapsed time since starting training: 0:04:36.780191
[2018-04-17 15:59:51.390002]: ====================
[2018-04-17 15:59:51.466199]: [Epoch: 41(2.735156771180787%): Data: 0.0%]:Running loss: 0.27630817890167236
[2018-04-17 15:59:52.781696]: [Epoch: 41(2.735156771180787%): Data: 25.333333333333336%]:Running loss: 5.520731180906296
[2018-04-17 15:59:54.132288]: [Epoch: 41(2.735156771180787%): Data: 50.66666666666667%]:Running loss: 10.754912495613098
[2018-04-17 15:59:57.868723]: Test set accuracy: 94.33962264150944% ,loss = 6.855098158121109
[2018-04-17 15:59:57.990547]: ====================
[2018-04-17 15:59:58.000072]: Elapsed time since starting training: 0:04:43.396271
[2018-04-17 15:59:58.009096]: ====================
[2018-04-17 15:59:58.088307]: [Epoch: 42(2.801867911941294%): Data: 0.0%]:Running loss: 0.27420392632484436
[2018-04-17 15:59:59.396798]: [Epoch: 42(2.801867911941294%): Data: 25.333333333333336%]:Running loss: 5.478893429040909
[2018-04-17 16:00:00.687730]: [Epoch: 42(2.801867911941294%): Data: 50.66666666666667%]:Running loss: 10.673807859420776
[2018-04-17 16:00:04.402427]: Test set accuracy: 94.33962264150944% ,loss = 6.804885715246201
[2018-04-17 16:00:04.511205]: ====================
[2018-04-17 16:00:04.517222]: Elapsed time since starting training: 0:04:49.912919
[2018-04-17 16:00:04.522736]: ====================
[2018-04-17 16:00:04.596432]: [Epoch: 43(2.868579052701801%): Data: 0.0%]:Running loss: 0.272195428609848
[2018-04-17 16:00:05.945018]: [Epoch: 43(2.868579052701801%): Data: 25.333333333333336%]:Running loss: 5.438953697681427
[2018-04-17 16:00:07.257517]: [Epoch: 43(2.868579052701801%): Data: 50.66666666666667%]:Running loss: 10.596375972032547
[2018-04-17 16:00:10.989036]: Test set accuracy: 94.33962264150944% ,loss = 6.756919622421265
[2018-04-17 16:00:11.100332]: ====================
[2018-04-17 16:00:11.107852]: Elapsed time since starting training: 0:04:56.503549
[2018-04-17 16:00:11.113868]: ====================
[2018-04-17 16:00:11.189068]: [Epoch: 44(2.935290193462308%): Data: 0.0%]:Running loss: 0.2702767848968506
[2018-04-17 16:00:12.517600]: [Epoch: 44(2.935290193462308%): Data: 25.333333333333336%]:Running loss: 5.400806963443756
[2018-04-17 16:00:13.845631]: [Epoch: 44(2.935290193462308%): Data: 50.66666666666667%]:Running loss: 10.522416293621063
[2018-04-17 16:00:17.534477]: Test set accuracy: 94.33962264150944% ,loss = 6.711096316576004
[2018-04-17 16:00:17.655800]: ====================
[2018-04-17 16:00:17.662819]: Elapsed time since starting training: 0:05:03.058527
[2018-04-17 16:00:17.668834]: ====================
[2018-04-17 16:00:17.744536]: [Epoch: 45(3.0020013342228156%): Data: 0.0%]:Running loss: 0.26844385266304016
[2018-04-17 16:00:19.064046]: [Epoch: 45(3.0020013342228156%): Data: 25.333333333333336%]:Running loss: 5.364349067211151
[2018-04-17 16:00:20.376534]: [Epoch: 45(3.0020013342228156%): Data: 50.66666666666667%]:Running loss: 10.451727896928787
[2018-04-17 16:00:24.114496]: Test set accuracy: 94.33962264150944% ,loss = 6.667272746562958
[2018-04-17 16:00:24.250358]: ====================
[2018-04-17 16:00:24.257879]: Elapsed time since starting training: 0:05:09.654078
[2018-04-17 16:00:24.263894]: ====================
[2018-04-17 16:00:24.342102]: [Epoch: 46(3.068712474983322%): Data: 0.0%]:Running loss: 0.2666909098625183
[2018-04-17 16:00:25.681664]: [Epoch: 46(3.068712474983322%): Data: 25.333333333333336%]:Running loss: 5.329490095376968
[2018-04-17 16:00:26.968084]: [Epoch: 46(3.068712474983322%): Data: 50.66666666666667%]:Running loss: 10.384133487939835
[2018-04-17 16:00:30.666440]: Test set accuracy: 94.33962264150944% ,loss = 6.6253505647182465
[2018-04-17 16:00:30.771721]: ====================
[2018-04-17 16:00:30.777739]: Elapsed time since starting training: 0:05:16.173938
[2018-04-17 16:00:30.784254]: ====================
[2018-04-17 16:00:30.858461]: [Epoch: 47(3.135423615743829%): Data: 0.0%]:Running loss: 0.26501402258872986
[2018-04-17 16:00:32.180968]: [Epoch: 47(3.135423615743829%): Data: 25.333333333333336%]:Running loss: 5.296140819787979
[2018-04-17 16:00:33.504488]: [Epoch: 47(3.135423615743829%): Data: 50.66666666666667%]:Running loss: 10.319463223218918
[2018-04-17 16:00:37.217607]: Test set accuracy: 94.33962264150944% ,loss = 6.58523291349411
[2018-04-17 16:00:37.329907]: ====================
[2018-04-17 16:00:37.336435]: Elapsed time since starting training: 0:05:22.732634
[2018-04-17 16:00:37.341938]: ====================
[2018-04-17 16:00:37.415634]: [Epoch: 48(3.2021347565043365%): Data: 0.0%]:Running loss: 0.2634093165397644
[2018-04-17 16:00:38.731149]: [Epoch: 48(3.2021347565043365%): Data: 25.333333333333336%]:Running loss: 5.264221012592316
[2018-04-17 16:00:40.069207]: [Epoch: 48(3.2021347565043365%): Data: 50.66666666666667%]:Running loss: 10.257560282945633
[2018-04-17 16:00:43.742990]: Test set accuracy: 94.33962264150944% ,loss = 6.546813249588013
[2018-04-17 16:00:43.849276]: ====================
[2018-04-17 16:00:43.855790]: Elapsed time since starting training: 0:05:29.251989
[2018-04-17 16:00:43.861806]: ====================
[2018-04-17 16:00:43.936003]: [Epoch: 49(3.268845897264843%): Data: 0.0%]:Running loss: 0.2618725299835205
[2018-04-17 16:00:45.259522]: [Epoch: 49(3.268845897264843%): Data: 25.333333333333336%]:Running loss: 5.233654767274857
[2018-04-17 16:00:46.578545]: [Epoch: 49(3.268845897264843%): Data: 50.66666666666667%]:Running loss: 10.19827726483345
[2018-04-17 16:00:50.234767]: Test set accuracy: 94.33962264150944% ,loss = 6.5100111067295074
[2018-04-17 16:00:50.348570]: ====================
[2018-04-17 16:00:50.355087]: Elapsed time since starting training: 0:05:35.750785
[2018-04-17 16:00:50.361103]: ====================
[2018-04-17 16:00:50.436310]: [Epoch: 50(3.3355570380253505%): Data: 0.0%]:Running loss: 0.2604004442691803
[2018-04-17 16:00:51.761852]: [Epoch: 50(3.3355570380253505%): Data: 25.333333333333336%]:Running loss: 5.204367637634277
[2018-04-17 16:00:53.076339]: [Epoch: 50(3.3355570380253505%): Data: 50.66666666666667%]:Running loss: 10.14147436618805
[2018-04-17 16:00:56.777200]: Test set accuracy: 94.33962264150944% ,loss = 6.474731862545013
[2018-04-17 16:00:56.882480]: ====================
[2018-04-17 16:00:56.889499]: Elapsed time since starting training: 0:05:42.285197
[2018-04-17 16:00:56.895515]: ====================
[2018-04-17 16:00:56.973737]: [Epoch: 51(3.402268178785857%): Data: 0.0%]:Running loss: 0.25898927450180054
[2018-04-17 16:00:58.312786]: [Epoch: 51(3.402268178785857%): Data: 25.333333333333336%]:Running loss: 5.176296085119247
[2018-04-17 16:00:59.633796]: [Epoch: 51(3.402268178785857%): Data: 50.66666666666667%]:Running loss: 10.087024450302124
[2018-04-17 16:01:03.365009]: Test set accuracy: 94.33962264150944% ,loss = 6.440898030996323
[2018-04-17 16:01:03.496360]: ====================
[2018-04-17 16:01:03.502877]: Elapsed time since starting training: 0:05:48.898574
[2018-04-17 16:01:03.509895]: ====================
[2018-04-17 16:01:03.584121]: [Epoch: 52(3.468979319546364%): Data: 0.0%]:Running loss: 0.2576359212398529
[2018-04-17 16:01:04.927712]: [Epoch: 52(3.468979319546364%): Data: 25.333333333333336%]:Running loss: 5.149375885725021
[2018-04-17 16:01:06.265308]: [Epoch: 52(3.468979319546364%): Data: 50.66666666666667%]:Running loss: 10.034805536270142
[2018-04-17 16:01:09.994911]: Test set accuracy: 94.33962264150944% ,loss = 6.4084492623806
[2018-04-17 16:01:10.101692]: ====================
[2018-04-17 16:01:10.108711]: Elapsed time since starting training: 0:05:55.504409
[2018-04-17 16:01:10.115228]: ====================
[2018-04-17 16:01:10.189425]: [Epoch: 53(3.5356904603068715%): Data: 0.0%]:Running loss: 0.256337970495224
[2018-04-17 16:01:11.505425]: [Epoch: 53(3.5356904603068715%): Data: 25.333333333333336%]:Running loss: 5.1235491335392
[2018-04-17 16:01:12.816410]: [Epoch: 53(3.5356904603068715%): Data: 50.66666666666667%]:Running loss: 9.984705358743668
[2018-04-17 16:01:16.495753]: Test set accuracy: 94.33962264150944% ,loss = 6.377297639846802
[2018-04-17 16:01:16.605546]: ====================
[2018-04-17 16:01:16.611562]: Elapsed time since starting training: 0:06:02.007761
[2018-04-17 16:01:16.617076]: ====================
[2018-04-17 16:01:16.690772]: [Epoch: 54(3.602401601067378%): Data: 0.0%]:Running loss: 0.25509190559387207
[2018-04-17 16:01:17.971678]: [Epoch: 54(3.602401601067378%): Data: 25.333333333333336%]:Running loss: 5.098759740591049
[2018-04-17 16:01:19.304222]: [Epoch: 54(3.602401601067378%): Data: 50.66666666666667%]:Running loss: 9.936614483594894
[2018-04-17 16:01:22.971527]: Test set accuracy: 94.33962264150944% ,loss = 6.347399204969406
[2018-04-17 16:01:23.097366]: ====================
[2018-04-17 16:01:23.103879]: Elapsed time since starting training: 0:06:08.500078
[2018-04-17 16:01:23.109895]: ====================
[2018-04-17 16:01:23.184593]: [Epoch: 55(3.6691127418278855%): Data: 0.0%]:Running loss: 0.25389596819877625
[2018-04-17 16:01:24.510619]: [Epoch: 55(3.6691127418278855%): Data: 25.333333333333336%]:Running loss: 5.074957758188248
[2018-04-17 16:01:25.800549]: [Epoch: 55(3.6691127418278855%): Data: 50.66666666666667%]:Running loss: 9.890436381101608
[2018-04-17 16:01:29.530517]: Test set accuracy: 94.33962264150944% ,loss = 6.318666785955429
[2018-04-17 16:01:29.645334]: ====================
[2018-04-17 16:01:29.651348]: Elapsed time since starting training: 0:06:15.047547
[2018-04-17 16:01:29.657866]: ====================
[2018-04-17 16:01:29.733066]: [Epoch: 56(3.7358238825883925%): Data: 0.0%]:Running loss: 0.25274667143821716
[2018-04-17 16:01:31.078643]: [Epoch: 56(3.7358238825883925%): Data: 25.333333333333336%]:Running loss: 5.052094250917435
[2018-04-17 16:01:32.393139]: [Epoch: 56(3.7358238825883925%): Data: 50.66666666666667%]:Running loss: 9.846077233552933
[2018-04-17 16:01:36.027922]: Test set accuracy: 94.33962264150944% ,loss = 6.291067600250244
[2018-04-17 16:01:36.137714]: ====================
[2018-04-17 16:01:36.144732]: Elapsed time since starting training: 0:06:21.540931
[2018-04-17 16:01:36.150749]: ====================
[2018-04-17 16:01:36.223944]: [Epoch: 57(3.802535023348899%): Data: 0.0%]:Running loss: 0.25164270401000977
[2018-04-17 16:01:37.555999]: [Epoch: 57(3.802535023348899%): Data: 25.333333333333336%]:Running loss: 5.030123949050903
[2018-04-17 16:01:38.848938]: [Epoch: 57(3.802535023348899%): Data: 50.66666666666667%]:Running loss: 9.803446978330612
[2018-04-17 16:01:42.532231]: Test set accuracy: 94.33962264150944% ,loss = 6.2645286321640015
[2018-04-17 16:01:42.642527]: ====================
[2018-04-17 16:01:42.648541]: Elapsed time since starting training: 0:06:28.044740
[2018-04-17 16:01:42.655059]: ====================
[2018-04-17 16:01:42.729255]: [Epoch: 58(3.8692461641094065%): Data: 0.0%]:Running loss: 0.25058114528656006
[2018-04-17 16:01:44.048779]: [Epoch: 58(3.8692461641094065%): Data: 25.333333333333336%]:Running loss: 5.009000301361084
[2018-04-17 16:01:45.359264]: [Epoch: 58(3.8692461641094065%): Data: 50.66666666666667%]:Running loss: 9.76246190071106
[2018-04-17 16:01:49.061682]: Test set accuracy: 94.33962264150944% ,loss = 6.239018961787224
[2018-04-17 16:01:49.182002]: ====================
[2018-04-17 16:01:49.187517]: Elapsed time since starting training: 0:06:34.583716
[2018-04-17 16:01:49.194034]: ====================
[2018-04-17 16:01:49.274249]: [Epoch: 59(3.935957304869913%): Data: 0.0%]:Running loss: 0.24956075847148895
[2018-04-17 16:01:50.601777]: [Epoch: 59(3.935957304869913%): Data: 25.333333333333336%]:Running loss: 4.988686099648476
[2018-04-17 16:01:51.913796]: [Epoch: 59(3.935957304869913%): Data: 50.66666666666667%]:Running loss: 9.72304131090641
[2018-04-17 16:01:55.573580]: Test set accuracy: 94.33962264150944% ,loss = 6.214464828372002
[2018-04-17 16:01:55.715958]: ====================
[2018-04-17 16:01:55.722476]: Elapsed time since starting training: 0:06:41.118675
[2018-04-17 16:01:55.729544]: ====================
[2018-04-17 16:01:55.801736]: [Epoch: 60(4.0026684456304205%): Data: 0.0%]:Running loss: 0.24857859313488007
[2018-04-17 16:01:57.145313]: [Epoch: 60(4.0026684456304205%): Data: 25.333333333333336%]:Running loss: 4.969141587615013
[2018-04-17 16:01:58.480864]: [Epoch: 60(4.0026684456304205%): Data: 50.66666666666667%]:Running loss: 9.685116454958916
[2018-04-17 16:02:02.215795]: Test set accuracy: 94.33962264150944% ,loss = 6.190847605466843
[2018-04-17 16:02:02.351657]: ====================
[2018-04-17 16:02:02.357172]: Elapsed time since starting training: 0:06:47.753371
[2018-04-17 16:02:02.363689]: ====================
[2018-04-17 16:02:02.428863]: [Epoch: 61(4.0693795863909275%): Data: 0.0%]:Running loss: 0.2476339042186737
[2018-04-17 16:02:03.719293]: [Epoch: 61(4.0693795863909275%): Data: 25.333333333333336%]:Running loss: 4.950332894921303
[2018-04-17 16:02:05.058364]: [Epoch: 61(4.0693795863909275%): Data: 50.66666666666667%]:Running loss: 9.648615285754204
[2018-04-17 16:02:08.724651]: Test set accuracy: 94.33962264150944% ,loss = 6.1680953949689865
[2018-04-17 16:02:08.857003]: ====================
[2018-04-17 16:02:08.863019]: Elapsed time since starting training: 0:06:54.258716
[2018-04-17 16:02:08.869036]: ====================
[2018-04-17 16:02:08.944235]: [Epoch: 62(4.136090727151434%): Data: 0.0%]:Running loss: 0.24672381579875946
[2018-04-17 16:02:10.258249]: [Epoch: 62(4.136090727151434%): Data: 25.333333333333336%]:Running loss: 4.932225719094276
[2018-04-17 16:02:11.615357]: [Epoch: 62(4.136090727151434%): Data: 50.66666666666667%]:Running loss: 9.6134732067585
[2018-04-17 16:02:15.292646]: Test set accuracy: 94.33962264150944% ,loss = 6.146201863884926
[2018-04-17 16:02:15.405948]: ====================
[2018-04-17 16:02:15.411964]: Elapsed time since starting training: 0:07:00.808163
[2018-04-17 16:02:15.418481]: ====================
[2018-04-17 16:02:15.492678]: [Epoch: 63(4.202801867911941%): Data: 0.0%]:Running loss: 0.24584807455539703
[2018-04-17 16:02:16.777094]: [Epoch: 63(4.202801867911941%): Data: 25.333333333333336%]:Running loss: 4.914785951375961
[2018-04-17 16:02:18.096608]: [Epoch: 63(4.202801867911941%): Data: 50.66666666666667%]:Running loss: 9.579625591635704
[2018-04-17 16:02:21.863127]: Test set accuracy: 94.33962264150944% ,loss = 6.1250951141119
[2018-04-17 16:02:22.082211]: ====================
[2018-04-17 16:02:22.089229]: Elapsed time since starting training: 0:07:07.484927
[2018-04-17 16:02:22.095747]: ====================
[2018-04-17 16:02:22.171450]: [Epoch: 64(4.2695130086724475%): Data: 0.0%]:Running loss: 0.245003804564476
[2018-04-17 16:02:23.462380]: [Epoch: 64(4.2695130086724475%): Data: 25.333333333333336%]:Running loss: 4.897984221577644
[2018-04-17 16:02:24.773868]: [Epoch: 64(4.2695130086724475%): Data: 50.66666666666667%]:Running loss: 9.54701629281044
[2018-04-17 16:02:28.423093]: Test set accuracy: 94.33962264150944% ,loss = 6.104760617017746
[2018-04-17 16:02:28.530379]: ====================
[2018-04-17 16:02:28.536896]: Elapsed time since starting training: 0:07:13.933095
[2018-04-17 16:02:28.542912]: ====================
[2018-04-17 16:02:28.619114]: [Epoch: 65(4.336224149432955%): Data: 0.0%]:Running loss: 0.24419042468070984
[2018-04-17 16:02:29.922580]: [Epoch: 65(4.336224149432955%): Data: 25.333333333333336%]:Running loss: 4.881791427731514
[2018-04-17 16:02:31.270164]: [Epoch: 65(4.336224149432955%): Data: 50.66666666666667%]:Running loss: 9.515586599707603
[2018-04-17 16:02:34.953457]: Test set accuracy: 94.33962264150944% ,loss = 6.085161492228508
[2018-04-17 16:02:35.095334]: ====================
[2018-04-17 16:02:35.101853]: Elapsed time since starting training: 0:07:20.498052
[2018-04-17 16:02:35.107869]: ====================
[2018-04-17 16:02:35.182569]: [Epoch: 66(4.402935290193462%): Data: 0.0%]:Running loss: 0.24340645968914032
[2018-04-17 16:02:36.459486]: [Epoch: 66(4.402935290193462%): Data: 25.333333333333336%]:Running loss: 4.8661829829216
[2018-04-17 16:02:37.784152]: [Epoch: 66(4.402935290193462%): Data: 50.66666666666667%]:Running loss: 9.485287383198738
[2018-04-17 16:02:41.495552]: Test set accuracy: 94.33962264150944% ,loss = 6.066254898905754
[2018-04-17 16:02:41.607350]: ====================
[2018-04-17 16:02:41.613868]: Elapsed time since starting training: 0:07:27.009565
[2018-04-17 16:02:41.619383]: ====================
[2018-04-17 16:02:41.689568]: [Epoch: 67(4.469646430953969%): Data: 0.0%]:Running loss: 0.24265019595623016
[2018-04-17 16:02:42.978997]: [Epoch: 67(4.469646430953969%): Data: 25.333333333333336%]:Running loss: 4.851128324866295
[2018-04-17 16:02:44.272937]: [Epoch: 67(4.469646430953969%): Data: 50.66666666666667%]:Running loss: 9.456066325306892
[2018-04-17 16:02:47.855093]: Test set accuracy: 94.33962264150944% ,loss = 6.0480184853076935
[2018-04-17 16:02:47.971403]: ====================
[2018-04-17 16:02:47.977931]: Elapsed time since starting training: 0:07:33.373628
[2018-04-17 16:02:47.983947]: ====================
[2018-04-17 16:02:48.056640]: [Epoch: 68(4.536357571714476%): Data: 0.0%]:Running loss: 0.24192073941230774
[2018-04-17 16:02:49.398207]: [Epoch: 68(4.536357571714476%): Data: 25.333333333333336%]:Running loss: 4.836608320474625
[2018-04-17 16:02:50.645022]: [Epoch: 68(4.536357571714476%): Data: 50.66666666666667%]:Running loss: 9.427879646420479
[2018-04-17 16:02:54.213511]: Test set accuracy: 94.33962264150944% ,loss = 6.0304272919893265
[2018-04-17 16:02:54.349373]: ====================
[2018-04-17 16:02:54.355389]: Elapsed time since starting training: 0:07:39.751588
[2018-04-17 16:02:54.361404]: ====================
[2018-04-17 16:02:54.434298]: [Epoch: 69(4.603068712474983%): Data: 0.0%]:Running loss: 0.24121709167957306
[2018-04-17 16:02:55.727235]: [Epoch: 69(4.603068712474983%): Data: 25.333333333333336%]:Running loss: 4.822596549987793
[2018-04-17 16:02:57.075319]: [Epoch: 69(4.603068712474983%): Data: 50.66666666666667%]:Running loss: 9.400678917765617
[2018-04-17 16:03:00.838826]: Test set accuracy: 94.33962264150944% ,loss = 6.013442948460579
[2018-04-17 16:03:00.971680]: ====================
[2018-04-17 16:03:00.979701]: Elapsed time since starting training: 0:07:46.375399
[2018-04-17 16:03:00.985717]: ====================
[2018-04-17 16:03:01.074453]: [Epoch: 70(4.66977985323549%): Data: 0.0%]:Running loss: 0.24053771793842316
[2018-04-17 16:03:02.406495]: [Epoch: 70(4.66977985323549%): Data: 25.333333333333336%]:Running loss: 4.809072896838188
[2018-04-17 16:03:03.743551]: [Epoch: 70(4.66977985323549%): Data: 50.66666666666667%]:Running loss: 9.37442460656166
[2018-04-17 16:03:07.352145]: Test set accuracy: 94.33962264150944% ,loss = 5.9970516711473465
[2018-04-17 16:03:07.477479]: ====================
[2018-04-17 16:03:07.484498]: Elapsed time since starting training: 0:07:52.880196
[2018-04-17 16:03:07.491517]: ====================
[2018-04-17 16:03:07.562205]: [Epoch: 71(4.736490993995997%): Data: 0.0%]:Running loss: 0.23988206684589386
[2018-04-17 16:03:08.885222]: [Epoch: 71(4.736490993995997%): Data: 25.333333333333336%]:Running loss: 4.796014502644539
[2018-04-17 16:03:10.173146]: [Epoch: 71(4.736490993995997%): Data: 50.66666666666667%]:Running loss: 9.349074140191078
[2018-04-17 16:03:13.880004]: Test set accuracy: 94.33962264150944% ,loss = 5.98122626543045
[2018-04-17 16:03:14.010350]: ====================
[2018-04-17 16:03:14.016868]: Elapsed time since starting training: 0:07:59.412565
[2018-04-17 16:03:14.022392]: ====================
[2018-04-17 16:03:14.096077]: [Epoch: 72(4.803202134756504%): Data: 0.0%]:Running loss: 0.23924905061721802
[2018-04-17 16:03:15.387010]: [Epoch: 72(4.803202134756504%): Data: 25.333333333333336%]:Running loss: 4.783406555652618
[2018-04-17 16:03:16.680449]: [Epoch: 72(4.803202134756504%): Data: 50.66666666666667%]:Running loss: 9.324596464633942
[2018-04-17 16:03:20.368272]: Test set accuracy: 94.33962264150944% ,loss = 5.965923890471458
[2018-04-17 16:03:20.514663]: ====================
[2018-04-17 16:03:20.522684]: Elapsed time since starting training: 0:08:05.918381
[2018-04-17 16:03:20.531707]: ====================
[2018-04-17 16:03:20.605905]: [Epoch: 73(4.869913275517011%): Data: 0.0%]:Running loss: 0.23863695561885834
[2018-04-17 16:03:21.869765]: [Epoch: 73(4.869913275517011%): Data: 25.333333333333336%]:Running loss: 4.7712254375219345
[2018-04-17 16:03:23.159201]: [Epoch: 73(4.869913275517011%): Data: 50.66666666666667%]:Running loss: 9.300945818424225
[2018-04-17 16:03:26.883103]: Test set accuracy: 94.33962264150944% ,loss = 5.951152369379997
[2018-04-17 16:03:27.013951]: ====================
[2018-04-17 16:03:27.019967]: Elapsed time since starting training: 0:08:12.416166
[2018-04-17 16:03:27.026484]: ====================
[2018-04-17 16:03:27.102186]: [Epoch: 74(4.936624416277518%): Data: 0.0%]:Running loss: 0.2380460947751999
[2018-04-17 16:03:28.416191]: [Epoch: 74(4.936624416277518%): Data: 25.333333333333336%]:Running loss: 4.75945582985878
[2018-04-17 16:03:29.745225]: [Epoch: 74(4.936624416277518%): Data: 50.66666666666667%]:Running loss: 9.278093934059143
[2018-04-17 16:03:33.370364]: Test set accuracy: 94.33962264150944% ,loss = 5.936874076724052
[2018-04-17 16:03:33.487175]: ====================
[2018-04-17 16:03:33.493191]: Elapsed time since starting training: 0:08:18.889390
[2018-04-17 16:03:33.499709]: ====================
[2018-04-17 16:03:33.577414]: [Epoch: 75(5.003335557038025%): Data: 0.0%]:Running loss: 0.2374749630689621
[2018-04-17 16:03:34.878374]: [Epoch: 75(5.003335557038025%): Data: 25.333333333333336%]:Running loss: 4.748081237077713
[2018-04-17 16:03:36.178336]: [Epoch: 75(5.003335557038025%): Data: 50.66666666666667%]:Running loss: 9.256008118391037
[2018-04-17 16:03:39.807987]: Test set accuracy: 94.33962264150944% ,loss = 5.923065543174744
[2018-04-17 16:03:39.935326]: ====================
[2018-04-17 16:03:39.941342]: Elapsed time since starting training: 0:08:25.337541
[2018-04-17 16:03:39.948361]: ====================
[2018-04-17 16:03:40.024062]: [Epoch: 76(5.070046697798532%): Data: 0.0%]:Running loss: 0.23692262172698975
[2018-04-17 16:03:41.309981]: [Epoch: 76(5.070046697798532%): Data: 25.333333333333336%]:Running loss: 4.7370825707912445
[2018-04-17 16:03:42.600915]: [Epoch: 76(5.070046697798532%): Data: 50.66666666666667%]:Running loss: 9.23465196788311
[2018-04-17 16:03:46.186056]: Test set accuracy: 94.33962264150944% ,loss = 5.909723788499832
[2018-04-17 16:03:46.300361]: ====================
[2018-04-17 16:03:46.311890]: Elapsed time since starting training: 0:08:31.708089
[2018-04-17 16:03:46.318409]: ====================
[2018-04-17 16:03:46.402131]: [Epoch: 77(5.136757838559039%): Data: 0.0%]:Running loss: 0.2363889515399933
[2018-04-17 16:03:47.699581]: [Epoch: 77(5.136757838559039%): Data: 25.333333333333336%]:Running loss: 4.726449221372604
[2018-04-17 16:03:49.000039]: [Epoch: 77(5.136757838559039%): Data: 50.66666666666667%]:Running loss: 9.214003920555115
[2018-04-17 16:03:52.653755]: Test set accuracy: 94.33962264150944% ,loss = 5.896805971860886
[2018-04-17 16:03:52.780592]: ====================
[2018-04-17 16:03:52.786615]: Elapsed time since starting training: 0:08:38.182814
[2018-04-17 16:03:52.793124]: ====================
[2018-04-17 16:03:52.866831]: [Epoch: 78(5.203468979319546%): Data: 0.0%]:Running loss: 0.23587223887443542
[2018-04-17 16:03:54.192020]: [Epoch: 78(5.203468979319546%): Data: 25.333333333333336%]:Running loss: 4.716163128614426
[2018-04-17 16:03:55.483454]: [Epoch: 78(5.203468979319546%): Data: 50.66666666666667%]:Running loss: 9.194029331207275
[2018-04-17 16:03:59.011335]: Test set accuracy: 94.33962264150944% ,loss = 5.884318053722382
[2018-04-17 16:03:59.138673]: ====================
[2018-04-17 16:03:59.145191]: Elapsed time since starting training: 0:08:44.540888
[2018-04-17 16:03:59.151708]: ====================
[2018-04-17 16:03:59.225414]: [Epoch: 79(5.270180120080053%): Data: 0.0%]:Running loss: 0.23537272214889526
[2018-04-17 16:04:00.507834]: [Epoch: 79(5.270180120080053%): Data: 25.333333333333336%]:Running loss: 4.706212937831879
[2018-04-17 16:04:01.770717]: [Epoch: 79(5.270180120080053%): Data: 50.66666666666667%]:Running loss: 9.174706384539604
[2018-04-17 16:04:05.392449]: Test set accuracy: 94.33962264150944% ,loss = 5.872228369116783
[2018-04-17 16:04:05.518785]: ====================
[2018-04-17 16:04:05.524801]: Elapsed time since starting training: 0:08:50.921000
[2018-04-17 16:04:05.531819]: ====================
[2018-04-17 16:04:05.605014]: [Epoch: 80(5.33689126084056%): Data: 0.0%]:Running loss: 0.23488913476467133
[2018-04-17 16:04:06.885418]: [Epoch: 80(5.33689126084056%): Data: 25.333333333333336%]:Running loss: 4.696581557393074
[2018-04-17 16:04:08.231497]: [Epoch: 80(5.33689126084056%): Data: 50.66666666666667%]:Running loss: 9.156005188822746
[2018-04-17 16:04:11.911295]: Test set accuracy: 94.33962264150944% ,loss = 5.860531702637672
[2018-04-17 16:04:12.062711]: ====================
[2018-04-17 16:04:12.069226]: Elapsed time since starting training: 0:08:57.464924
[2018-04-17 16:04:12.075744]: ====================
[2018-04-17 16:04:12.150442]: [Epoch: 81(5.403602401601067%): Data: 0.0%]:Running loss: 0.2344212681055069
[2018-04-17 16:04:13.484489]: [Epoch: 81(5.403602401601067%): Data: 25.333333333333336%]:Running loss: 4.687263131141663
[2018-04-17 16:04:14.818543]: [Epoch: 81(5.403602401601067%): Data: 50.66666666666667%]:Running loss: 9.137904956936836
[2018-04-17 16:04:18.436162]: Test set accuracy: 94.33962264150944% ,loss = 5.849208310246468
[2018-04-17 16:04:18.586060]: ====================
[2018-04-17 16:04:18.591577]: Elapsed time since starting training: 0:09:03.987776
[2018-04-17 16:04:18.597591]: ====================
[2018-04-17 16:04:18.672796]: [Epoch: 82(5.470313542361574%): Data: 0.0%]:Running loss: 0.2339683324098587
[2018-04-17 16:04:19.948683]: [Epoch: 82(5.470313542361574%): Data: 25.333333333333336%]:Running loss: 4.678238123655319
[2018-04-17 16:04:21.209035]: [Epoch: 82(5.470313542361574%): Data: 50.66666666666667%]:Running loss: 9.1203792989254
[2018-04-17 16:04:24.837684]: Test set accuracy: 94.33962264150944% ,loss = 5.838233977556229
[2018-04-17 16:04:24.948980]: ====================
[2018-04-17 16:04:24.958003]: Elapsed time since starting training: 0:09:10.354202
[2018-04-17 16:04:24.967028]: ====================
[2018-04-17 16:04:25.052254]: [Epoch: 83(5.537024683122081%): Data: 0.0%]:Running loss: 0.23352935910224915
[2018-04-17 16:04:26.346194]: [Epoch: 83(5.537024683122081%): Data: 25.333333333333336%]:Running loss: 4.669499173760414
[2018-04-17 16:04:27.617591]: [Epoch: 83(5.537024683122081%): Data: 50.66666666666667%]:Running loss: 9.103408560156822
[2018-04-17 16:04:31.169043]: Test set accuracy: 94.33962264150944% ,loss = 5.827616900205612
[2018-04-17 16:04:31.282347]: ====================
[2018-04-17 16:04:31.291871]: Elapsed time since starting training: 0:09:16.687568
[2018-04-17 16:04:31.299891]: ====================
[2018-04-17 16:04:31.375092]: [Epoch: 84(5.603735823882588%): Data: 0.0%]:Running loss: 0.2331046760082245
[2018-04-17 16:04:32.671037]: [Epoch: 84(5.603735823882588%): Data: 25.333333333333336%]:Running loss: 4.661035925149918
[2018-04-17 16:04:33.946930]: [Epoch: 84(5.603735823882588%): Data: 50.66666666666667%]:Running loss: 9.086972191929817
[2018-04-17 16:04:37.550624]: Test set accuracy: 94.33962264150944% ,loss = 5.817324668169022
[2018-04-17 16:04:37.661420]: ====================
[2018-04-17 16:04:37.667435]: Elapsed time since starting training: 0:09:23.063634
[2018-04-17 16:04:37.673953]: ====================
[2018-04-17 16:04:37.748159]: [Epoch: 85(5.670446964643095%): Data: 0.0%]:Running loss: 0.23269298672676086
[2018-04-17 16:04:39.059637]: [Epoch: 85(5.670446964643095%): Data: 25.333333333333336%]:Running loss: 4.652837306261063
[2018-04-17 16:04:40.412246]: [Epoch: 85(5.670446964643095%): Data: 50.66666666666667%]:Running loss: 9.071048110723495
[2018-04-17 16:04:44.154236]: Test set accuracy: 94.33962264150944% ,loss = 5.807356536388397
[2018-04-17 16:04:44.269543]: ====================
[2018-04-17 16:04:44.276561]: Elapsed time since starting training: 0:09:29.672760
[2018-04-17 16:04:44.282578]: ====================
[2018-04-17 16:04:44.357275]: [Epoch: 86(5.737158105403602%): Data: 0.0%]:Running loss: 0.2322942614555359
[2018-04-17 16:04:45.683837]: [Epoch: 86(5.737158105403602%): Data: 25.333333333333336%]:Running loss: 4.6448937356472015
[2018-04-17 16:04:47.000352]: [Epoch: 86(5.737158105403602%): Data: 50.66666666666667%]:Running loss: 9.055618539452553
[2018-04-17 16:04:50.730318]: Test set accuracy: 94.33962264150944% ,loss = 5.797699838876724
[2018-04-17 16:04:50.850136]: ====================
[2018-04-17 16:04:50.856152]: Elapsed time since starting training: 0:09:36.251850
[2018-04-17 16:04:50.862169]: ====================
[2018-04-17 16:04:50.937870]: [Epoch: 87(5.803869246164109%): Data: 0.0%]:Running loss: 0.23190799355506897
[2018-04-17 16:04:52.259405]: [Epoch: 87(5.803869246164109%): Data: 25.333333333333336%]:Running loss: 4.637194663286209
[2018-04-17 16:04:53.638071]: [Epoch: 87(5.803869246164109%): Data: 50.66666666666667%]:Running loss: 9.040664926171303
[2018-04-17 16:04:57.322951]: Test set accuracy: 94.33962264150944% ,loss = 5.788330361247063
[2018-04-17 16:04:57.453298]: ====================
[2018-04-17 16:04:57.459314]: Elapsed time since starting training: 0:09:42.855513
[2018-04-17 16:04:57.467335]: ====================
[2018-04-17 16:04:57.542545]: [Epoch: 88(5.870580386924616%): Data: 0.0%]:Running loss: 0.2315332144498825
[2018-04-17 16:04:58.932230]: [Epoch: 88(5.870580386924616%): Data: 25.333333333333336%]:Running loss: 4.62973353266716
[2018-04-17 16:05:00.279813]: [Epoch: 88(5.870580386924616%): Data: 50.66666666666667%]:Running loss: 9.026170909404755
[2018-04-17 16:05:04.049838]: Test set accuracy: 94.33962264150944% ,loss = 5.779251083731651
[2018-04-17 16:05:04.165144]: ====================
[2018-04-17 16:05:04.171662]: Elapsed time since starting training: 0:09:49.567359
[2018-04-17 16:05:04.177678]: ====================
[2018-04-17 16:05:04.253888]: [Epoch: 89(5.937291527685123%): Data: 0.0%]:Running loss: 0.23117004334926605
[2018-04-17 16:05:05.553335]: [Epoch: 89(5.937291527685123%): Data: 25.333333333333336%]:Running loss: 4.6224958300590515
[2018-04-17 16:05:06.839255]: [Epoch: 89(5.937291527685123%): Data: 50.66666666666667%]:Running loss: 9.012114092707634
[2018-04-17 16:05:10.454410]: Test set accuracy: 94.33962264150944% ,loss = 5.770447477698326
[2018-04-17 16:05:10.567209]: ====================
[2018-04-17 16:05:10.573727]: Elapsed time since starting training: 0:09:55.969926
[2018-04-17 16:05:10.579743]: ====================
[2018-04-17 16:05:10.651935]: [Epoch: 90(6.004002668445631%): Data: 0.0%]:Running loss: 0.23081789910793304
[2018-04-17 16:05:11.990996]: [Epoch: 90(6.004002668445631%): Data: 25.333333333333336%]:Running loss: 4.615479424595833
[2018-04-17 16:05:13.290953]: [Epoch: 90(6.004002668445631%): Data: 50.66666666666667%]:Running loss: 8.998484700918198
[2018-04-17 16:05:16.945210]: Test set accuracy: 94.33962264150944% ,loss = 5.761908739805222
[2018-04-17 16:05:17.052996]: ====================
[2018-04-17 16:05:17.058010]: Elapsed time since starting training: 0:10:02.454209
[2018-04-17 16:05:17.064025]: ====================
[2018-04-17 16:05:17.136229]: [Epoch: 91(6.070713809206137%): Data: 0.0%]:Running loss: 0.23047634959220886
[2018-04-17 16:05:18.482296]: [Epoch: 91(6.070713809206137%): Data: 25.333333333333336%]:Running loss: 4.608674630522728
[2018-04-17 16:05:19.796791]: [Epoch: 91(6.070713809206137%): Data: 50.66666666666667%]:Running loss: 8.985266521573067
[2018-04-17 16:05:23.493621]: Test set accuracy: 94.33962264150944% ,loss = 5.753622949123383
[2018-04-17 16:05:23.609429]: ====================
[2018-04-17 16:05:23.616448]: Elapsed time since starting training: 0:10:09.012146
[2018-04-17 16:05:23.623467]: ====================
[2018-04-17 16:05:23.701173]: [Epoch: 92(6.137424949966644%): Data: 0.0%]:Running loss: 0.2301449179649353
[2018-04-17 16:05:25.021684]: [Epoch: 92(6.137424949966644%): Data: 25.333333333333336%]:Running loss: 4.602072969079018
[2018-04-17 16:05:26.352222]: [Epoch: 92(6.137424949966644%): Data: 50.66666666666667%]:Running loss: 8.972442761063576
[2018-04-17 16:05:30.062741]: Test set accuracy: 94.33962264150944% ,loss = 5.74558824300766
[2018-04-17 16:05:30.162005]: ====================
[2018-04-17 16:05:30.167519]: Elapsed time since starting training: 0:10:15.563718
[2018-04-17 16:05:30.173535]: ====================
[2018-04-17 16:05:30.247231]: [Epoch: 93(6.204136090727151%): Data: 0.0%]:Running loss: 0.2298235297203064
[2018-04-17 16:05:31.564234]: [Epoch: 93(6.204136090727151%): Data: 25.333333333333336%]:Running loss: 4.59566804766655
[2018-04-17 16:05:32.885766]: [Epoch: 93(6.204136090727151%): Data: 50.66666666666667%]:Running loss: 8.960000395774841
[2018-04-17 16:05:36.503904]: Test set accuracy: 94.33962264150944% ,loss = 5.737786740064621
[2018-04-17 16:05:36.613696]: ====================
[2018-04-17 16:05:36.621216]: Elapsed time since starting training: 0:10:22.016914
[2018-04-17 16:05:36.627733]: ====================
[2018-04-17 16:05:36.700426]: [Epoch: 94(6.270847231487658%): Data: 0.0%]:Running loss: 0.22951146960258484
[2018-04-17 16:05:37.997877]: [Epoch: 94(6.270847231487658%): Data: 25.333333333333336%]:Running loss: 4.589452177286148
[2018-04-17 16:05:39.307872]: [Epoch: 94(6.270847231487658%): Data: 50.66666666666667%]:Running loss: 8.94792515039444
[2018-04-17 16:05:42.908958]: Test set accuracy: 94.33962264150944% ,loss = 5.730212852358818
[2018-04-17 16:05:43.021257]: ====================
[2018-04-17 16:05:43.027774]: Elapsed time since starting training: 0:10:28.423472
[2018-04-17 16:05:43.034292]: ====================
[2018-04-17 16:05:43.108488]: [Epoch: 95(6.337558372248166%): Data: 0.0%]:Running loss: 0.22920851409435272
[2018-04-17 16:05:44.456072]: [Epoch: 95(6.337558372248166%): Data: 25.333333333333336%]:Running loss: 4.583419978618622
[2018-04-17 16:05:45.786627]: [Epoch: 95(6.337558372248166%): Data: 50.66666666666667%]:Running loss: 8.936207205057144
[2018-04-17 16:05:49.425804]: Test set accuracy: 94.33962264150944% ,loss = 5.72287030518055
[2018-04-17 16:05:49.544621]: ====================
[2018-04-17 16:05:49.551138]: Elapsed time since starting training: 0:10:34.947337
[2018-04-17 16:05:49.557655]: ====================
[2018-04-17 16:05:49.634359]: [Epoch: 96(6.404269513008673%): Data: 0.0%]:Running loss: 0.22891481220722198
[2018-04-17 16:05:50.944342]: [Epoch: 96(6.404269513008673%): Data: 25.333333333333336%]:Running loss: 4.577564045786858
[2018-04-17 16:05:52.227758]: [Epoch: 96(6.404269513008673%): Data: 50.66666666666667%]:Running loss: 8.924829602241516
[2018-04-17 16:05:55.831873]: Test set accuracy: 94.33962264150944% ,loss = 5.715734884142876
[2018-04-17 16:05:55.944674]: ====================
[2018-04-17 16:05:55.950188]: Elapsed time since starting training: 0:10:41.346387
[2018-04-17 16:05:55.959714]: ====================
[2018-04-17 16:05:56.035916]: [Epoch: 97(6.470980653769179%): Data: 0.0%]:Running loss: 0.22862939536571503
[2018-04-17 16:05:57.327350]: [Epoch: 97(6.470980653769179%): Data: 25.333333333333336%]:Running loss: 4.571876809000969
[2018-04-17 16:05:58.629813]: [Epoch: 97(6.470980653769179%): Data: 50.66666666666667%]:Running loss: 8.91378253698349
[2018-04-17 16:06:02.256957]: Test set accuracy: 94.33962264150944% ,loss = 5.708805471658707
[2018-04-17 16:06:02.457003]: ====================
[2018-04-17 16:06:02.466528]: Elapsed time since starting training: 0:10:47.862225
[2018-04-17 16:06:02.473045]: ====================
[2018-04-17 16:06:02.549247]: [Epoch: 98(6.537691794529686%): Data: 0.0%]:Running loss: 0.22835221886634827
[2018-04-17 16:06:03.859145]: [Epoch: 98(6.537691794529686%): Data: 25.333333333333336%]:Running loss: 4.566357180476189
[2018-04-17 16:06:05.173640]: [Epoch: 98(6.537691794529686%): Data: 50.66666666666667%]:Running loss: 8.903057351708412
[2018-04-17 16:06:08.928123]: Test set accuracy: 94.33962264150944% ,loss = 5.702085047960281
[2018-04-17 16:06:09.042428]: ====================
[2018-04-17 16:06:09.048946]: Elapsed time since starting training: 0:10:54.444643
[2018-04-17 16:06:09.055963]: ====================
[2018-04-17 16:06:09.130620]: [Epoch: 99(6.604402935290193%): Data: 0.0%]:Running loss: 0.22808340191841125
[2018-04-17 16:06:10.455242]: [Epoch: 99(6.604402935290193%): Data: 25.333333333333336%]:Running loss: 4.560995236039162
[2018-04-17 16:06:11.785779]: [Epoch: 99(6.604402935290193%): Data: 50.66666666666667%]:Running loss: 8.89263878762722
[2018-04-17 16:06:15.517253]: Test set accuracy: 94.33962264150944% ,loss = 5.695547163486481
[2018-04-17 16:06:15.634564]: ====================
[2018-04-17 16:06:15.641082]: Elapsed time since starting training: 0:11:01.036779
[2018-04-17 16:06:15.647104]: ====================
[2018-04-17 16:06:15.723333]: [Epoch: 100(6.671114076050701%): Data: 0.0%]:Running loss: 0.22782188653945923
[2018-04-17 16:06:17.062896]: [Epoch: 100(6.671114076050701%): Data: 25.333333333333336%]:Running loss: 4.555785521864891
[2018-04-17 16:06:18.421508]: [Epoch: 100(6.671114076050701%): Data: 50.66666666666667%]:Running loss: 8.882518202066422
[2018-04-17 16:06:22.105302]: Test set accuracy: 94.33962264150944% ,loss = 5.6891947984695435
[2018-04-17 16:06:22.221621]: ====================
[2018-04-17 16:06:22.228129]: Elapsed time since starting training: 0:11:07.624328
[2018-04-17 16:06:22.233644]: ====================
[2018-04-17 16:06:22.307844]: [Epoch: 101(6.737825216811208%): Data: 0.0%]:Running loss: 0.22756779193878174
[2018-04-17 16:06:23.636875]: [Epoch: 101(6.737825216811208%): Data: 25.333333333333336%]:Running loss: 4.5507248640060425
[2018-04-17 16:06:24.947861]: [Epoch: 101(6.737825216811208%): Data: 50.66666666666667%]:Running loss: 8.872685715556145
[2018-04-17 16:06:28.588844]: Test set accuracy: 94.33962264150944% ,loss = 5.6830257177352905
[2018-04-17 16:06:28.708663]: ====================
[2018-04-17 16:06:28.715681]: Elapsed time since starting training: 0:11:14.111379
[2018-04-17 16:06:28.722700]: ====================
[2018-04-17 16:06:28.798401]: [Epoch: 102(6.804536357571714%): Data: 0.0%]:Running loss: 0.22732102870941162
[2018-04-17 16:06:30.141475]: [Epoch: 102(6.804536357571714%): Data: 25.333333333333336%]:Running loss: 4.545806869864464
[2018-04-17 16:06:31.448948]: [Epoch: 102(6.804536357571714%): Data: 50.66666666666667%]:Running loss: 8.863131165504456
[2018-04-17 16:06:35.166333]: Test set accuracy: 94.33962264150944% ,loss = 5.677032843232155
[2018-04-17 16:06:35.284146]: ====================
[2018-04-17 16:06:35.290664]: Elapsed time since starting training: 0:11:20.686362
[2018-04-17 16:06:35.296680]: ====================
[2018-04-17 16:06:35.370877]: [Epoch: 103(6.871247498332221%): Data: 0.0%]:Running loss: 0.2270813137292862
[2018-04-17 16:06:36.682866]: [Epoch: 103(6.871247498332221%): Data: 25.333333333333336%]:Running loss: 4.541029617190361
[2018-04-17 16:06:37.994866]: [Epoch: 103(6.871247498332221%): Data: 50.66666666666667%]:Running loss: 8.853847905993462
[2018-04-17 16:06:41.657594]: Test set accuracy: 94.33962264150944% ,loss = 5.671209841966629
[2018-04-17 16:06:41.769391]: ====================
[2018-04-17 16:06:41.776911]: Elapsed time since starting training: 0:11:27.172608
[2018-04-17 16:06:41.782926]: ====================
[2018-04-17 16:06:41.854617]: [Epoch: 104(6.937958639092728%): Data: 0.0%]:Running loss: 0.22684839367866516
[2018-04-17 16:06:43.150062]: [Epoch: 104(6.937958639092728%): Data: 25.333333333333336%]:Running loss: 4.536384731531143
[2018-04-17 16:06:44.434991]: [Epoch: 104(6.937958639092728%): Data: 50.66666666666667%]:Running loss: 8.844823122024536
[2018-04-17 16:06:48.066662]: Test set accuracy: 94.33962264150944% ,loss = 5.665541440248489
[2018-04-17 16:06:48.183110]: ====================
[2018-04-17 16:06:48.189124]: Elapsed time since starting training: 0:11:33.584821
[2018-04-17 16:06:48.194638]: ====================
[2018-04-17 16:06:48.267832]: [Epoch: 105(7.004669779853236%): Data: 0.0%]:Running loss: 0.22662165760993958
[2018-04-17 16:06:49.580323]: [Epoch: 105(7.004669779853236%): Data: 25.333333333333336%]:Running loss: 4.531869456171989
[2018-04-17 16:06:50.908354]: [Epoch: 105(7.004669779853236%): Data: 50.66666666666667%]:Running loss: 8.836049750447273
[2018-04-17 16:06:54.623244]: Test set accuracy: 94.33962264150944% ,loss = 5.6600309908390045
[2018-04-17 16:06:54.737548]: ====================
[2018-04-17 16:06:54.743564]: Elapsed time since starting training: 0:11:40.139763
[2018-04-17 16:06:54.749582]: ====================
[2018-04-17 16:06:54.822273]: [Epoch: 106(7.071380920613743%): Data: 0.0%]:Running loss: 0.22640123963356018
[2018-04-17 16:06:56.113206]: [Epoch: 106(7.071380920613743%): Data: 25.333333333333336%]:Running loss: 4.527480140328407
[2018-04-17 16:06:57.421710]: [Epoch: 106(7.071380920613743%): Data: 50.66666666666667%]:Running loss: 8.827520430088043
[2018-04-17 16:07:01.071912]: Test set accuracy: 94.33962264150944% ,loss = 5.654686689376831
[2018-04-17 16:07:01.188723]: ====================
[2018-04-17 16:07:01.195240]: Elapsed time since starting training: 0:11:46.591439
[2018-04-17 16:07:01.201256]: ====================
[2018-04-17 16:07:01.275955]: [Epoch: 107(7.13809206137425%): Data: 0.0%]:Running loss: 0.22618746757507324
[2018-04-17 16:07:02.571399]: [Epoch: 107(7.13809206137425%): Data: 25.333333333333336%]:Running loss: 4.523212105035782
[2018-04-17 16:07:03.849804]: [Epoch: 107(7.13809206137425%): Data: 50.66666666666667%]:Running loss: 8.819227680563927
[2018-04-17 16:07:07.405754]: Test set accuracy: 94.33962264150944% ,loss = 5.649472773075104
[2018-04-17 16:07:07.532090]: ====================
[2018-04-17 16:07:07.541615]: Elapsed time since starting training: 0:11:52.937814
[2018-04-17 16:07:07.547631]: ====================
[2018-04-17 16:07:07.624837]: [Epoch: 108(7.204803202134756%): Data: 0.0%]:Running loss: 0.22597891092300415
[2018-04-17 16:07:08.914766]: [Epoch: 108(7.204803202134756%): Data: 25.333333333333336%]:Running loss: 4.519060373306274
[2018-04-17 16:07:10.224749]: [Epoch: 108(7.204803202134756%): Data: 50.66666666666667%]:Running loss: 8.81116034090519
[2018-04-17 16:07:13.841880]: Test set accuracy: 94.33962264150944% ,loss = 5.644405633211136
[2018-04-17 16:07:13.955181]: ====================
[2018-04-17 16:07:13.961698]: Elapsed time since starting training: 0:11:59.357396
[2018-04-17 16:07:13.967715]: ====================
[2018-04-17 16:07:14.045421]: [Epoch: 109(7.271514342895263%): Data: 0.0%]:Running loss: 0.22577622532844543
[2018-04-17 16:07:15.383981]: [Epoch: 109(7.271514342895263%): Data: 25.333333333333336%]:Running loss: 4.5150217562913895
[2018-04-17 16:07:16.718027]: [Epoch: 109(7.271514342895263%): Data: 50.66666666666667%]:Running loss: 8.803314223885536
[2018-04-17 16:07:20.428398]: Test set accuracy: 94.33962264150944% ,loss = 5.639481917023659
[2018-04-17 16:07:20.534180]: ====================
[2018-04-17 16:07:20.540196]: Elapsed time since starting training: 0:12:05.936395
[2018-04-17 16:07:20.546212]: ====================
[2018-04-17 16:07:20.616899]: [Epoch: 110(7.338225483655771%): Data: 0.0%]:Running loss: 0.22557927668094635
[2018-04-17 16:07:21.929929]: [Epoch: 110(7.338225483655771%): Data: 25.333333333333336%]:Running loss: 4.511096924543381
[2018-04-17 16:07:23.217352]: [Epoch: 110(7.338225483655771%): Data: 50.66666666666667%]:Running loss: 8.795685485005379
[2018-04-17 16:07:26.829983]: Test set accuracy: 94.33962264150944% ,loss = 5.634698644280434
[2018-04-17 16:07:26.944778]: ====================
[2018-04-17 16:07:26.952297]: Elapsed time since starting training: 0:12:12.347994
[2018-04-17 16:07:26.958814]: ====================
[2018-04-17 16:07:27.033513]: [Epoch: 111(7.404936624416278%): Data: 0.0%]:Running loss: 0.22538794577121735
[2018-04-17 16:07:28.332467]: [Epoch: 111(7.404936624416278%): Data: 25.333333333333336%]:Running loss: 4.507275611162186
[2018-04-17 16:07:29.633927]: [Epoch: 111(7.404936624416278%): Data: 50.66666666666667%]:Running loss: 8.788260713219643
[2018-04-17 16:07:33.338277]: Test set accuracy: 94.33962264150944% ,loss = 5.630031600594521
[2018-04-17 16:07:33.456593]: ====================
[2018-04-17 16:07:33.462608]: Elapsed time since starting training: 0:12:18.858807
[2018-04-17 16:07:33.469125]: ====================
[2018-04-17 16:07:33.546832]: [Epoch: 112(7.471647765176785%): Data: 0.0%]:Running loss: 0.22520126402378082
[2018-04-17 16:07:34.878381]: [Epoch: 112(7.471647765176785%): Data: 25.333333333333336%]:Running loss: 4.503558099269867
[2018-04-17 16:07:36.214424]: [Epoch: 112(7.471647765176785%): Data: 50.66666666666667%]:Running loss: 8.781034871935844
[2018-04-17 16:07:39.909259]: Test set accuracy: 94.33962264150944% ,loss = 5.6254953145980835
[2018-04-17 16:07:40.028075]: ====================
[2018-04-17 16:07:40.035094]: Elapsed time since starting training: 0:12:25.431293
[2018-04-17 16:07:40.041611]: ====================
[2018-04-17 16:07:40.115808]: [Epoch: 113(7.538358905937291%): Data: 0.0%]:Running loss: 0.22501981258392334
[2018-04-17 16:07:41.462389]: [Epoch: 113(7.538358905937291%): Data: 25.333333333333336%]:Running loss: 4.499940142035484
[2018-04-17 16:07:42.756330]: [Epoch: 113(7.538358905937291%): Data: 50.66666666666667%]:Running loss: 8.774004861712456
[2018-04-17 16:07:46.410546]: Test set accuracy: 94.33962264150944% ,loss = 5.621079728007317
[2018-04-17 16:07:46.537885]: ====================
[2018-04-17 16:07:46.544904]: Elapsed time since starting training: 0:12:31.941103
[2018-04-17 16:07:46.551922]: ====================
[2018-04-17 16:07:46.629127]: [Epoch: 114(7.605070046697798%): Data: 0.0%]:Running loss: 0.22484318912029266
[2018-04-17 16:07:47.918054]: [Epoch: 114(7.605070046697798%): Data: 25.333333333333336%]:Running loss: 4.4964184165000916
[2018-04-17 16:07:49.214502]: [Epoch: 114(7.605070046697798%): Data: 50.66666666666667%]:Running loss: 8.76716098189354
[2018-04-17 16:07:52.882274]: Test set accuracy: 94.33962264150944% ,loss = 5.616769567131996
[2018-04-17 16:07:53.005102]: ====================
[2018-04-17 16:07:53.012119]: Elapsed time since starting training: 0:12:38.408318
[2018-04-17 16:07:53.018637]: ====================
[2018-04-17 16:07:53.094338]: [Epoch: 115(7.671781187458306%): Data: 0.0%]:Running loss: 0.22467078268527985
[2018-04-17 16:07:54.414347]: [Epoch: 115(7.671781187458306%): Data: 25.333333333333336%]:Running loss: 4.492991730570793
[2018-04-17 16:07:55.755914]: [Epoch: 115(7.671781187458306%): Data: 50.66666666666667%]:Running loss: 8.760501891374588
[2018-04-17 16:07:59.487350]: Test set accuracy: 94.33962264150944% ,loss = 5.612590536475182
[2018-04-17 16:07:59.613687]: ====================
[2018-04-17 16:07:59.620203]: Elapsed time since starting training: 0:12:45.016402
[2018-04-17 16:07:59.626722]: ====================
[2018-04-17 16:07:59.704428]: [Epoch: 116(7.738492328218813%): Data: 0.0%]:Running loss: 0.22450362145900726
[2018-04-17 16:08:01.030955]: [Epoch: 116(7.738492328218813%): Data: 25.333333333333336%]:Running loss: 4.489655628800392
[2018-04-17 16:08:02.341456]: [Epoch: 116(7.738492328218813%): Data: 50.66666666666667%]:Running loss: 8.754019394516945
[2018-04-17 16:08:06.006237]: Test set accuracy: 94.33962264150944% ,loss = 5.608521401882172
[2018-04-17 16:08:06.129565]: ====================
[2018-04-17 16:08:06.136083]: Elapsed time since starting training: 0:12:51.531780
[2018-04-17 16:08:06.142601]: ====================
[2018-04-17 16:08:06.219305]: [Epoch: 117(7.80520346897932%): Data: 0.0%]:Running loss: 0.22434085607528687
[2018-04-17 16:08:07.506226]: [Epoch: 117(7.80520346897932%): Data: 25.333333333333336%]:Running loss: 4.486408442258835
[2018-04-17 16:08:08.812198]: [Epoch: 117(7.80520346897932%): Data: 50.66666666666667%]:Running loss: 8.747706830501556
[2018-04-17 16:08:12.739691]: Test set accuracy: 94.33962264150944% ,loss = 5.604549124836922
[2018-04-17 16:08:12.874550]: ====================
[2018-04-17 16:08:12.881067]: Elapsed time since starting training: 0:12:58.276765
[2018-04-17 16:08:12.887586]: ====================
[2018-04-17 16:08:12.964790]: [Epoch: 118(7.871914609739826%): Data: 0.0%]:Running loss: 0.22418196499347687
[2018-04-17 16:08:14.307917]: [Epoch: 118(7.871914609739826%): Data: 25.333333333333336%]:Running loss: 4.483245298266411
[2018-04-17 16:08:15.626925]: [Epoch: 118(7.871914609739826%): Data: 50.66666666666667%]:Running loss: 8.741560310125351
[2018-04-17 16:08:19.277130]: Test set accuracy: 94.33962264150944% ,loss = 5.600683018565178
[2018-04-17 16:08:19.426027]: ====================
[2018-04-17 16:08:19.432544]: Elapsed time since starting training: 0:13:04.828743
[2018-04-17 16:08:19.438560]: ====================
[2018-04-17 16:08:19.512757]: [Epoch: 119(7.938625750500333%): Data: 0.0%]:Running loss: 0.22402732074260712
[2018-04-17 16:08:20.777620]: [Epoch: 119(7.938625750500333%): Data: 25.333333333333336%]:Running loss: 4.4801649153232574
[2018-04-17 16:08:22.042484]: [Epoch: 119(7.938625750500333%): Data: 50.66666666666667%]:Running loss: 8.735573694109917
[2018-04-17 16:08:25.665106]: Test set accuracy: 94.33962264150944% ,loss = 5.596927925944328
[2018-04-17 16:08:25.793447]: ====================
[2018-04-17 16:08:25.798962]: Elapsed time since starting training: 0:13:11.194660
[2018-04-17 16:08:25.805480]: ====================
[2018-04-17 16:08:25.883688]: [Epoch: 120(8.005336891260841%): Data: 0.0%]:Running loss: 0.22387711703777313
[2018-04-17 16:08:27.208712]: [Epoch: 120(8.005336891260841%): Data: 25.333333333333336%]:Running loss: 4.4771668165922165
[2018-04-17 16:08:28.546769]: [Epoch: 120(8.005336891260841%): Data: 50.66666666666667%]:Running loss: 8.729745253920555
[2018-04-17 16:08:32.359517]: Test set accuracy: 94.33962264150944% ,loss = 5.593258887529373
[2018-04-17 16:08:32.504904]: ====================
[2018-04-17 16:08:32.511421]: Elapsed time since starting training: 0:13:17.907620
[2018-04-17 16:08:32.517938]: ====================
[2018-04-17 16:08:32.594147]: [Epoch: 121(8.072048032021348%): Data: 0.0%]:Running loss: 0.22373035550117493
[2018-04-17 16:08:33.907633]: [Epoch: 121(8.072048032021348%): Data: 25.333333333333336%]:Running loss: 4.474242925643921
[2018-04-17 16:08:35.276229]: [Epoch: 121(8.072048032021348%): Data: 50.66666666666667%]:Running loss: 8.724064722657204
[2018-04-17 16:08:38.923771]: Test set accuracy: 94.33962264150944% ,loss = 5.589687451720238
[2018-04-17 16:08:39.050608]: ====================
[2018-04-17 16:08:39.056624]: Elapsed time since starting training: 0:13:24.452823
[2018-04-17 16:08:39.064145]: ====================
[2018-04-17 16:08:39.170246]: [Epoch: 122(8.138759172781855%): Data: 0.0%]:Running loss: 0.2235874980688095
[2018-04-17 16:08:40.439150]: [Epoch: 122(8.138759172781855%): Data: 25.333333333333336%]:Running loss: 4.471397086977959
[2018-04-17 16:08:41.797763]: [Epoch: 122(8.138759172781855%): Data: 50.66666666666667%]:Running loss: 8.718533486127853
[2018-04-17 16:08:45.568532]: Test set accuracy: 94.33962264150944% ,loss = 5.5862147361040115
[2018-04-17 16:08:45.726454]: ====================
[2018-04-17 16:08:45.732971]: Elapsed time since starting training: 0:13:31.129170
[2018-04-17 16:08:45.738986]: ====================
[2018-04-17 16:08:45.815189]: [Epoch: 123(8.20547031354236%): Data: 0.0%]:Running loss: 0.22344858944416046
[2018-04-17 16:08:47.128693]: [Epoch: 123(8.20547031354236%): Data: 25.333333333333336%]:Running loss: 4.4686246663331985
[2018-04-17 16:08:48.435155]: [Epoch: 123(8.20547031354236%): Data: 50.66666666666667%]:Running loss: 8.713144853711128
[2018-04-17 16:08:52.096135]: Test set accuracy: 94.33962264150944% ,loss = 5.582831799983978
[2018-04-17 16:08:52.214951]: ====================
[2018-04-17 16:08:52.220466]: Elapsed time since starting training: 0:13:37.616665
[2018-04-17 16:08:52.227986]: ====================
[2018-04-17 16:08:52.299175]: [Epoch: 124(8.272181454302869%): Data: 0.0%]:Running loss: 0.22331327199935913
[2018-04-17 16:08:53.647395]: [Epoch: 124(8.272181454302869%): Data: 25.333333333333336%]:Running loss: 4.465923234820366
[2018-04-17 16:08:54.964007]: [Epoch: 124(8.272181454302869%): Data: 50.66666666666667%]:Running loss: 8.707892954349518
[2018-04-17 16:08:58.760102]: Test set accuracy: 94.33962264150944% ,loss = 5.579524487257004
[2018-04-17 16:08:58.935569]: ====================
[2018-04-17 16:08:58.942087]: Elapsed time since starting training: 0:13:44.338286
[2018-04-17 16:08:58.951612]: ====================
[2018-04-17 16:08:59.032326]: [Epoch: 125(8.338892595063376%): Data: 0.0%]:Running loss: 0.22318097949028015
[2018-04-17 16:09:00.314263]: [Epoch: 125(8.338892595063376%): Data: 25.333333333333336%]:Running loss: 4.463290512561798
[2018-04-17 16:09:01.611713]: [Epoch: 125(8.338892595063376%): Data: 50.66666666666667%]:Running loss: 8.70277689397335
[2018-04-17 16:09:05.229833]: Test set accuracy: 94.33962264150944% ,loss = 5.576303228735924
[2018-04-17 16:09:05.351168]: ====================
[2018-04-17 16:09:05.357172]: Elapsed time since starting training: 0:13:50.753371
[2018-04-17 16:09:05.363189]: ====================
[2018-04-17 16:09:05.438890]: [Epoch: 126(8.405603735823883%): Data: 0.0%]:Running loss: 0.22305212914943695
[2018-04-17 16:09:06.745874]: [Epoch: 126(8.405603735823883%): Data: 25.333333333333336%]:Running loss: 4.460724592208862
[2018-04-17 16:09:07.995187]: [Epoch: 126(8.405603735823883%): Data: 50.66666666666667%]:Running loss: 8.697788581252098
[2018-04-17 16:09:11.506525]: Test set accuracy: 94.33962264150944% ,loss = 5.573170632123947
[2018-04-17 16:09:11.637873]: ====================
[2018-04-17 16:09:11.643888]: Elapsed time since starting training: 0:13:57.040087
[2018-04-17 16:09:11.649403]: ====================
[2018-04-17 16:09:11.722598]: [Epoch: 127(8.47231487658439%): Data: 0.0%]:Running loss: 0.22292682528495789
[2018-04-17 16:09:12.981946]: [Epoch: 127(8.47231487658439%): Data: 25.333333333333336%]:Running loss: 4.458223611116409
[2018-04-17 16:09:14.237284]: [Epoch: 127(8.47231487658439%): Data: 50.66666666666667%]:Running loss: 8.692929238080978
[2018-04-17 16:09:17.750829]: Test set accuracy: 94.33962264150944% ,loss = 5.570117011666298
[2018-04-17 16:09:17.881678]: ====================
[2018-04-17 16:09:17.887193]: Elapsed time since starting training: 0:14:03.283392
[2018-04-17 16:09:17.894725]: ====================
[2018-04-17 16:09:17.967405]: [Epoch: 128(8.539026017344895%): Data: 0.0%]:Running loss: 0.22280468046665192
[2018-04-17 16:09:19.229762]: [Epoch: 128(8.539026017344895%): Data: 25.333333333333336%]:Running loss: 4.455786541104317
[2018-04-17 16:09:20.478092]: [Epoch: 128(8.539026017344895%): Data: 50.66666666666667%]:Running loss: 8.688192427158356
[2018-04-17 16:09:24.004970]: Test set accuracy: 94.33962264150944% ,loss = 5.567140504717827
[2018-04-17 16:09:24.136822]: ====================
[2018-04-17 16:09:24.142336]: Elapsed time since starting training: 0:14:09.538535
[2018-04-17 16:09:24.149355]: ====================
[2018-04-17 16:09:24.223051]: [Epoch: 129(8.605737158105404%): Data: 0.0%]:Running loss: 0.22268562018871307
[2018-04-17 16:09:25.479400]: [Epoch: 129(8.605737158105404%): Data: 25.333333333333336%]:Running loss: 4.45341069996357
[2018-04-17 16:09:26.733726]: [Epoch: 129(8.605737158105404%): Data: 50.66666666666667%]:Running loss: 8.683573231101036
[2018-04-17 16:09:30.233659]: Test set accuracy: 94.33962264150944% ,loss = 5.564230680465698
[2018-04-17 16:09:30.356987]: ====================
[2018-04-17 16:09:30.364507]: Elapsed time since starting training: 0:14:15.760706
[2018-04-17 16:09:30.370022]: ====================
[2018-04-17 16:09:30.445224]: [Epoch: 130(8.67244829886591%): Data: 0.0%]:Running loss: 0.22256922721862793
[2018-04-17 16:09:31.708079]: [Epoch: 130(8.67244829886591%): Data: 25.333333333333336%]:Running loss: 4.451094597578049
[2018-04-17 16:09:32.964431]: [Epoch: 130(8.67244829886591%): Data: 50.66666666666667%]:Running loss: 8.67907129228115
[2018-04-17 16:09:36.694395]: Test set accuracy: 94.33962264150944% ,loss = 5.5613987147808075
[2018-04-17 16:09:36.821243]: ====================
[2018-04-17 16:09:36.827248]: Elapsed time since starting training: 0:14:22.222945
[2018-04-17 16:09:36.833765]: ====================
[2018-04-17 16:09:36.905455]: [Epoch: 131(8.739159439626418%): Data: 0.0%]:Running loss: 0.2224559485912323
[2018-04-17 16:09:38.303844]: [Epoch: 131(8.739159439626418%): Data: 25.333333333333336%]:Running loss: 4.448837235569954
[2018-04-17 16:09:39.546147]: [Epoch: 131(8.739159439626418%): Data: 50.66666666666667%]:Running loss: 8.674682959914207
[2018-04-17 16:09:43.066006]: Test set accuracy: 94.33962264150944% ,loss = 5.558636412024498
[2018-04-17 16:09:43.290102]: ====================
[2018-04-17 16:09:43.296620]: Elapsed time since starting training: 0:14:28.692317
[2018-04-17 16:09:43.302134]: ====================
[2018-04-17 16:09:43.372822]: [Epoch: 132(8.805870580386925%): Data: 0.0%]:Running loss: 0.22234545648097992
[2018-04-17 16:09:44.629163]: [Epoch: 132(8.805870580386925%): Data: 25.333333333333336%]:Running loss: 4.446634188294411
[2018-04-17 16:09:45.868458]: [Epoch: 132(8.805870580386925%): Data: 50.66666666666667%]:Running loss: 8.67040129005909
[2018-04-17 16:09:49.343698]: Test set accuracy: 94.33962264150944% ,loss = 5.555949732661247
[2018-04-17 16:09:49.465022]: ====================
[2018-04-17 16:09:49.471037]: Elapsed time since starting training: 0:14:34.867236
[2018-04-17 16:09:49.476552]: ====================
[2018-04-17 16:09:49.547741]: [Epoch: 133(8.872581721147432%): Data: 0.0%]:Running loss: 0.2222379893064499
[2018-04-17 16:09:50.790044]: [Epoch: 133(8.872581721147432%): Data: 25.333333333333336%]:Running loss: 4.444487512111664
[2018-04-17 16:09:52.059921]: [Epoch: 133(8.872581721147432%): Data: 50.66666666666667%]:Running loss: 8.666228219866753
[2018-04-17 16:09:55.542681]: Test set accuracy: 94.33962264150944% ,loss = 5.553321540355682
[2018-04-17 16:09:55.674532]: ====================
[2018-04-17 16:09:55.680549]: Elapsed time since starting training: 0:14:41.076748
[2018-04-17 16:09:55.686564]: ====================
[2018-04-17 16:09:55.758756]: [Epoch: 134(8.939292861907939%): Data: 0.0%]:Running loss: 0.2221328616142273
[2018-04-17 16:09:56.998553]: [Epoch: 134(8.939292861907939%): Data: 25.333333333333336%]:Running loss: 4.442392975091934
[2018-04-17 16:09:58.224813]: [Epoch: 134(8.939292861907939%): Data: 50.66666666666667%]:Running loss: 8.662157103419304
[2018-04-17 16:10:01.672995]: Test set accuracy: 94.33962264150944% ,loss = 5.55075891315937
[2018-04-17 16:10:01.784779]: ====================
[2018-04-17 16:10:01.790795]: Elapsed time since starting training: 0:14:47.186493
[2018-04-17 16:10:01.796811]: ====================
[2018-04-17 16:10:01.866997]: [Epoch: 135(9.006004002668446%): Data: 0.0%]:Running loss: 0.22203035652637482
[2018-04-17 16:10:03.126848]: [Epoch: 135(9.006004002668446%): Data: 25.333333333333336%]:Running loss: 4.440351277589798
[2018-04-17 16:10:04.371157]: [Epoch: 135(9.006004002668446%): Data: 50.66666666666667%]:Running loss: 8.658186852931976
[2018-04-17 16:10:07.831858]: Test set accuracy: 94.33962264150944% ,loss = 5.548256263136864
[2018-04-17 16:10:07.952680]: ====================
[2018-04-17 16:10:07.959197]: Elapsed time since starting training: 0:14:53.355396
[2018-04-17 16:10:07.965213]: ====================
[2018-04-17 16:10:08.036402]: [Epoch: 136(9.072715143428953%): Data: 0.0%]:Running loss: 0.22193025052547455
[2018-04-17 16:10:09.305777]: [Epoch: 136(9.072715143428953%): Data: 25.333333333333336%]:Running loss: 4.438357159495354
[2018-04-17 16:10:10.570140]: [Epoch: 136(9.072715143428953%): Data: 50.66666666666667%]:Running loss: 8.654311835765839
[2018-04-17 16:10:14.148661]: Test set accuracy: 94.33962264150944% ,loss = 5.545821413397789
[2018-04-17 16:10:14.278507]: ====================
[2018-04-17 16:10:14.285025]: Elapsed time since starting training: 0:14:59.681224
[2018-04-17 16:10:14.290539]: ====================
[2018-04-17 16:10:14.360224]: [Epoch: 137(9.13942628418946%): Data: 0.0%]:Running loss: 0.22183285653591156
[2018-04-17 16:10:15.605034]: [Epoch: 137(9.13942628418946%): Data: 25.333333333333336%]:Running loss: 4.4364133179187775
[2018-04-17 16:10:16.843342]: [Epoch: 137(9.13942628418946%): Data: 50.66666666666667%]:Running loss: 8.650533556938171
[2018-04-17 16:10:20.323084]: Test set accuracy: 94.33962264150944% ,loss = 5.54344467818737
[2018-04-17 16:10:20.441399]: ====================
[2018-04-17 16:10:20.447415]: Elapsed time since starting training: 0:15:05.843614
[2018-04-17 16:10:20.453432]: ====================
[2018-04-17 16:10:20.522615]: [Epoch: 138(9.206137424949967%): Data: 0.0%]:Running loss: 0.2217377871274948
[2018-04-17 16:10:21.759403]: [Epoch: 138(9.206137424949967%): Data: 25.333333333333336%]:Running loss: 4.434517741203308
[2018-04-17 16:10:22.995189]: [Epoch: 138(9.206137424949967%): Data: 50.66666666666667%]:Running loss: 8.646848365664482
[2018-04-17 16:10:26.488980]: Test set accuracy: 94.33962264150944% ,loss = 5.541125684976578
[2018-04-17 16:10:26.619827]: ====================
[2018-04-17 16:10:26.626345]: Elapsed time since starting training: 0:15:12.022544
[2018-04-17 16:10:26.633866]: ====================
[2018-04-17 16:10:26.729619]: [Epoch: 139(9.272848565710474%): Data: 0.0%]:Running loss: 0.2216450273990631
[2018-04-17 16:10:27.970921]: [Epoch: 139(9.272848565710474%): Data: 25.333333333333336%]:Running loss: 4.432667687535286
[2018-04-17 16:10:29.254332]: [Epoch: 139(9.272848565710474%): Data: 50.66666666666667%]:Running loss: 8.643250301480293
[2018-04-17 16:10:32.848891]: Test set accuracy: 94.33962264150944% ,loss = 5.538866296410561
[2018-04-17 16:10:32.965701]: ====================
[2018-04-17 16:10:32.971216]: Elapsed time since starting training: 0:15:18.367415
[2018-04-17 16:10:32.976730]: ====================
[2018-04-17 16:10:33.048421]: [Epoch: 140(9.33955970647098%): Data: 0.0%]:Running loss: 0.22155465185642242
[2018-04-17 16:10:34.346372]: [Epoch: 140(9.33955970647098%): Data: 25.333333333333336%]:Running loss: 4.430861473083496
[2018-04-17 16:10:35.578147]: [Epoch: 140(9.33955970647098%): Data: 50.66666666666667%]:Running loss: 8.639740988612175
[2018-04-17 16:10:39.216822]: Test set accuracy: 94.33962264150944% ,loss = 5.536652356386185
[2018-04-17 16:10:39.355200]: ====================
[2018-04-17 16:10:39.361207]: Elapsed time since starting training: 0:15:24.757406
[2018-04-17 16:10:39.367223]: ====================
[2018-04-17 16:10:39.437911]: [Epoch: 141(9.406270847231488%): Data: 0.0%]:Running loss: 0.2214660942554474
[2018-04-17 16:10:40.696758]: [Epoch: 141(9.406270847231488%): Data: 25.333333333333336%]:Running loss: 4.4290997087955475
[2018-04-17 16:10:41.925525]: [Epoch: 141(9.406270847231488%): Data: 50.66666666666667%]:Running loss: 8.63631646335125
[2018-04-17 16:10:45.590771]: Test set accuracy: 94.33962264150944% ,loss = 5.534498766064644
[2018-04-17 16:10:45.708584]: ====================
[2018-04-17 16:10:45.714601]: Elapsed time since starting training: 0:15:31.110298
[2018-04-17 16:10:45.720616]: ====================
[2018-04-17 16:10:45.793811]: [Epoch: 142(9.472981987991995%): Data: 0.0%]:Running loss: 0.22137995064258575
[2018-04-17 16:10:47.066695]: [Epoch: 142(9.472981987991995%): Data: 25.333333333333336%]:Running loss: 4.427381157875061
[2018-04-17 16:10:48.385202]: [Epoch: 142(9.472981987991995%): Data: 50.66666666666667%]:Running loss: 8.632975026965141
[2018-04-17 16:10:51.884014]: Test set accuracy: 94.33962264150944% ,loss = 5.532392859458923
[2018-04-17 16:10:52.033913]: ====================
[2018-04-17 16:10:52.039428]: Elapsed time since starting training: 0:15:37.435126
[2018-04-17 16:10:52.044942]: ====================
[2018-04-17 16:10:52.115129]: [Epoch: 143(9.539693128752502%): Data: 0.0%]:Running loss: 0.22129571437835693
[2018-04-17 16:10:53.354926]: [Epoch: 143(9.539693128752502%): Data: 25.333333333333336%]:Running loss: 4.425702780485153
[2018-04-17 16:10:54.575170]: [Epoch: 143(9.539693128752502%): Data: 50.66666666666667%]:Running loss: 8.629712030291557
[2018-04-17 16:10:57.931093]: Test set accuracy: 94.33962264150944% ,loss = 5.530333518981934
[2018-04-17 16:10:58.037877]: ====================
[2018-04-17 16:10:58.042891]: Elapsed time since starting training: 0:15:43.439090
[2018-04-17 16:10:58.048907]: ====================
[2018-04-17 16:10:58.121103]: [Epoch: 144(9.606404269513009%): Data: 0.0%]:Running loss: 0.22121334075927734
[2018-04-17 16:10:59.323296]: [Epoch: 144(9.606404269513009%): Data: 25.333333333333336%]:Running loss: 4.424064055085182
[2018-04-17 16:11:00.540532]: [Epoch: 144(9.606404269513009%): Data: 50.66666666666667%]:Running loss: 8.626528024673462
[2018-04-17 16:11:03.885426]: Test set accuracy: 94.33962264150944% ,loss = 5.528335273265839
[2018-04-17 16:11:04.000735]: ====================
[2018-04-17 16:11:04.007751]: Elapsed time since starting training: 0:15:49.403950
[2018-04-17 16:11:04.013768]: ====================
[2018-04-17 16:11:04.082951]: [Epoch: 145(9.673115410273516%): Data: 0.0%]:Running loss: 0.22113341093063354
[2018-04-17 16:11:05.314225]: [Epoch: 145(9.673115410273516%): Data: 25.333333333333336%]:Running loss: 4.42246612906456
[2018-04-17 16:11:06.530459]: [Epoch: 145(9.673115410273516%): Data: 50.66666666666667%]:Running loss: 8.623420044779778
[2018-04-17 16:11:09.901423]: Test set accuracy: 94.33962264150944% ,loss = 5.526375398039818
[2018-04-17 16:11:10.016228]: ====================
[2018-04-17 16:11:10.022245]: Elapsed time since starting training: 0:15:55.417941
[2018-04-17 16:11:10.027759]: ====================
[2018-04-17 16:11:10.095438]: [Epoch: 146(9.739826551034023%): Data: 0.0%]:Running loss: 0.2210550159215927
[2018-04-17 16:11:11.306158]: [Epoch: 146(9.739826551034023%): Data: 25.333333333333336%]:Running loss: 4.420904755592346
[2018-04-17 16:11:12.512866]: [Epoch: 146(9.739826551034023%): Data: 50.66666666666667%]:Running loss: 8.620385736227036
[2018-04-17 16:11:15.918422]: Test set accuracy: 94.33962264150944% ,loss = 5.524464696645737
[2018-04-17 16:11:16.048267]: ====================
[2018-04-17 16:11:16.054283]: Elapsed time since starting training: 0:16:01.449981
[2018-04-17 16:11:16.059798]: ====================
[2018-04-17 16:11:16.127979]: [Epoch: 147(9.80653769179453%): Data: 0.0%]:Running loss: 0.22097858786582947
[2018-04-17 16:11:17.348725]: [Epoch: 147(9.80653769179453%): Data: 25.333333333333336%]:Running loss: 4.41938179731369
[2018-04-17 16:11:18.550921]: [Epoch: 147(9.80653769179453%): Data: 50.66666666666667%]:Running loss: 8.617423623800278
[2018-04-17 16:11:21.887292]: Test set accuracy: 94.33962264150944% ,loss = 5.522602424025536
[2018-04-17 16:11:22.001598]: ====================
[2018-04-17 16:11:22.008615]: Elapsed time since starting training: 0:16:07.404814
[2018-04-17 16:11:22.014631]: ====================
[2018-04-17 16:11:22.082311]: [Epoch: 148(9.873248832555037%): Data: 0.0%]:Running loss: 0.22090409696102142
[2018-04-17 16:11:23.299047]: [Epoch: 148(9.873248832555037%): Data: 25.333333333333336%]:Running loss: 4.417894169688225
[2018-04-17 16:11:24.521798]: [Epoch: 148(9.873248832555037%): Data: 50.66666666666667%]:Running loss: 8.61453115940094
[2018-04-17 16:11:27.861678]: Test set accuracy: 94.33962264150944% ,loss = 5.5207811295986176
[2018-04-17 16:11:27.980495]: ====================
[2018-04-17 16:11:27.986511]: Elapsed time since starting training: 0:16:13.382710
[2018-04-17 16:11:27.991524]: ====================
[2018-04-17 16:11:28.062212]: [Epoch: 149(9.939959973315544%): Data: 0.0%]:Running loss: 0.2208312451839447
[2018-04-17 16:11:29.270926]: [Epoch: 149(9.939959973315544%): Data: 25.333333333333336%]:Running loss: 4.416442155838013
[2018-04-17 16:11:30.494178]: [Epoch: 149(9.939959973315544%): Data: 50.66666666666667%]:Running loss: 8.61170805990696
[2018-04-17 16:11:33.830550]: Test set accuracy: 94.33962264150944% ,loss = 5.5190060287714005
[2018-04-17 16:11:33.948363]: ====================
[2018-04-17 16:11:33.954379]: Elapsed time since starting training: 0:16:19.350578
[2018-04-17 16:11:33.959894]: ====================
[2018-04-17 16:11:34.025568]: [Epoch: 150(10.00667111407605%): Data: 0.0%]:Running loss: 0.22076024115085602
[2018-04-17 16:11:35.238794]: [Epoch: 150(10.00667111407605%): Data: 25.333333333333336%]:Running loss: 4.415023311972618
[2018-04-17 16:11:36.460543]: [Epoch: 150(10.00667111407605%): Data: 50.66666666666667%]:Running loss: 8.608950600028038
[2018-04-17 16:11:39.766834]: Test set accuracy: 94.33962264150944% ,loss = 5.517259985208511
[2018-04-17 16:11:39.881139]: ====================
[2018-04-17 16:11:39.887154]: Elapsed time since starting training: 0:16:25.282852
[2018-04-17 16:11:39.892168]: ====================
[2018-04-17 16:11:39.958344]: [Epoch: 151(10.073382254836558%): Data: 0.0%]:Running loss: 0.22069039940834045
[2018-04-17 16:11:41.183602]: [Epoch: 151(10.073382254836558%): Data: 25.333333333333336%]:Running loss: 4.413637667894363
[2018-04-17 16:11:42.421393]: [Epoch: 151(10.073382254836558%): Data: 50.66666666666667%]:Running loss: 8.606256440281868
[2018-04-17 16:11:45.850510]: Test set accuracy: 94.33962264150944% ,loss = 5.51556684076786
[2018-04-17 16:11:45.964314]: ====================
[2018-04-17 16:11:45.970329]: Elapsed time since starting training: 0:16:31.366528
[2018-04-17 16:11:45.976345]: ====================
[2018-04-17 16:11:46.049540]: [Epoch: 152(10.140093395597065%): Data: 0.0%]:Running loss: 0.22062267363071442
[2018-04-17 16:11:47.328440]: [Epoch: 152(10.140093395597065%): Data: 25.333333333333336%]:Running loss: 4.412284478545189
[2018-04-17 16:11:48.619379]: [Epoch: 152(10.140093395597065%): Data: 50.66666666666667%]:Running loss: 8.603625997900963
[2018-04-17 16:11:52.108651]: Test set accuracy: 94.33962264150944% ,loss = 5.513911694288254
[2018-04-17 16:11:52.238496]: ====================
[2018-04-17 16:11:52.244513]: Elapsed time since starting training: 0:16:37.640210
[2018-04-17 16:11:52.250027]: ====================
[2018-04-17 16:11:52.321216]: [Epoch: 153(10.206804536357572%): Data: 0.0%]:Running loss: 0.22055646777153015
[2018-04-17 16:11:53.607135]: [Epoch: 153(10.206804536357572%): Data: 25.333333333333336%]:Running loss: 4.410964161157608
[2018-04-17 16:11:54.896063]: [Epoch: 153(10.206804536357572%): Data: 50.66666666666667%]:Running loss: 8.601057589054108
[2018-04-17 16:11:58.339218]: Test set accuracy: 94.33962264150944% ,loss = 5.512295663356781
[2018-04-17 16:11:58.465554]: ====================
[2018-04-17 16:11:58.471570]: Elapsed time since starting training: 0:16:43.867769
[2018-04-17 16:11:58.477085]: ====================
[2018-04-17 16:11:58.553789]: [Epoch: 154(10.273515677118079%): Data: 0.0%]:Running loss: 0.22049182653427124
[2018-04-17 16:11:59.813137]: [Epoch: 154(10.273515677118079%): Data: 25.333333333333336%]:Running loss: 4.409673556685448
[2018-04-17 16:12:01.166736]: [Epoch: 154(10.273515677118079%): Data: 50.66666666666667%]:Running loss: 8.598548978567123
[2018-04-17 16:12:04.751769]: Test set accuracy: 94.33962264150944% ,loss = 5.510710924863815
[2018-04-17 16:12:04.881614]: ====================
[2018-04-17 16:12:04.887630]: Elapsed time since starting training: 0:16:50.283829
[2018-04-17 16:12:04.892645]: ====================
[2018-04-17 16:12:04.964837]: [Epoch: 155(10.340226817878586%): Data: 0.0%]:Running loss: 0.2204284369945526
[2018-04-17 16:12:06.244237]: [Epoch: 155(10.340226817878586%): Data: 25.333333333333336%]:Running loss: 4.408411622047424
[2018-04-17 16:12:07.545705]: [Epoch: 155(10.340226817878586%): Data: 50.66666666666667%]:Running loss: 8.596096813678741
[2018-04-17 16:12:11.337281]: Test set accuracy: 94.33962264150944% ,loss = 5.5091742426157
[2018-04-17 16:12:11.534304]: ====================
[2018-04-17 16:12:11.542325]: Elapsed time since starting training: 0:16:56.938524
[2018-04-17 16:12:11.548341]: ====================
[2018-04-17 16:12:11.626549]: [Epoch: 156(10.406937958639093%): Data: 0.0%]:Running loss: 0.220366969704628
[2018-04-17 16:12:13.224799]: [Epoch: 156(10.406937958639093%): Data: 25.333333333333336%]:Running loss: 4.40718138217926
[2018-04-17 16:12:14.784947]: [Epoch: 156(10.406937958639093%): Data: 50.66666666666667%]:Running loss: 8.593704178929329
[2018-04-17 16:12:18.729937]: Test set accuracy: 94.33962264150944% ,loss = 5.5076684802770615
[2018-04-17 16:12:18.928966]: ====================
[2018-04-17 16:12:18.947516]: Elapsed time since starting training: 0:17:04.343715
[2018-04-17 16:12:18.955037]: ====================
[2018-04-17 16:12:19.030236]: [Epoch: 157(10.4736490993996%): Data: 0.0%]:Running loss: 0.22030673921108246
[2018-04-17 16:12:20.808965]: [Epoch: 157(10.4736490993996%): Data: 25.333333333333336%]:Running loss: 4.405978232622147
[2018-04-17 16:12:22.441306]: [Epoch: 157(10.4736490993996%): Data: 50.66666666666667%]:Running loss: 8.5913637727499
[2018-04-17 16:12:26.320621]: Test set accuracy: 94.33962264150944% ,loss = 5.506190285086632
[2018-04-17 16:12:26.459992]: ====================
[2018-04-17 16:12:26.466509]: Elapsed time since starting training: 0:17:11.862708
[2018-04-17 16:12:26.473527]: ====================
[2018-04-17 16:12:26.545217]: [Epoch: 158(10.540360240160107%): Data: 0.0%]:Running loss: 0.22024761140346527
[2018-04-17 16:12:27.843169]: [Epoch: 158(10.540360240160107%): Data: 25.333333333333336%]:Running loss: 4.404802709817886
[2018-04-17 16:12:29.124075]: [Epoch: 158(10.540360240160107%): Data: 50.66666666666667%]:Running loss: 8.589078143239021
[2018-04-17 16:12:32.724649]: Test set accuracy: 94.33962264150944% ,loss = 5.504743382334709
[2018-04-17 16:12:32.846974]: ====================
[2018-04-17 16:12:32.853993]: Elapsed time since starting training: 0:17:18.250192
[2018-04-17 16:12:32.859507]: ====================
[2018-04-17 16:12:32.928190]: [Epoch: 159(10.607071380920614%): Data: 0.0%]:Running loss: 0.22018973529338837
[2018-04-17 16:12:34.186536]: [Epoch: 159(10.607071380920614%): Data: 25.333333333333336%]:Running loss: 4.403654247522354
[2018-04-17 16:12:35.577735]: [Epoch: 159(10.607071380920614%): Data: 50.66666666666667%]:Running loss: 8.586846321821213
[2018-04-17 16:12:39.199867]: Test set accuracy: 94.33962264150944% ,loss = 5.503340810537338
[2018-04-17 16:12:39.322692]: ====================
[2018-04-17 16:12:39.329211]: Elapsed time since starting training: 0:17:24.724908
[2018-04-17 16:12:39.334725]: ====================
[2018-04-17 16:12:39.411930]: [Epoch: 160(10.67378252168112%): Data: 0.0%]:Running loss: 0.22013363242149353
[2018-04-17 16:12:40.745476]: [Epoch: 160(10.67378252168112%): Data: 25.333333333333336%]:Running loss: 4.402532413601875
[2018-04-17 16:12:42.035907]: [Epoch: 160(10.67378252168112%): Data: 50.66666666666667%]:Running loss: 8.584665298461914
[2018-04-17 16:12:45.753793]: Test set accuracy: 94.33962264150944% ,loss = 5.501966178417206
[2018-04-17 16:12:45.875617]: ====================
[2018-04-17 16:12:45.881132]: Elapsed time since starting training: 0:17:31.276830
[2018-04-17 16:12:45.888151]: ====================
[2018-04-17 16:12:45.956331]: [Epoch: 161(10.740493662441628%): Data: 0.0%]:Running loss: 0.22007864713668823
[2018-04-17 16:12:47.197632]: [Epoch: 161(10.740493662441628%): Data: 25.333333333333336%]:Running loss: 4.401435226202011
[2018-04-17 16:12:48.446453]: [Epoch: 161(10.740493662441628%): Data: 50.66666666666667%]:Running loss: 8.582532674074173
[2018-04-17 16:12:51.927709]: Test set accuracy: 94.33962264150944% ,loss = 5.500621721148491
[2018-04-17 16:12:52.042516]: ====================
[2018-04-17 16:12:52.048030]: Elapsed time since starting training: 0:17:37.443727
[2018-04-17 16:12:52.054045]: ====================
[2018-04-17 16:12:52.123731]: [Epoch: 162(10.807204803202135%): Data: 0.0%]:Running loss: 0.22002486884593964
[2018-04-17 16:12:53.392108]: [Epoch: 162(10.807204803202135%): Data: 25.333333333333336%]:Running loss: 4.400365009903908
[2018-04-17 16:12:54.658977]: [Epoch: 162(10.807204803202135%): Data: 50.66666666666667%]:Running loss: 8.580449655652046
[2018-04-17 16:12:58.116671]: Test set accuracy: 94.33962264150944% ,loss = 5.499309301376343
[2018-04-17 16:12:58.231978]: ====================
[2018-04-17 16:12:58.238997]: Elapsed time since starting training: 0:17:43.635196
[2018-04-17 16:12:58.245013]: ====================
[2018-04-17 16:12:58.316201]: [Epoch: 163(10.873915943962642%): Data: 0.0%]:Running loss: 0.2199723720550537
[2018-04-17 16:12:59.592095]: [Epoch: 163(10.873915943962642%): Data: 25.333333333333336%]:Running loss: 4.399316683411598
[2018-04-17 16:13:00.829384]: [Epoch: 163(10.873915943962642%): Data: 50.66666666666667%]:Running loss: 8.578412517905235
[2018-04-17 16:13:04.329191]: Test set accuracy: 94.33962264150944% ,loss = 5.498028174042702
[2018-04-17 16:13:04.531729]: ====================
[2018-04-17 16:13:04.539249]: Elapsed time since starting training: 0:17:49.935448
[2018-04-17 16:13:04.545264]: ====================
[2018-04-17 16:13:04.611444]: [Epoch: 164(10.940627084723149%): Data: 0.0%]:Running loss: 0.21992112696170807
[2018-04-17 16:13:05.872795]: [Epoch: 164(10.940627084723149%): Data: 25.333333333333336%]:Running loss: 4.398293346166611
[2018-04-17 16:13:07.139663]: [Epoch: 164(10.940627084723149%): Data: 50.66666666666667%]:Running loss: 8.576422840356827
[2018-04-17 16:13:10.679075]: Test set accuracy: 94.33962264150944% ,loss = 5.496777221560478
[2018-04-17 16:13:10.790871]: ====================
[2018-04-17 16:13:10.796888]: Elapsed time since starting training: 0:17:56.192586
[2018-04-17 16:13:10.802403]: ====================
[2018-04-17 16:13:10.876600]: [Epoch: 165(11.007338225483656%): Data: 0.0%]:Running loss: 0.21987108886241913
[2018-04-17 16:13:12.138956]: [Epoch: 165(11.007338225483656%): Data: 25.333333333333336%]:Running loss: 4.397292658686638
[2018-04-17 16:13:13.408332]: [Epoch: 165(11.007338225483656%): Data: 50.66666666666667%]:Running loss: 8.574477434158325
[2018-04-17 16:13:17.146772]: Test set accuracy: 94.33962264150944% ,loss = 5.495548248291016
[2018-04-17 16:13:17.264585]: ====================
[2018-04-17 16:13:17.273108]: Elapsed time since starting training: 0:18:02.669307
[2018-04-17 16:13:17.279124]: ====================
[2018-04-17 16:13:17.353321]: [Epoch: 166(11.074049366244163%): Data: 0.0%]:Running loss: 0.21982192993164062
[2018-04-17 16:13:18.644254]: [Epoch: 166(11.074049366244163%): Data: 25.333333333333336%]:Running loss: 4.396315395832062
[2018-04-17 16:13:20.112658]: [Epoch: 166(11.074049366244163%): Data: 50.66666666666667%]:Running loss: 8.572576686739922
[2018-04-17 16:13:24.222587]: Test set accuracy: 94.33962264150944% ,loss = 5.494349077343941
[2018-04-17 16:13:24.346917]: ====================
[2018-04-17 16:13:24.352433]: Elapsed time since starting training: 0:18:09.748632
[2018-04-17 16:13:24.360453]: ====================
[2018-04-17 16:13:24.434149]: [Epoch: 167(11.14076050700467%): Data: 0.0%]:Running loss: 0.21977396309375763
[2018-04-17 16:13:25.735610]: [Epoch: 167(11.14076050700467%): Data: 25.333333333333336%]:Running loss: 4.395358443260193
[2018-04-17 16:13:27.114777]: [Epoch: 167(11.14076050700467%): Data: 50.66666666666667%]:Running loss: 8.570716828107834
[2018-04-17 16:13:30.761473]: Test set accuracy: 94.33962264150944% ,loss = 5.493170768022537
[2018-04-17 16:13:30.888812]: ====================
[2018-04-17 16:13:30.895831]: Elapsed time since starting training: 0:18:16.292030
[2018-04-17 16:13:30.903350]: ====================
[2018-04-17 16:13:30.981057]: [Epoch: 168(11.207471647765177%): Data: 0.0%]:Running loss: 0.2197268307209015
[2018-04-17 16:13:32.341174]: [Epoch: 168(11.207471647765177%): Data: 25.333333333333336%]:Running loss: 4.394424289464951
[2018-04-17 16:13:33.645141]: [Epoch: 168(11.207471647765177%): Data: 50.66666666666667%]:Running loss: 8.568900093436241
[2018-04-17 16:13:37.230675]: Test set accuracy: 94.33962264150944% ,loss = 5.492027476429939
[2018-04-17 16:13:37.346984]: ====================
[2018-04-17 16:13:37.352499]: Elapsed time since starting training: 0:18:22.748698
[2018-04-17 16:13:37.359518]: ====================
[2018-04-17 16:13:37.425693]: [Epoch: 169(11.274182788525684%): Data: 0.0%]:Running loss: 0.21968109905719757
[2018-04-17 16:13:38.760744]: [Epoch: 169(11.274182788525684%): Data: 25.333333333333336%]:Running loss: 4.39351150393486
[2018-04-17 16:13:40.167985]: [Epoch: 169(11.274182788525684%): Data: 50.66666666666667%]:Running loss: 8.567124530673027
[2018-04-17 16:13:43.993658]: Test set accuracy: 94.33962264150944% ,loss = 5.4909151047468185
[2018-04-17 16:13:44.126010]: ====================
[2018-04-17 16:13:44.131524]: Elapsed time since starting training: 0:18:29.527723
[2018-04-17 16:13:44.137540]: ====================
[2018-04-17 16:13:44.216250]: [Epoch: 170(11.34089392928619%): Data: 0.0%]:Running loss: 0.21963660418987274
[2018-04-17 16:13:45.509689]: [Epoch: 170(11.34089392928619%): Data: 25.333333333333336%]:Running loss: 4.392617911100388
[2018-04-17 16:13:46.829698]: [Epoch: 170(11.34089392928619%): Data: 50.66666666666667%]:Running loss: 8.565387204289436
[2018-04-17 16:13:50.856406]: Test set accuracy: 94.33962264150944% ,loss = 5.489813536405563
[2018-04-17 16:13:51.013323]: ====================
[2018-04-17 16:13:51.019841]: Elapsed time since starting training: 0:18:36.416040
[2018-04-17 16:13:51.027862]: ====================
[2018-04-17 16:13:51.106070]: [Epoch: 171(11.407605070046698%): Data: 0.0%]:Running loss: 0.21959254145622253
[2018-04-17 16:13:52.462175]: [Epoch: 171(11.407605070046698%): Data: 25.333333333333336%]:Running loss: 4.391744717955589
[2018-04-17 16:13:53.722527]: [Epoch: 171(11.407605070046698%): Data: 50.66666666666667%]:Running loss: 8.563689142465591
[2018-04-17 16:13:57.299036]: Test set accuracy: 94.33962264150944% ,loss = 5.488746613264084
[2018-04-17 16:13:57.406823]: ====================
[2018-04-17 16:13:57.411836]: Elapsed time since starting training: 0:18:42.808035
[2018-04-17 16:13:57.417852]: ====================
[2018-04-17 16:13:57.493053]: [Epoch: 172(11.474316210807205%): Data: 0.0%]:Running loss: 0.21954986453056335
[2018-04-17 16:13:58.790503]: [Epoch: 172(11.474316210807205%): Data: 25.333333333333336%]:Running loss: 4.390890538692474
[2018-04-17 16:14:00.188720]: [Epoch: 172(11.474316210807205%): Data: 50.66666666666667%]:Running loss: 8.562027156352997
[2018-04-17 16:14:03.788292]: Test set accuracy: 94.33962264150944% ,loss = 5.487699061632156
[2018-04-17 16:14:03.921646]: ====================
[2018-04-17 16:14:03.928163]: Elapsed time since starting training: 0:18:49.324362
[2018-04-17 16:14:03.933678]: ====================
[2018-04-17 16:14:04.006873]: [Epoch: 173(11.541027351567712%): Data: 0.0%]:Running loss: 0.21950796246528625
[2018-04-17 16:14:05.279757]: [Epoch: 173(11.541027351567712%): Data: 25.333333333333336%]:Running loss: 4.390053078532219
[2018-04-17 16:14:06.593751]: [Epoch: 173(11.541027351567712%): Data: 50.66666666666667%]:Running loss: 8.56040433049202
[2018-04-17 16:14:10.086037]: Test set accuracy: 94.33962264150944% ,loss = 5.486674606800079
[2018-04-17 16:14:10.205856]: ====================
[2018-04-17 16:14:10.211370]: Elapsed time since starting training: 0:18:55.607068
[2018-04-17 16:14:10.216393]: ====================
[2018-04-17 16:14:10.286069]: [Epoch: 174(11.607738492328219%): Data: 0.0%]:Running loss: 0.21946698427200317
[2018-04-17 16:14:11.503309]: [Epoch: 174(11.607738492328219%): Data: 25.333333333333336%]:Running loss: 4.389238610863686
[2018-04-17 16:14:12.769175]: [Epoch: 174(11.607738492328219%): Data: 50.66666666666667%]:Running loss: 8.558817356824875
[2018-04-17 16:14:16.282517]: Test set accuracy: 94.33962264150944% ,loss = 5.4856739938259125
[2018-04-17 16:14:16.398827]: ====================
[2018-04-17 16:14:16.404341]: Elapsed time since starting training: 0:19:01.800540
[2018-04-17 16:14:16.411360]: ====================
[2018-04-17 16:14:16.479041]: [Epoch: 175(11.674449633088726%): Data: 0.0%]:Running loss: 0.2194269597530365
[2018-04-17 16:14:17.746911]: [Epoch: 175(11.674449633088726%): Data: 25.333333333333336%]:Running loss: 4.388441234827042
[2018-04-17 16:14:19.012777]: [Epoch: 175(11.674449633088726%): Data: 50.66666666666667%]:Running loss: 8.557266265153885
[2018-04-17 16:14:22.531634]: Test set accuracy: 94.33962264150944% ,loss = 5.4846953600645065
[2018-04-17 16:14:22.647943]: ====================
[2018-04-17 16:14:22.653459]: Elapsed time since starting training: 0:19:08.049155
[2018-04-17 16:14:22.658972]: ====================
[2018-04-17 16:14:22.730162]: [Epoch: 176(11.741160773849233%): Data: 0.0%]:Running loss: 0.21938781440258026
[2018-04-17 16:14:23.995526]: [Epoch: 176(11.741160773849233%): Data: 25.333333333333336%]:Running loss: 4.387660786509514
[2018-04-17 16:14:25.292475]: [Epoch: 176(11.741160773849233%): Data: 50.66666666666667%]:Running loss: 8.555747747421265
[2018-04-17 16:14:28.832890]: Test set accuracy: 94.33962264150944% ,loss = 5.483739823102951
[2018-04-17 16:14:28.974265]: ====================
[2018-04-17 16:14:28.979779]: Elapsed time since starting training: 0:19:14.375978
[2018-04-17 16:14:28.986297]: ====================
[2018-04-17 16:14:29.063502]: [Epoch: 177(11.80787191460974%): Data: 0.0%]:Running loss: 0.21934959292411804
[2018-04-17 16:14:30.322349]: [Epoch: 177(11.80787191460974%): Data: 25.333333333333336%]:Running loss: 4.3868971318006516
[2018-04-17 16:14:31.591724]: [Epoch: 177(11.80787191460974%): Data: 50.66666666666667%]:Running loss: 8.554263204336166
[2018-04-17 16:14:35.128629]: Test set accuracy: 94.33962264150944% ,loss = 5.4828062653541565
[2018-04-17 16:14:35.245440]: ====================
[2018-04-17 16:14:35.251456]: Elapsed time since starting training: 0:19:20.647655
[2018-04-17 16:14:35.257472]: ====================
[2018-04-17 16:14:35.330666]: [Epoch: 178(11.874583055370246%): Data: 0.0%]:Running loss: 0.21931225061416626
[2018-04-17 16:14:36.605055]: [Epoch: 178(11.874583055370246%): Data: 25.333333333333336%]:Running loss: 4.386149376630783
[2018-04-17 16:14:37.822793]: [Epoch: 178(11.874583055370246%): Data: 50.66666666666667%]:Running loss: 8.552809417247772
[2018-04-17 16:14:41.250413]: Test set accuracy: 94.33962264150944% ,loss = 5.481887236237526
[2018-04-17 16:14:41.370232]: ====================
[2018-04-17 16:14:41.376248]: Elapsed time since starting training: 0:19:26.771945
[2018-04-17 16:14:41.381762]: ====================
[2018-04-17 16:14:41.450946]: [Epoch: 179(11.941294196130753%): Data: 0.0%]:Running loss: 0.21927548944950104
[2018-04-17 16:14:42.690743]: [Epoch: 179(11.941294196130753%): Data: 25.333333333333336%]:Running loss: 4.38541941344738
[2018-04-17 16:14:43.932545]: [Epoch: 179(11.941294196130753%): Data: 50.66666666666667%]:Running loss: 8.551390051841736
[2018-04-17 16:14:47.454409]: Test set accuracy: 94.33962264150944% ,loss = 5.480990186333656
[2018-04-17 16:14:47.568212]: ====================
[2018-04-17 16:14:47.574729]: Elapsed time since starting training: 0:19:32.970928
[2018-04-17 16:14:47.580245]: ====================
[2018-04-17 16:14:47.650431]: [Epoch: 180(12.008005336891262%): Data: 0.0%]:Running loss: 0.21923960745334625
[2018-04-17 16:14:48.897246]: [Epoch: 180(12.008005336891262%): Data: 25.333333333333336%]:Running loss: 4.3847039341926575
[2018-04-17 16:14:50.172636]: [Epoch: 180(12.008005336891262%): Data: 50.66666666666667%]:Running loss: 8.549998924136162
[2018-04-17 16:14:53.764688]: Test set accuracy: 94.33962264150944% ,loss = 5.4801154881715775
[2018-04-17 16:14:53.881499]: ====================
[2018-04-17 16:14:53.890022]: Elapsed time since starting training: 0:19:39.286221
[2018-04-17 16:14:53.896038]: ====================
[2018-04-17 16:14:53.970736]: [Epoch: 181(12.074716477651767%): Data: 0.0%]:Running loss: 0.2192046195268631
[2018-04-17 16:14:55.264676]: [Epoch: 181(12.074716477651767%): Data: 25.333333333333336%]:Running loss: 4.384005784988403
[2018-04-17 16:14:56.548590]: [Epoch: 181(12.074716477651767%): Data: 50.66666666666667%]:Running loss: 8.548640578985214
[2018-04-17 16:15:00.101037]: Test set accuracy: 94.33962264150944% ,loss = 5.479258298873901
[2018-04-17 16:15:00.220354]: ====================
[2018-04-17 16:15:00.226872]: Elapsed time since starting training: 0:19:45.622569
[2018-04-17 16:15:00.231884]: ====================
[2018-04-17 16:15:00.306081]: [Epoch: 182(12.141427618412274%): Data: 0.0%]:Running loss: 0.21917033195495605
[2018-04-17 16:15:01.600524]: [Epoch: 182(12.141427618412274%): Data: 25.333333333333336%]:Running loss: 4.383321225643158
[2018-04-17 16:15:02.838315]: [Epoch: 182(12.141427618412274%): Data: 50.66666666666667%]:Running loss: 8.547310546040535
[2018-04-17 16:15:06.364190]: Test set accuracy: 94.33962264150944% ,loss = 5.478420853614807
[2018-04-17 16:15:06.481502]: ====================
[2018-04-17 16:15:06.487518]: Elapsed time since starting training: 0:19:51.883717
[2018-04-17 16:15:06.494047]: ====================
[2018-04-17 16:15:06.567230]: [Epoch: 183(12.208138759172781%): Data: 0.0%]:Running loss: 0.21913683414459229
[2018-04-17 16:15:07.827080]: [Epoch: 183(12.208138759172781%): Data: 25.333333333333336%]:Running loss: 4.382652461528778
[2018-04-17 16:15:09.088935]: [Epoch: 183(12.208138759172781%): Data: 50.66666666666667%]:Running loss: 8.546009063720703
[2018-04-17 16:15:12.596768]: Test set accuracy: 94.33962264150944% ,loss = 5.477598309516907
[2018-04-17 16:15:12.722602]: ====================
[2018-04-17 16:15:12.731125]: Elapsed time since starting training: 0:19:58.127324
[2018-04-17 16:15:12.736138]: ====================
[2018-04-17 16:15:12.814847]: [Epoch: 184(12.274849899933288%): Data: 0.0%]:Running loss: 0.21910393238067627
[2018-04-17 16:15:14.036596]: [Epoch: 184(12.274849899933288%): Data: 25.333333333333336%]:Running loss: 4.381998121738434
[2018-04-17 16:15:15.321516]: [Epoch: 184(12.274849899933288%): Data: 50.66666666666667%]:Running loss: 8.544735759496689
[2018-04-17 16:15:18.790737]: Test set accuracy: 94.33962264150944% ,loss = 5.476801469922066
[2018-04-17 16:15:18.909053]: ====================
[2018-04-17 16:15:18.915068]: Elapsed time since starting training: 0:20:04.310766
[2018-04-17 16:15:18.920082]: ====================
[2018-04-17 16:15:18.988263]: [Epoch: 185(12.341561040693797%): Data: 0.0%]:Running loss: 0.21907205879688263
[2018-04-17 16:15:20.211515]: [Epoch: 185(12.341561040693797%): Data: 25.333333333333336%]:Running loss: 4.381357491016388
[2018-04-17 16:15:21.445797]: [Epoch: 185(12.341561040693797%): Data: 50.66666666666667%]:Running loss: 8.543491631746292
[2018-04-17 16:15:24.981699]: Test set accuracy: 94.33962264150944% ,loss = 5.476007983088493
[2018-04-17 16:15:25.095001]: ====================
[2018-04-17 16:15:25.101016]: Elapsed time since starting training: 0:20:10.497215
[2018-04-17 16:15:25.107032]: ====================
[2018-04-17 16:15:25.177720]: [Epoch: 186(12.408272181454302%): Data: 0.0%]:Running loss: 0.21904031932353973
[2018-04-17 16:15:26.449602]: [Epoch: 186(12.408272181454302%): Data: 25.333333333333336%]:Running loss: 4.380730926990509
[2018-04-17 16:15:27.688402]: [Epoch: 186(12.408272181454302%): Data: 50.66666666666667%]:Running loss: 8.542271375656128
[2018-04-17 16:15:31.224805]: Test set accuracy: 94.33962264150944% ,loss = 5.475248396396637
[2018-04-17 16:15:31.337104]: ====================
[2018-04-17 16:15:31.343120]: Elapsed time since starting training: 0:20:16.738818
[2018-04-17 16:15:31.350138]: ====================
[2018-04-17 16:15:31.418821]: [Epoch: 187(12.47498332221481%): Data: 0.0%]:Running loss: 0.21900993585586548
[2018-04-17 16:15:32.693711]: [Epoch: 187(12.47498332221481%): Data: 25.333333333333336%]:Running loss: 4.380117401480675
[2018-04-17 16:15:33.959577]: [Epoch: 187(12.47498332221481%): Data: 50.66666666666667%]:Running loss: 8.541080296039581
[2018-04-17 16:15:37.464897]: Test set accuracy: 94.33962264150944% ,loss = 5.474493280053139
[2018-04-17 16:15:37.590232]: ====================
[2018-04-17 16:15:37.596247]: Elapsed time since starting training: 0:20:22.992446
[2018-04-17 16:15:37.602764]: ====================
[2018-04-17 16:15:37.670946]: [Epoch: 188(12.541694462975316%): Data: 0.0%]:Running loss: 0.21897973120212555
[2018-04-17 16:15:38.937318]: [Epoch: 188(12.541694462975316%): Data: 25.333333333333336%]:Running loss: 4.379518091678619
[2018-04-17 16:15:40.194656]: [Epoch: 188(12.541694462975316%): Data: 50.66666666666667%]:Running loss: 8.539914473891258
[2018-04-17 16:15:43.645833]: Test set accuracy: 94.33962264150944% ,loss = 5.473760515451431
[2018-04-17 16:15:43.764649]: ====================
[2018-04-17 16:15:43.770163]: Elapsed time since starting training: 0:20:29.166362
[2018-04-17 16:15:43.775678]: ====================
[2018-04-17 16:15:43.848371]: [Epoch: 189(12.608405603735823%): Data: 0.0%]:Running loss: 0.21895042061805725
[2018-04-17 16:15:45.130782]: [Epoch: 189(12.608405603735823%): Data: 25.333333333333336%]:Running loss: 4.378931611776352
[2018-04-17 16:15:46.401158]: [Epoch: 189(12.608405603735823%): Data: 50.66666666666667%]:Running loss: 8.538772568106651
[2018-04-17 16:15:49.935557]: Test set accuracy: 94.33962264150944% ,loss = 5.47303631901741
[2018-04-17 16:15:50.063397]: ====================
[2018-04-17 16:15:50.069413]: Elapsed time since starting training: 0:20:35.465612
[2018-04-17 16:15:50.075429]: ====================
[2018-04-17 16:15:50.144618]: [Epoch: 190(12.675116744496332%): Data: 0.0%]:Running loss: 0.2189214527606964
[2018-04-17 16:15:51.409476]: [Epoch: 190(12.675116744496332%): Data: 25.333333333333336%]:Running loss: 4.3783570528030396
[2018-04-17 16:15:52.667822]: [Epoch: 190(12.675116744496332%): Data: 50.66666666666667%]:Running loss: 8.537656545639038
[2018-04-17 16:15:56.179660]: Test set accuracy: 94.33962264150944% ,loss = 5.47233447432518
[2018-04-17 16:15:56.299979]: ====================
[2018-04-17 16:15:56.306497]: Elapsed time since starting training: 0:20:41.702696
[2018-04-17 16:15:56.312513]: ====================
[2018-04-17 16:15:56.380193]: [Epoch: 191(12.741827885256837%): Data: 0.0%]:Running loss: 0.2188933789730072
[2018-04-17 16:15:57.623499]: [Epoch: 191(12.741827885256837%): Data: 25.333333333333336%]:Running loss: 4.377794846892357
[2018-04-17 16:15:58.873823]: [Epoch: 191(12.741827885256837%): Data: 50.66666666666667%]:Running loss: 8.53656280040741
[2018-04-17 16:16:02.331518]: Test set accuracy: 94.33962264150944% ,loss = 5.471647530794144
[2018-04-17 16:16:02.448329]: ====================
[2018-04-17 16:16:02.455347]: Elapsed time since starting training: 0:20:47.851546
[2018-04-17 16:16:02.461865]: ====================
[2018-04-17 16:16:02.534558]: [Epoch: 192(12.808539026017346%): Data: 0.0%]:Running loss: 0.21886590123176575
[2018-04-17 16:16:03.766333]: [Epoch: 192(12.808539026017346%): Data: 25.333333333333336%]:Running loss: 4.377244353294373
[2018-04-17 16:16:05.019164]: [Epoch: 192(12.808539026017346%): Data: 50.66666666666667%]:Running loss: 8.535492449998856
[2018-04-17 16:16:08.459813]: Test set accuracy: 94.33962264150944% ,loss = 5.470962822437286
[2018-04-17 16:16:08.586149]: ====================
[2018-04-17 16:16:08.591669]: Elapsed time since starting training: 0:20:53.987868
[2018-04-17 16:16:08.597680]: ====================
[2018-04-17 16:16:08.669872]: [Epoch: 193(12.875250166777851%): Data: 0.0%]:Running loss: 0.21883851289749146
[2018-04-17 16:16:09.932729]: [Epoch: 193(12.875250166777851%): Data: 25.333333333333336%]:Running loss: 4.376705586910248
[2018-04-17 16:16:11.167512]: [Epoch: 193(12.875250166777851%): Data: 50.66666666666667%]:Running loss: 8.53444491326809
[2018-04-17 16:16:14.677846]: Test set accuracy: 94.33962264150944% ,loss = 5.470307916402817
[2018-04-17 16:16:14.791148]: ====================
[2018-04-17 16:16:14.797164]: Elapsed time since starting training: 0:21:00.193363
[2018-04-17 16:16:14.802679]: ====================
[2018-04-17 16:16:14.870359]: [Epoch: 194(12.941961307538358%): Data: 0.0%]:Running loss: 0.21881231665611267
[2018-04-17 16:16:16.131211]: [Epoch: 194(12.941961307538358%): Data: 25.333333333333336%]:Running loss: 4.376179561018944
[2018-04-17 16:16:17.402591]: [Epoch: 194(12.941961307538358%): Data: 50.66666666666667%]:Running loss: 8.53341943025589
[2018-04-17 16:16:21.135924]: Test set accuracy: 94.33962264150944% ,loss = 5.469655618071556
[2018-04-17 16:16:21.361523]: ====================
[2018-04-17 16:16:21.371049]: Elapsed time since starting training: 0:21:06.766746
[2018-04-17 16:16:21.379070]: ====================
[2018-04-17 16:16:21.473822]: [Epoch: 195(13.008672448298867%): Data: 0.0%]:Running loss: 0.21878622472286224
[2018-04-17 16:16:22.980829]: [Epoch: 195(13.008672448298867%): Data: 25.333333333333336%]:Running loss: 4.375661328434944
[2018-04-17 16:16:24.464273]: [Epoch: 195(13.008672448298867%): Data: 50.66666666666667%]:Running loss: 8.532417446374893
[2018-04-17 16:16:28.375674]: Test set accuracy: 94.33962264150944% ,loss = 5.469029396772385
[2018-04-17 16:16:28.520559]: ====================
[2018-04-17 16:16:28.526575]: Elapsed time since starting training: 0:21:13.922774
[2018-04-17 16:16:28.533594]: ====================
[2018-04-17 16:16:28.616815]: [Epoch: 196(13.075383589059372%): Data: 0.0%]:Running loss: 0.21876117587089539
[2018-04-17 16:16:29.936825]: [Epoch: 196(13.075383589059372%): Data: 25.333333333333336%]:Running loss: 4.375157207250595
[2018-04-17 16:16:31.300952]: [Epoch: 196(13.075383589059372%): Data: 50.66666666666667%]:Running loss: 8.531435564160347
[2018-04-17 16:16:35.107574]: Test set accuracy: 94.33962264150944% ,loss = 5.46841025352478
[2018-04-17 16:16:35.247947]: ====================
[2018-04-17 16:16:35.253963]: Elapsed time since starting training: 0:21:20.650162
[2018-04-17 16:16:35.259478]: ====================
[2018-04-17 16:16:35.332673]: [Epoch: 197(13.142094729819881%): Data: 0.0%]:Running loss: 0.2187364101409912
[2018-04-17 16:16:36.613077]: [Epoch: 197(13.142094729819881%): Data: 25.333333333333336%]:Running loss: 4.374663770198822
[2018-04-17 16:16:37.867412]: [Epoch: 197(13.142094729819881%): Data: 50.66666666666667%]:Running loss: 8.530473917722702
[2018-04-17 16:16:41.331624]: Test set accuracy: 94.33962264150944% ,loss = 5.467794835567474
[2018-04-17 16:16:41.494055]: ====================
[2018-04-17 16:16:41.501074]: Elapsed time since starting training: 0:21:26.896772
[2018-04-17 16:16:41.506589]: ====================
[2018-04-17 16:16:41.596327]: [Epoch: 198(13.208805870580386%): Data: 0.0%]:Running loss: 0.21871179342269897
[2018-04-17 16:16:43.106844]: [Epoch: 198(13.208805870580386%): Data: 25.333333333333336%]:Running loss: 4.374179512262344
[2018-04-17 16:16:44.419835]: [Epoch: 198(13.208805870580386%): Data: 50.66666666666667%]:Running loss: 8.529532000422478
[2018-04-17 16:16:47.946713]: Test set accuracy: 94.33962264150944% ,loss = 5.467205494642258
[2018-04-17 16:16:48.091598]: ====================
[2018-04-17 16:16:48.097614]: Elapsed time since starting training: 0:21:33.493813
[2018-04-17 16:16:48.103129]: ====================
[2018-04-17 16:16:48.170809]: [Epoch: 199(13.275517011340893%): Data: 0.0%]:Running loss: 0.2186882197856903
[2018-04-17 16:16:49.552483]: [Epoch: 199(13.275517011340893%): Data: 25.333333333333336%]:Running loss: 4.373706474900246
[2018-04-17 16:16:50.862465]: [Epoch: 199(13.275517011340893%): Data: 50.66666666666667%]:Running loss: 8.528611600399017
[2018-04-17 16:16:54.561301]: Test set accuracy: 94.33962264150944% ,loss = 5.466624349355698
[2018-04-17 16:16:54.704181]: ====================
[2018-04-17 16:16:54.711701]: Elapsed time since starting training: 0:21:40.107900
[2018-04-17 16:16:54.721226]: ====================
[2018-04-17 16:16:54.800938]: [Epoch: 200(13.342228152101402%): Data: 0.0%]:Running loss: 0.2186649739742279
[2018-04-17 16:16:56.162058]: [Epoch: 200(13.342228152101402%): Data: 25.333333333333336%]:Running loss: 4.373243108391762
[2018-04-17 16:16:57.427923]: [Epoch: 200(13.342228152101402%): Data: 50.66666666666667%]:Running loss: 8.52771058678627
[2018-04-17 16:17:00.971847]: Test set accuracy: 94.33962264150944% ,loss = 5.466057732701302
[2018-04-17 16:17:01.185916]: ====================
[2018-04-17 16:17:01.191431]: Elapsed time since starting training: 0:21:46.587630
[2018-04-17 16:17:01.197948]: ====================
[2018-04-17 16:17:01.272646]: [Epoch: 201(13.408939292861907%): Data: 0.0%]:Running loss: 0.21864230930805206
[2018-04-17 16:17:02.548539]: [Epoch: 201(13.408939292861907%): Data: 25.333333333333336%]:Running loss: 4.372788980603218
[2018-04-17 16:17:03.780816]: [Epoch: 201(13.408939292861907%): Data: 50.66666666666667%]:Running loss: 8.52682812511921
[2018-04-17 16:17:07.237511]: Test set accuracy: 94.33962264150944% ,loss = 5.4654959589242935
[2018-04-17 16:17:07.355325]: ====================
[2018-04-17 16:17:07.360840]: Elapsed time since starting training: 0:21:52.756537
[2018-04-17 16:17:07.366354]: ====================
[2018-04-17 16:17:07.440551]: [Epoch: 202(13.475650433622416%): Data: 0.0%]:Running loss: 0.21861983835697174
[2018-04-17 16:17:08.736498]: [Epoch: 202(13.475650433622416%): Data: 25.333333333333336%]:Running loss: 4.372344613075256
[2018-04-17 16:17:09.964763]: [Epoch: 202(13.475650433622416%): Data: 50.66666666666667%]:Running loss: 8.525963976979256
[2018-04-17 16:17:13.471587]: Test set accuracy: 94.33962264150944% ,loss = 5.464950203895569
[2018-04-17 16:17:13.594917]: ====================
[2018-04-17 16:17:13.601434]: Elapsed time since starting training: 0:21:58.997131
[2018-04-17 16:17:13.606948]: ====================
[2018-04-17 16:17:13.687662]: [Epoch: 203(13.542361574382921%): Data: 0.0%]:Running loss: 0.21859800815582275
[2018-04-17 16:17:14.937486]: [Epoch: 203(13.542361574382921%): Data: 25.333333333333336%]:Running loss: 4.371909901499748
[2018-04-17 16:17:16.229421]: [Epoch: 203(13.542361574382921%): Data: 50.66666666666667%]:Running loss: 8.525117829442024
[2018-04-17 16:17:19.708672]: Test set accuracy: 94.33962264150944% ,loss = 5.464424565434456
[2018-04-17 16:17:19.826987]: ====================
[2018-04-17 16:17:19.832502]: Elapsed time since starting training: 0:22:05.228701
[2018-04-17 16:17:19.839019]: ====================
[2018-04-17 16:17:19.909205]: [Epoch: 204(13.609072715143428%): Data: 0.0%]:Running loss: 0.21857698261737823
[2018-04-17 16:17:21.173567]: [Epoch: 204(13.609072715143428%): Data: 25.333333333333336%]:Running loss: 4.371484756469727
[2018-04-17 16:17:22.432414]: [Epoch: 204(13.609072715143428%): Data: 50.66666666666667%]:Running loss: 8.524290919303894
[2018-04-17 16:17:25.974834]: Test set accuracy: 94.33962264150944% ,loss = 5.463901534676552
[2018-04-17 16:17:26.091646]: ====================
[2018-04-17 16:17:26.097660]: Elapsed time since starting training: 0:22:11.493358
[2018-04-17 16:17:26.103175]: ====================
[2018-04-17 16:17:26.171356]: [Epoch: 205(13.675783855903937%): Data: 0.0%]:Running loss: 0.21855606138706207
[2018-04-17 16:17:27.422182]: [Epoch: 205(13.675783855903937%): Data: 25.333333333333336%]:Running loss: 4.371067106723785
[2018-04-17 16:17:28.657467]: [Epoch: 205(13.675783855903937%): Data: 50.66666666666667%]:Running loss: 8.523476988077164
[2018-04-17 16:17:32.115161]: Test set accuracy: 94.33962264150944% ,loss = 5.4633863270282745
[2018-04-17 16:17:32.219439]: ====================
[2018-04-17 16:17:32.224953]: Elapsed time since starting training: 0:22:17.621152
[2018-04-17 16:17:32.230468]: ====================
[2018-04-17 16:17:32.307672]: [Epoch: 206(13.742494996664442%): Data: 0.0%]:Running loss: 0.21853545308113098
[2018-04-17 16:17:33.566018]: [Epoch: 206(13.742494996664442%): Data: 25.333333333333336%]:Running loss: 4.370658174157143
[2018-04-17 16:17:34.808823]: [Epoch: 206(13.742494996664442%): Data: 50.66666666666667%]:Running loss: 8.522683650255203
[2018-04-17 16:17:38.270527]: Test set accuracy: 94.33962264150944% ,loss = 5.46288900077343
[2018-04-17 16:17:38.377815]: ====================
[2018-04-17 16:17:38.384832]: Elapsed time since starting training: 0:22:23.781031
[2018-04-17 16:17:38.389845]: ====================
[2018-04-17 16:17:38.455018]: [Epoch: 207(13.809206137424951%): Data: 0.0%]:Running loss: 0.2185155600309372
[2018-04-17 16:17:39.708351]: [Epoch: 207(13.809206137424951%): Data: 25.333333333333336%]:Running loss: 4.370258390903473
[2018-04-17 16:17:40.941630]: [Epoch: 207(13.809206137424951%): Data: 50.66666666666667%]:Running loss: 8.521906420588493
[2018-04-17 16:17:44.390300]: Test set accuracy: 94.33962264150944% ,loss = 5.462396517395973
[2018-04-17 16:17:44.490066]: ====================
[2018-04-17 16:17:44.495580]: Elapsed time since starting training: 0:22:29.891779
[2018-04-17 16:17:44.501095]: ====================
[2018-04-17 16:17:44.564764]: [Epoch: 208(13.875917278185456%): Data: 0.0%]:Running loss: 0.21849586069583893
[2018-04-17 16:17:45.800550]: [Epoch: 208(13.875917278185456%): Data: 25.333333333333336%]:Running loss: 4.36986631155014
[2018-04-17 16:17:47.050875]: [Epoch: 208(13.875917278185456%): Data: 50.66666666666667%]:Running loss: 8.521144106984138
[2018-04-17 16:17:50.488014]: Test set accuracy: 94.33962264150944% ,loss = 5.461909994482994
[2018-04-17 16:17:50.594297]: ====================
[2018-04-17 16:17:50.601817]: Elapsed time since starting training: 0:22:35.998016
[2018-04-17 16:17:50.607833]: ====================
[2018-04-17 16:17:50.676014]: [Epoch: 209(13.942628418945963%): Data: 0.0%]:Running loss: 0.21847639977931976
[2018-04-17 16:17:51.917315]: [Epoch: 209(13.942628418945963%): Data: 25.333333333333336%]:Running loss: 4.369483649730682
[2018-04-17 16:17:53.170146]: [Epoch: 209(13.942628418945963%): Data: 50.66666666666667%]:Running loss: 8.520399525761604
[2018-04-17 16:17:56.598893]: Test set accuracy: 94.33962264150944% ,loss = 5.461442843079567
[2018-04-17 16:17:56.694647]: ====================
[2018-04-17 16:17:56.700162]: Elapsed time since starting training: 0:22:42.096361
[2018-04-17 16:17:56.705175]: ====================
[2018-04-17 16:17:56.773356]: [Epoch: 210(14.009339559706472%): Data: 0.0%]:Running loss: 0.21845771372318268
[2018-04-17 16:17:58.018166]: [Epoch: 210(14.009339559706472%): Data: 25.333333333333336%]:Running loss: 4.369107618927956
[2018-04-17 16:17:59.284534]: [Epoch: 210(14.009339559706472%): Data: 50.66666666666667%]:Running loss: 8.519667699933052
[2018-04-17 16:18:02.720675]: Test set accuracy: 94.33962264150944% ,loss = 5.460983514785767
[2018-04-17 16:18:02.827460]: ====================
[2018-04-17 16:18:02.833475]: Elapsed time since starting training: 0:22:48.229674
[2018-04-17 16:18:02.839491]: ====================
[2018-04-17 16:18:02.909678]: [Epoch: 211(14.076050700466977%): Data: 0.0%]:Running loss: 0.21843934059143066
[2018-04-17 16:18:04.167021]: [Epoch: 211(14.076050700466977%): Data: 25.333333333333336%]:Running loss: 4.368739798665047
[2018-04-17 16:18:05.398796]: [Epoch: 211(14.076050700466977%): Data: 50.66666666666667%]:Running loss: 8.518952265381813
[2018-04-17 16:18:08.835934]: Test set accuracy: 94.33962264150944% ,loss = 5.460529774427414
[2018-04-17 16:18:08.937705]: ====================
[2018-04-17 16:18:08.942718]: Elapsed time since starting training: 0:22:54.338917
[2018-04-17 16:18:08.947731]: ====================
[2018-04-17 16:18:09.021929]: [Epoch: 212(14.142761841227486%): Data: 0.0%]:Running loss: 0.21842119097709656
[2018-04-17 16:18:10.268247]: [Epoch: 212(14.142761841227486%): Data: 25.333333333333336%]:Running loss: 4.368379384279251
[2018-04-17 16:18:11.521073]: [Epoch: 212(14.142761841227486%): Data: 50.66666666666667%]:Running loss: 8.51825188100338
[2018-04-17 16:18:15.090063]: Test set accuracy: 94.33962264150944% ,loss = 5.460083857178688
[2018-04-17 16:18:15.195344]: ====================
[2018-04-17 16:18:15.201861]: Elapsed time since starting training: 0:23:00.597558
[2018-04-17 16:18:15.207375]: ====================
[2018-04-17 16:18:15.274554]: [Epoch: 213(14.209472981987991%): Data: 0.0%]:Running loss: 0.21840335428714752
[2018-04-17 16:18:16.580025]: [Epoch: 213(14.209472981987991%): Data: 25.333333333333336%]:Running loss: 4.368026107549667
[2018-04-17 16:18:17.898531]: [Epoch: 213(14.209472981987991%): Data: 50.66666666666667%]:Running loss: 8.517564788460732
[2018-04-17 16:18:21.424907]: Test set accuracy: 94.33962264150944% ,loss = 5.459655821323395
[2018-04-17 16:18:21.524172]: ====================
[2018-04-17 16:18:21.529686]: Elapsed time since starting training: 0:23:06.925384
[2018-04-17 16:18:21.535201]: ====================
[2018-04-17 16:18:21.607895]: [Epoch: 214(14.2761841227485%): Data: 0.0%]:Running loss: 0.2183862328529358
[2018-04-17 16:18:22.876267]: [Epoch: 214(14.2761841227485%): Data: 25.333333333333336%]:Running loss: 4.367680758237839
[2018-04-17 16:18:24.148153]: [Epoch: 214(14.2761841227485%): Data: 50.66666666666667%]:Running loss: 8.516893580555916
[2018-04-17 16:18:27.682547]: Test set accuracy: 94.33962264150944% ,loss = 5.4592277854681015
[2018-04-17 16:18:27.787827]: ====================
[2018-04-17 16:18:27.793343]: Elapsed time since starting training: 0:23:13.189039
[2018-04-17 16:18:27.798856]: ====================
[2018-04-17 16:18:27.874056]: [Epoch: 215(14.342895263509007%): Data: 0.0%]:Running loss: 0.21836911141872406
[2018-04-17 16:18:29.171005]: [Epoch: 215(14.342895263509007%): Data: 25.333333333333336%]:Running loss: 4.367341682314873
[2018-04-17 16:18:30.472967]: [Epoch: 215(14.342895263509007%): Data: 50.66666666666667%]:Running loss: 8.516235694289207
[2018-04-17 16:18:33.949711]: Test set accuracy: 94.33962264150944% ,loss = 5.458815768361092
[2018-04-17 16:18:34.049476]: ====================
[2018-04-17 16:18:34.055493]: Elapsed time since starting training: 0:23:19.451190
[2018-04-17 16:18:34.060506]: ====================
[2018-04-17 16:18:34.135205]: [Epoch: 216(14.409606404269512%): Data: 0.0%]:Running loss: 0.21835263073444366
[2018-04-17 16:18:35.412100]: [Epoch: 216(14.409606404269512%): Data: 25.333333333333336%]:Running loss: 4.367011249065399
[2018-04-17 16:18:36.704035]: [Epoch: 216(14.409606404269512%): Data: 50.66666666666667%]:Running loss: 8.515591442584991
[2018-04-17 16:18:40.174262]: Test set accuracy: 94.33962264150944% ,loss = 5.4584115743637085
[2018-04-17 16:18:40.277035]: ====================
[2018-04-17 16:18:40.283554]: Elapsed time since starting training: 0:23:25.679250
[2018-04-17 16:18:40.291073]: ====================
[2018-04-17 16:18:40.364275]: [Epoch: 217(14.476317545030021%): Data: 0.0%]:Running loss: 0.21833646297454834
[2018-04-17 16:18:41.650688]: [Epoch: 217(14.476317545030021%): Data: 25.333333333333336%]:Running loss: 4.366685584187508
[2018-04-17 16:18:42.911039]: [Epoch: 217(14.476317545030021%): Data: 50.66666666666667%]:Running loss: 8.51495911180973
[2018-04-17 16:18:46.372242]: Test set accuracy: 94.33962264150944% ,loss = 5.458014830946922
[2018-04-17 16:18:46.469000]: ====================
[2018-04-17 16:18:46.475016]: Elapsed time since starting training: 0:23:31.871215
[2018-04-17 16:18:46.480531]: ====================
[2018-04-17 16:18:46.552723]: [Epoch: 218(14.543028685790526%): Data: 0.0%]:Running loss: 0.2183205932378769
[2018-04-17 16:18:47.834632]: [Epoch: 218(14.543028685790526%): Data: 25.333333333333336%]:Running loss: 4.366369515657425
[2018-04-17 16:18:49.126065]: [Epoch: 218(14.543028685790526%): Data: 50.66666666666667%]:Running loss: 8.514342457056046
[2018-04-17 16:18:52.651940]: Test set accuracy: 94.33962264150944% ,loss = 5.457625910639763
[2018-04-17 16:18:52.758223]: ====================
[2018-04-17 16:18:52.764239]: Elapsed time since starting training: 0:23:38.159937
[2018-04-17 16:18:52.770255]: ====================
[2018-04-17 16:18:52.843449]: [Epoch: 219(14.609739826551035%): Data: 0.0%]:Running loss: 0.21830503642559052
[2018-04-17 16:18:54.120356]: [Epoch: 219(14.609739826551035%): Data: 25.333333333333336%]:Running loss: 4.366057261824608
[2018-04-17 16:18:55.393229]: [Epoch: 219(14.609739826551035%): Data: 50.66666666666667%]:Running loss: 8.513734728097916
[2018-04-17 16:18:58.945174]: Test set accuracy: 94.33962264150944% ,loss = 5.4572343826293945
[2018-04-17 16:18:59.046945]: ====================
[2018-04-17 16:18:59.052960]: Elapsed time since starting training: 0:23:44.449159
[2018-04-17 16:18:59.058476]: ====================
[2018-04-17 16:18:59.133174]: [Epoch: 220(14.676450967311542%): Data: 0.0%]:Running loss: 0.21828937530517578
[2018-04-17 16:19:00.410571]: [Epoch: 220(14.676450967311542%): Data: 25.333333333333336%]:Running loss: 4.365751653909683
[2018-04-17 16:19:01.664404]: [Epoch: 220(14.676450967311542%): Data: 50.66666666666667%]:Running loss: 8.5131416618824
[2018-04-17 16:19:05.333160]: Test set accuracy: 94.33962264150944% ,loss = 5.456862226128578
[2018-04-17 16:19:05.436435]: ====================
[2018-04-17 16:19:05.441949]: Elapsed time since starting training: 0:23:50.838148
[2018-04-17 16:19:05.447464]: ====================
[2018-04-17 16:19:05.520157]: [Epoch: 221(14.743162108072047%): Data: 0.0%]:Running loss: 0.21827448904514313
[2018-04-17 16:19:06.933916]: [Epoch: 221(14.743162108072047%): Data: 25.333333333333336%]:Running loss: 4.3654534965753555
[2018-04-17 16:19:08.326619]: [Epoch: 221(14.743162108072047%): Data: 50.66666666666667%]:Running loss: 8.51256114244461
[2018-04-17 16:19:11.840462]: Test set accuracy: 94.33962264150944% ,loss = 5.456501618027687
[2018-04-17 16:19:11.952769]: ====================
[2018-04-17 16:19:11.958276]: Elapsed time since starting training: 0:23:57.354475
[2018-04-17 16:19:11.964793]: ====================
[2018-04-17 16:19:12.037486]: [Epoch: 222(14.809873248832556%): Data: 0.0%]:Running loss: 0.21826006472110748
[2018-04-17 16:19:13.304355]: [Epoch: 222(14.809873248832556%): Data: 25.333333333333336%]:Running loss: 4.365159824490547
[2018-04-17 16:19:14.570221]: [Epoch: 222(14.809873248832556%): Data: 50.66666666666667%]:Running loss: 8.511990010738373
[2018-04-17 16:19:18.162272]: Test set accuracy: 94.33962264150944% ,loss = 5.456135794520378
[2018-04-17 16:19:18.274070]: ====================
[2018-04-17 16:19:18.281089]: Elapsed time since starting training: 0:24:03.676786
[2018-04-17 16:19:18.287605]: ====================
[2018-04-17 16:19:18.360800]: [Epoch: 223(14.876584389593061%): Data: 0.0%]:Running loss: 0.21824543178081512
[2018-04-17 16:19:19.607114]: [Epoch: 223(14.876584389593061%): Data: 25.333333333333336%]:Running loss: 4.364873394370079
[2018-04-17 16:19:20.859945]: [Epoch: 223(14.876584389593061%): Data: 50.66666666666667%]:Running loss: 8.511433631181717
[2018-04-17 16:19:24.424924]: Test set accuracy: 94.33962264150944% ,loss = 5.455788969993591
[2018-04-17 16:19:24.536223]: ====================
[2018-04-17 16:19:24.542237]: Elapsed time since starting training: 0:24:09.938436
[2018-04-17 16:19:24.548754]: ====================
[2018-04-17 16:19:24.620945]: [Epoch: 224(14.94329553035357%): Data: 0.0%]:Running loss: 0.21823155879974365
[2018-04-17 16:19:25.903356]: [Epoch: 224(14.94329553035357%): Data: 25.333333333333336%]:Running loss: 4.364592283964157
[2018-04-17 16:19:27.193787]: [Epoch: 224(14.94329553035357%): Data: 50.66666666666667%]:Running loss: 8.510885655879974
[2018-04-17 16:19:30.858030]: Test set accuracy: 94.33962264150944% ,loss = 5.455440282821655
[2018-04-17 16:19:30.973337]: ====================
[2018-04-17 16:19:30.978851]: Elapsed time since starting training: 0:24:16.375050
[2018-04-17 16:19:30.985368]: ====================
[2018-04-17 16:19:31.060067]: [Epoch: 225(15.010006671114077%): Data: 0.0%]:Running loss: 0.2182176113128662
[2018-04-17 16:19:32.340472]: [Epoch: 225(15.010006671114077%): Data: 25.333333333333336%]:Running loss: 4.364316686987877
[2018-04-17 16:19:33.619372]: [Epoch: 225(15.010006671114077%): Data: 50.66666666666667%]:Running loss: 8.510349959135056
[2018-04-17 16:19:37.200394]: Test set accuracy: 94.33962264150944% ,loss = 5.455101281404495
[2018-04-17 16:19:37.311189]: ====================
[2018-04-17 16:19:37.317707]: Elapsed time since starting training: 0:24:22.713906
[2018-04-17 16:19:37.324223]: ====================
[2018-04-17 16:19:37.395413]: [Epoch: 226(15.076717811874582%): Data: 0.0%]:Running loss: 0.2182040512561798
[2018-04-17 16:19:38.688352]: [Epoch: 226(15.076717811874582%): Data: 25.333333333333336%]:Running loss: 4.364047512412071
[2018-04-17 16:19:39.995827]: [Epoch: 226(15.076717811874582%): Data: 50.66666666666667%]:Running loss: 8.509825348854065
[2018-04-17 16:19:43.717727]: Test set accuracy: 94.33962264150944% ,loss = 5.454764142632484
[2018-04-17 16:19:43.825515]: ====================
[2018-04-17 16:19:43.831029]: Elapsed time since starting training: 0:24:29.227228
[2018-04-17 16:19:43.837045]: ====================
[2018-04-17 16:19:43.910741]: [Epoch: 227(15.143428952635091%): Data: 0.0%]:Running loss: 0.21819056570529938
[2018-04-17 16:19:45.200169]: [Epoch: 227(15.143428952635091%): Data: 25.333333333333336%]:Running loss: 4.363779798150063
[2018-04-17 16:19:46.507646]: [Epoch: 227(15.143428952635091%): Data: 50.66666666666667%]:Running loss: 8.509309187531471
[2018-04-17 16:19:50.332316]: Test set accuracy: 94.33962264150944% ,loss = 5.454442650079727
[2018-04-17 16:19:50.442108]: ====================
[2018-04-17 16:19:50.448625]: Elapsed time since starting training: 0:24:35.844824
[2018-04-17 16:19:50.454642]: ====================
[2018-04-17 16:19:50.525830]: [Epoch: 228(15.210140093395596%): Data: 0.0%]:Running loss: 0.2181777060031891
[2018-04-17 16:19:51.840826]: [Epoch: 228(15.210140093395596%): Data: 25.333333333333336%]:Running loss: 4.363522857427597
[2018-04-17 16:19:53.137775]: [Epoch: 228(15.210140093395596%): Data: 50.66666666666667%]:Running loss: 8.508806467056274
[2018-04-17 16:19:56.804025]: Test set accuracy: 94.33962264150944% ,loss = 5.454131215810776
[2018-04-17 16:19:56.948408]: ====================
[2018-04-17 16:19:56.955427]: Elapsed time since starting training: 0:24:42.351125
[2018-04-17 16:19:56.960942]: ====================
[2018-04-17 16:19:57.031630]: [Epoch: 229(15.276851234156105%): Data: 0.0%]:Running loss: 0.21816524863243103
[2018-04-17 16:19:58.559692]: [Epoch: 229(15.276851234156105%): Data: 25.333333333333336%]:Running loss: 4.363271594047546
[2018-04-17 16:19:59.919809]: [Epoch: 229(15.276851234156105%): Data: 50.66666666666667%]:Running loss: 8.508315160870552
[2018-04-17 16:20:03.485790]: Test set accuracy: 94.33962264150944% ,loss = 5.453819781541824
[2018-04-17 16:20:03.596586]: ====================
[2018-04-17 16:20:03.602602]: Elapsed time since starting training: 0:24:48.998299
[2018-04-17 16:20:03.609119]: ====================
[2018-04-17 16:20:03.679806]: [Epoch: 230(15.343562374916612%): Data: 0.0%]:Running loss: 0.21815279126167297
[2018-04-17 16:20:05.071507]: [Epoch: 230(15.343562374916612%): Data: 25.333333333333336%]:Running loss: 4.363020360469818
[2018-04-17 16:20:06.542920]: [Epoch: 230(15.343562374916612%): Data: 50.66666666666667%]:Running loss: 8.507829889655113
[2018-04-17 16:20:10.224208]: Test set accuracy: 94.33962264150944% ,loss = 5.4535068571567535
[2018-04-17 16:20:10.332997]: ====================
[2018-04-17 16:20:10.339013]: Elapsed time since starting training: 0:24:55.735212
[2018-04-17 16:20:10.345030]: ====================
[2018-04-17 16:20:10.421734]: [Epoch: 231(15.410273515677117%): Data: 0.0%]:Running loss: 0.21814027428627014
[2018-04-17 16:20:11.710159]: [Epoch: 231(15.410273515677117%): Data: 25.333333333333336%]:Running loss: 4.362775683403015
[2018-04-17 16:20:13.023652]: [Epoch: 231(15.410273515677117%): Data: 50.66666666666667%]:Running loss: 8.507354363799095
[2018-04-17 16:20:16.835788]: Test set accuracy: 94.33962264150944% ,loss = 5.453213304281235
[2018-04-17 16:20:16.966636]: ====================
[2018-04-17 16:20:16.974157]: Elapsed time since starting training: 0:25:02.370356
[2018-04-17 16:20:16.980172]: ====================
[2018-04-17 16:20:17.059383]: [Epoch: 232(15.476984656437626%): Data: 0.0%]:Running loss: 0.2181285321712494
[2018-04-17 16:20:18.360342]: [Epoch: 232(15.476984656437626%): Data: 25.333333333333336%]:Running loss: 4.362538635730743
[2018-04-17 16:20:19.656790]: [Epoch: 232(15.476984656437626%): Data: 50.66666666666667%]:Running loss: 8.506891638040543
[2018-04-17 16:20:23.186675]: Test set accuracy: 94.33962264150944% ,loss = 5.452918261289597
[2018-04-17 16:20:23.291955]: ====================
[2018-04-17 16:20:23.297470]: Elapsed time since starting training: 0:25:08.693669
[2018-04-17 16:20:23.302985]: ====================
[2018-04-17 16:20:23.370665]: [Epoch: 233(15.543695797198131%): Data: 0.0%]:Running loss: 0.21811673045158386
[2018-04-17 16:20:24.627506]: [Epoch: 233(15.543695797198131%): Data: 25.333333333333336%]:Running loss: 4.3623044937849045
[2018-04-17 16:20:25.901394]: [Epoch: 233(15.543695797198131%): Data: 50.66666666666667%]:Running loss: 8.506436064839363
[2018-04-17 16:20:29.409722]: Test set accuracy: 94.33962264150944% ,loss = 5.452624708414078
[2018-04-17 16:20:29.514000]: ====================
[2018-04-17 16:20:29.520517]: Elapsed time since starting training: 0:25:14.916215
[2018-04-17 16:20:29.526032]: ====================
[2018-04-17 16:20:29.600241]: [Epoch: 234(15.61040693795864%): Data: 0.0%]:Running loss: 0.2181049883365631
[2018-04-17 16:20:30.854564]: [Epoch: 234(15.61040693795864%): Data: 25.333333333333336%]:Running loss: 4.362075015902519
[2018-04-17 16:20:32.131961]: [Epoch: 234(15.61040693795864%): Data: 50.66666666666667%]:Running loss: 8.505990207195282
[2018-04-17 16:20:35.687916]: Test set accuracy: 94.33962264150944% ,loss = 5.452341586351395
[2018-04-17 16:20:35.797207]: ====================
[2018-04-17 16:20:35.803223]: Elapsed time since starting training: 0:25:21.198920
[2018-04-17 16:20:35.809239]: ====================
[2018-04-17 16:20:35.881932]: [Epoch: 235(15.677118078719147%): Data: 0.0%]:Running loss: 0.2180936634540558
[2018-04-17 16:20:37.153313]: [Epoch: 235(15.677118078719147%): Data: 25.333333333333336%]:Running loss: 4.361849367618561
[2018-04-17 16:20:38.408154]: [Epoch: 235(15.677118078719147%): Data: 50.66666666666667%]:Running loss: 8.505551844835281
[2018-04-17 16:20:41.879384]: Test set accuracy: 94.33962264150944% ,loss = 5.452073737978935
[2018-04-17 16:20:41.978649]: ====================
[2018-04-17 16:20:41.984669]: Elapsed time since starting training: 0:25:27.380868
[2018-04-17 16:20:41.990680]: ====================
[2018-04-17 16:20:42.062871]: [Epoch: 236(15.743829219479652%): Data: 0.0%]:Running loss: 0.2180829495191574
[2018-04-17 16:20:43.327735]: [Epoch: 236(15.743829219479652%): Data: 25.333333333333336%]:Running loss: 4.361629888415337
[2018-04-17 16:20:44.580065]: [Epoch: 236(15.743829219479652%): Data: 50.66666666666667%]:Running loss: 8.505124554038048
[2018-04-17 16:20:48.043775]: Test set accuracy: 94.33962264150944% ,loss = 5.451801046729088
[2018-04-17 16:20:48.147551]: ====================
[2018-04-17 16:20:48.153065]: Elapsed time since starting training: 0:25:33.549264
[2018-04-17 16:20:48.158591]: ====================
[2018-04-17 16:20:48.229268]: [Epoch: 237(15.81054036024016%): Data: 0.0%]:Running loss: 0.2180720418691635
[2018-04-17 16:20:49.496137]: [Epoch: 237(15.81054036024016%): Data: 25.333333333333336%]:Running loss: 4.361414074897766
[2018-04-17 16:20:50.754985]: [Epoch: 237(15.81054036024016%): Data: 50.66666666666667%]:Running loss: 8.504704713821411
[2018-04-17 16:20:54.279857]: Test set accuracy: 94.33962264150944% ,loss = 5.451539158821106
[2018-04-17 16:20:54.384134]: ====================
[2018-04-17 16:20:54.389649]: Elapsed time since starting training: 0:25:39.785848
[2018-04-17 16:20:54.395163]: ====================
[2018-04-17 16:20:54.466862]: [Epoch: 238(15.877251501000666%): Data: 0.0%]:Running loss: 0.21806156635284424
[2018-04-17 16:20:55.719685]: [Epoch: 238(15.877251501000666%): Data: 25.333333333333336%]:Running loss: 4.361202239990234
[2018-04-17 16:20:56.997081]: [Epoch: 238(15.877251501000666%): Data: 50.66666666666667%]:Running loss: 8.504292652010918
[2018-04-17 16:21:00.512930]: Test set accuracy: 94.33962264150944% ,loss = 5.451280623674393
[2018-04-17 16:21:00.625730]: ====================
[2018-04-17 16:21:00.631750]: Elapsed time since starting training: 0:25:46.027949
[2018-04-17 16:21:00.637762]: ====================
[2018-04-17 16:21:00.705442]: [Epoch: 239(15.943962641761175%): Data: 0.0%]:Running loss: 0.2180512249469757
[2018-04-17 16:21:01.965292]: [Epoch: 239(15.943962641761175%): Data: 25.333333333333336%]:Running loss: 4.360995411872864
[2018-04-17 16:21:03.209601]: [Epoch: 239(15.943962641761175%): Data: 50.66666666666667%]:Running loss: 8.50388953089714
[2018-04-17 16:21:06.717428]: Test set accuracy: 94.33962264150944% ,loss = 5.451027676463127
[2018-04-17 16:21:06.819700]: ====================
[2018-04-17 16:21:06.825716]: Elapsed time since starting training: 0:25:52.221915
[2018-04-17 16:21:06.831732]: ====================
[2018-04-17 16:21:06.897908]: [Epoch: 240(16.010673782521682%): Data: 0.0%]:Running loss: 0.21804110705852509
[2018-04-17 16:21:08.161773]: [Epoch: 240(16.010673782521682%): Data: 25.333333333333336%]:Running loss: 4.360791623592377
[2018-04-17 16:21:09.433154]: [Epoch: 240(16.010673782521682%): Data: 50.66666666666667%]:Running loss: 8.503495126962662
[2018-04-17 16:21:12.890847]: Test set accuracy: 94.33962264150944% ,loss = 5.450775846838951
[2018-04-17 16:21:13.001142]: ====================
[2018-04-17 16:21:13.009163]: Elapsed time since starting training: 0:25:58.405362
[2018-04-17 16:21:13.014678]: ====================
[2018-04-17 16:21:13.082858]: [Epoch: 241(16.077384923282185%): Data: 0.0%]:Running loss: 0.21803103387355804
[2018-04-17 16:21:14.325161]: [Epoch: 241(16.077384923282185%): Data: 25.333333333333336%]:Running loss: 4.360592424869537
[2018-04-17 16:21:15.578996]: [Epoch: 241(16.077384923282185%): Data: 50.66666666666667%]:Running loss: 8.503106728196144
[2018-04-17 16:21:19.017137]: Test set accuracy: 94.33962264150944% ,loss = 5.450530722737312
[2018-04-17 16:21:19.125927]: ====================
[2018-04-17 16:21:19.131442]: Elapsed time since starting training: 0:26:04.527641
[2018-04-17 16:21:19.136956]: ====================
[2018-04-17 16:21:19.208647]: [Epoch: 242(16.144096064042696%): Data: 0.0%]:Running loss: 0.2180212289094925
[2018-04-17 16:21:20.476518]: [Epoch: 242(16.144096064042696%): Data: 25.333333333333336%]:Running loss: 4.360397443175316
[2018-04-17 16:21:21.749403]: [Epoch: 242(16.144096064042696%): Data: 50.66666666666667%]:Running loss: 8.50272698700428
[2018-04-17 16:21:25.204088]: Test set accuracy: 94.33962264150944% ,loss = 5.4502882063388824
[2018-04-17 16:21:25.311373]: ====================
[2018-04-17 16:21:25.316889]: Elapsed time since starting training: 0:26:10.712586
[2018-04-17 16:21:25.322404]: ====================
[2018-04-17 16:21:25.391587]: [Epoch: 243(16.210807204803203%): Data: 0.0%]:Running loss: 0.2180115282535553
[2018-04-17 16:21:26.658957]: [Epoch: 243(16.210807204803203%): Data: 25.333333333333336%]:Running loss: 4.360205754637718
[2018-04-17 16:21:27.908780]: [Epoch: 243(16.210807204803203%): Data: 50.66666666666667%]:Running loss: 8.502354875206947
[2018-04-17 16:21:31.343413]: Test set accuracy: 94.33962264150944% ,loss = 5.450053885579109
[2018-04-17 16:21:31.449195]: ====================
[2018-04-17 16:21:31.455210]: Elapsed time since starting training: 0:26:16.850908
[2018-04-17 16:21:31.461227]: ====================
[2018-04-17 16:21:31.533418]: [Epoch: 244(16.27751834556371%): Data: 0.0%]:Running loss: 0.21800215542316437
[2018-04-17 16:21:32.799284]: [Epoch: 244(16.27751834556371%): Data: 25.333333333333336%]:Running loss: 4.36001855134964
[2018-04-17 16:21:34.042590]: [Epoch: 244(16.27751834556371%): Data: 50.66666666666667%]:Running loss: 8.501989856362343
[2018-04-17 16:21:37.504796]: Test set accuracy: 94.33962264150944% ,loss = 5.449822545051575
[2018-04-17 16:21:37.618098]: ====================
[2018-04-17 16:21:37.624113]: Elapsed time since starting training: 0:26:23.020312
[2018-04-17 16:21:37.630630]: ====================
[2018-04-17 16:21:37.697809]: [Epoch: 245(16.344229486324217%): Data: 0.0%]:Running loss: 0.217992901802063
[2018-04-17 16:21:38.922566]: [Epoch: 245(16.344229486324217%): Data: 25.333333333333336%]:Running loss: 4.35983507335186
[2018-04-17 16:21:40.175899]: [Epoch: 245(16.344229486324217%): Data: 50.66666666666667%]:Running loss: 8.501632779836655
[2018-04-17 16:21:43.661667]: Test set accuracy: 94.33962264150944% ,loss = 5.449593439698219
[2018-04-17 16:21:43.860195]: ====================
[2018-04-17 16:21:43.866713]: Elapsed time since starting training: 0:26:29.262912
[2018-04-17 16:21:43.872729]: ====================
[2018-04-17 16:21:43.943918]: [Epoch: 246(16.41094062708472%): Data: 0.0%]:Running loss: 0.21798373758792877
[2018-04-17 16:21:45.178700]: [Epoch: 246(16.41094062708472%): Data: 25.333333333333336%]:Running loss: 4.359654679894447
[2018-04-17 16:21:46.429527]: [Epoch: 246(16.41094062708472%): Data: 50.66666666666667%]:Running loss: 8.501282274723053
[2018-04-17 16:21:49.915796]: Test set accuracy: 94.33962264150944% ,loss = 5.449380353093147
[2018-04-17 16:21:50.023082]: ====================
[2018-04-17 16:21:50.028597]: Elapsed time since starting training: 0:26:35.424796
[2018-04-17 16:21:50.034613]: ====================
[2018-04-17 16:21:50.106303]: [Epoch: 247(16.47765176784523%): Data: 0.0%]:Running loss: 0.2179752141237259
[2018-04-17 16:21:51.375679]: [Epoch: 247(16.47765176784523%): Data: 25.333333333333336%]:Running loss: 4.359478130936623
[2018-04-17 16:21:52.623497]: [Epoch: 247(16.47765176784523%): Data: 50.66666666666667%]:Running loss: 8.500939190387726
[2018-04-17 16:21:56.147366]: Test set accuracy: 94.33962264150944% ,loss = 5.449160188436508
[2018-04-17 16:21:56.250642]: ====================
[2018-04-17 16:21:56.256156]: Elapsed time since starting training: 0:26:41.651854
[2018-04-17 16:21:56.261672]: ====================
[2018-04-17 16:21:56.338374]: [Epoch: 248(16.544362908605738%): Data: 0.0%]:Running loss: 0.21796640753746033
[2018-04-17 16:21:57.584187]: [Epoch: 248(16.544362908605738%): Data: 25.333333333333336%]:Running loss: 4.3593045473098755
[2018-04-17 16:21:58.848047]: [Epoch: 248(16.544362908605738%): Data: 50.66666666666667%]:Running loss: 8.500602155923843
[2018-04-17 16:22:02.346851]: Test set accuracy: 94.33962264150944% ,loss = 5.448943376541138
[2018-04-17 16:22:02.457144]: ====================
[2018-04-17 16:22:02.464163]: Elapsed time since starting training: 0:26:47.860362
[2018-04-17 16:22:02.469177]: ====================
[2018-04-17 16:22:02.543875]: [Epoch: 249(16.611074049366245%): Data: 0.0%]:Running loss: 0.2179577350616455
[2018-04-17 16:22:03.829794]: [Epoch: 249(16.611074049366245%): Data: 25.333333333333336%]:Running loss: 4.359134763479233
[2018-04-17 16:22:05.073606]: [Epoch: 249(16.611074049366245%): Data: 50.66666666666667%]:Running loss: 8.500271648168564
[2018-04-17 16:22:08.555364]: Test set accuracy: 94.33962264150944% ,loss = 5.448734387755394
[2018-04-17 16:22:08.659141]: ====================
[2018-04-17 16:22:08.665156]: Elapsed time since starting training: 0:26:54.061355
[2018-04-17 16:22:08.670671]: ====================
[2018-04-17 16:22:08.740857]: [Epoch: 250(16.67778519012675%): Data: 0.0%]:Running loss: 0.21794937551021576
[2018-04-17 16:22:10.020760]: [Epoch: 250(16.67778519012675%): Data: 25.333333333333336%]:Running loss: 4.35896871984005
[2018-04-17 16:22:11.265571]: [Epoch: 250(16.67778519012675%): Data: 50.66666666666667%]:Running loss: 8.499948605895042
[2018-04-17 16:22:14.733291]: Test set accuracy: 94.33962264150944% ,loss = 5.448529496788979
[2018-04-17 16:22:14.840576]: ====================
[2018-04-17 16:22:14.846593]: Elapsed time since starting training: 0:27:00.242792
[2018-04-17 16:22:14.851606]: ====================
[2018-04-17 16:22:14.920789]: [Epoch: 251(16.744496330887255%): Data: 0.0%]:Running loss: 0.21794117987155914
[2018-04-17 16:22:16.198186]: [Epoch: 251(16.744496330887255%): Data: 25.333333333333336%]:Running loss: 4.358805730938911
[2018-04-17 16:22:17.470068]: [Epoch: 251(16.744496330887255%): Data: 50.66666666666667%]:Running loss: 8.499630779027939
[2018-04-17 16:22:20.970376]: Test set accuracy: 94.33962264150944% ,loss = 5.44833205640316
[2018-04-17 16:22:21.080168]: ====================
[2018-04-17 16:22:21.085682]: Elapsed time since starting training: 0:27:06.481381
[2018-04-17 16:22:21.091698]: ====================
[2018-04-17 16:22:21.159879]: [Epoch: 252(16.811207471647766%): Data: 0.0%]:Running loss: 0.2179332822561264
[2018-04-17 16:22:22.418225]: [Epoch: 252(16.811207471647766%): Data: 25.333333333333336%]:Running loss: 4.358645871281624
[2018-04-17 16:22:23.666545]: [Epoch: 252(16.811207471647766%): Data: 50.66666666666667%]:Running loss: 8.499320045113564
[2018-04-17 16:22:27.152814]: Test set accuracy: 94.33962264150944% ,loss = 5.4481275379657745
[2018-04-17 16:22:27.267119]: ====================
[2018-04-17 16:22:27.272634]: Elapsed time since starting training: 0:27:12.668833
[2018-04-17 16:22:27.278649]: ====================
[2018-04-17 16:22:27.351342]: [Epoch: 253(16.877918612408273%): Data: 0.0%]:Running loss: 0.21792510151863098
[2018-04-17 16:22:28.614200]: [Epoch: 253(16.877918612408273%): Data: 25.333333333333336%]:Running loss: 4.358486890792847
[2018-04-17 16:22:29.860013]: [Epoch: 253(16.877918612408273%): Data: 50.66666666666667%]:Running loss: 8.499011293053627
[2018-04-17 16:22:33.352298]: Test set accuracy: 94.33962264150944% ,loss = 5.447946861386299
[2018-04-17 16:22:33.458080]: ====================
[2018-04-17 16:22:33.464598]: Elapsed time since starting training: 0:27:18.860797
[2018-04-17 16:22:33.470112]: ====================
[2018-04-17 16:22:33.538293]: [Epoch: 254(16.94462975316878%): Data: 0.0%]:Running loss: 0.21791787445545197
[2018-04-17 16:22:34.790623]: [Epoch: 254(16.94462975316878%): Data: 25.333333333333336%]:Running loss: 4.358336254954338
[2018-04-17 16:22:36.044457]: [Epoch: 254(16.94462975316878%): Data: 50.66666666666667%]:Running loss: 8.498718693852425
[2018-04-17 16:22:39.482098]: Test set accuracy: 94.33962264150944% ,loss = 5.447754263877869
[2018-04-17 16:22:39.589383]: ====================
[2018-04-17 16:22:39.594898]: Elapsed time since starting training: 0:27:24.991097
[2018-04-17 16:22:39.600413]: ====================
[2018-04-17 16:22:39.669596]: [Epoch: 255(17.011340893929287%): Data: 0.0%]:Running loss: 0.21791017055511475
[2018-04-17 16:22:40.900369]: [Epoch: 255(17.011340893929287%): Data: 25.333333333333336%]:Running loss: 4.358183413743973
[2018-04-17 16:22:42.178267]: [Epoch: 255(17.011340893929287%): Data: 50.66666666666667%]:Running loss: 8.498422026634216
[2018-04-17 16:22:45.647993]: Test set accuracy: 94.33962264150944% ,loss = 5.447565391659737
[2018-04-17 16:22:45.750767]: ====================
[2018-04-17 16:22:45.756281]: Elapsed time since starting training: 0:27:31.152480
[2018-04-17 16:22:45.761295]: ====================
[2018-04-17 16:22:45.834501]: [Epoch: 256(17.07805203468979%): Data: 0.0%]:Running loss: 0.21790261566638947
[2018-04-17 16:22:47.079808]: [Epoch: 256(17.07805203468979%): Data: 25.333333333333336%]:Running loss: 4.358037009835243
[2018-04-17 16:22:48.344162]: [Epoch: 256(17.07805203468979%): Data: 50.66666666666667%]:Running loss: 8.498135104775429
[2018-04-17 16:22:51.816398]: Test set accuracy: 94.33962264150944% ,loss = 5.44738844037056
[2018-04-17 16:22:51.923685]: ====================
[2018-04-17 16:22:51.929199]: Elapsed time since starting training: 0:27:37.325398
[2018-04-17 16:22:51.935215]: ====================
[2018-04-17 16:22:52.003396]: [Epoch: 257(17.1447631754503%): Data: 0.0%]:Running loss: 0.2178955376148224
[2018-04-17 16:22:53.329422]: [Epoch: 257(17.1447631754503%): Data: 25.333333333333336%]:Running loss: 4.357891827821732
[2018-04-17 16:22:54.652449]: [Epoch: 257(17.1447631754503%): Data: 50.66666666666667%]:Running loss: 8.49785302579403
[2018-04-17 16:22:58.195361]: Test set accuracy: 94.33962264150944% ,loss = 5.447212979197502
[2018-04-17 16:22:58.307659]: ====================
[2018-04-17 16:22:58.314177]: Elapsed time since starting training: 0:27:43.709874
[2018-04-17 16:22:58.319190]: ====================
[2018-04-17 16:22:58.394390]: [Epoch: 258(17.211474316210808%): Data: 0.0%]:Running loss: 0.21788851916790009
[2018-04-17 16:22:59.661760]: [Epoch: 258(17.211474316210808%): Data: 25.333333333333336%]:Running loss: 4.357749059796333
[2018-04-17 16:23:00.936649]: [Epoch: 258(17.211474316210808%): Data: 50.66666666666667%]:Running loss: 8.497576162219048
[2018-04-17 16:23:04.480572]: Test set accuracy: 94.33962264150944% ,loss = 5.447036400437355
[2018-04-17 16:23:04.593374]: ====================
[2018-04-17 16:23:04.599389]: Elapsed time since starting training: 0:27:49.995588
[2018-04-17 16:23:04.605417]: ====================
[2018-04-17 16:23:04.677597]: [Epoch: 259(17.278185456971315%): Data: 0.0%]:Running loss: 0.2178814560174942
[2018-04-17 16:23:05.953990]: [Epoch: 259(17.278185456971315%): Data: 25.333333333333336%]:Running loss: 4.357609435915947
[2018-04-17 16:23:07.204817]: [Epoch: 259(17.278185456971315%): Data: 50.66666666666667%]:Running loss: 8.497305363416672
[2018-04-17 16:23:10.721668]: Test set accuracy: 94.33962264150944% ,loss = 5.446867272257805
[2018-04-17 16:23:10.824943]: ====================
[2018-04-17 16:23:10.830457]: Elapsed time since starting training: 0:27:56.226656
[2018-04-17 16:23:10.836473]: ====================
[2018-04-17 16:23:10.905156]: [Epoch: 260(17.34489659773182%): Data: 0.0%]:Running loss: 0.2178746908903122
[2018-04-17 16:23:12.150467]: [Epoch: 260(17.34489659773182%): Data: 25.333333333333336%]:Running loss: 4.357473284006119
[2018-04-17 16:23:13.434882]: [Epoch: 260(17.34489659773182%): Data: 50.66666666666667%]:Running loss: 8.497039049863815
[2018-04-17 16:23:16.887563]: Test set accuracy: 94.33962264150944% ,loss = 5.4466936737298965
[2018-04-17 16:23:16.995851]: ====================
[2018-04-17 16:23:17.001365]: Elapsed time since starting training: 0:28:02.397063
[2018-04-17 16:23:17.006880]: ====================
[2018-04-17 16:23:17.077067]: [Epoch: 261(17.41160773849233%): Data: 0.0%]:Running loss: 0.21786774694919586
[2018-04-17 16:23:18.333407]: [Epoch: 261(17.41160773849233%): Data: 25.333333333333336%]:Running loss: 4.357339426875114
[2018-04-17 16:23:19.596766]: [Epoch: 261(17.41160773849233%): Data: 50.66666666666667%]:Running loss: 8.496779263019562
[2018-04-17 16:23:23.074514]: Test set accuracy: 94.33962264150944% ,loss = 5.4465267807245255
[2018-04-17 16:23:23.177789]: ====================
[2018-04-17 16:23:23.183805]: Elapsed time since starting training: 0:28:08.580004
[2018-04-17 16:23:23.189319]: ====================
[2018-04-17 16:23:23.259506]: [Epoch: 262(17.478318879252836%): Data: 0.0%]:Running loss: 0.21786107122898102
[2018-04-17 16:23:24.564476]: [Epoch: 262(17.478318879252836%): Data: 25.333333333333336%]:Running loss: 4.35720731317997
[2018-04-17 16:23:25.836859]: [Epoch: 262(17.478318879252836%): Data: 50.66666666666667%]:Running loss: 8.49652424454689
[2018-04-17 16:23:29.377273]: Test set accuracy: 94.33962264150944% ,loss = 5.446366965770721
[2018-04-17 16:23:29.496591]: ====================
[2018-04-17 16:23:29.502105]: Elapsed time since starting training: 0:28:14.898304
[2018-04-17 16:23:29.508121]: ====================
[2018-04-17 16:23:29.581817]: [Epoch: 263(17.545030020013343%): Data: 0.0%]:Running loss: 0.21785467863082886
[2018-04-17 16:23:30.850189]: [Epoch: 263(17.545030020013343%): Data: 25.333333333333336%]:Running loss: 4.3570796847343445
[2018-04-17 16:23:32.119564]: [Epoch: 263(17.545030020013343%): Data: 50.66666666666667%]:Running loss: 8.496274322271347
[2018-04-17 16:23:35.689557]: Test set accuracy: 94.33962264150944% ,loss = 5.4462045431137085
[2018-04-17 16:23:35.798847]: ====================
[2018-04-17 16:23:35.804864]: Elapsed time since starting training: 0:28:21.200562
[2018-04-17 16:23:35.811381]: ====================
[2018-04-17 16:23:35.885578]: [Epoch: 264(17.61174116077385%): Data: 0.0%]:Running loss: 0.21784818172454834
[2018-04-17 16:23:37.114859]: [Epoch: 264(17.61174116077385%): Data: 25.333333333333336%]:Running loss: 4.356953382492065
[2018-04-17 16:23:38.347123]: [Epoch: 264(17.61174116077385%): Data: 50.66666666666667%]:Running loss: 8.496027499437332
[2018-04-17 16:23:41.847431]: Test set accuracy: 94.33962264150944% ,loss = 5.446050316095352
[2018-04-17 16:23:41.961735]: ====================
[2018-04-17 16:23:41.968252]: Elapsed time since starting training: 0:28:27.364451
[2018-04-17 16:23:41.973767]: ====================
[2018-04-17 16:23:42.048475]: [Epoch: 265(17.678452301534357%): Data: 0.0%]:Running loss: 0.2178420126438141
[2018-04-17 16:23:43.300294]: [Epoch: 265(17.678452301534357%): Data: 25.333333333333336%]:Running loss: 4.356829151511192
[2018-04-17 16:23:44.609275]: [Epoch: 265(17.678452301534357%): Data: 50.66666666666667%]:Running loss: 8.49578706920147
[2018-04-17 16:23:48.091534]: Test set accuracy: 94.33962264150944% ,loss = 5.445905774831772
[2018-04-17 16:23:48.209347]: ====================
[2018-04-17 16:23:48.215363]: Elapsed time since starting training: 0:28:33.611562
[2018-04-17 16:23:48.222382]: ====================
[2018-04-17 16:23:48.290563]: [Epoch: 266(17.745163442294864%): Data: 0.0%]:Running loss: 0.21783623099327087
[2018-04-17 16:23:49.524348]: [Epoch: 266(17.745163442294864%): Data: 25.333333333333336%]:Running loss: 4.35670804977417
[2018-04-17 16:23:50.769159]: [Epoch: 266(17.745163442294864%): Data: 50.66666666666667%]:Running loss: 8.495551511645317
[2018-04-17 16:23:54.278489]: Test set accuracy: 94.33962264150944% ,loss = 5.445753037929535
[2018-04-17 16:23:54.417359]: ====================
[2018-04-17 16:23:54.422874]: Elapsed time since starting training: 0:28:39.818571
[2018-04-17 16:23:54.427887]: ====================
[2018-04-17 16:23:54.496569]: [Epoch: 267(17.81187458305537%): Data: 0.0%]:Running loss: 0.2178301215171814
[2018-04-17 16:23:55.722328]: [Epoch: 267(17.81187458305537%): Data: 25.333333333333336%]:Running loss: 4.35658971965313
[2018-04-17 16:23:56.948088]: [Epoch: 267(17.81187458305537%): Data: 50.66666666666667%]:Running loss: 8.495320975780487
[2018-04-17 16:24:00.296992]: Test set accuracy: 94.33962264150944% ,loss = 5.4456111043691635
[2018-04-17 16:24:00.403275]: ====================
[2018-04-17 16:24:00.408791]: Elapsed time since starting training: 0:28:45.804487
[2018-04-17 16:24:00.414806]: ====================
[2018-04-17 16:24:00.485995]: [Epoch: 268(17.878585723815878%): Data: 0.0%]:Running loss: 0.21782444417476654
[2018-04-17 16:24:01.714261]: [Epoch: 268(17.878585723815878%): Data: 25.333333333333336%]:Running loss: 4.356472983956337
[2018-04-17 16:24:02.995167]: [Epoch: 268(17.878585723815878%): Data: 50.66666666666667%]:Running loss: 8.495093300938606
[2018-04-17 16:24:06.697010]: Test set accuracy: 94.33962264150944% ,loss = 5.445465072989464
[2018-04-17 16:24:06.816829]: ====================
[2018-04-17 16:24:06.822343]: Elapsed time since starting training: 0:28:52.218542
[2018-04-17 16:24:06.827858]: ====================
[2018-04-17 16:24:06.899047]: [Epoch: 269(17.945296864576385%): Data: 0.0%]:Running loss: 0.21781860291957855
[2018-04-17 16:24:08.189478]: [Epoch: 269(17.945296864576385%): Data: 25.333333333333336%]:Running loss: 4.356357753276825
[2018-04-17 16:24:09.453840]: [Epoch: 269(17.945296864576385%): Data: 50.66666666666667%]:Running loss: 8.494870007038116
[2018-04-17 16:24:12.969187]: Test set accuracy: 94.33962264150944% ,loss = 5.445319786667824
[2018-04-17 16:24:13.086500]: ====================
[2018-04-17 16:24:13.092015]: Elapsed time since starting training: 0:28:58.487712
[2018-04-17 16:24:13.097032]: ====================
[2018-04-17 16:24:13.172228]: [Epoch: 270(18.01200800533689%): Data: 0.0%]:Running loss: 0.21781279146671295
[2018-04-17 16:24:14.420053]: [Epoch: 270(18.01200800533689%): Data: 25.333333333333336%]:Running loss: 4.356244966387749
[2018-04-17 16:24:15.660845]: [Epoch: 270(18.01200800533689%): Data: 50.66666666666667%]:Running loss: 8.494650736451149
[2018-04-17 16:24:19.237354]: Test set accuracy: 94.33962264150944% ,loss = 5.4451871663331985
[2018-04-17 16:24:19.355670]: ====================
[2018-04-17 16:24:19.360683]: Elapsed time since starting training: 0:29:04.756882
[2018-04-17 16:24:19.368203]: ====================
[2018-04-17 16:24:19.440394]: [Epoch: 271(18.0787191460974%): Data: 0.0%]:Running loss: 0.21780748665332794
[2018-04-17 16:24:20.713279]: [Epoch: 271(18.0787191460974%): Data: 25.333333333333336%]:Running loss: 4.356135696172714
[2018-04-17 16:24:21.986665]: [Epoch: 271(18.0787191460974%): Data: 50.66666666666667%]:Running loss: 8.494437485933304
[2018-04-17 16:24:25.596269]: Test set accuracy: 94.33962264150944% ,loss = 5.4450564086437225
[2018-04-17 16:24:25.722609]: ====================
[2018-04-17 16:24:25.728119]: Elapsed time since starting training: 0:29:11.124318
[2018-04-17 16:24:25.735138]: ====================
[2018-04-17 16:24:25.803821]: [Epoch: 272(18.145430286857906%): Data: 0.0%]:Running loss: 0.2178022563457489
[2018-04-17 16:24:27.126337]: [Epoch: 272(18.145430286857906%): Data: 25.333333333333336%]:Running loss: 4.3560274094343185
[2018-04-17 16:24:28.408747]: [Epoch: 272(18.145430286857906%): Data: 50.66666666666667%]:Running loss: 8.494227200746536
[2018-04-17 16:24:31.959689]: Test set accuracy: 94.33962264150944% ,loss = 5.444923788309097
[2018-04-17 16:24:32.074995]: ====================
[2018-04-17 16:24:32.081012]: Elapsed time since starting training: 0:29:17.476709
[2018-04-17 16:24:32.087529]: ====================
[2018-04-17 16:24:32.157215]: [Epoch: 273(18.212141427618413%): Data: 0.0%]:Running loss: 0.2177969515323639
[2018-04-17 16:24:33.441128]: [Epoch: 273(18.212141427618413%): Data: 25.333333333333336%]:Running loss: 4.355921998620033
[2018-04-17 16:24:34.729062]: [Epoch: 273(18.212141427618413%): Data: 50.66666666666667%]:Running loss: 8.494022190570831
[2018-04-17 16:24:38.277989]: Test set accuracy: 94.33962264150944% ,loss = 5.444786325097084
[2018-04-17 16:24:38.395803]: ====================
[2018-04-17 16:24:38.402320]: Elapsed time since starting training: 0:29:23.798519
[2018-04-17 16:24:38.407835]: ====================
[2018-04-17 16:24:38.484038]: [Epoch: 274(18.27885256837892%): Data: 0.0%]:Running loss: 0.21779145300388336
[2018-04-17 16:24:39.765946]: [Epoch: 274(18.27885256837892%): Data: 25.333333333333336%]:Running loss: 4.355817899107933
[2018-04-17 16:24:41.032313]: [Epoch: 274(18.27885256837892%): Data: 50.66666666666667%]:Running loss: 8.493819460272789
[2018-04-17 16:24:44.559692]: Test set accuracy: 94.33962264150944% ,loss = 5.444658547639847
[2018-04-17 16:24:44.676503]: ====================
[2018-04-17 16:24:44.682018]: Elapsed time since starting training: 0:29:30.078217
[2018-04-17 16:24:44.688535]: ====================
[2018-04-17 16:24:44.764738]: [Epoch: 275(18.345563709139427%): Data: 0.0%]:Running loss: 0.21778634190559387
[2018-04-17 16:24:46.057675]: [Epoch: 275(18.345563709139427%): Data: 25.333333333333336%]:Running loss: 4.355716586112976
[2018-04-17 16:24:47.339584]: [Epoch: 275(18.345563709139427%): Data: 50.66666666666667%]:Running loss: 8.493621438741684
[2018-04-17 16:24:50.824350]: Test set accuracy: 94.33962264150944% ,loss = 5.444535985589027
[2018-04-17 16:24:50.929630]: ====================
[2018-04-17 16:24:50.935145]: Elapsed time since starting training: 0:29:36.331344
[2018-04-17 16:24:50.940659]: ====================
[2018-04-17 16:24:51.012350]: [Epoch: 276(18.412274849899934%): Data: 0.0%]:Running loss: 0.2177814394235611
[2018-04-17 16:24:52.286738]: [Epoch: 276(18.412274849899934%): Data: 25.333333333333336%]:Running loss: 4.355615943670273
[2018-04-17 16:24:53.524530]: [Epoch: 276(18.412274849899934%): Data: 50.66666666666667%]:Running loss: 8.493426069617271
[2018-04-17 16:24:56.946629]: Test set accuracy: 94.33962264150944% ,loss = 5.444415286183357
[2018-04-17 16:24:57.056922]: ====================
[2018-04-17 16:24:57.062437]: Elapsed time since starting training: 0:29:42.458636
[2018-04-17 16:24:57.068955]: ====================
[2018-04-17 16:24:57.136133]: [Epoch: 277(18.47898599066044%): Data: 0.0%]:Running loss: 0.2177766114473343
[2018-04-17 16:24:58.399492]: [Epoch: 277(18.47898599066044%): Data: 25.333333333333336%]:Running loss: 4.3555182963609695
[2018-04-17 16:24:59.673379]: [Epoch: 277(18.47898599066044%): Data: 50.66666666666667%]:Running loss: 8.493236988782883
[2018-04-17 16:25:03.110018]: Test set accuracy: 94.33962264150944% ,loss = 5.444296821951866
[2018-04-17 16:25:03.218807]: ====================
[2018-04-17 16:25:03.226327]: Elapsed time since starting training: 0:29:48.622526
[2018-04-17 16:25:03.235852]: ====================
[2018-04-17 16:25:03.307543]: [Epoch: 278(18.545697131420948%): Data: 0.0%]:Running loss: 0.21777187287807465
[2018-04-17 16:25:04.570401]: [Epoch: 278(18.545697131420948%): Data: 25.333333333333336%]:Running loss: 4.355422630906105
[2018-04-17 16:25:05.810699]: [Epoch: 278(18.545697131420948%): Data: 50.66666666666667%]:Running loss: 8.493049696087837
[2018-04-17 16:25:09.290451]: Test set accuracy: 94.33962264150944% ,loss = 5.444176122546196
[2018-04-17 16:25:09.414784]: ====================
[2018-04-17 16:25:09.420798]: Elapsed time since starting training: 0:29:54.816997
[2018-04-17 16:25:09.427315]: ====================
[2018-04-17 16:25:09.501512]: [Epoch: 279(18.612408272181455%): Data: 0.0%]:Running loss: 0.21776704490184784
[2018-04-17 16:25:10.749330]: [Epoch: 279(18.612408272181455%): Data: 25.333333333333336%]:Running loss: 4.3553281128406525
[2018-04-17 16:25:12.007676]: [Epoch: 279(18.612408272181455%): Data: 50.66666666666667%]:Running loss: 8.49286736547947
[2018-04-17 16:25:15.503472]: Test set accuracy: 94.33962264150944% ,loss = 5.444063246250153
[2018-04-17 16:25:15.611259]: ====================
[2018-04-17 16:25:15.616271]: Elapsed time since starting training: 0:30:01.012470
[2018-04-17 16:25:15.621787]: ====================
[2018-04-17 16:25:15.690469]: [Epoch: 280(18.67911941294196%): Data: 0.0%]:Running loss: 0.2177625298500061
[2018-04-17 16:25:16.947310]: [Epoch: 280(18.67911941294196%): Data: 25.333333333333336%]:Running loss: 4.35523521900177
[2018-04-17 16:25:18.196632]: [Epoch: 280(18.67911941294196%): Data: 50.66666666666667%]:Running loss: 8.492686808109283
[2018-04-17 16:25:21.660844]: Test set accuracy: 94.33962264150944% ,loss = 5.44394738972187
[2018-04-17 16:25:21.775148]: ====================
[2018-04-17 16:25:21.780663]: Elapsed time since starting training: 0:30:07.176361
[2018-04-17 16:25:21.787180]: ====================
[2018-04-17 16:25:21.859372]: [Epoch: 281(18.74583055370247%): Data: 0.0%]:Running loss: 0.21775789558887482
[2018-04-17 16:25:23.096662]: [Epoch: 281(18.74583055370247%): Data: 25.333333333333336%]:Running loss: 4.355144679546356
[2018-04-17 16:25:24.335957]: [Epoch: 281(18.74583055370247%): Data: 50.66666666666667%]:Running loss: 8.492509722709656
[2018-04-17 16:25:27.790643]: Test set accuracy: 94.33962264150944% ,loss = 5.443831533193588
[2018-04-17 16:25:27.897428]: ====================
[2018-04-17 16:25:27.904445]: Elapsed time since starting training: 0:30:13.300644
[2018-04-17 16:25:27.909960]: ====================
[2018-04-17 16:25:27.973128]: [Epoch: 282(18.812541694462976%): Data: 0.0%]:Running loss: 0.21775326132774353
[2018-04-17 16:25:29.221448]: [Epoch: 282(18.812541694462976%): Data: 25.333333333333336%]:Running loss: 4.355055585503578
[2018-04-17 16:25:30.462748]: [Epoch: 282(18.812541694462976%): Data: 50.66666666666667%]:Running loss: 8.492337375879288
[2018-04-17 16:25:33.948016]: Test set accuracy: 94.33962264150944% ,loss = 5.443720519542694
[2018-04-17 16:25:34.059311]: ====================
[2018-04-17 16:25:34.065328]: Elapsed time since starting training: 0:30:19.461032
[2018-04-17 16:25:34.070341]: ====================
[2018-04-17 16:25:34.137018]: [Epoch: 283(18.879252835223483%): Data: 0.0%]:Running loss: 0.21774882078170776
[2018-04-17 16:25:35.383332]: [Epoch: 283(18.879252835223483%): Data: 25.333333333333336%]:Running loss: 4.354968890547752
[2018-04-17 16:25:36.663235]: [Epoch: 283(18.879252835223483%): Data: 50.66666666666667%]:Running loss: 8.492167815566063
[2018-04-17 16:25:40.187606]: Test set accuracy: 94.33962264150944% ,loss = 5.443616211414337
[2018-04-17 16:25:40.297398]: ====================
[2018-04-17 16:25:40.303916]: Elapsed time since starting training: 0:30:25.700115
[2018-04-17 16:25:40.309430]: ====================
[2018-04-17 16:25:40.382124]: [Epoch: 284(18.94596397598399%): Data: 0.0%]:Running loss: 0.2177446484565735
[2018-04-17 16:25:41.618411]: [Epoch: 284(18.94596397598399%): Data: 25.333333333333336%]:Running loss: 4.354883447289467
[2018-04-17 16:25:42.873749]: [Epoch: 284(18.94596397598399%): Data: 50.66666666666667%]:Running loss: 8.492001175880432
[2018-04-17 16:25:46.375059]: Test set accuracy: 94.33962264150944% ,loss = 5.443510413169861
[2018-04-17 16:25:46.580606]: ====================
[2018-04-17 16:25:46.588126]: Elapsed time since starting training: 0:30:31.984325
[2018-04-17 16:25:46.594141]: ====================
[2018-04-17 16:25:46.661320]: [Epoch: 285(19.012675116744497%): Data: 0.0%]:Running loss: 0.21774041652679443
[2018-04-17 16:25:47.907635]: [Epoch: 285(19.012675116744497%): Data: 25.333333333333336%]:Running loss: 4.354799598455429
[2018-04-17 16:25:49.166983]: [Epoch: 285(19.012675116744497%): Data: 50.66666666666667%]:Running loss: 8.491837561130524
[2018-04-17 16:25:52.642724]: Test set accuracy: 94.33962264150944% ,loss = 5.443403497338295
[2018-04-17 16:25:52.751014]: ====================
[2018-04-17 16:25:52.757532]: Elapsed time since starting training: 0:30:38.153228
[2018-04-17 16:25:52.763044]: ====================
[2018-04-17 16:25:52.832228]: [Epoch: 286(19.079386257505003%): Data: 0.0%]:Running loss: 0.2177361398935318
[2018-04-17 16:25:54.082553]: [Epoch: 286(19.079386257505003%): Data: 25.333333333333336%]:Running loss: 4.354716375470161
[2018-04-17 16:25:55.399555]: [Epoch: 286(19.079386257505003%): Data: 50.66666666666667%]:Running loss: 8.491676777601242
[2018-04-17 16:25:59.033718]: Test set accuracy: 94.33962264150944% ,loss = 5.443304404616356
[2018-04-17 16:25:59.154540]: ====================
[2018-04-17 16:25:59.160555]: Elapsed time since starting training: 0:30:44.556754
[2018-04-17 16:25:59.166572]: ====================
[2018-04-17 16:25:59.237260]: [Epoch: 287(19.14609739826551%): Data: 0.0%]:Running loss: 0.21773217618465424
[2018-04-17 16:26:00.510645]: [Epoch: 287(19.14609739826551%): Data: 25.333333333333336%]:Running loss: 4.354636624455452
[2018-04-17 16:26:01.806591]: [Epoch: 287(19.14609739826551%): Data: 50.66666666666667%]:Running loss: 8.491520568728447
[2018-04-17 16:26:05.330962]: Test set accuracy: 94.33962264150944% ,loss = 5.443212762475014
[2018-04-17 16:26:05.445768]: ====================
[2018-04-17 16:26:05.451282]: Elapsed time since starting training: 0:30:50.846984
[2018-04-17 16:26:05.456797]: ====================
[2018-04-17 16:26:05.525981]: [Epoch: 288(19.212808539026017%): Data: 0.0%]:Running loss: 0.21772851049900055
[2018-04-17 16:26:06.793350]: [Epoch: 288(19.212808539026017%): Data: 25.333333333333336%]:Running loss: 4.35455647110939
[2018-04-17 16:26:08.070246]: [Epoch: 288(19.212808539026017%): Data: 50.66666666666667%]:Running loss: 8.491365849971771
[2018-04-17 16:26:11.845284]: Test set accuracy: 94.33962264150944% ,loss = 5.443115159869194
[2018-04-17 16:26:11.956079]: ====================
[2018-04-17 16:26:11.961602]: Elapsed time since starting training: 0:30:57.357801
[2018-04-17 16:26:11.967108]: ====================
[2018-04-17 16:26:12.039802]: [Epoch: 289(19.279519679786524%): Data: 0.0%]:Running loss: 0.21772460639476776
[2018-04-17 16:26:13.494168]: [Epoch: 289(19.279519679786524%): Data: 25.333333333333336%]:Running loss: 4.35447858273983
[2018-04-17 16:26:14.972599]: [Epoch: 289(19.279519679786524%): Data: 50.66666666666667%]:Running loss: 8.49121542274952
[2018-04-17 16:26:18.724580]: Test set accuracy: 94.33962264150944% ,loss = 5.443016812205315
[2018-04-17 16:26:18.834874]: ====================
[2018-04-17 16:26:18.840388]: Elapsed time since starting training: 0:31:04.236587
[2018-04-17 16:26:18.845903]: ====================
[2018-04-17 16:26:18.922106]: [Epoch: 290(19.34623082054703%): Data: 0.0%]:Running loss: 0.21772067248821259
[2018-04-17 16:26:20.317817]: [Epoch: 290(19.34623082054703%): Data: 25.333333333333336%]:Running loss: 4.354404553771019
[2018-04-17 16:26:21.744109]: [Epoch: 290(19.34623082054703%): Data: 50.66666666666667%]:Running loss: 8.491067364811897
[2018-04-17 16:26:26.004443]: Test set accuracy: 94.33962264150944% ,loss = 5.442918837070465
[2018-04-17 16:26:26.130278]: ====================
[2018-04-17 16:26:26.135793]: Elapsed time since starting training: 0:31:11.531992
[2018-04-17 16:26:26.141809]: ====================
[2018-04-17 16:26:26.210490]: [Epoch: 291(19.41294196130754%): Data: 0.0%]:Running loss: 0.2177167534828186
[2018-04-17 16:26:27.475354]: [Epoch: 291(19.41294196130754%): Data: 25.333333333333336%]:Running loss: 4.354328244924545
[2018-04-17 16:26:28.737209]: [Epoch: 291(19.41294196130754%): Data: 50.66666666666667%]:Running loss: 8.490922719240189
[2018-04-17 16:26:32.228994]: Test set accuracy: 94.33962264150944% ,loss = 5.442830920219421
[2018-04-17 16:26:32.354327]: ====================
[2018-04-17 16:26:32.359842]: Elapsed time since starting training: 0:31:17.756041
[2018-04-17 16:26:32.365858]: ====================
[2018-04-17 16:26:32.434541]: [Epoch: 292(19.479653102068045%): Data: 0.0%]:Running loss: 0.21771323680877686
[2018-04-17 16:26:33.692385]: [Epoch: 292(19.479653102068045%): Data: 25.333333333333336%]:Running loss: 4.354254946112633
[2018-04-17 16:26:34.967275]: [Epoch: 292(19.479653102068045%): Data: 50.66666666666667%]:Running loss: 8.49077869951725
[2018-04-17 16:26:38.574366]: Test set accuracy: 94.33962264150944% ,loss = 5.442734807729721
[2018-04-17 16:26:38.708222]: ====================
[2018-04-17 16:26:38.715743]: Elapsed time since starting training: 0:31:24.111440
[2018-04-17 16:26:38.725268]: ====================
[2018-04-17 16:26:38.805983]: [Epoch: 293(19.546364242828552%): Data: 0.0%]:Running loss: 0.21770939230918884
[2018-04-17 16:26:40.062824]: [Epoch: 293(19.546364242828552%): Data: 25.333333333333336%]:Running loss: 4.354181036353111
[2018-04-17 16:26:41.368295]: [Epoch: 293(19.546364242828552%): Data: 50.66666666666667%]:Running loss: 8.49063715338707
[2018-04-17 16:26:44.946810]: Test set accuracy: 94.33962264150944% ,loss = 5.442649871110916
[2018-04-17 16:26:45.101222]: ====================
[2018-04-17 16:26:45.108252]: Elapsed time since starting training: 0:31:30.504451
[2018-04-17 16:26:45.113755]: ====================
[2018-04-17 16:26:45.184944]: [Epoch: 294(19.61307538358906%): Data: 0.0%]:Running loss: 0.21770599484443665
[2018-04-17 16:26:46.529028]: [Epoch: 294(19.61307538358906%): Data: 25.333333333333336%]:Running loss: 4.354111015796661
[2018-04-17 16:26:48.223022]: [Epoch: 294(19.61307538358906%): Data: 50.66666666666667%]:Running loss: 8.490501075983047
[2018-04-17 16:26:51.813067]: Test set accuracy: 94.33962264150944% ,loss = 5.442561581730843
[2018-04-17 16:26:51.943916]: ====================
[2018-04-17 16:26:51.949430]: Elapsed time since starting training: 0:31:37.345128
[2018-04-17 16:26:51.954946]: ====================
[2018-04-17 16:26:52.024129]: [Epoch: 295(19.679786524349566%): Data: 0.0%]:Running loss: 0.2177024632692337
[2018-04-17 16:26:53.289494]: [Epoch: 295(19.679786524349566%): Data: 25.333333333333336%]:Running loss: 4.354043066501617
[2018-04-17 16:26:54.550346]: [Epoch: 295(19.679786524349566%): Data: 50.66666666666667%]:Running loss: 8.490365818142891
[2018-04-17 16:26:58.171977]: Test set accuracy: 94.33962264150944% ,loss = 5.442484468221664
[2018-04-17 16:26:58.280264]: ====================
[2018-04-17 16:26:58.286280]: Elapsed time since starting training: 0:31:43.682479
[2018-04-17 16:26:58.291795]: ====================
[2018-04-17 16:26:58.357970]: [Epoch: 296(19.746497665110073%): Data: 0.0%]:Running loss: 0.21769937872886658
[2018-04-17 16:26:59.741650]: [Epoch: 296(19.746497665110073%): Data: 25.333333333333336%]:Running loss: 4.353975057601929
[2018-04-17 16:27:01.041105]: [Epoch: 296(19.746497665110073%): Data: 50.66666666666667%]:Running loss: 8.490235716104507
[2018-04-17 16:27:05.162062]: Test set accuracy: 94.33962264150944% ,loss = 5.4423995316028595
[2018-04-17 16:27:05.281380]: ====================
[2018-04-17 16:27:05.287396]: Elapsed time since starting training: 0:31:50.683595
[2018-04-17 16:27:05.293913]: ====================
[2018-04-17 16:27:05.363097]: [Epoch: 297(19.81320880587058%): Data: 0.0%]:Running loss: 0.21769598126411438
[2018-04-17 16:27:06.640495]: [Epoch: 297(19.81320880587058%): Data: 25.333333333333336%]:Running loss: 4.353908151388168
[2018-04-17 16:27:07.944962]: [Epoch: 297(19.81320880587058%): Data: 50.66666666666667%]:Running loss: 8.490105167031288
[2018-04-17 16:27:11.513451]: Test set accuracy: 94.33962264150944% ,loss = 5.442313477396965
[2018-04-17 16:27:11.639787]: ====================
[2018-04-17 16:27:11.646306]: Elapsed time since starting training: 0:31:57.042002
[2018-04-17 16:27:11.651819]: ====================
[2018-04-17 16:27:11.725013]: [Epoch: 298(19.879919946631087%): Data: 0.0%]:Running loss: 0.2176925390958786
[2018-04-17 16:27:13.024970]: [Epoch: 298(19.879919946631087%): Data: 25.333333333333336%]:Running loss: 4.353843003511429
[2018-04-17 16:27:14.358014]: [Epoch: 298(19.879919946631087%): Data: 50.66666666666667%]:Running loss: 8.489978030323982
[2018-04-17 16:27:17.889906]: Test set accuracy: 94.33962264150944% ,loss = 5.442238226532936
[2018-04-17 16:27:18.024764]: ====================
[2018-04-17 16:27:18.030279]: Elapsed time since starting training: 0:32:03.426478
[2018-04-17 16:27:18.035794]: ====================
[2018-04-17 16:27:18.111996]: [Epoch: 299(19.946631087391594%): Data: 0.0%]:Running loss: 0.21768952906131744
[2018-04-17 16:27:19.394406]: [Epoch: 299(19.946631087391594%): Data: 25.333333333333336%]:Running loss: 4.353779420256615
[2018-04-17 16:27:20.668795]: [Epoch: 299(19.946631087391594%): Data: 50.66666666666667%]:Running loss: 8.489852890372276
[2018-04-17 16:27:24.452857]: Test set accuracy: 94.33962264150944% ,loss = 5.442152917385101
[2018-04-17 16:27:24.571177]: ====================
[2018-04-17 16:27:24.577188]: Elapsed time since starting training: 0:32:09.973387
[2018-04-17 16:27:24.583203]: ====================
[2018-04-17 16:27:24.650884]: [Epoch: 300(20.0133422281521%): Data: 0.0%]:Running loss: 0.21768611669540405
[2018-04-17 16:27:25.972899]: [Epoch: 300(20.0133422281521%): Data: 25.333333333333336%]:Running loss: 4.35371620953083
[2018-04-17 16:27:27.283383]: [Epoch: 300(20.0133422281521%): Data: 50.66666666666667%]:Running loss: 8.489730268716812
[2018-04-17 16:27:31.119583]: Test set accuracy: 94.33962264150944% ,loss = 5.442081391811371
[2018-04-17 16:27:31.248928]: ====================
[2018-04-17 16:27:31.254944]: Elapsed time since starting training: 0:32:16.651143
[2018-04-17 16:27:31.261963]: ====================
[2018-04-17 16:27:31.341674]: [Epoch: 301(20.08005336891261%): Data: 0.0%]:Running loss: 0.21768325567245483
[2018-04-17 16:27:32.944937]: [Epoch: 301(20.08005336891261%): Data: 25.333333333333336%]:Running loss: 4.3536544144153595
[2018-04-17 16:27:34.288008]: [Epoch: 301(20.08005336891261%): Data: 50.66666666666667%]:Running loss: 8.489611774682999
[2018-04-17 16:27:38.163313]: Test set accuracy: 94.33962264150944% ,loss = 5.441997945308685
[2018-04-17 16:27:38.285638]: ====================
[2018-04-17 16:27:38.291153]: Elapsed time since starting training: 0:32:23.687352
[2018-04-17 16:27:38.298171]: ====================
[2018-04-17 16:27:38.375376]: [Epoch: 302(20.146764509673115%): Data: 0.0%]:Running loss: 0.2176799178123474
[2018-04-17 16:27:39.642746]: [Epoch: 302(20.146764509673115%): Data: 25.333333333333336%]:Running loss: 4.3535923808813095
[2018-04-17 16:27:40.878532]: [Epoch: 302(20.146764509673115%): Data: 50.66666666666667%]:Running loss: 8.489490643143654
[2018-04-17 16:27:44.390872]: Test set accuracy: 94.33962264150944% ,loss = 5.4419271647930145
[2018-04-17 16:27:44.509688]: ====================
[2018-04-17 16:27:44.515203]: Elapsed time since starting training: 0:32:29.910900
[2018-04-17 16:27:44.520718]: ====================
[2018-04-17 16:27:44.587395]: [Epoch: 303(20.213475650433622%): Data: 0.0%]:Running loss: 0.21767708659172058
[2018-04-17 16:27:45.833214]: [Epoch: 303(20.213475650433622%): Data: 25.333333333333336%]:Running loss: 4.353534087538719
[2018-04-17 16:27:47.078518]: [Epoch: 303(20.213475650433622%): Data: 50.66666666666667%]:Running loss: 8.489377200603485
[2018-04-17 16:27:50.569300]: Test set accuracy: 94.33962264150944% ,loss = 5.441851168870926
[2018-04-17 16:27:50.685609]: ====================
[2018-04-17 16:27:50.691626]: Elapsed time since starting training: 0:32:36.087825
[2018-04-17 16:27:50.698143]: ====================
[2018-04-17 16:27:50.772340]: [Epoch: 304(20.28018679119413%): Data: 0.0%]:Running loss: 0.21767404675483704
[2018-04-17 16:27:52.107892]: [Epoch: 304(20.28018679119413%): Data: 25.333333333333336%]:Running loss: 4.353475287556648
[2018-04-17 16:27:53.448956]: [Epoch: 304(20.28018679119413%): Data: 50.66666666666667%]:Running loss: 8.489262700080872
[2018-04-17 16:27:57.445083]: Test set accuracy: 94.33962264150944% ,loss = 5.441782251000404
[2018-04-17 16:27:57.574427]: ====================
[2018-04-17 16:27:57.580443]: Elapsed time since starting training: 0:32:42.976140
[2018-04-17 16:27:57.585957]: ====================
[2018-04-17 16:27:57.654640]: [Epoch: 305(20.346897931954636%): Data: 0.0%]:Running loss: 0.21767129004001617
[2018-04-17 16:27:58.931034]: [Epoch: 305(20.346897931954636%): Data: 25.333333333333336%]:Running loss: 4.353417977690697
[2018-04-17 16:28:00.263577]: [Epoch: 305(20.346897931954636%): Data: 50.66666666666667%]:Running loss: 8.489151522517204
[2018-04-17 16:28:03.856631]: Test set accuracy: 94.33962264150944% ,loss = 5.441715195775032
[2018-04-17 16:28:03.970934]: ====================
[2018-04-17 16:28:03.976951]: Elapsed time since starting training: 0:32:49.372648
[2018-04-17 16:28:03.981964]: ====================
[2018-04-17 16:28:04.054658]: [Epoch: 306(20.413609072715143%): Data: 0.0%]:Running loss: 0.21766860783100128
[2018-04-17 16:28:05.303979]: [Epoch: 306(20.413609072715143%): Data: 25.333333333333336%]:Running loss: 4.353361994028091
[2018-04-17 16:28:06.566837]: [Epoch: 306(20.413609072715143%): Data: 50.66666666666667%]:Running loss: 8.489041954278946
[2018-04-17 16:28:10.135326]: Test set accuracy: 94.33962264150944% ,loss = 5.441640317440033
[2018-04-17 16:28:10.245620]: ====================
[2018-04-17 16:28:10.251134]: Elapsed time since starting training: 0:32:55.647333
[2018-04-17 16:28:10.257151]: ====================
[2018-04-17 16:28:10.325833]: [Epoch: 307(20.48032021347565%): Data: 0.0%]:Running loss: 0.21766561269760132
[2018-04-17 16:28:11.605744]: [Epoch: 307(20.48032021347565%): Data: 25.333333333333336%]:Running loss: 4.353307470679283
[2018-04-17 16:28:12.875620]: [Epoch: 307(20.48032021347565%): Data: 50.66666666666667%]:Running loss: 8.488936126232147
[2018-04-17 16:28:16.434082]: Test set accuracy: 94.33962264150944% ,loss = 5.44157549738884
[2018-04-17 16:28:16.552899]: ====================
[2018-04-17 16:28:16.558420]: Elapsed time since starting training: 0:33:01.954619
[2018-04-17 16:28:16.565431]: ====================
[2018-04-17 16:28:16.635618]: [Epoch: 308(20.547031354236157%): Data: 0.0%]:Running loss: 0.2176630198955536
[2018-04-17 16:28:17.878924]: [Epoch: 308(20.547031354236157%): Data: 25.333333333333336%]:Running loss: 4.353253781795502
[2018-04-17 16:28:19.133260]: [Epoch: 308(20.547031354236157%): Data: 50.66666666666667%]:Running loss: 8.488831669092178
[2018-04-17 16:28:22.653620]: Test set accuracy: 94.33962264150944% ,loss = 5.441506579518318
[2018-04-17 16:28:22.774441]: ====================
[2018-04-17 16:28:22.779956]: Elapsed time since starting training: 0:33:08.176155
[2018-04-17 16:28:22.785972]: ====================
[2018-04-17 16:28:22.860169]: [Epoch: 309(20.613742494996664%): Data: 0.0%]:Running loss: 0.21766026318073273
[2018-04-17 16:28:24.127038]: [Epoch: 309(20.613742494996664%): Data: 25.333333333333336%]:Running loss: 4.353199616074562
[2018-04-17 16:28:25.374855]: [Epoch: 309(20.613742494996664%): Data: 50.66666666666667%]:Running loss: 8.488727316260338
[2018-04-17 16:28:28.837062]: Test set accuracy: 94.33962264150944% ,loss = 5.441444739699364
[2018-04-17 16:28:28.947355]: ====================
[2018-04-17 16:28:28.953371]: Elapsed time since starting training: 0:33:14.349068
[2018-04-17 16:28:28.958886]: ====================
[2018-04-17 16:28:29.026565]: [Epoch: 310(20.68045363575717%): Data: 0.0%]:Running loss: 0.21765778958797455
[2018-04-17 16:28:30.291428]: [Epoch: 310(20.68045363575717%): Data: 25.333333333333336%]:Running loss: 4.353148087859154
[2018-04-17 16:28:31.537242]: [Epoch: 310(20.68045363575717%): Data: 50.66666666666667%]:Running loss: 8.488626301288605
[2018-04-17 16:28:35.030028]: Test set accuracy: 94.33962264150944% ,loss = 5.441375449299812
[2018-04-17 16:28:35.141826]: ====================
[2018-04-17 16:28:35.147842]: Elapsed time since starting training: 0:33:20.544041
[2018-04-17 16:28:35.153356]: ====================
[2018-04-17 16:28:35.224045]: [Epoch: 311(20.74716477651768%): Data: 0.0%]:Running loss: 0.2176550179719925
[2018-04-17 16:28:36.483894]: [Epoch: 311(20.74716477651768%): Data: 25.333333333333336%]:Running loss: 4.353096604347229
[2018-04-17 16:28:37.732213]: [Epoch: 311(20.74716477651768%): Data: 50.66666666666667%]:Running loss: 8.48852552473545
[2018-04-17 16:28:41.162334]: Test set accuracy: 94.33962264150944% ,loss = 5.441321432590485
[2018-04-17 16:28:41.272627]: ====================
[2018-04-17 16:28:41.278142]: Elapsed time since starting training: 0:33:26.674341
[2018-04-17 16:28:41.284159]: ====================
[2018-04-17 16:28:41.351838]: [Epoch: 312(20.813875917278185%): Data: 0.0%]:Running loss: 0.21765285730361938
[2018-04-17 16:28:42.598152]: [Epoch: 312(20.813875917278185%): Data: 25.333333333333336%]:Running loss: 4.353047236800194
[2018-04-17 16:28:43.843464]: [Epoch: 312(20.813875917278185%): Data: 50.66666666666667%]:Running loss: 8.488429382443428
[2018-04-17 16:28:47.595440]: Test set accuracy: 94.33962264150944% ,loss = 5.441253632307053
[2018-04-17 16:28:47.715259]: ====================
[2018-04-17 16:28:47.721275]: Elapsed time since starting training: 0:33:33.116974
[2018-04-17 16:28:47.727291]: ====================
[2018-04-17 16:28:47.801487]: [Epoch: 313(20.880587058038692%): Data: 0.0%]:Running loss: 0.2176501452922821
[2018-04-17 16:28:49.088911]: [Epoch: 313(20.880587058038692%): Data: 25.333333333333336%]:Running loss: 4.352998465299606
[2018-04-17 16:28:50.425465]: [Epoch: 313(20.880587058038692%): Data: 50.66666666666667%]:Running loss: 8.488333895802498
[2018-04-17 16:28:53.965879]: Test set accuracy: 94.33962264150944% ,loss = 5.441198870539665
[2018-04-17 16:28:54.075170]: ====================
[2018-04-17 16:28:54.081186]: Elapsed time since starting training: 0:33:39.477385
[2018-04-17 16:28:54.086700]: ====================
[2018-04-17 16:28:54.156386]: [Epoch: 314(20.9472981987992%): Data: 0.0%]:Running loss: 0.2176479548215866
[2018-04-17 16:28:55.417739]: [Epoch: 314(20.9472981987992%): Data: 25.333333333333336%]:Running loss: 4.352949529886246
[2018-04-17 16:28:56.694635]: [Epoch: 314(20.9472981987992%): Data: 50.66666666666667%]:Running loss: 8.488239839673042
[2018-04-17 16:29:00.314760]: Test set accuracy: 94.33962264150944% ,loss = 5.441129580140114
[2018-04-17 16:29:00.431069]: ====================
[2018-04-17 16:29:00.437085]: Elapsed time since starting training: 0:33:45.832783
[2018-04-17 16:29:00.443102]: ====================
[2018-04-17 16:29:00.511283]: [Epoch: 315(21.014009339559706%): Data: 0.0%]:Running loss: 0.21764518320560455
[2018-04-17 16:29:01.802717]: [Epoch: 315(21.014009339559706%): Data: 25.333333333333336%]:Running loss: 4.352901369333267
[2018-04-17 16:29:03.109191]: [Epoch: 315(21.014009339559706%): Data: 50.66666666666667%]:Running loss: 8.488146916031837
[2018-04-17 16:29:06.750874]: Test set accuracy: 94.33962264150944% ,loss = 5.441077798604965
[2018-04-17 16:29:06.868186]: ====================
[2018-04-17 16:29:06.875204]: Elapsed time since starting training: 0:33:52.271403
[2018-04-17 16:29:06.882223]: ====================
[2018-04-17 16:29:06.963940]: [Epoch: 316(21.080720480320213%): Data: 0.0%]:Running loss: 0.2176431119441986
[2018-04-17 16:29:08.333582]: [Epoch: 316(21.080720480320213%): Data: 25.333333333333336%]:Running loss: 4.3528566509485245
[2018-04-17 16:29:09.599448]: [Epoch: 316(21.080720480320213%): Data: 50.66666666666667%]:Running loss: 8.488057985901833
[2018-04-17 16:29:13.240630]: Test set accuracy: 94.33962264150944% ,loss = 5.441015213727951
[2018-04-17 16:29:13.362454]: ====================
[2018-04-17 16:29:13.367969]: Elapsed time since starting training: 0:33:58.763667
[2018-04-17 16:29:13.373985]: ====================
[2018-04-17 16:29:13.451190]: [Epoch: 317(21.14743162108072%): Data: 0.0%]:Running loss: 0.21764060854911804
[2018-04-17 16:29:14.770197]: [Epoch: 317(21.14743162108072%): Data: 25.333333333333336%]:Running loss: 4.352809771895409
[2018-04-17 16:29:16.036063]: [Epoch: 317(21.14743162108072%): Data: 50.66666666666667%]:Running loss: 8.48796796798706
[2018-04-17 16:29:19.531858]: Test set accuracy: 94.33962264150944% ,loss = 5.440961569547653
[2018-04-17 16:29:19.660200]: ====================
[2018-04-17 16:29:19.666216]: Elapsed time since starting training: 0:34:05.062415
[2018-04-17 16:29:19.671730]: ====================
[2018-04-17 16:29:19.743922]: [Epoch: 318(21.214142761841227%): Data: 0.0%]:Running loss: 0.21763846278190613
[2018-04-17 16:29:21.066940]: [Epoch: 318(21.214142761841227%): Data: 25.333333333333336%]:Running loss: 4.352764785289764
[2018-04-17 16:29:22.332806]: [Epoch: 318(21.214142761841227%): Data: 50.66666666666667%]:Running loss: 8.487880110740662
[2018-04-17 16:29:25.867204]: Test set accuracy: 94.33962264150944% ,loss = 5.440912023186684
[2018-04-17 16:29:25.990532]: ====================
[2018-04-17 16:29:25.996548]: Elapsed time since starting training: 0:34:11.392747
[2018-04-17 16:29:26.002063]: ====================
[2018-04-17 16:29:26.076261]: [Epoch: 319(21.280853902601734%): Data: 0.0%]:Running loss: 0.21763648092746735
[2018-04-17 16:29:27.320568]: [Epoch: 319(21.280853902601734%): Data: 25.333333333333336%]:Running loss: 4.352722376585007
[2018-04-17 16:29:28.594456]: [Epoch: 319(21.280853902601734%): Data: 50.66666666666667%]:Running loss: 8.487797766923904
[2018-04-17 16:29:32.149408]: Test set accuracy: 94.33962264150944% ,loss = 5.440852418541908
[2018-04-17 16:29:32.257198]: ====================
[2018-04-17 16:29:32.262710]: Elapsed time since starting training: 0:34:17.658407
[2018-04-17 16:29:32.267723]: ====================
[2018-04-17 16:29:32.336406]: [Epoch: 320(21.34756504336224%): Data: 0.0%]:Running loss: 0.21763409674167633
[2018-04-17 16:29:33.626837]: [Epoch: 320(21.34756504336224%): Data: 25.333333333333336%]:Running loss: 4.352679178118706
[2018-04-17 16:29:34.908244]: [Epoch: 320(21.34756504336224%): Data: 50.66666666666667%]:Running loss: 8.487714767456055
[2018-04-17 16:29:38.352402]: Test set accuracy: 94.33962264150944% ,loss = 5.440802127122879
[2018-04-17 16:29:38.461192]: ====================
[2018-04-17 16:29:38.466707]: Elapsed time since starting training: 0:34:23.862906
[2018-04-17 16:29:38.472222]: ====================
[2018-04-17 16:29:38.543410]: [Epoch: 321(21.41427618412275%): Data: 0.0%]:Running loss: 0.21763208508491516
[2018-04-17 16:29:39.824315]: [Epoch: 321(21.41427618412275%): Data: 25.333333333333336%]:Running loss: 4.352636024355888
[2018-04-17 16:29:41.111238]: [Epoch: 321(21.41427618412275%): Data: 50.66666666666667%]:Running loss: 8.487629503011703
[2018-04-17 16:29:44.620569]: Test set accuracy: 94.33962264150944% ,loss = 5.440753698348999
[2018-04-17 16:29:44.727353]: ====================
[2018-04-17 16:29:44.733368]: Elapsed time since starting training: 0:34:30.129567
[2018-04-17 16:29:44.738884]: ====================
[2018-04-17 16:29:44.811578]: [Epoch: 322(21.480987324883255%): Data: 0.0%]:Running loss: 0.21763014793395996
[2018-04-17 16:29:46.099502]: [Epoch: 322(21.480987324883255%): Data: 25.333333333333336%]:Running loss: 4.352594405412674
[2018-04-17 16:29:47.389432]: [Epoch: 322(21.480987324883255%): Data: 50.66666666666667%]:Running loss: 8.487549617886543
[2018-04-17 16:29:50.869184]: Test set accuracy: 94.33962264150944% ,loss = 5.440697073936462
[2018-04-17 16:29:50.979477]: ====================
[2018-04-17 16:29:50.984993]: Elapsed time since starting training: 0:34:36.381192
[2018-04-17 16:29:50.991008]: ====================
[2018-04-17 16:29:51.063701]: [Epoch: 323(21.547698465643762%): Data: 0.0%]:Running loss: 0.2176278829574585
[2018-04-17 16:29:52.361151]: [Epoch: 323(21.547698465643762%): Data: 25.333333333333336%]:Running loss: 4.352553129196167
[2018-04-17 16:29:53.647070]: [Epoch: 323(21.547698465643762%): Data: 50.66666666666667%]:Running loss: 8.48747043311596
[2018-04-17 16:29:57.157404]: Test set accuracy: 94.33962264150944% ,loss = 5.440651252865791
[2018-04-17 16:29:57.354930]: ====================
[2018-04-17 16:29:57.360946]: Elapsed time since starting training: 0:34:42.756644
[2018-04-17 16:29:57.366963]: ====================
[2018-04-17 16:29:57.434642]: [Epoch: 324(21.61440960640427%): Data: 0.0%]:Running loss: 0.21762605011463165
[2018-04-17 16:29:58.711035]: [Epoch: 324(21.61440960640427%): Data: 25.333333333333336%]:Running loss: 4.352514058351517
[2018-04-17 16:29:59.977403]: [Epoch: 324(21.61440960640427%): Data: 50.66666666666667%]:Running loss: 8.487392529845238
[2018-04-17 16:30:03.447129]: Test set accuracy: 94.33962264150944% ,loss = 5.440597236156464
[2018-04-17 16:30:03.550905]: ====================
[2018-04-17 16:30:03.556420]: Elapsed time since starting training: 0:34:48.952117
[2018-04-17 16:30:03.561934]: ====================
[2018-04-17 16:30:03.635129]: [Epoch: 325(21.681120747164776%): Data: 0.0%]:Running loss: 0.21762388944625854
[2018-04-17 16:30:04.925560]: [Epoch: 325(21.681120747164776%): Data: 25.333333333333336%]:Running loss: 4.352474480867386
[2018-04-17 16:30:06.239052]: [Epoch: 325(21.681120747164776%): Data: 50.66666666666667%]:Running loss: 8.487315818667412
[2018-04-17 16:30:09.732341]: Test set accuracy: 94.33962264150944% ,loss = 5.440554395318031
[2018-04-17 16:30:09.837621]: ====================
[2018-04-17 16:30:09.842634]: Elapsed time since starting training: 0:34:55.238833
[2018-04-17 16:30:09.847648]: ====================
[2018-04-17 16:30:09.914324]: [Epoch: 326(21.747831887925283%): Data: 0.0%]:Running loss: 0.21762217581272125
[2018-04-17 16:30:11.219796]: [Epoch: 326(21.747831887925283%): Data: 25.333333333333336%]:Running loss: 4.35243546962738
[2018-04-17 16:30:12.502206]: [Epoch: 326(21.747831887925283%): Data: 50.66666666666667%]:Running loss: 8.48724040389061
[2018-04-17 16:30:16.040113]: Test set accuracy: 94.33962264150944% ,loss = 5.440503731369972
[2018-04-17 16:30:16.150407]: ====================
[2018-04-17 16:30:16.155921]: Elapsed time since starting training: 0:35:01.552120
[2018-04-17 16:30:16.161436]: ====================
[2018-04-17 16:30:16.232124]: [Epoch: 327(21.81454302868579%): Data: 0.0%]:Running loss: 0.2176201492547989
[2018-04-17 16:30:17.508016]: [Epoch: 327(21.81454302868579%): Data: 25.333333333333336%]:Running loss: 4.3523982763290405
[2018-04-17 16:30:18.791435]: [Epoch: 327(21.81454302868579%): Data: 50.66666666666667%]:Running loss: 8.487168475985527
[2018-04-17 16:30:22.327331]: Test set accuracy: 94.33962264150944% ,loss = 5.440451204776764
[2018-04-17 16:30:22.436622]: ====================
[2018-04-17 16:30:22.445646]: Elapsed time since starting training: 0:35:07.841845
[2018-04-17 16:30:22.451161]: ====================
[2018-04-17 16:30:22.523854]: [Epoch: 328(21.881254169446297%): Data: 0.0%]:Running loss: 0.21761804819107056
[2018-04-17 16:30:23.800247]: [Epoch: 328(21.881254169446297%): Data: 25.333333333333336%]:Running loss: 4.35236120223999
[2018-04-17 16:30:25.102210]: [Epoch: 328(21.881254169446297%): Data: 50.66666666666667%]:Running loss: 8.487096071243286
[2018-04-17 16:30:28.602516]: Test set accuracy: 94.33962264150944% ,loss = 5.440407991409302
[2018-04-17 16:30:28.713311]: ====================
[2018-04-17 16:30:28.719327]: Elapsed time since starting training: 0:35:14.115526
[2018-04-17 16:30:28.725343]: ====================
[2018-04-17 16:30:28.793524]: [Epoch: 329(21.947965310206804%): Data: 0.0%]:Running loss: 0.21761631965637207
[2018-04-17 16:30:30.096489]: [Epoch: 329(21.947965310206804%): Data: 25.333333333333336%]:Running loss: 4.352324768900871
[2018-04-17 16:30:31.374387]: [Epoch: 329(21.947965310206804%): Data: 50.66666666666667%]:Running loss: 8.487024500966072
[2018-04-17 16:30:34.880710]: Test set accuracy: 94.33962264150944% ,loss = 5.4403673857450485
[2018-04-17 16:30:34.990503]: ====================
[2018-04-17 16:30:34.996017]: Elapsed time since starting training: 0:35:20.392216
[2018-04-17 16:30:35.001532]: ====================
[2018-04-17 16:30:35.073723]: [Epoch: 330(22.01467645096731%): Data: 0.0%]:Running loss: 0.21761469542980194
[2018-04-17 16:30:36.364656]: [Epoch: 330(22.01467645096731%): Data: 25.333333333333336%]:Running loss: 4.3522893488407135
[2018-04-17 16:30:37.629521]: [Epoch: 330(22.01467645096731%): Data: 50.66666666666667%]:Running loss: 8.48695570230484
[2018-04-17 16:30:41.139352]: Test set accuracy: 94.33962264150944% ,loss = 5.440330132842064
[2018-04-17 16:30:41.250648]: ====================
[2018-04-17 16:30:41.256163]: Elapsed time since starting training: 0:35:26.652362
[2018-04-17 16:30:41.261176]: ====================
[2018-04-17 16:30:41.335874]: [Epoch: 331(22.081387591727818%): Data: 0.0%]:Running loss: 0.21761320531368256
[2018-04-17 16:30:42.614775]: [Epoch: 331(22.081387591727818%): Data: 25.333333333333336%]:Running loss: 4.352254256606102
[2018-04-17 16:30:43.908716]: [Epoch: 331(22.081387591727818%): Data: 50.66666666666667%]:Running loss: 8.486887812614441
[2018-04-17 16:30:47.457151]: Test set accuracy: 94.33962264150944% ,loss = 5.440279096364975
[2018-04-17 16:30:47.559423]: ====================
[2018-04-17 16:30:47.565439]: Elapsed time since starting training: 0:35:32.961638
[2018-04-17 16:30:47.570953]: ====================
[2018-04-17 16:30:47.645652]: [Epoch: 332(22.148098732488325%): Data: 0.0%]:Running loss: 0.217611163854599
[2018-04-17 16:30:48.946611]: [Epoch: 332(22.148098732488325%): Data: 25.333333333333336%]:Running loss: 4.352219745516777
[2018-04-17 16:30:50.236039]: [Epoch: 332(22.148098732488325%): Data: 50.66666666666667%]:Running loss: 8.486819252371788
[2018-04-17 16:30:53.774949]: Test set accuracy: 94.33962264150944% ,loss = 5.44024184346199
[2018-04-17 16:30:53.887750]: ====================
[2018-04-17 16:30:53.893265]: Elapsed time since starting training: 0:35:39.288962
[2018-04-17 16:30:53.899281]: ====================
[2018-04-17 16:30:53.973979]: [Epoch: 333(22.214809873248832%): Data: 0.0%]:Running loss: 0.21760967373847961
[2018-04-17 16:30:55.247867]: [Epoch: 333(22.214809873248832%): Data: 25.333333333333336%]:Running loss: 4.352186784148216
[2018-04-17 16:30:56.538799]: [Epoch: 333(22.214809873248832%): Data: 50.66666666666667%]:Running loss: 8.486754551529884
[2018-04-17 16:31:00.128344]: Test set accuracy: 94.33962264150944% ,loss = 5.44019378721714
[2018-04-17 16:31:00.241144]: ====================
[2018-04-17 16:31:00.246659]: Elapsed time since starting training: 0:35:45.642357
[2018-04-17 16:31:00.252173]: ====================
[2018-04-17 16:31:00.325367]: [Epoch: 334(22.28152101400934%): Data: 0.0%]:Running loss: 0.2176077514886856
[2018-04-17 16:31:01.620310]: [Epoch: 334(22.28152101400934%): Data: 25.333333333333336%]:Running loss: 4.352153420448303
[2018-04-17 16:31:02.909740]: [Epoch: 334(22.28152101400934%): Data: 50.66666666666667%]:Running loss: 8.486690863966942
[2018-04-17 16:31:06.452158]: Test set accuracy: 94.33962264150944% ,loss = 5.440159514546394
[2018-04-17 16:31:06.569972]: ====================
[2018-04-17 16:31:06.575988]: Elapsed time since starting training: 0:35:51.971685
[2018-04-17 16:31:06.581502]: ====================
[2018-04-17 16:31:06.656201]: [Epoch: 335(22.348232154769846%): Data: 0.0%]:Running loss: 0.21760638058185577
[2018-04-17 16:31:07.959166]: [Epoch: 335(22.348232154769846%): Data: 25.333333333333336%]:Running loss: 4.352120742201805
[2018-04-17 16:31:09.249597]: [Epoch: 335(22.348232154769846%): Data: 50.66666666666667%]:Running loss: 8.48662768304348
[2018-04-17 16:31:12.857189]: Test set accuracy: 94.33962264150944% ,loss = 5.440115928649902
[2018-04-17 16:31:12.975504]: ====================
[2018-04-17 16:31:12.980517]: Elapsed time since starting training: 0:35:58.376716
[2018-04-17 16:31:12.986032]: ====================
[2018-04-17 16:31:13.053211]: [Epoch: 336(22.414943295530353%): Data: 0.0%]:Running loss: 0.2176046371459961
[2018-04-17 16:31:14.352667]: [Epoch: 336(22.414943295530353%): Data: 25.333333333333336%]:Running loss: 4.35208848118782
[2018-04-17 16:31:15.665657]: [Epoch: 336(22.414943295530353%): Data: 50.66666666666667%]:Running loss: 8.486564815044403
[2018-04-17 16:31:19.282274]: Test set accuracy: 94.33962264150944% ,loss = 5.440078675746918
[2018-04-17 16:31:19.396585]: ====================
[2018-04-17 16:31:19.402093]: Elapsed time since starting training: 0:36:04.798292
[2018-04-17 16:31:19.407607]: ====================
[2018-04-17 16:31:19.477794]: [Epoch: 337(22.48165443629086%): Data: 0.0%]:Running loss: 0.2176031470298767
[2018-04-17 16:31:20.866988]: [Epoch: 337(22.48165443629086%): Data: 25.333333333333336%]:Running loss: 4.352057188749313
[2018-04-17 16:31:22.237130]: [Epoch: 337(22.48165443629086%): Data: 50.66666666666667%]:Running loss: 8.486504346132278
[2018-04-17 16:31:26.011667]: Test set accuracy: 94.33962264150944% ,loss = 5.440035834908485
[2018-04-17 16:31:26.124467]: ====================
[2018-04-17 16:31:26.129982]: Elapsed time since starting training: 0:36:11.525679
[2018-04-17 16:31:26.137000]: ====================
[2018-04-17 16:31:26.214707]: [Epoch: 338(22.548365577051367%): Data: 0.0%]:Running loss: 0.21760143339633942
[2018-04-17 16:31:27.525191]: [Epoch: 338(22.548365577051367%): Data: 25.333333333333336%]:Running loss: 4.352026432752609
[2018-04-17 16:31:28.921404]: [Epoch: 338(22.548365577051367%): Data: 50.66666666666667%]:Running loss: 8.486444637179375
[2018-04-17 16:31:32.531504]: Test set accuracy: 94.33962264150944% ,loss = 5.440004914999008
[2018-04-17 16:31:32.696443]: ====================
[2018-04-17 16:31:32.702458]: Elapsed time since starting training: 0:36:18.098156
[2018-04-17 16:31:32.708975]: ====================
[2018-04-17 16:31:32.786682]: [Epoch: 339(22.615076717811874%): Data: 0.0%]:Running loss: 0.21760019659996033
[2018-04-17 16:31:34.348836]: [Epoch: 339(22.615076717811874%): Data: 25.333333333333336%]:Running loss: 4.351996809244156
[2018-04-17 16:31:35.690403]: [Epoch: 339(22.615076717811874%): Data: 50.66666666666667%]:Running loss: 8.486386120319366
[2018-04-17 16:31:39.398763]: Test set accuracy: 94.33962264150944% ,loss = 5.439962819218636
[2018-04-17 16:31:39.528608]: ====================
[2018-04-17 16:31:39.534625]: Elapsed time since starting training: 0:36:24.930824
[2018-04-17 16:31:39.542646]: ====================
[2018-04-17 16:31:39.613835]: [Epoch: 340(22.68178785857238%): Data: 0.0%]:Running loss: 0.21759851276874542
[2018-04-17 16:31:40.887722]: [Epoch: 340(22.68178785857238%): Data: 25.333333333333336%]:Running loss: 4.351966857910156
[2018-04-17 16:31:42.140553]: [Epoch: 340(22.68178785857238%): Data: 50.66666666666667%]:Running loss: 8.486327901482582
[2018-04-17 16:31:45.738120]: Test set accuracy: 94.33962264150944% ,loss = 5.439931154251099
[2018-04-17 16:31:45.851922]: ====================
[2018-04-17 16:31:45.859442]: Elapsed time since starting training: 0:36:31.255641
[2018-04-17 16:31:45.864957]: ====================
[2018-04-17 16:31:45.934141]: [Epoch: 341(22.748498999332888%): Data: 0.0%]:Running loss: 0.21759724617004395
[2018-04-17 16:31:47.208529]: [Epoch: 341(22.748498999332888%): Data: 25.333333333333336%]:Running loss: 4.351937860250473
[2018-04-17 16:31:48.499964]: [Epoch: 341(22.748498999332888%): Data: 50.66666666666667%]:Running loss: 8.486271813511848
[2018-04-17 16:31:51.977711]: Test set accuracy: 94.33962264150944% ,loss = 5.439896136522293
[2018-04-17 16:31:52.092516]: ====================
[2018-04-17 16:31:52.099034]: Elapsed time since starting training: 0:36:37.494731
[2018-04-17 16:31:52.104549]: ====================
[2018-04-17 16:31:52.176238]: [Epoch: 342(22.815210140093395%): Data: 0.0%]:Running loss: 0.21759584546089172
[2018-04-17 16:31:53.427065]: [Epoch: 342(22.815210140093395%): Data: 25.333333333333336%]:Running loss: 4.351909801363945
[2018-04-17 16:31:54.674882]: [Epoch: 342(22.815210140093395%): Data: 50.66666666666667%]:Running loss: 8.486216977238655
[2018-04-17 16:31:58.154133]: Test set accuracy: 94.33962264150944% ,loss = 5.439858511090279
[2018-04-17 16:31:58.274453]: ====================
[2018-04-17 16:31:58.279467]: Elapsed time since starting training: 0:36:43.675666
[2018-04-17 16:31:58.286486]: ====================
[2018-04-17 16:31:58.356171]: [Epoch: 343(22.881921280853902%): Data: 0.0%]:Running loss: 0.21759434044361115
[2018-04-17 16:31:59.601482]: [Epoch: 343(22.881921280853902%): Data: 25.333333333333336%]:Running loss: 4.351882457733154
[2018-04-17 16:32:00.871359]: [Epoch: 343(22.881921280853902%): Data: 50.66666666666667%]:Running loss: 8.486163139343262
[2018-04-17 16:32:04.355122]: Test set accuracy: 94.33962264150944% ,loss = 5.439819395542145
[2018-04-17 16:32:04.467922]: ====================
[2018-04-17 16:32:04.473938]: Elapsed time since starting training: 0:36:49.870137
[2018-04-17 16:32:04.479453]: ====================
[2018-04-17 16:32:04.547132]: [Epoch: 344(22.94863242161441%): Data: 0.0%]:Running loss: 0.2175927758216858
[2018-04-17 16:32:05.803974]: [Epoch: 344(22.94863242161441%): Data: 25.333333333333336%]:Running loss: 4.351853892207146
[2018-04-17 16:32:07.064325]: [Epoch: 344(22.94863242161441%): Data: 50.66666666666667%]:Running loss: 8.48610831797123
[2018-04-17 16:32:10.580676]: Test set accuracy: 94.33962264150944% ,loss = 5.4397933185100555
[2018-04-17 16:32:10.712526]: ====================
[2018-04-17 16:32:10.718542]: Elapsed time since starting training: 0:36:56.114240
[2018-04-17 16:32:10.725060]: ====================
[2018-04-17 16:32:10.796249]: [Epoch: 345(23.015343562374916%): Data: 0.0%]:Running loss: 0.21759173274040222
[2018-04-17 16:32:12.104728]: [Epoch: 345(23.015343562374916%): Data: 25.333333333333336%]:Running loss: 4.351826757192612
[2018-04-17 16:32:13.342018]: [Epoch: 345(23.015343562374916%): Data: 50.66666666666667%]:Running loss: 8.48605491220951
[2018-04-17 16:32:16.821269]: Test set accuracy: 94.33962264150944% ,loss = 5.4397545754909515
[2018-04-17 16:32:16.937579]: ====================
[2018-04-17 16:32:16.943093]: Elapsed time since starting training: 0:37:02.338791
[2018-04-17 16:32:16.948107]: ====================
[2018-04-17 16:32:17.022806]: [Epoch: 346(23.082054703135423%): Data: 0.0%]:Running loss: 0.21759018301963806
[2018-04-17 16:32:18.273130]: [Epoch: 346(23.082054703135423%): Data: 25.333333333333336%]:Running loss: 4.351799979805946
[2018-04-17 16:32:19.543007]: [Epoch: 346(23.082054703135423%): Data: 50.66666666666667%]:Running loss: 8.48600372672081
[2018-04-17 16:32:23.040807]: Test set accuracy: 94.33962264150944% ,loss = 5.439723655581474
[2018-04-17 16:32:23.154109]: ====================
[2018-04-17 16:32:23.159122]: Elapsed time since starting training: 0:37:08.555321
[2018-04-17 16:32:23.164636]: ====================
[2018-04-17 16:32:23.228807]: [Epoch: 347(23.14876584389593%): Data: 0.0%]:Running loss: 0.21758894622325897
[2018-04-17 16:32:24.517734]: [Epoch: 347(23.14876584389593%): Data: 25.333333333333336%]:Running loss: 4.3517744690179825
[2018-04-17 16:32:25.809670]: [Epoch: 347(23.14876584389593%): Data: 50.66666666666667%]:Running loss: 8.485953867435455
[2018-04-17 16:32:29.360612]: Test set accuracy: 94.33962264150944% ,loss = 5.439688637852669
[2018-04-17 16:32:29.487449]: ====================
[2018-04-17 16:32:29.493465]: Elapsed time since starting training: 0:37:14.889664
[2018-04-17 16:32:29.499481]: ====================
[2018-04-17 16:32:29.577688]: [Epoch: 348(23.215476984656437%): Data: 0.0%]:Running loss: 0.21758754551410675
[2018-04-17 16:32:30.919256]: [Epoch: 348(23.215476984656437%): Data: 25.333333333333336%]:Running loss: 4.351749047636986
[2018-04-17 16:32:32.200663]: [Epoch: 348(23.215476984656437%): Data: 50.66666666666667%]:Running loss: 8.485904544591904
[2018-04-17 16:32:35.757126]: Test set accuracy: 94.33962264150944% ,loss = 5.4396528750658035
[2018-04-17 16:32:35.909531]: ====================
[2018-04-17 16:32:35.915547]: Elapsed time since starting training: 0:37:21.311746
[2018-04-17 16:32:35.921562]: ====================
[2018-04-17 16:32:35.993755]: [Epoch: 349(23.282188125416944%): Data: 0.0%]:Running loss: 0.21758611500263214
[2018-04-17 16:32:37.264132]: [Epoch: 349(23.282188125416944%): Data: 25.333333333333336%]:Running loss: 4.351723477244377
[2018-04-17 16:32:38.559583]: [Epoch: 349(23.282188125416944%): Data: 50.66666666666667%]:Running loss: 8.485855489969254
[2018-04-17 16:32:42.115030]: Test set accuracy: 94.33962264150944% ,loss = 5.439626052975655
[2018-04-17 16:32:42.233345]: ====================
[2018-04-17 16:32:42.239863]: Elapsed time since starting training: 0:37:27.635560
[2018-04-17 16:32:42.244876]: ====================
[2018-04-17 16:32:42.316566]: [Epoch: 350(23.34889926617745%): Data: 0.0%]:Running loss: 0.21758504211902618
[2018-04-17 16:32:43.576918]: [Epoch: 350(23.34889926617745%): Data: 25.333333333333336%]:Running loss: 4.351699233055115
[2018-04-17 16:32:44.847295]: [Epoch: 350(23.34889926617745%): Data: 50.66666666666667%]:Running loss: 8.485807806253433
[2018-04-17 16:32:48.404755]: Test set accuracy: 94.33962264150944% ,loss = 5.439601838588715
[2018-04-17 16:32:48.527081]: ====================
[2018-04-17 16:32:48.532594]: Elapsed time since starting training: 0:37:33.928793
[2018-04-17 16:32:48.539614]: ====================
[2018-04-17 16:32:48.612809]: [Epoch: 351(23.415610406937958%): Data: 0.0%]:Running loss: 0.21758407354354858
[2018-04-17 16:32:49.864135]: [Epoch: 351(23.415610406937958%): Data: 25.333333333333336%]:Running loss: 4.351673856377602
[2018-04-17 16:32:51.127495]: [Epoch: 351(23.415610406937958%): Data: 50.66666666666667%]:Running loss: 8.485759362578392
[2018-04-17 16:32:54.646351]: Test set accuracy: 94.33962264150944% ,loss = 5.439568310976028
[2018-04-17 16:32:54.760655]: ====================
[2018-04-17 16:32:54.766170]: Elapsed time since starting training: 0:37:40.162369
[2018-04-17 16:32:54.771685]: ====================
[2018-04-17 16:32:54.843375]: [Epoch: 352(23.482321547698465%): Data: 0.0%]:Running loss: 0.21758273243904114
[2018-04-17 16:32:56.087182]: [Epoch: 352(23.482321547698465%): Data: 25.333333333333336%]:Running loss: 4.351651921868324
[2018-04-17 16:32:57.335000]: [Epoch: 352(23.482321547698465%): Data: 50.66666666666667%]:Running loss: 8.48571540415287
[2018-04-17 16:33:00.819265]: Test set accuracy: 94.33962264150944% ,loss = 5.4395392537117
[2018-04-17 16:33:00.940589]: ====================
[2018-04-17 16:33:00.946102]: Elapsed time since starting training: 0:37:46.342301
[2018-04-17 16:33:00.951617]: ====================
[2018-04-17 16:33:01.028321]: [Epoch: 353(23.549032688458972%): Data: 0.0%]:Running loss: 0.21758157014846802
[2018-04-17 16:33:02.261600]: [Epoch: 353(23.549032688458972%): Data: 25.333333333333336%]:Running loss: 4.351628243923187
[2018-04-17 16:33:03.523455]: [Epoch: 353(23.549032688458972%): Data: 50.66666666666667%]:Running loss: 8.485668987035751
[2018-04-17 16:33:07.123528]: Test set accuracy: 94.33962264150944% ,loss = 5.439509451389313
[2018-04-17 16:33:07.233822]: ====================
[2018-04-17 16:33:07.239838]: Elapsed time since starting training: 0:37:52.635535
[2018-04-17 16:33:07.245352]: ====================
[2018-04-17 16:33:07.318546]: [Epoch: 354(23.61574382921948%): Data: 0.0%]:Running loss: 0.2175803780555725
[2018-04-17 16:33:08.579399]: [Epoch: 354(23.61574382921948%): Data: 25.333333333333336%]:Running loss: 4.351605877280235
[2018-04-17 16:33:09.856795]: [Epoch: 354(23.61574382921948%): Data: 50.66666666666667%]:Running loss: 8.485625743865967
[2018-04-17 16:33:13.414756]: Test set accuracy: 94.33962264150944% ,loss = 5.439475178718567
[2018-04-17 16:33:13.548111]: ====================
[2018-04-17 16:33:13.554629]: Elapsed time since starting training: 0:37:58.950828
[2018-04-17 16:33:13.560645]: ====================
[2018-04-17 16:33:13.630831]: [Epoch: 355(23.68245496997999%): Data: 0.0%]:Running loss: 0.21757900714874268
[2018-04-17 16:33:14.898702]: [Epoch: 355(23.68245496997999%): Data: 25.333333333333336%]:Running loss: 4.351582452654839
[2018-04-17 16:33:16.184120]: [Epoch: 355(23.68245496997999%): Data: 50.66666666666667%]:Running loss: 8.485580757260323
[2018-04-17 16:33:19.692954]: Test set accuracy: 94.33962264150944% ,loss = 5.439453199505806
[2018-04-17 16:33:19.807258]: ====================
[2018-04-17 16:33:19.813274]: Elapsed time since starting training: 0:38:05.209473
[2018-04-17 16:33:19.819290]: ====================
[2018-04-17 16:33:19.887471]: [Epoch: 356(23.749166110740493%): Data: 0.0%]:Running loss: 0.21757812798023224
[2018-04-17 16:33:21.176398]: [Epoch: 356(23.749166110740493%): Data: 25.333333333333336%]:Running loss: 4.35156112909317
[2018-04-17 16:33:22.431235]: [Epoch: 356(23.749166110740493%): Data: 50.66666666666667%]:Running loss: 8.485539361834526
[2018-04-17 16:33:25.961622]: Test set accuracy: 94.33962264150944% ,loss = 5.439424514770508
[2018-04-17 16:33:26.083948]: ====================
[2018-04-17 16:33:26.089964]: Elapsed time since starting training: 0:38:11.486163
[2018-04-17 16:33:26.095478]: ====================
[2018-04-17 16:33:26.170678]: [Epoch: 357(23.815877251501%): Data: 0.0%]:Running loss: 0.2175769805908203
[2018-04-17 16:33:27.421003]: [Epoch: 357(23.815877251501%): Data: 25.333333333333336%]:Running loss: 4.351540058851242
[2018-04-17 16:33:28.702912]: [Epoch: 357(23.815877251501%): Data: 50.66666666666667%]:Running loss: 8.485497534275055
[2018-04-17 16:33:32.268392]: Test set accuracy: 94.33962264150944% ,loss = 5.43939583003521
[2018-04-17 16:33:32.384200]: ====================
[2018-04-17 16:33:32.389714]: Elapsed time since starting training: 0:38:17.785412
[2018-04-17 16:33:32.395229]: ====================
[2018-04-17 16:33:32.462909]: [Epoch: 358(23.882588392261507%): Data: 0.0%]:Running loss: 0.2175758332014084
[2018-04-17 16:33:33.743815]: [Epoch: 358(23.882588392261507%): Data: 25.333333333333336%]:Running loss: 4.351518392562866
[2018-04-17 16:33:35.017702]: [Epoch: 358(23.882588392261507%): Data: 50.66666666666667%]:Running loss: 8.485456377267838
[2018-04-17 16:33:38.519012]: Test set accuracy: 94.33962264150944% ,loss = 5.4393768310546875
[2018-04-17 16:33:38.632314]: ====================
[2018-04-17 16:33:38.637828]: Elapsed time since starting training: 0:38:24.034027
[2018-04-17 16:33:38.643343]: ====================
[2018-04-17 16:33:38.712527]: [Epoch: 359(23.949299533022014%): Data: 0.0%]:Running loss: 0.2175750732421875
[2018-04-17 16:33:39.991428]: [Epoch: 359(23.949299533022014%): Data: 25.333333333333336%]:Running loss: 4.35149809718132
[2018-04-17 16:33:41.236237]: [Epoch: 359(23.949299533022014%): Data: 50.66666666666667%]:Running loss: 8.485415145754814
[2018-04-17 16:33:44.736043]: Test set accuracy: 94.33962264150944% ,loss = 5.439349263906479
[2018-04-17 16:33:44.935072]: ====================
[2018-04-17 16:33:44.942593]: Elapsed time since starting training: 0:38:30.338290
[2018-04-17 16:33:44.947606]: ====================
[2018-04-17 16:33:45.012780]: [Epoch: 360(24.016010673782525%): Data: 0.0%]:Running loss: 0.21757397055625916
[2018-04-17 16:33:46.323264]: [Epoch: 360(24.016010673782525%): Data: 25.333333333333336%]:Running loss: 4.351477801799774
[2018-04-17 16:33:47.662834]: [Epoch: 360(24.016010673782525%): Data: 50.66666666666667%]:Running loss: 8.485375866293907
[2018-04-17 16:33:51.271421]: Test set accuracy: 94.33962264150944% ,loss = 5.439329147338867
[2018-04-17 16:33:51.405277]: ====================
[2018-04-17 16:33:51.413800]: Elapsed time since starting training: 0:38:36.809999
[2018-04-17 16:33:51.419816]: ====================
[2018-04-17 16:33:51.497022]: [Epoch: 361(24.082721814543028%): Data: 0.0%]:Running loss: 0.2175731658935547
[2018-04-17 16:33:52.891228]: [Epoch: 361(24.082721814543028%): Data: 25.333333333333336%]:Running loss: 4.35145790874958
[2018-04-17 16:33:54.486469]: [Epoch: 361(24.082721814543028%): Data: 50.66666666666667%]:Running loss: 8.485337004065514
[2018-04-17 16:33:58.114116]: Test set accuracy: 94.33962264150944% ,loss = 5.439303070306778
[2018-04-17 16:33:58.246467]: ====================
[2018-04-17 16:33:58.251481]: Elapsed time since starting training: 0:38:43.647680
[2018-04-17 16:33:58.257999]: ====================
[2018-04-17 16:33:58.330692]: [Epoch: 362(24.149432955303535%): Data: 0.0%]:Running loss: 0.21757212281227112
[2018-04-17 16:33:59.560963]: [Epoch: 362(24.149432955303535%): Data: 25.333333333333336%]:Running loss: 4.351438149809837
[2018-04-17 16:34:00.836855]: [Epoch: 362(24.149432955303535%): Data: 50.66666666666667%]:Running loss: 8.485298439860344
[2018-04-17 16:34:04.370752]: Test set accuracy: 94.33962264150944% ,loss = 5.439279228448868
[2018-04-17 16:34:04.515136]: ====================
[2018-04-17 16:34:04.520651]: Elapsed time since starting training: 0:38:49.916850
[2018-04-17 16:34:04.526666]: ====================
[2018-04-17 16:34:04.596853]: [Epoch: 363(24.216144096064042%): Data: 0.0%]:Running loss: 0.2175711691379547
[2018-04-17 16:34:05.878260]: [Epoch: 363(24.216144096064042%): Data: 25.333333333333336%]:Running loss: 4.351418316364288
[2018-04-17 16:34:07.134601]: [Epoch: 363(24.216144096064042%): Data: 50.66666666666667%]:Running loss: 8.485261023044586
[2018-04-17 16:34:10.619367]: Test set accuracy: 94.33962264150944% ,loss = 5.439255386590958
[2018-04-17 16:34:10.743699]: ====================
[2018-04-17 16:34:10.749213]: Elapsed time since starting training: 0:38:56.145412
[2018-04-17 16:34:10.754727]: ====================
[2018-04-17 16:34:10.825415]: [Epoch: 364(24.28285523682455%): Data: 0.0%]:Running loss: 0.2175702154636383
[2018-04-17 16:34:12.112337]: [Epoch: 364(24.28285523682455%): Data: 25.333333333333336%]:Running loss: 4.351398840546608
[2018-04-17 16:34:13.384720]: [Epoch: 364(24.28285523682455%): Data: 50.66666666666667%]:Running loss: 8.485224232077599
[2018-04-17 16:34:16.946190]: Test set accuracy: 94.33962264150944% ,loss = 5.439228564500809
[2018-04-17 16:34:17.071029]: ====================
[2018-04-17 16:34:17.077540]: Elapsed time since starting training: 0:39:02.473739
[2018-04-17 16:34:17.083054]: ====================
[2018-04-17 16:34:17.149731]: [Epoch: 365(24.34956637758506%): Data: 0.0%]:Running loss: 0.21756914258003235
[2018-04-17 16:34:18.408578]: [Epoch: 365(24.34956637758506%): Data: 25.333333333333336%]:Running loss: 4.351380988955498
[2018-04-17 16:34:19.659906]: [Epoch: 365(24.34956637758506%): Data: 50.66666666666667%]:Running loss: 8.485188007354736
[2018-04-17 16:34:23.148180]: Test set accuracy: 94.33962264150944% ,loss = 5.439205095171928
[2018-04-17 16:34:23.267499]: ====================
[2018-04-17 16:34:23.273013]: Elapsed time since starting training: 0:39:08.669212
[2018-04-17 16:34:23.279029]: ====================
[2018-04-17 16:34:23.351722]: [Epoch: 366(24.416277518345563%): Data: 0.0%]:Running loss: 0.21756820380687714
[2018-04-17 16:34:24.604052]: [Epoch: 366(24.416277518345563%): Data: 25.333333333333336%]:Running loss: 4.35136242210865
[2018-04-17 16:34:25.836830]: [Epoch: 366(24.416277518345563%): Data: 50.66666666666667%]:Running loss: 8.48515199124813
[2018-04-17 16:34:29.355185]: Test set accuracy: 94.33962264150944% ,loss = 5.439179390668869
[2018-04-17 16:34:29.471996]: ====================
[2018-04-17 16:34:29.477512]: Elapsed time since starting training: 0:39:14.873711
[2018-04-17 16:34:29.483527]: ====================
[2018-04-17 16:34:29.556721]: [Epoch: 367(24.48298865910607%): Data: 0.0%]:Running loss: 0.21756717562675476
[2018-04-17 16:34:30.810054]: [Epoch: 367(24.48298865910607%): Data: 25.333333333333336%]:Running loss: 4.351344496011734
[2018-04-17 16:34:32.057370]: [Epoch: 367(24.48298865910607%): Data: 50.66666666666667%]:Running loss: 8.485117256641388
[2018-04-17 16:34:35.524089]: Test set accuracy: 94.33962264150944% ,loss = 5.439157411456108
[2018-04-17 16:34:35.638392]: ====================
[2018-04-17 16:34:35.644409]: Elapsed time since starting training: 0:39:21.040608
[2018-04-17 16:34:35.649923]: ====================
[2018-04-17 16:34:35.719107]: [Epoch: 368(24.549699799866577%): Data: 0.0%]:Running loss: 0.21756629645824432
[2018-04-17 16:34:36.977954]: [Epoch: 368(24.549699799866577%): Data: 25.333333333333336%]:Running loss: 4.351326808333397
[2018-04-17 16:34:38.211234]: [Epoch: 368(24.549699799866577%): Data: 50.66666666666667%]:Running loss: 8.485083535313606
[2018-04-17 16:34:41.676447]: Test set accuracy: 94.33962264150944% ,loss = 5.439135804772377
[2018-04-17 16:34:41.801279]: ====================
[2018-04-17 16:34:41.806794]: Elapsed time since starting training: 0:39:27.202993
[2018-04-17 16:34:41.813311]: ====================
[2018-04-17 16:34:41.881994]: [Epoch: 369(24.616410940627084%): Data: 0.0%]:Running loss: 0.21756543219089508
[2018-04-17 16:34:43.115779]: [Epoch: 369(24.616410940627084%): Data: 25.333333333333336%]:Running loss: 4.351309433579445
[2018-04-17 16:34:44.368108]: [Epoch: 369(24.616410940627084%): Data: 50.66666666666667%]:Running loss: 8.485050186514854
[2018-04-17 16:34:47.921057]: Test set accuracy: 94.33962264150944% ,loss = 5.439113825559616
[2018-04-17 16:34:48.036869]: ====================
[2018-04-17 16:34:48.043883]: Elapsed time since starting training: 0:39:33.440082
[2018-04-17 16:34:48.049899]: ====================
[2018-04-17 16:34:48.120588]: [Epoch: 370(24.683122081387594%): Data: 0.0%]:Running loss: 0.21756455302238464
[2018-04-17 16:34:49.382943]: [Epoch: 370(24.683122081387594%): Data: 25.333333333333336%]:Running loss: 4.351292580366135
[2018-04-17 16:34:50.647812]: [Epoch: 370(24.683122081387594%): Data: 50.66666666666667%]:Running loss: 8.485016226768494
[2018-04-17 16:34:54.404295]: Test set accuracy: 94.33962264150944% ,loss = 5.439102277159691
[2018-04-17 16:34:54.522109]: ====================
[2018-04-17 16:34:54.527623]: Elapsed time since starting training: 0:39:39.923822
[2018-04-17 16:34:54.533639]: ====================
[2018-04-17 16:34:54.606332]: [Epoch: 371(24.749833222148098%): Data: 0.0%]:Running loss: 0.21756409108638763
[2018-04-17 16:34:55.929852]: [Epoch: 371(24.749833222148098%): Data: 25.333333333333336%]:Running loss: 4.3512764275074005
[2018-04-17 16:34:57.271920]: [Epoch: 371(24.749833222148098%): Data: 50.66666666666667%]:Running loss: 8.484984442591667
[2018-04-17 16:35:00.881518]: Test set accuracy: 94.33962264150944% ,loss = 5.439078435301781
[2018-04-17 16:35:01.014873]: ====================
[2018-04-17 16:35:01.020888]: Elapsed time since starting training: 0:39:46.416586
[2018-04-17 16:35:01.026905]: ====================
[2018-04-17 16:35:01.098596]: [Epoch: 372(24.816544362908605%): Data: 0.0%]:Running loss: 0.21756313741207123
[2018-04-17 16:35:02.436152]: [Epoch: 372(24.816544362908605%): Data: 25.333333333333336%]:Running loss: 4.351259529590607
[2018-04-17 16:35:03.895031]: [Epoch: 372(24.816544362908605%): Data: 50.66666666666667%]:Running loss: 8.484951928257942
[2018-04-17 16:35:07.535210]: Test set accuracy: 94.33962264150944% ,loss = 5.439061671495438
[2018-04-17 16:35:07.657034]: ====================
[2018-04-17 16:35:07.663551]: Elapsed time since starting training: 0:39:53.059249
[2018-04-17 16:35:07.669067]: ====================
[2018-04-17 16:35:07.738751]: [Epoch: 373(24.883255503669112%): Data: 0.0%]:Running loss: 0.2175624668598175
[2018-04-17 16:35:09.024671]: [Epoch: 373(24.883255503669112%): Data: 25.333333333333336%]:Running loss: 4.351243644952774
[2018-04-17 16:35:10.300568]: [Epoch: 373(24.883255503669112%): Data: 50.66666666666667%]:Running loss: 8.484920963644981
[2018-04-17 16:35:13.858530]: Test set accuracy: 94.33962264150944% ,loss = 5.439043417572975
[2018-04-17 16:35:13.976344]: ====================
[2018-04-17 16:35:13.981858]: Elapsed time since starting training: 0:39:59.378057
[2018-04-17 16:35:13.987372]: ====================
[2018-04-17 16:35:14.059063]: [Epoch: 374(24.94996664442962%): Data: 0.0%]:Running loss: 0.217561736702919
[2018-04-17 16:35:15.458284]: [Epoch: 374(24.94996664442962%): Data: 25.333333333333336%]:Running loss: 4.3512283861637115
[2018-04-17 16:35:16.850988]: [Epoch: 374(24.94996664442962%): Data: 50.66666666666667%]:Running loss: 8.484891474246979
[2018-04-17 16:35:20.557342]: Test set accuracy: 94.33962264150944% ,loss = 5.4390255361795425
[2018-04-17 16:35:20.755870]: ====================
[2018-04-17 16:35:20.764393]: Elapsed time since starting training: 0:40:06.160091
[2018-04-17 16:35:20.770409]: ====================
[2018-04-17 16:35:20.848617]: [Epoch: 375(25.01667778519013%): Data: 0.0%]:Running loss: 0.2175610214471817
[2018-04-17 16:35:22.350109]: [Epoch: 375(25.01667778519013%): Data: 25.333333333333336%]:Running loss: 4.35121263563633
[2018-04-17 16:35:23.685660]: [Epoch: 375(25.01667778519013%): Data: 50.66666666666667%]:Running loss: 8.484861493110657
[2018-04-17 16:35:27.401039]: Test set accuracy: 94.33962264150944% ,loss = 5.438994616270065
[2018-04-17 16:35:27.556453]: ====================
[2018-04-17 16:35:27.563973]: Elapsed time since starting training: 0:40:12.960172
[2018-04-17 16:35:27.569989]: ====================
[2018-04-17 16:35:27.652710]: [Epoch: 376(25.083388925950633%): Data: 0.0%]:Running loss: 0.2175597846508026
[2018-04-17 16:35:28.925092]: [Epoch: 376(25.083388925950633%): Data: 25.333333333333336%]:Running loss: 4.351196616888046
[2018-04-17 16:35:30.217027]: [Epoch: 376(25.083388925950633%): Data: 50.66666666666667%]:Running loss: 8.484831273555756
[2018-04-17 16:35:33.748918]: Test set accuracy: 94.33962264150944% ,loss = 5.438975617289543
[2018-04-17 16:35:33.865229]: ====================
[2018-04-17 16:35:33.870742]: Elapsed time since starting training: 0:40:19.266440
[2018-04-17 16:35:33.876257]: ====================
[2018-04-17 16:35:33.950454]: [Epoch: 377(25.15010006671114%): Data: 0.0%]:Running loss: 0.21755902469158173
[2018-04-17 16:35:35.182230]: [Epoch: 377(25.15010006671114%): Data: 25.333333333333336%]:Running loss: 4.351181581616402
[2018-04-17 16:35:36.464138]: [Epoch: 377(25.15010006671114%): Data: 50.66666666666667%]:Running loss: 8.48480187356472
[2018-04-17 16:35:39.919827]: Test set accuracy: 94.33962264150944% ,loss = 5.438955873250961
[2018-04-17 16:35:40.049673]: ====================
[2018-04-17 16:35:40.056190]: Elapsed time since starting training: 0:40:25.451887
[2018-04-17 16:35:40.064212]: ====================
[2018-04-17 16:35:40.133407]: [Epoch: 378(25.216811207471647%): Data: 0.0%]:Running loss: 0.21755823493003845
[2018-04-17 16:35:41.388232]: [Epoch: 378(25.216811207471647%): Data: 25.333333333333336%]:Running loss: 4.351167783141136
[2018-04-17 16:35:42.656604]: [Epoch: 378(25.216811207471647%): Data: 50.66666666666667%]:Running loss: 8.484773352742195
[2018-04-17 16:35:46.170447]: Test set accuracy: 94.33962264150944% ,loss = 5.438942462205887
[2018-04-17 16:35:46.290266]: ====================
[2018-04-17 16:35:46.297285]: Elapsed time since starting training: 0:40:31.693484
[2018-04-17 16:35:46.303301]: ====================
[2018-04-17 16:35:46.373989]: [Epoch: 379(25.283522348232157%): Data: 0.0%]:Running loss: 0.21755769848823547
[2018-04-17 16:35:47.626319]: [Epoch: 379(25.283522348232157%): Data: 25.333333333333336%]:Running loss: 4.351153656840324
[2018-04-17 16:35:48.887672]: [Epoch: 379(25.283522348232157%): Data: 50.66666666666667%]:Running loss: 8.484745442867279
[2018-04-17 16:35:52.437110]: Test set accuracy: 94.33962264150944% ,loss = 5.4389286786317825
[2018-04-17 16:35:52.550912]: ====================
[2018-04-17 16:35:52.556929]: Elapsed time since starting training: 0:40:37.953128
[2018-04-17 16:35:52.562945]: ====================
[2018-04-17 16:35:52.630123]: [Epoch: 380(25.350233488992664%): Data: 0.0%]:Running loss: 0.2175571471452713
[2018-04-17 16:35:53.873931]: [Epoch: 380(25.350233488992664%): Data: 25.333333333333336%]:Running loss: 4.351139217615128
[2018-04-17 16:35:55.144309]: [Epoch: 380(25.350233488992664%): Data: 50.66666666666667%]:Running loss: 8.484717637300491
[2018-04-17 16:35:58.661169]: Test set accuracy: 94.33962264150944% ,loss = 5.4389022290706635
[2018-04-17 16:35:58.783996]: ====================
[2018-04-17 16:35:58.789510]: Elapsed time since starting training: 0:40:44.185709
[2018-04-17 16:35:58.795025]: ====================
[2018-04-17 16:35:58.861702]: [Epoch: 381(25.416944629753168%): Data: 0.0%]:Running loss: 0.21755608916282654
[2018-04-17 16:36:00.113029]: [Epoch: 381(25.416944629753168%): Data: 25.333333333333336%]:Running loss: 4.351125612854958
[2018-04-17 16:36:01.389925]: [Epoch: 381(25.416944629753168%): Data: 50.66666666666667%]:Running loss: 8.484691858291626
[2018-04-17 16:36:04.837097]: Test set accuracy: 94.33962264150944% ,loss = 5.438889563083649
[2018-04-17 16:36:04.960425]: ====================
[2018-04-17 16:36:04.965940]: Elapsed time since starting training: 0:40:50.361637
[2018-04-17 16:36:04.970953]: ====================
[2018-04-17 16:36:05.038634]: [Epoch: 382(25.483655770513675%): Data: 0.0%]:Running loss: 0.21755558252334595
[2018-04-17 16:36:06.316029]: [Epoch: 382(25.483655770513675%): Data: 25.333333333333336%]:Running loss: 4.351111486554146
[2018-04-17 16:36:07.571869]: [Epoch: 382(25.483655770513675%): Data: 50.66666666666667%]:Running loss: 8.484665513038635
[2018-04-17 16:36:11.118298]: Test set accuracy: 94.33962264150944% ,loss = 5.438872054219246
[2018-04-17 16:36:11.255163]: ====================
[2018-04-17 16:36:11.260677]: Elapsed time since starting training: 0:40:56.656876
[2018-04-17 16:36:11.267195]: ====================
[2018-04-17 16:36:11.336880]: [Epoch: 383(25.550366911274182%): Data: 0.0%]:Running loss: 0.21755488216876984
[2018-04-17 16:36:12.599236]: [Epoch: 383(25.550366911274182%): Data: 25.333333333333336%]:Running loss: 4.351098746061325
[2018-04-17 16:36:13.833017]: [Epoch: 383(25.550366911274182%): Data: 50.66666666666667%]:Running loss: 8.484639078378677
[2018-04-17 16:36:17.401004]: Test set accuracy: 94.33962264150944% ,loss = 5.438855290412903
[2018-04-17 16:36:17.523329]: ====================
[2018-04-17 16:36:17.529849]: Elapsed time since starting training: 0:41:02.926048
[2018-04-17 16:36:17.536364]: ====================
[2018-04-17 16:36:17.609559]: [Epoch: 384(25.617078052034692%): Data: 0.0%]:Running loss: 0.2175542116165161
[2018-04-17 16:36:18.930571]: [Epoch: 384(25.617078052034692%): Data: 25.333333333333336%]:Running loss: 4.351084917783737
[2018-04-17 16:36:20.184906]: [Epoch: 384(25.617078052034692%): Data: 50.66666666666667%]:Running loss: 8.484612420201302
[2018-04-17 16:36:23.719805]: Test set accuracy: 94.33962264150944% ,loss = 5.438841134309769
[2018-04-17 16:36:23.851156]: ====================
[2018-04-17 16:36:23.857171]: Elapsed time since starting training: 0:41:09.253370
[2018-04-17 16:36:23.864190]: ====================
[2018-04-17 16:36:23.936382]: [Epoch: 385(25.6837891927952%): Data: 0.0%]:Running loss: 0.21755364537239075
[2018-04-17 16:36:25.205256]: [Epoch: 385(25.6837891927952%): Data: 25.333333333333336%]:Running loss: 4.351072192192078
[2018-04-17 16:36:26.475132]: [Epoch: 385(25.6837891927952%): Data: 50.66666666666667%]:Running loss: 8.484587550163269
[2018-04-17 16:36:30.008027]: Test set accuracy: 94.33962264150944% ,loss = 5.438828840851784
[2018-04-17 16:36:30.126341]: ====================
[2018-04-17 16:36:30.131855]: Elapsed time since starting training: 0:41:15.528054
[2018-04-17 16:36:30.138373]: ====================
[2018-04-17 16:36:30.208559]: [Epoch: 386(25.750500333555703%): Data: 0.0%]:Running loss: 0.21755315363407135
[2018-04-17 16:36:31.518042]: [Epoch: 386(25.750500333555703%): Data: 25.333333333333336%]:Running loss: 4.351059526205063
[2018-04-17 16:36:32.752824]: [Epoch: 386(25.750500333555703%): Data: 50.66666666666667%]:Running loss: 8.484563693404198
[2018-04-17 16:36:36.220044]: Test set accuracy: 94.33962264150944% ,loss = 5.438816919922829
[2018-04-17 16:36:36.343873]: ====================
[2018-04-17 16:36:36.349388]: Elapsed time since starting training: 0:41:21.745587
[2018-04-17 16:36:36.355404]: ====================
[2018-04-17 16:36:36.427095]: [Epoch: 387(25.81721147431621%): Data: 0.0%]:Running loss: 0.21755267679691315
[2018-04-17 16:36:37.665888]: [Epoch: 387(25.81721147431621%): Data: 25.333333333333336%]:Running loss: 4.351047396659851
[2018-04-17 16:36:38.915210]: [Epoch: 387(25.81721147431621%): Data: 50.66666666666667%]:Running loss: 8.484539404511452
[2018-04-17 16:36:42.371400]: Test set accuracy: 94.33962264150944% ,loss = 5.438793450593948
[2018-04-17 16:36:42.490717]: ====================
[2018-04-17 16:36:42.496733]: Elapsed time since starting training: 0:41:27.892932
[2018-04-17 16:36:42.502254]: ====================
[2018-04-17 16:36:42.577455]: [Epoch: 388(25.883922615076717%): Data: 0.0%]:Running loss: 0.21755173802375793
[2018-04-17 16:36:43.866877]: [Epoch: 388(25.883922615076717%): Data: 25.333333333333336%]:Running loss: 4.3510351330041885
[2018-04-17 16:36:45.101660]: [Epoch: 388(25.883922615076717%): Data: 50.66666666666667%]:Running loss: 8.484516263008118
[2018-04-17 16:36:48.579407]: Test set accuracy: 94.33962264150944% ,loss = 5.438780784606934
[2018-04-17 16:36:48.724795]: ====================
[2018-04-17 16:36:48.733818]: Elapsed time since starting training: 0:41:34.129516
[2018-04-17 16:36:48.738831]: ====================
[2018-04-17 16:36:48.807513]: [Epoch: 389(25.950633755837227%): Data: 0.0%]:Running loss: 0.21755123138427734
[2018-04-17 16:36:50.053326]: [Epoch: 389(25.950633755837227%): Data: 25.333333333333336%]:Running loss: 4.351023077964783
[2018-04-17 16:36:51.271064]: [Epoch: 389(25.950633755837227%): Data: 50.66666666666667%]:Running loss: 8.48449270427227
[2018-04-17 16:36:54.754827]: Test set accuracy: 94.33962264150944% ,loss = 5.438767001032829
[2018-04-17 16:36:54.880663]: ====================
[2018-04-17 16:36:54.886177]: Elapsed time since starting training: 0:41:40.282376
[2018-04-17 16:36:54.891191]: ====================
[2018-04-17 16:36:54.960875]: [Epoch: 390(26.017344896597734%): Data: 0.0%]:Running loss: 0.21755068004131317
[2018-04-17 16:36:56.199669]: [Epoch: 390(26.017344896597734%): Data: 25.333333333333336%]:Running loss: 4.351011112332344
[2018-04-17 16:36:57.405877]: [Epoch: 390(26.017344896597734%): Data: 50.66666666666667%]:Running loss: 8.484468817710876
[2018-04-17 16:37:00.822461]: Test set accuracy: 94.33962264150944% ,loss = 5.438753962516785
[2018-04-17 16:37:00.940783]: ====================
[2018-04-17 16:37:00.946291]: Elapsed time since starting training: 0:41:46.341989
[2018-04-17 16:37:00.951805]: ====================
[2018-04-17 16:37:01.020989]: [Epoch: 391(26.084056037358238%): Data: 0.0%]:Running loss: 0.2175501585006714
[2018-04-17 16:37:02.256274]: [Epoch: 391(26.084056037358238%): Data: 25.333333333333336%]:Running loss: 4.350999131798744
[2018-04-17 16:37:03.466993]: [Epoch: 391(26.084056037358238%): Data: 50.66666666666667%]:Running loss: 8.484446376562119
[2018-04-17 16:37:06.846479]: Test set accuracy: 94.33962264150944% ,loss = 5.43874092400074
[2018-04-17 16:37:07.061552]: ====================
[2018-04-17 16:37:07.070576]: Elapsed time since starting training: 0:41:52.466273
[2018-04-17 16:37:07.078095]: ====================
[2018-04-17 16:37:07.151791]: [Epoch: 392(26.150767178118745%): Data: 0.0%]:Running loss: 0.2175496369600296
[2018-04-17 16:37:08.356494]: [Epoch: 392(26.150767178118745%): Data: 25.333333333333336%]:Running loss: 4.350988194346428
[2018-04-17 16:37:09.576237]: [Epoch: 392(26.150767178118745%): Data: 50.66666666666667%]:Running loss: 8.484424754977226
[2018-04-17 16:37:12.957228]: Test set accuracy: 94.33962264150944% ,loss = 5.4387204349040985
[2018-04-17 16:37:13.079553]: ====================
[2018-04-17 16:37:13.085569]: Elapsed time since starting training: 0:41:58.481768
[2018-04-17 16:37:13.091084]: ====================
[2018-04-17 16:37:13.158763]: [Epoch: 393(26.21747831887925%): Data: 0.0%]:Running loss: 0.21754881739616394
[2018-04-17 16:37:14.390539]: [Epoch: 393(26.21747831887925%): Data: 25.333333333333336%]:Running loss: 4.350977972149849
[2018-04-17 16:37:15.610783]: [Epoch: 393(26.21747831887925%): Data: 50.66666666666667%]:Running loss: 8.48440369963646
[2018-04-17 16:37:18.985757]: Test set accuracy: 94.33962264150944% ,loss = 5.438709631562233
[2018-04-17 16:37:19.113598]: ====================
[2018-04-17 16:37:19.120115]: Elapsed time since starting training: 0:42:04.515813
[2018-04-17 16:37:19.125128]: ====================
[2018-04-17 16:37:19.194813]: [Epoch: 394(26.284189459639762%): Data: 0.0%]:Running loss: 0.21754838526248932
[2018-04-17 16:37:20.419068]: [Epoch: 394(26.284189459639762%): Data: 25.333333333333336%]:Running loss: 4.350967273116112
[2018-04-17 16:37:21.664881]: [Epoch: 394(26.284189459639762%): Data: 50.66666666666667%]:Running loss: 8.484383270144463
[2018-04-17 16:37:25.062416]: Test set accuracy: 94.33962264150944% ,loss = 5.43869324028492
[2018-04-17 16:37:25.182736]: ====================
[2018-04-17 16:37:25.187748]: Elapsed time since starting training: 0:42:10.583947
[2018-04-17 16:37:25.194266]: ====================
[2018-04-17 16:37:25.266961]: [Epoch: 395(26.35090060040027%): Data: 0.0%]:Running loss: 0.2175477296113968
[2018-04-17 16:37:26.505252]: [Epoch: 395(26.35090060040027%): Data: 25.333333333333336%]:Running loss: 4.350956082344055
[2018-04-17 16:37:27.735523]: [Epoch: 395(26.35090060040027%): Data: 50.66666666666667%]:Running loss: 8.484361350536346
[2018-04-17 16:37:31.126038]: Test set accuracy: 94.33962264150944% ,loss = 5.438683927059174
[2018-04-17 16:37:31.255884]: ====================
[2018-04-17 16:37:31.261900]: Elapsed time since starting training: 0:42:16.658099
[2018-04-17 16:37:31.267916]: ====================
[2018-04-17 16:37:31.342113]: [Epoch: 396(26.417611741160773%): Data: 0.0%]:Running loss: 0.21754735708236694
[2018-04-17 16:37:32.566870]: [Epoch: 396(26.417611741160773%): Data: 25.333333333333336%]:Running loss: 4.35094590485096
[2018-04-17 16:37:33.787114]: [Epoch: 396(26.417611741160773%): Data: 50.66666666666667%]:Running loss: 8.484340846538544
[2018-04-17 16:37:37.146547]: Test set accuracy: 94.33962264150944% ,loss = 5.438674241304398
[2018-04-17 16:37:37.266366]: ====================
[2018-04-17 16:37:37.272381]: Elapsed time since starting training: 0:42:22.668580
[2018-04-17 16:37:37.277400]: ====================
[2018-04-17 16:37:37.347582]: [Epoch: 397(26.48432288192128%): Data: 0.0%]:Running loss: 0.2175469696521759
[2018-04-17 16:37:38.651047]: [Epoch: 397(26.48432288192128%): Data: 25.333333333333336%]:Running loss: 4.350935310125351
[2018-04-17 16:37:39.876806]: [Epoch: 397(26.48432288192128%): Data: 50.66666666666667%]:Running loss: 8.484321177005768
[2018-04-17 16:37:43.254287]: Test set accuracy: 94.33962264150944% ,loss = 5.438653379678726
[2018-04-17 16:37:43.377114]: ====================
[2018-04-17 16:37:43.382127]: Elapsed time since starting training: 0:42:28.778326
[2018-04-17 16:37:43.387652]: ====================
[2018-04-17 16:37:43.456325]: [Epoch: 398(26.551034022681787%): Data: 0.0%]:Running loss: 0.21754613518714905
[2018-04-17 16:37:44.688601]: [Epoch: 398(26.551034022681787%): Data: 25.333333333333336%]:Running loss: 4.350924491882324
[2018-04-17 16:37:45.898819]: [Epoch: 398(26.551034022681787%): Data: 50.66666666666667%]:Running loss: 8.484300687909126
[2018-04-17 16:37:49.270284]: Test set accuracy: 94.33962264150944% ,loss = 5.438645556569099
[2018-04-17 16:37:49.394113]: ====================
[2018-04-17 16:37:49.399628]: Elapsed time since starting training: 0:42:34.795827
[2018-04-17 16:37:49.405142]: ====================
[2018-04-17 16:37:49.472321]: [Epoch: 399(26.617745163442297%): Data: 0.0%]:Running loss: 0.21754582226276398
[2018-04-17 16:37:50.719137]: [Epoch: 399(26.617745163442297%): Data: 25.333333333333336%]:Running loss: 4.350915506482124
[2018-04-17 16:37:51.921333]: [Epoch: 399(26.617745163442297%): Data: 50.66666666666667%]:Running loss: 8.484281823039055
[2018-04-17 16:37:55.308841]: Test set accuracy: 94.33962264150944% ,loss = 5.438629165291786
[2018-04-17 16:37:55.429662]: ====================
[2018-04-17 16:37:55.435677]: Elapsed time since starting training: 0:42:40.831876
[2018-04-17 16:37:55.440691]: ====================
[2018-04-17 16:37:55.509374]: [Epoch: 400(26.684456304202804%): Data: 0.0%]:Running loss: 0.21754516661167145
[2018-04-17 16:37:56.728615]: [Epoch: 400(26.684456304202804%): Data: 25.333333333333336%]:Running loss: 4.3509054481983185
[2018-04-17 16:37:57.977937]: [Epoch: 400(26.684456304202804%): Data: 50.66666666666667%]:Running loss: 8.484263256192207
[2018-04-17 16:38:01.423599]: Test set accuracy: 94.33962264150944% ,loss = 5.438622459769249
[2018-04-17 16:38:01.542415]: ====================
[2018-04-17 16:38:01.547930]: Elapsed time since starting training: 0:42:46.944129
[2018-04-17 16:38:01.553445]: ====================
[2018-04-17 16:38:01.618618]: [Epoch: 401(26.751167444963308%): Data: 0.0%]:Running loss: 0.21754489839076996
[2018-04-17 16:38:02.894010]: [Epoch: 401(26.751167444963308%): Data: 25.333333333333336%]:Running loss: 4.3508956134319305
[2018-04-17 16:38:04.152355]: [Epoch: 401(26.751167444963308%): Data: 50.66666666666667%]:Running loss: 8.484244391322136
[2018-04-17 16:38:07.617569]: Test set accuracy: 94.33962264150944% ,loss = 5.438605323433876
[2018-04-17 16:38:07.734881]: ====================
[2018-04-17 16:38:07.739895]: Elapsed time since starting training: 0:42:53.136094
[2018-04-17 16:38:07.745409]: ====================
[2018-04-17 16:38:07.809579]: [Epoch: 402(26.817878585723815%): Data: 0.0%]:Running loss: 0.21754421293735504
[2018-04-17 16:38:09.072939]: [Epoch: 402(26.817878585723815%): Data: 25.333333333333336%]:Running loss: 4.350886642932892
[2018-04-17 16:38:10.342314]: [Epoch: 402(26.817878585723815%): Data: 50.66666666666667%]:Running loss: 8.484226658940315
[2018-04-17 16:38:13.786973]: Test set accuracy: 94.33962264150944% ,loss = 5.438598245382309
[2018-04-17 16:38:13.904286]: ====================
[2018-04-17 16:38:13.908797]: Elapsed time since starting training: 0:42:59.304996
[2018-04-17 16:38:13.914312]: ====================
[2018-04-17 16:38:13.987507]: [Epoch: 403(26.88458972648432%): Data: 0.0%]:Running loss: 0.21754392981529236
[2018-04-17 16:38:15.251368]: [Epoch: 403(26.88458972648432%): Data: 25.333333333333336%]:Running loss: 4.350877806544304
[2018-04-17 16:38:16.533276]: [Epoch: 403(26.88458972648432%): Data: 50.66666666666667%]:Running loss: 8.484208732843399
[2018-04-17 16:38:19.968911]: Test set accuracy: 94.33962264150944% ,loss = 5.438581109046936
[2018-04-17 16:38:20.085722]: ====================
[2018-04-17 16:38:20.091237]: Elapsed time since starting training: 0:43:05.487436
[2018-04-17 16:38:20.096751]: ====================
[2018-04-17 16:38:20.173956]: [Epoch: 404(26.951300867244832%): Data: 0.0%]:Running loss: 0.21754324436187744
[2018-04-17 16:38:21.441828]: [Epoch: 404(26.951300867244832%): Data: 25.333333333333336%]:Running loss: 4.350867658853531
[2018-04-17 16:38:22.708696]: [Epoch: 404(26.951300867244832%): Data: 50.66666666666667%]:Running loss: 8.484190881252289
[2018-04-17 16:38:26.196972]: Test set accuracy: 94.33962264150944% ,loss = 5.4385751485824585
[2018-04-17 16:38:26.333334]: ====================
[2018-04-17 16:38:26.338849]: Elapsed time since starting training: 0:43:11.735048
[2018-04-17 16:38:26.343862]: ====================
[2018-04-17 16:38:26.415052]: [Epoch: 405(27.01801200800534%): Data: 0.0%]:Running loss: 0.21754300594329834
[2018-04-17 16:38:27.693952]: [Epoch: 405(27.01801200800534%): Data: 25.333333333333336%]:Running loss: 4.350859075784683
[2018-04-17 16:38:28.981375]: [Epoch: 405(27.01801200800534%): Data: 50.66666666666667%]:Running loss: 8.484173074364662
[2018-04-17 16:38:32.470152]: Test set accuracy: 94.33962264150944% ,loss = 5.438566952943802
[2018-04-17 16:38:32.586462]: ====================
[2018-04-17 16:38:32.591976]: Elapsed time since starting training: 0:43:17.987674
[2018-04-17 16:38:32.596990]: ====================
[2018-04-17 16:38:32.673701]: [Epoch: 406(27.084723148765843%): Data: 0.0%]:Running loss: 0.21754267811775208
[2018-04-17 16:38:33.945582]: [Epoch: 406(27.084723148765843%): Data: 25.333333333333336%]:Running loss: 4.3508501797914505
[2018-04-17 16:38:35.217965]: [Epoch: 406(27.084723148765843%): Data: 50.66666666666667%]:Running loss: 8.484155550599098
[2018-04-17 16:38:38.665633]: Test set accuracy: 94.33962264150944% ,loss = 5.438549444079399
[2018-04-17 16:38:38.787458]: ====================
[2018-04-17 16:38:38.792972]: Elapsed time since starting training: 0:43:24.189171
[2018-04-17 16:38:38.798486]: ====================
[2018-04-17 16:38:38.871681]: [Epoch: 407(27.15143428952635%): Data: 0.0%]:Running loss: 0.21754197776317596
[2018-04-17 16:38:40.140053]: [Epoch: 407(27.15143428952635%): Data: 25.333333333333336%]:Running loss: 4.350841730833054
[2018-04-17 16:38:41.373835]: [Epoch: 407(27.15143428952635%): Data: 50.66666666666667%]:Running loss: 8.484139487147331
[2018-04-17 16:38:44.819997]: Test set accuracy: 94.33962264150944% ,loss = 5.43854720890522
[2018-04-17 16:38:44.936809]: ====================
[2018-04-17 16:38:44.942323]: Elapsed time since starting training: 0:43:30.338522
[2018-04-17 16:38:44.947838]: ====================
[2018-04-17 16:38:45.020538]: [Epoch: 408(27.218145430286857%): Data: 0.0%]:Running loss: 0.2175418883562088
[2018-04-17 16:38:46.249799]: [Epoch: 408(27.218145430286857%): Data: 25.333333333333336%]:Running loss: 4.3508335798978806
[2018-04-17 16:38:47.530705]: [Epoch: 408(27.218145430286857%): Data: 50.66666666666667%]:Running loss: 8.484123334288597
[2018-04-17 16:38:51.022491]: Test set accuracy: 94.33962264150944% ,loss = 5.438534170389175
[2018-04-17 16:38:51.139802]: ====================
[2018-04-17 16:38:51.145818]: Elapsed time since starting training: 0:43:36.542017
[2018-04-17 16:38:51.151333]: ====================
[2018-04-17 16:38:51.217509]: [Epoch: 409(27.284856571047367%): Data: 0.0%]:Running loss: 0.21754136681556702
[2018-04-17 16:38:52.520473]: [Epoch: 409(27.284856571047367%): Data: 25.333333333333336%]:Running loss: 4.350825086236
[2018-04-17 16:38:53.762777]: [Epoch: 409(27.284856571047367%): Data: 50.66666666666667%]:Running loss: 8.48410676419735
[2018-04-17 16:38:57.015926]: Test set accuracy: 94.33962264150944% ,loss = 5.438518896698952
[2018-04-17 16:38:57.134242]: ====================
[2018-04-17 16:38:57.139255]: Elapsed time since starting training: 0:43:42.535454
[2018-04-17 16:38:57.144770]: ====================
[2018-04-17 16:38:57.207436]: [Epoch: 410(27.351567711807874%): Data: 0.0%]:Running loss: 0.21754075586795807
[2018-04-17 16:38:58.503883]: [Epoch: 410(27.351567711807874%): Data: 25.333333333333336%]:Running loss: 4.350817188620567
[2018-04-17 16:38:59.777269]: [Epoch: 410(27.351567711807874%): Data: 50.66666666666667%]:Running loss: 8.484092056751251
[2018-04-17 16:39:03.219923]: Test set accuracy: 94.33962264150944% ,loss = 5.438505113124847
[2018-04-17 16:39:03.324200]: ====================
[2018-04-17 16:39:03.329715]: Elapsed time since starting training: 0:43:48.725914
[2018-04-17 16:39:03.335229]: ====================
[2018-04-17 16:39:03.400402]: [Epoch: 411(27.418278852568378%): Data: 0.0%]:Running loss: 0.2175402045249939
[2018-04-17 16:39:04.640204]: [Epoch: 411(27.418278852568378%): Data: 25.333333333333336%]:Running loss: 4.350808754563332
[2018-04-17 16:39:05.924118]: [Epoch: 411(27.418278852568378%): Data: 50.66666666666667%]:Running loss: 8.484075427055359
[2018-04-17 16:39:09.336692]: Test set accuracy: 94.33962264150944% ,loss = 5.438502877950668
[2018-04-17 16:39:09.440477]: ====================
[2018-04-17 16:39:09.445983]: Elapsed time since starting training: 0:43:54.841680
[2018-04-17 16:39:09.451497]: ====================
[2018-04-17 16:39:09.525193]: [Epoch: 412(27.484989993328885%): Data: 0.0%]:Running loss: 0.21754011511802673
[2018-04-17 16:39:10.804093]: [Epoch: 412(27.484989993328885%): Data: 25.333333333333336%]:Running loss: 4.3508012890815735
[2018-04-17 16:39:12.053917]: [Epoch: 412(27.484989993328885%): Data: 50.66666666666667%]:Running loss: 8.484060287475586
[2018-04-17 16:39:15.485542]: Test set accuracy: 94.33962264150944% ,loss = 5.438490211963654
[2018-04-17 16:39:15.592828]: ====================
[2018-04-17 16:39:15.598341]: Elapsed time since starting training: 0:44:00.994540
[2018-04-17 16:39:15.603857]: ====================
[2018-04-17 16:39:15.669531]: [Epoch: 413(27.55170113408939%): Data: 0.0%]:Running loss: 0.21753960847854614
[2018-04-17 16:39:16.949935]: [Epoch: 413(27.55170113408939%): Data: 25.333333333333336%]:Running loss: 4.350792929530144
[2018-04-17 16:39:18.231844]: [Epoch: 413(27.55170113408939%): Data: 50.66666666666667%]:Running loss: 8.4840447306633
[2018-04-17 16:39:21.704076]: Test set accuracy: 94.33962264150944% ,loss = 5.438484251499176
[2018-04-17 16:39:21.807853]: ====================
[2018-04-17 16:39:21.814370]: Elapsed time since starting training: 0:44:07.210569
[2018-04-17 16:39:21.820386]: ====================
[2018-04-17 16:39:21.894583]: [Epoch: 414(27.618412274849902%): Data: 0.0%]:Running loss: 0.21753937005996704
[2018-04-17 16:39:23.153932]: [Epoch: 414(27.618412274849902%): Data: 25.333333333333336%]:Running loss: 4.3507858365774155
[2018-04-17 16:39:24.415787]: [Epoch: 414(27.618412274849902%): Data: 50.66666666666667%]:Running loss: 8.484029665589333
[2018-04-17 16:39:27.841395]: Test set accuracy: 94.33962264150944% ,loss = 5.438466742634773
[2018-04-17 16:39:27.948179]: ====================
[2018-04-17 16:39:27.955198]: Elapsed time since starting training: 0:44:13.351397
[2018-04-17 16:39:27.960713]: ====================
[2018-04-17 16:39:28.031902]: [Epoch: 415(27.68512341561041%): Data: 0.0%]:Running loss: 0.21753866970539093
[2018-04-17 16:39:29.291251]: [Epoch: 415(27.68512341561041%): Data: 25.333333333333336%]:Running loss: 4.3507771492004395
[2018-04-17 16:39:30.522525]: [Epoch: 415(27.68512341561041%): Data: 50.66666666666667%]:Running loss: 8.48401452600956
[2018-04-17 16:39:33.938608]: Test set accuracy: 94.33962264150944% ,loss = 5.438468232750893
[2018-04-17 16:39:34.041883]: ====================
[2018-04-17 16:39:34.047397]: Elapsed time since starting training: 0:44:19.443095
[2018-04-17 16:39:34.052411]: ====================
[2018-04-17 16:39:34.124603]: [Epoch: 416(27.751834556370913%): Data: 0.0%]:Running loss: 0.2175387293100357
[2018-04-17 16:39:35.390469]: [Epoch: 416(27.751834556370913%): Data: 25.333333333333336%]:Running loss: 4.350771874189377
[2018-04-17 16:39:36.628260]: [Epoch: 416(27.751834556370913%): Data: 50.66666666666667%]:Running loss: 8.484002634882927
[2018-04-17 16:39:40.062892]: Test set accuracy: 94.33962264150944% ,loss = 5.438457429409027
[2018-04-17 16:39:40.170679]: ====================
[2018-04-17 16:39:40.176194]: Elapsed time since starting training: 0:44:25.572393
[2018-04-17 16:39:40.181709]: ====================
[2018-04-17 16:39:40.252396]: [Epoch: 417(27.81854569713142%): Data: 0.0%]:Running loss: 0.21753829717636108
[2018-04-17 16:39:41.497207]: [Epoch: 417(27.81854569713142%): Data: 25.333333333333336%]:Running loss: 4.350763902068138
[2018-04-17 16:39:42.742518]: [Epoch: 417(27.81854569713142%): Data: 50.66666666666667%]:Running loss: 8.48398831486702
[2018-04-17 16:39:46.199711]: Test set accuracy: 94.33962264150944% ,loss = 5.438446253538132
[2018-04-17 16:39:46.303988]: ====================
[2018-04-17 16:39:46.309503]: Elapsed time since starting training: 0:44:31.705702
[2018-04-17 16:39:46.316521]: ====================
[2018-04-17 16:39:46.383699]: [Epoch: 418(27.885256837891927%): Data: 0.0%]:Running loss: 0.21753785014152527
[2018-04-17 16:39:47.616979]: [Epoch: 418(27.885256837891927%): Data: 25.333333333333336%]:Running loss: 4.35075731575489
[2018-04-17 16:39:48.904903]: [Epoch: 418(27.885256837891927%): Data: 50.66666666666667%]:Running loss: 8.48397396504879
[2018-04-17 16:39:52.316475]: Test set accuracy: 94.33962264150944% ,loss = 5.438435450196266
[2018-04-17 16:39:52.423761]: ====================
[2018-04-17 16:39:52.429776]: Elapsed time since starting training: 0:44:37.825975
[2018-04-17 16:39:52.435291]: ====================
[2018-04-17 16:39:52.499963]: [Epoch: 419(27.951967978652437%): Data: 0.0%]:Running loss: 0.21753741800785065
[2018-04-17 16:39:53.776863]: [Epoch: 419(27.951967978652437%): Data: 25.333333333333336%]:Running loss: 4.350749775767326
[2018-04-17 16:39:55.026180]: [Epoch: 419(27.951967978652437%): Data: 50.66666666666667%]:Running loss: 8.483961150050163
[2018-04-17 16:39:58.477858]: Test set accuracy: 94.33962264150944% ,loss = 5.438433215022087
[2018-04-17 16:39:58.577624]: ====================
[2018-04-17 16:39:58.583639]: Elapsed time since starting training: 0:44:43.979838
[2018-04-17 16:39:58.588653]: ====================
[2018-04-17 16:39:58.662348]: [Epoch: 420(28.018679119412944%): Data: 0.0%]:Running loss: 0.21753732860088348
[2018-04-17 16:39:59.931724]: [Epoch: 420(28.018679119412944%): Data: 25.333333333333336%]:Running loss: 4.350743904709816
[2018-04-17 16:40:01.176533]: [Epoch: 420(28.018679119412944%): Data: 50.66666666666667%]:Running loss: 8.483949169516563
[2018-04-17 16:40:04.655283]: Test set accuracy: 94.33962264150944% ,loss = 5.438421666622162
[2018-04-17 16:40:04.764073]: ====================
[2018-04-17 16:40:04.769087]: Elapsed time since starting training: 0:44:50.165286
[2018-04-17 16:40:04.774601]: ====================
[2018-04-17 16:40:04.847795]: [Epoch: 421(28.085390260173448%): Data: 0.0%]:Running loss: 0.21753686666488647
[2018-04-17 16:40:06.128701]: [Epoch: 421(28.085390260173448%): Data: 25.333333333333336%]:Running loss: 4.35073658823967
[2018-04-17 16:40:07.405095]: [Epoch: 421(28.085390260173448%): Data: 50.66666666666667%]:Running loss: 8.483934864401817
[2018-04-17 16:40:10.887855]: Test set accuracy: 94.33962264150944% ,loss = 5.438410118222237
[2018-04-17 16:40:10.989627]: ====================
[2018-04-17 16:40:10.995142]: Elapsed time since starting training: 0:44:56.391341
[2018-04-17 16:40:11.000656]: ====================
[2018-04-17 16:40:11.077861]: [Epoch: 422(28.152101400933955%): Data: 0.0%]:Running loss: 0.21753640472888947
[2018-04-17 16:40:12.338715]: [Epoch: 422(28.152101400933955%): Data: 25.333333333333336%]:Running loss: 4.350730091333389
[2018-04-17 16:40:13.600569]: [Epoch: 422(28.152101400933955%): Data: 50.66666666666667%]:Running loss: 8.483921840786934
[2018-04-17 16:40:17.043223]: Test set accuracy: 94.33962264150944% ,loss = 5.4384104907512665
[2018-04-17 16:40:17.147500]: ====================
[2018-04-17 16:40:17.153024]: Elapsed time since starting training: 0:45:02.549223
[2018-04-17 16:40:17.158028]: ====================
[2018-04-17 16:40:17.224204]: [Epoch: 423(28.218812541694465%): Data: 0.0%]:Running loss: 0.21753641963005066
[2018-04-17 16:40:18.493079]: [Epoch: 423(28.218812541694465%): Data: 25.333333333333336%]:Running loss: 4.350723430514336
[2018-04-17 16:40:19.725355]: [Epoch: 423(28.218812541694465%): Data: 50.66666666666667%]:Running loss: 8.483909100294113
[2018-04-17 16:40:23.173022]: Test set accuracy: 94.33962264150944% ,loss = 5.438397824764252
[2018-04-17 16:40:23.273289]: ====================
[2018-04-17 16:40:23.279305]: Elapsed time since starting training: 0:45:08.675002
[2018-04-17 16:40:23.284318]: ====================
[2018-04-17 16:40:23.351998]: [Epoch: 424(28.285523682454972%): Data: 0.0%]:Running loss: 0.21753591299057007
[2018-04-17 16:40:24.618365]: [Epoch: 424(28.285523682454972%): Data: 25.333333333333336%]:Running loss: 4.350717052817345
[2018-04-17 16:40:25.891751]: [Epoch: 424(28.285523682454972%): Data: 50.66666666666667%]:Running loss: 8.483896717429161
[2018-04-17 16:40:29.305328]: Test set accuracy: 94.33962264150944% ,loss = 5.438388884067535
[2018-04-17 16:40:29.417125]: ====================
[2018-04-17 16:40:29.426149]: Elapsed time since starting training: 0:45:14.821847
[2018-04-17 16:40:29.431162]: ====================
[2018-04-17 16:40:29.505861]: [Epoch: 425(28.35223482321548%): Data: 0.0%]:Running loss: 0.21753555536270142
[2018-04-17 16:40:30.774735]: [Epoch: 425(28.35223482321548%): Data: 25.333333333333336%]:Running loss: 4.350710347294807
[2018-04-17 16:40:32.014031]: [Epoch: 425(28.35223482321548%): Data: 50.66666666666667%]:Running loss: 8.483884036540985
[2018-04-17 16:40:35.468215]: Test set accuracy: 94.33962264150944% ,loss = 5.438382551074028
[2018-04-17 16:40:35.573495]: ====================
[2018-04-17 16:40:35.579010]: Elapsed time since starting training: 0:45:20.975209
[2018-04-17 16:40:35.585026]: ====================
[2018-04-17 16:40:35.661730]: [Epoch: 426(28.418945963975982%): Data: 0.0%]:Running loss: 0.21753530204296112
[2018-04-17 16:40:36.926592]: [Epoch: 426(28.418945963975982%): Data: 25.333333333333336%]:Running loss: 4.350704982876778
[2018-04-17 16:40:38.202986]: [Epoch: 426(28.418945963975982%): Data: 50.66666666666667%]:Running loss: 8.483873799443245
[2018-04-17 16:40:41.615059]: Test set accuracy: 94.33962264150944% ,loss = 5.4383739829063416
[2018-04-17 16:40:41.718836]: ====================
[2018-04-17 16:40:41.725854]: Elapsed time since starting training: 0:45:27.121551
[2018-04-17 16:40:41.730867]: ====================
[2018-04-17 16:40:41.798046]: [Epoch: 427(28.48565710473649%): Data: 0.0%]:Running loss: 0.21753495931625366
[2018-04-17 16:40:43.046365]: [Epoch: 427(28.48565710473649%): Data: 25.333333333333336%]:Running loss: 4.350699156522751
[2018-04-17 16:40:44.305212]: [Epoch: 427(28.48565710473649%): Data: 50.66666666666667%]:Running loss: 8.483861550688744
[2018-04-17 16:40:47.731823]: Test set accuracy: 94.33962264150944% ,loss = 5.438365042209625
[2018-04-17 16:40:47.838106]: ====================
[2018-04-17 16:40:47.843621]: Elapsed time since starting training: 0:45:33.239820
[2018-04-17 16:40:47.848634]: ====================
[2018-04-17 16:40:47.924335]: [Epoch: 428(28.552368245497%): Data: 0.0%]:Running loss: 0.217534601688385
[2018-04-17 16:40:49.185689]: [Epoch: 428(28.552368245497%): Data: 25.333333333333336%]:Running loss: 4.350693047046661
[2018-04-17 16:40:50.479630]: [Epoch: 428(28.552368245497%): Data: 50.66666666666667%]:Running loss: 8.483850002288818
[2018-04-17 16:40:53.938828]: Test set accuracy: 94.33962264150944% ,loss = 5.438358336687088
[2018-04-17 16:40:54.047618]: ====================
[2018-04-17 16:40:54.053633]: Elapsed time since starting training: 0:45:39.449832
[2018-04-17 16:40:54.059148]: ====================
[2018-04-17 16:40:54.136353]: [Epoch: 429(28.619079386257507%): Data: 0.0%]:Running loss: 0.21753433346748352
[2018-04-17 16:40:55.416758]: [Epoch: 429(28.619079386257507%): Data: 25.333333333333336%]:Running loss: 4.350687801837921
[2018-04-17 16:40:56.695157]: [Epoch: 429(28.619079386257507%): Data: 50.66666666666667%]:Running loss: 8.483839184045792
[2018-04-17 16:41:00.169395]: Test set accuracy: 94.33962264150944% ,loss = 5.438350141048431
[2018-04-17 16:41:00.368424]: ====================
[2018-04-17 16:41:00.374942]: Elapsed time since starting training: 0:45:45.771141
[2018-04-17 16:41:00.380456]: ====================
[2018-04-17 16:41:00.449139]: [Epoch: 430(28.685790527018014%): Data: 0.0%]:Running loss: 0.21753400564193726
[2018-04-17 16:41:01.688936]: [Epoch: 430(28.685790527018014%): Data: 25.333333333333336%]:Running loss: 4.3506816029548645
[2018-04-17 16:41:02.961820]: [Epoch: 430(28.685790527018014%): Data: 50.66666666666667%]:Running loss: 8.483828336000443
[2018-04-17 16:41:06.421519]: Test set accuracy: 94.33962264150944% ,loss = 5.438341200351715
[2018-04-17 16:41:06.525296]: ====================
[2018-04-17 16:41:06.530818]: Elapsed time since starting training: 0:45:51.927017
[2018-04-17 16:41:06.536826]: ====================
[2018-04-17 16:41:06.605007]: [Epoch: 431(28.752501667778517%): Data: 0.0%]:Running loss: 0.2175336480140686
[2018-04-17 16:41:07.857838]: [Epoch: 431(28.752501667778517%): Data: 25.333333333333336%]:Running loss: 4.350676164031029
[2018-04-17 16:41:09.133230]: [Epoch: 431(28.752501667778517%): Data: 50.66666666666667%]:Running loss: 8.483818173408508
[2018-04-17 16:41:12.570878]: Test set accuracy: 94.33962264150944% ,loss = 5.438343808054924
[2018-04-17 16:41:12.676161]: ====================
[2018-04-17 16:41:12.681679]: Elapsed time since starting training: 0:45:58.077878
[2018-04-17 16:41:12.687187]: ====================
[2018-04-17 16:41:12.760383]: [Epoch: 432(28.819212808539024%): Data: 0.0%]:Running loss: 0.21753375232219696
[2018-04-17 16:41:14.009203]: [Epoch: 432(28.819212808539024%): Data: 25.333333333333336%]:Running loss: 4.35067044198513
[2018-04-17 16:41:15.272061]: [Epoch: 432(28.819212808539024%): Data: 50.66666666666667%]:Running loss: 8.48380608856678
[2018-04-17 16:41:18.706193]: Test set accuracy: 94.33962264150944% ,loss = 5.438336730003357
[2018-04-17 16:41:18.811473]: ====================
[2018-04-17 16:41:18.816988]: Elapsed time since starting training: 0:46:04.212685
[2018-04-17 16:41:18.822502]: ====================
[2018-04-17 16:41:18.890182]: [Epoch: 433(28.885923949299535%): Data: 0.0%]:Running loss: 0.21753346920013428
[2018-04-17 16:41:20.124475]: [Epoch: 433(28.885923949299535%): Data: 25.333333333333336%]:Running loss: 4.350665867328644
[2018-04-17 16:41:21.365275]: [Epoch: 433(28.885923949299535%): Data: 50.66666666666667%]:Running loss: 8.483795776963234
[2018-04-17 16:41:24.813432]: Test set accuracy: 94.33962264150944% ,loss = 5.4383255541324615
[2018-04-17 16:41:24.915704]: ====================
[2018-04-17 16:41:24.921218]: Elapsed time since starting training: 0:46:10.316916
[2018-04-17 16:41:24.926733]: ====================
[2018-04-17 16:41:24.999927]: [Epoch: 434(28.952635090060042%): Data: 0.0%]:Running loss: 0.21753302216529846
[2018-04-17 16:41:26.244743]: [Epoch: 434(28.952635090060042%): Data: 25.333333333333336%]:Running loss: 4.350659638643265
[2018-04-17 16:41:27.491558]: [Epoch: 434(28.952635090060042%): Data: 50.66666666666667%]:Running loss: 8.483785793185234
[2018-04-17 16:41:30.931204]: Test set accuracy: 94.33962264150944% ,loss = 5.438322573900223
[2018-04-17 16:41:31.039995]: ====================
[2018-04-17 16:41:31.046009]: Elapsed time since starting training: 0:46:16.442208
[2018-04-17 16:41:31.051524]: ====================
[2018-04-17 16:41:31.121711]: [Epoch: 435(29.01934623082055%): Data: 0.0%]:Running loss: 0.2175329029560089
[2018-04-17 16:41:32.397101]: [Epoch: 435(29.01934623082055%): Data: 25.333333333333336%]:Running loss: 4.350655138492584
[2018-04-17 16:41:33.687031]: [Epoch: 435(29.01934623082055%): Data: 50.66666666666667%]:Running loss: 8.48377639055252
[2018-04-17 16:41:37.125184]: Test set accuracy: 94.33962264150944% ,loss = 5.438319221138954
[2018-04-17 16:41:37.227446]: ====================
[2018-04-17 16:41:37.234465]: Elapsed time since starting training: 0:46:22.630664
[2018-04-17 16:41:37.239478]: ====================
[2018-04-17 16:41:37.313173]: [Epoch: 436(29.086057371581052%): Data: 0.0%]:Running loss: 0.21753276884555817
[2018-04-17 16:41:38.544948]: [Epoch: 436(29.086057371581052%): Data: 25.333333333333336%]:Running loss: 4.350650265812874
[2018-04-17 16:41:39.779732]: [Epoch: 436(29.086057371581052%): Data: 50.66666666666667%]:Running loss: 8.483766630291939
[2018-04-17 16:41:43.169244]: Test set accuracy: 94.33962264150944% ,loss = 5.438302457332611
[2018-04-17 16:41:43.276029]: ====================
[2018-04-17 16:41:43.283048]: Elapsed time since starting training: 0:46:28.678745
[2018-04-17 16:41:43.288562]: ====================
[2018-04-17 16:41:43.360253]: [Epoch: 437(29.15276851234156%): Data: 0.0%]:Running loss: 0.21753209829330444
[2018-04-17 16:41:44.623612]: [Epoch: 437(29.15276851234156%): Data: 25.333333333333336%]:Running loss: 4.350644797086716
[2018-04-17 16:41:45.856891]: [Epoch: 437(29.15276851234156%): Data: 50.66666666666667%]:Running loss: 8.483756616711617
[2018-04-17 16:41:49.263950]: Test set accuracy: 94.33962264150944% ,loss = 5.438297614455223
[2018-04-17 16:41:49.368729]: ====================
[2018-04-17 16:41:49.374243]: Elapsed time since starting training: 0:46:34.770442
[2018-04-17 16:41:49.379257]: ====================
[2018-04-17 16:41:49.444431]: [Epoch: 438(29.21947965310207%): Data: 0.0%]:Running loss: 0.21753190457820892
[2018-04-17 16:41:50.698264]: [Epoch: 438(29.21947965310207%): Data: 25.333333333333336%]:Running loss: 4.350639820098877
[2018-04-17 16:41:51.961624]: [Epoch: 438(29.21947965310207%): Data: 50.66666666666667%]:Running loss: 8.483746990561485
[2018-04-17 16:41:55.379211]: Test set accuracy: 94.33962264150944% ,loss = 5.438292399048805
[2018-04-17 16:41:55.485496]: ====================
[2018-04-17 16:41:55.491510]: Elapsed time since starting training: 0:46:40.887709
[2018-04-17 16:41:55.497024]: ====================
[2018-04-17 16:41:55.566208]: [Epoch: 439(29.286190793862577%): Data: 0.0%]:Running loss: 0.2175316959619522
[2018-04-17 16:41:56.836586]: [Epoch: 439(29.286190793862577%): Data: 25.333333333333336%]:Running loss: 4.350635200738907
[2018-04-17 16:41:58.099444]: [Epoch: 439(29.286190793862577%): Data: 50.66666666666667%]:Running loss: 8.483737021684647
[2018-04-17 16:42:01.511517]: Test set accuracy: 94.33962264150944% ,loss = 5.438286438584328
[2018-04-17 16:42:01.618301]: ====================
[2018-04-17 16:42:01.623815]: Elapsed time since starting training: 0:46:47.019513
[2018-04-17 16:42:01.629330]: ====================
[2018-04-17 16:42:01.704028]: [Epoch: 440(29.352901934623084%): Data: 0.0%]:Running loss: 0.2175314575433731
[2018-04-17 16:42:02.963878]: [Epoch: 440(29.352901934623084%): Data: 25.333333333333336%]:Running loss: 4.35063099861145
[2018-04-17 16:42:04.256315]: [Epoch: 440(29.352901934623084%): Data: 50.66666666666667%]:Running loss: 8.483728855848312
[2018-04-17 16:42:07.695961]: Test set accuracy: 94.33962264150944% ,loss = 5.43828085064888
[2018-04-17 16:42:07.801241]: ====================
[2018-04-17 16:42:07.806755]: Elapsed time since starting training: 0:46:53.202954
[2018-04-17 16:42:07.813774]: ====================
[2018-04-17 16:42:07.885966]: [Epoch: 441(29.419613075383587%): Data: 0.0%]:Running loss: 0.2175312340259552
[2018-04-17 16:42:09.138797]: [Epoch: 441(29.419613075383587%): Data: 25.333333333333336%]:Running loss: 4.3506264090538025
[2018-04-17 16:42:10.417197]: [Epoch: 441(29.419613075383587%): Data: 50.66666666666667%]:Running loss: 8.483720257878304
[2018-04-17 16:42:13.879910]: Test set accuracy: 94.33962264150944% ,loss = 5.438274145126343
[2018-04-17 16:42:13.978172]: ====================
[2018-04-17 16:42:13.984689]: Elapsed time since starting training: 0:46:59.380888
[2018-04-17 16:42:13.990204]: ====================
[2018-04-17 16:42:14.061393]: [Epoch: 442(29.486324216144094%): Data: 0.0%]:Running loss: 0.2175309658050537
[2018-04-17 16:42:15.351322]: [Epoch: 442(29.486324216144094%): Data: 25.333333333333336%]:Running loss: 4.3506209552288055
[2018-04-17 16:42:16.627717]: [Epoch: 442(29.486324216144094%): Data: 50.66666666666667%]:Running loss: 8.483709827065468
[2018-04-17 16:42:20.077891]: Test set accuracy: 94.33962264150944% ,loss = 5.438267812132835
[2018-04-17 16:42:20.187181]: ====================
[2018-04-17 16:42:20.192696]: Elapsed time since starting training: 0:47:05.588895
[2018-04-17 16:42:20.198211]: ====================
[2018-04-17 16:42:20.271405]: [Epoch: 443(29.553035356904605%): Data: 0.0%]:Running loss: 0.21753071248531342
[2018-04-17 16:42:21.523234]: [Epoch: 443(29.553035356904605%): Data: 25.333333333333336%]:Running loss: 4.350616708397865
[2018-04-17 16:42:22.770049]: [Epoch: 443(29.553035356904605%): Data: 50.66666666666667%]:Running loss: 8.483701407909393
[2018-04-17 16:42:26.174601]: Test set accuracy: 94.33962264150944% ,loss = 5.438262224197388
[2018-04-17 16:42:26.279882]: ====================
[2018-04-17 16:42:26.285396]: Elapsed time since starting training: 0:47:11.681595
[2018-04-17 16:42:26.290410]: ====================
[2018-04-17 16:42:26.359092]: [Epoch: 444(29.619746497665112%): Data: 0.0%]:Running loss: 0.2175304889678955
[2018-04-17 16:42:27.602900]: [Epoch: 444(29.619746497665112%): Data: 25.333333333333336%]:Running loss: 4.350612103939056
[2018-04-17 16:42:28.876787]: [Epoch: 444(29.619746497665112%): Data: 50.66666666666667%]:Running loss: 8.483692914247513
[2018-04-17 16:42:32.343504]: Test set accuracy: 94.33962264150944% ,loss = 5.438267812132835
[2018-04-17 16:42:32.448785]: ====================
[2018-04-17 16:42:32.454801]: Elapsed time since starting training: 0:47:17.850498
[2018-04-17 16:42:32.460316]: ====================
[2018-04-17 16:42:32.527004]: [Epoch: 445(29.68645763842562%): Data: 0.0%]:Running loss: 0.21753071248531342
[2018-04-17 16:42:33.807898]: [Epoch: 445(29.68645763842562%): Data: 25.333333333333336%]:Running loss: 4.350608095526695
[2018-04-17 16:42:35.062735]: [Epoch: 445(29.68645763842562%): Data: 50.66666666666667%]:Running loss: 8.48368427157402
[2018-04-17 16:42:38.520429]: Test set accuracy: 94.33962264150944% ,loss = 5.438254401087761
[2018-04-17 16:42:38.625709]: ====================
[2018-04-17 16:42:38.631223]: Elapsed time since starting training: 0:47:24.027422
[2018-04-17 16:42:38.636739]: ====================
[2018-04-17 16:42:38.700407]: [Epoch: 446(29.753168779186122%): Data: 0.0%]:Running loss: 0.21753017604351044
[2018-04-17 16:42:39.963767]: [Epoch: 446(29.753168779186122%): Data: 25.333333333333336%]:Running loss: 4.350604340434074
[2018-04-17 16:42:41.201558]: [Epoch: 446(29.753168779186122%): Data: 50.66666666666667%]:Running loss: 8.483676716685295
[2018-04-17 16:42:44.611124]: Test set accuracy: 94.33962264150944% ,loss = 5.438251048326492
[2018-04-17 16:42:44.716906]: ====================
[2018-04-17 16:42:44.722420]: Elapsed time since starting training: 0:47:30.118619
[2018-04-17 16:42:44.727433]: ====================
[2018-04-17 16:42:44.800628]: [Epoch: 447(29.81987991994663%): Data: 0.0%]:Running loss: 0.2175300419330597
[2018-04-17 16:42:46.043433]: [Epoch: 447(29.81987991994663%): Data: 25.333333333333336%]:Running loss: 4.350600451231003
[2018-04-17 16:42:47.296765]: [Epoch: 447(29.81987991994663%): Data: 50.66666666666667%]:Running loss: 8.483670338988304
[2018-04-17 16:42:50.757467]: Test set accuracy: 94.33962264150944% ,loss = 5.438249558210373
[2018-04-17 16:42:50.863249]: ====================
[2018-04-17 16:42:50.868262]: Elapsed time since starting training: 0:47:36.264461
[2018-04-17 16:42:50.873777]: ====================
[2018-04-17 16:42:50.947974]: [Epoch: 448(29.88659106070714%): Data: 0.0%]:Running loss: 0.21752998232841492
[2018-04-17 16:42:52.208826]: [Epoch: 448(29.88659106070714%): Data: 25.333333333333336%]:Running loss: 4.350596025586128
[2018-04-17 16:42:53.470180]: [Epoch: 448(29.88659106070714%): Data: 50.66666666666667%]:Running loss: 8.483661577105522
[2018-04-17 16:42:56.927373]: Test set accuracy: 94.33962264150944% ,loss = 5.438236519694328
[2018-04-17 16:42:57.033669]: ====================
[2018-04-17 16:42:57.039672]: Elapsed time since starting training: 0:47:42.435871
[2018-04-17 16:42:57.045186]: ====================
[2018-04-17 16:42:57.109858]: [Epoch: 449(29.953302201467647%): Data: 0.0%]:Running loss: 0.21752946078777313
[2018-04-17 16:42:58.365196]: [Epoch: 449(29.953302201467647%): Data: 25.333333333333336%]:Running loss: 4.350590825080872
[2018-04-17 16:42:59.633068]: [Epoch: 449(29.953302201467647%): Data: 50.66666666666667%]:Running loss: 8.483651593327522
[2018-04-17 16:43:03.127860]: Test set accuracy: 94.33962264150944% ,loss = 5.43823279440403
[2018-04-17 16:43:03.236148]: ====================
[2018-04-17 16:43:03.242164]: Elapsed time since starting training: 0:47:48.638363
[2018-04-17 16:43:03.247679]: ====================
[2018-04-17 16:43:03.322377]: [Epoch: 450(30.020013342228154%): Data: 0.0%]:Running loss: 0.2175293117761612
[2018-04-17 16:43:04.593256]: [Epoch: 450(30.020013342228154%): Data: 25.333333333333336%]:Running loss: 4.3505885154008865
[2018-04-17 16:43:05.843080]: [Epoch: 450(30.020013342228154%): Data: 50.66666666666667%]:Running loss: 8.483646482229233
[2018-04-17 16:43:09.315312]: Test set accuracy: 94.33962264150944% ,loss = 5.43823316693306
[2018-04-17 16:43:09.421093]: ====================
[2018-04-17 16:43:09.426608]: Elapsed time since starting training: 0:47:54.822807
[2018-04-17 16:43:09.432624]: ====================
[2018-04-17 16:43:09.506320]: [Epoch: 451(30.086724482988657%): Data: 0.0%]:Running loss: 0.2175293266773224
[2018-04-17 16:43:10.761157]: [Epoch: 451(30.086724482988657%): Data: 25.333333333333336%]:Running loss: 4.350583985447884
[2018-04-17 16:43:12.023525]: [Epoch: 451(30.086724482988657%): Data: 50.66666666666667%]:Running loss: 8.483638003468513
[2018-04-17 16:43:15.476695]: Test set accuracy: 94.33962264150944% ,loss = 5.438229441642761
[2018-04-17 16:43:15.578967]: ====================
[2018-04-17 16:43:15.584482]: Elapsed time since starting training: 0:48:00.980681
[2018-04-17 16:43:15.589495]: ====================
[2018-04-17 16:43:15.655672]: [Epoch: 452(30.153435623749164%): Data: 0.0%]:Running loss: 0.21752917766571045
[2018-04-17 16:43:16.900983]: [Epoch: 452(30.153435623749164%): Data: 25.333333333333336%]:Running loss: 4.350580587983131
[2018-04-17 16:43:18.172363]: [Epoch: 452(30.153435623749164%): Data: 50.66666666666667%]:Running loss: 8.483630299568176
[2018-04-17 16:43:21.618526]: Test set accuracy: 94.33962264150944% ,loss = 5.438214913010597
[2018-04-17 16:43:21.722303]: ====================
[2018-04-17 16:43:21.727817]: Elapsed time since starting training: 0:48:07.123515
[2018-04-17 16:43:21.733332]: ====================
[2018-04-17 16:43:21.802516]: [Epoch: 453(30.220146764509675%): Data: 0.0%]:Running loss: 0.2175285965204239
[2018-04-17 16:43:23.084931]: [Epoch: 453(30.220146764509675%): Data: 25.333333333333336%]:Running loss: 4.350576296448708
[2018-04-17 16:43:24.379869]: [Epoch: 453(30.220146764509675%): Data: 50.66666666666667%]:Running loss: 8.483623206615448
[2018-04-17 16:43:27.849093]: Test set accuracy: 94.33962264150944% ,loss = 5.438214540481567
[2018-04-17 16:43:27.956379]: ====================
[2018-04-17 16:43:27.962395]: Elapsed time since starting training: 0:48:13.358594
[2018-04-17 16:43:27.967910]: ====================
[2018-04-17 16:43:28.044112]: [Epoch: 454(30.286857905270182%): Data: 0.0%]:Running loss: 0.2175285816192627
[2018-04-17 16:43:29.320506]: [Epoch: 454(30.286857905270182%): Data: 25.333333333333336%]:Running loss: 4.350572407245636
[2018-04-17 16:43:30.573839]: [Epoch: 454(30.286857905270182%): Data: 50.66666666666667%]:Running loss: 8.483615025877953
[2018-04-17 16:43:34.065623]: Test set accuracy: 94.33962264150944% ,loss = 5.438210442662239
[2018-04-17 16:43:34.168898]: ====================
[2018-04-17 16:43:34.174413]: Elapsed time since starting training: 0:48:19.570612
[2018-04-17 16:43:34.179927]: ====================
[2018-04-17 16:43:34.252119]: [Epoch: 455(30.35356904603069%): Data: 0.0%]:Running loss: 0.21752841770648956
[2018-04-17 16:43:35.516485]: [Epoch: 455(30.35356904603069%): Data: 25.333333333333336%]:Running loss: 4.350569114089012
[2018-04-17 16:43:36.779845]: [Epoch: 455(30.35356904603069%): Data: 50.66666666666667%]:Running loss: 8.483608573675156
[2018-04-17 16:43:40.201442]: Test set accuracy: 94.33962264150944% ,loss = 5.4382070899009705
[2018-04-17 16:43:40.308226]: ====================
[2018-04-17 16:43:40.313239]: Elapsed time since starting training: 0:48:25.709438
[2018-04-17 16:43:40.318755]: ====================
[2018-04-17 16:43:40.380421]: [Epoch: 456(30.420280186791192%): Data: 0.0%]:Running loss: 0.21752828359603882
[2018-04-17 16:43:41.649292]: [Epoch: 456(30.420280186791192%): Data: 25.333333333333336%]:Running loss: 4.350565791130066
[2018-04-17 16:43:42.896119]: [Epoch: 456(30.420280186791192%): Data: 50.66666666666667%]:Running loss: 8.483602494001389
[2018-04-17 16:43:46.325732]: Test set accuracy: 94.33962264150944% ,loss = 5.438204854726791
[2018-04-17 16:43:46.428507]: ====================
[2018-04-17 16:43:46.435023]: Elapsed time since starting training: 0:48:31.830721
[2018-04-17 16:43:46.440037]: ====================
[2018-04-17 16:43:46.503706]: [Epoch: 457(30.4869913275517%): Data: 0.0%]:Running loss: 0.21752819418907166
[2018-04-17 16:43:47.753529]: [Epoch: 457(30.4869913275517%): Data: 25.333333333333336%]:Running loss: 4.350561663508415
[2018-04-17 16:43:49.057998]: [Epoch: 457(30.4869913275517%): Data: 50.66666666666667%]:Running loss: 8.483594536781311
[2018-04-17 16:43:52.528225]: Test set accuracy: 94.33962264150944% ,loss = 5.438199266791344
[2018-04-17 16:43:52.636513]: ====================
[2018-04-17 16:43:52.642529]: Elapsed time since starting training: 0:48:38.038226
[2018-04-17 16:43:52.647542]: ====================
[2018-04-17 16:43:52.720737]: [Epoch: 458(30.55370246831221%): Data: 0.0%]:Running loss: 0.21752797067165375
[2018-04-17 16:43:53.963542]: [Epoch: 458(30.55370246831221%): Data: 25.333333333333336%]:Running loss: 4.3505584597587585
[2018-04-17 16:43:55.223391]: [Epoch: 458(30.55370246831221%): Data: 50.66666666666667%]:Running loss: 8.483588263392448
[2018-04-17 16:43:58.683592]: Test set accuracy: 94.33962264150944% ,loss = 5.438191443681717
[2018-04-17 16:43:58.790376]: ====================
[2018-04-17 16:43:58.797395]: Elapsed time since starting training: 0:48:44.193594
[2018-04-17 16:43:58.803411]: ====================
[2018-04-17 16:43:58.879112]: [Epoch: 459(30.620413609072717%): Data: 0.0%]:Running loss: 0.21752765774726868
[2018-04-17 16:44:00.151997]: [Epoch: 459(30.620413609072717%): Data: 25.333333333333336%]:Running loss: 4.350555449724197
[2018-04-17 16:44:01.397809]: [Epoch: 459(30.620413609072717%): Data: 50.66666666666667%]:Running loss: 8.483582109212875
[2018-04-17 16:44:04.885081]: Test set accuracy: 94.33962264150944% ,loss = 5.438191071152687
[2018-04-17 16:44:04.987862]: ====================
[2018-04-17 16:44:04.993369]: Elapsed time since starting training: 0:48:50.389568
[2018-04-17 16:44:04.998884]: ====================
[2018-04-17 16:44:05.071076]: [Epoch: 460(30.687124749833224%): Data: 0.0%]:Running loss: 0.21752764284610748
[2018-04-17 16:44:06.351982]: [Epoch: 460(30.687124749833224%): Data: 25.333333333333336%]:Running loss: 4.350552082061768
[2018-04-17 16:44:07.577741]: [Epoch: 460(30.687124749833224%): Data: 50.66666666666667%]:Running loss: 8.48357567191124
[2018-04-17 16:44:11.086571]: Test set accuracy: 94.33962264150944% ,loss = 5.438182502985001
[2018-04-17 16:44:11.192853]: ====================
[2018-04-17 16:44:11.197867]: Elapsed time since starting training: 0:48:56.594066
[2018-04-17 16:44:11.203883]: ====================
[2018-04-17 16:44:11.275574]: [Epoch: 461(30.753835890593727%): Data: 0.0%]:Running loss: 0.21752730011940002
[2018-04-17 16:44:12.513866]: [Epoch: 461(30.753835890593727%): Data: 25.333333333333336%]:Running loss: 4.350549206137657
[2018-04-17 16:44:13.783743]: [Epoch: 461(30.753835890593727%): Data: 50.66666666666667%]:Running loss: 8.483570173382759
[2018-04-17 16:44:17.258482]: Test set accuracy: 94.33962264150944% ,loss = 5.43818324804306
[2018-04-17 16:44:17.362767]: ====================
[2018-04-17 16:44:17.368776]: Elapsed time since starting training: 0:49:02.764473
[2018-04-17 16:44:17.374290]: ====================
[2018-04-17 16:44:17.448989]: [Epoch: 462(30.820547031354234%): Data: 0.0%]:Running loss: 0.2175273299217224
[2018-04-17 16:44:18.711846]: [Epoch: 462(30.820547031354234%): Data: 25.333333333333336%]:Running loss: 4.350545272231102
[2018-04-17 16:44:19.929084]: [Epoch: 462(30.820547031354234%): Data: 50.66666666666667%]:Running loss: 8.483563601970673
[2018-04-17 16:44:23.089487]: Test set accuracy: 94.33962264150944% ,loss = 5.438185483217239
[2018-04-17 16:44:23.188249]: ====================
[2018-04-17 16:44:23.193263]: Elapsed time since starting training: 0:49:08.589462
[2018-04-17 16:44:23.198778]: ====================
[2018-04-17 16:44:23.260943]: [Epoch: 463(30.887258172114745%): Data: 0.0%]:Running loss: 0.21752741932868958
[2018-04-17 16:44:24.487203]: [Epoch: 463(30.887258172114745%): Data: 25.333333333333336%]:Running loss: 4.350542962551117
[2018-04-17 16:44:25.737528]: [Epoch: 463(30.887258172114745%): Data: 50.66666666666667%]:Running loss: 8.483557909727097
[2018-04-17 16:44:29.182689]: Test set accuracy: 94.33962264150944% ,loss = 5.438175797462463
[2018-04-17 16:44:29.285963]: ====================
[2018-04-17 16:44:29.291478]: Elapsed time since starting training: 0:49:14.687677
[2018-04-17 16:44:29.297494]: ====================
[2018-04-17 16:44:29.372694]: [Epoch: 464(30.95396931287525%): Data: 0.0%]:Running loss: 0.21752703189849854
[2018-04-17 16:44:30.636555]: [Epoch: 464(30.95396931287525%): Data: 25.333333333333336%]:Running loss: 4.3505396246910095
[2018-04-17 16:44:31.909439]: [Epoch: 464(30.95396931287525%): Data: 50.66666666666667%]:Running loss: 8.483552187681198
[2018-04-17 16:44:35.361118]: Test set accuracy: 94.33962264150944% ,loss = 5.438164994120598
[2018-04-17 16:44:35.466397]: ====================
[2018-04-17 16:44:35.473416]: Elapsed time since starting training: 0:49:20.869615
[2018-04-17 16:44:35.478930]: ====================
[2018-04-17 16:44:35.551624]: [Epoch: 465(31.02068045363576%): Data: 0.0%]:Running loss: 0.2175265997648239
[2018-04-17 16:44:36.832028]: [Epoch: 465(31.02068045363576%): Data: 25.333333333333336%]:Running loss: 4.350536346435547
[2018-04-17 16:44:38.088870]: [Epoch: 465(31.02068045363576%): Data: 50.66666666666667%]:Running loss: 8.483545571565628
[2018-04-17 16:44:41.543556]: Test set accuracy: 94.33962264150944% ,loss = 5.438166111707687
[2018-04-17 16:44:41.650842]: ====================
[2018-04-17 16:44:41.656858]: Elapsed time since starting training: 0:49:27.053057
[2018-04-17 16:44:41.662372]: ====================
[2018-04-17 16:44:41.735566]: [Epoch: 466(31.087391594396262%): Data: 0.0%]:Running loss: 0.2175266444683075
[2018-04-17 16:44:42.999929]: [Epoch: 466(31.087391594396262%): Data: 25.333333333333336%]:Running loss: 4.350533679127693
[2018-04-17 16:44:44.257272]: [Epoch: 466(31.087391594396262%): Data: 50.66666666666667%]:Running loss: 8.483539953827858
[2018-04-17 16:44:47.751563]: Test set accuracy: 94.33962264150944% ,loss = 5.438165366649628
[2018-04-17 16:44:47.858849]: ====================
[2018-04-17 16:44:47.864363]: Elapsed time since starting training: 0:49:33.260562
[2018-04-17 16:44:47.869878]: ====================
[2018-04-17 16:44:47.940064]: [Epoch: 467(31.15410273515677%): Data: 0.0%]:Running loss: 0.2175266146659851
[2018-04-17 16:44:49.208437]: [Epoch: 467(31.15410273515677%): Data: 25.333333333333336%]:Running loss: 4.3505309373140335
[2018-04-17 16:44:50.500372]: [Epoch: 467(31.15410273515677%): Data: 50.66666666666667%]:Running loss: 8.483534693717957
[2018-04-17 16:44:53.963581]: Test set accuracy: 94.33962264150944% ,loss = 5.438164621591568
[2018-04-17 16:44:54.062344]: ====================
[2018-04-17 16:44:54.067858]: Elapsed time since starting training: 0:49:39.464057
[2018-04-17 16:44:54.073373]: ====================
[2018-04-17 16:44:54.140050]: [Epoch: 468(31.22081387591728%): Data: 0.0%]:Running loss: 0.21752658486366272
[2018-04-17 16:44:55.409426]: [Epoch: 468(31.22081387591728%): Data: 25.333333333333336%]:Running loss: 4.350528061389923
[2018-04-17 16:44:56.670779]: [Epoch: 468(31.22081387591728%): Data: 50.66666666666667%]:Running loss: 8.483528807759285
[2018-04-17 16:45:00.083855]: Test set accuracy: 94.33962264150944% ,loss = 5.438154190778732
[2018-04-17 16:45:00.191140]: ====================
[2018-04-17 16:45:00.197156]: Elapsed time since starting training: 0:49:45.592854
[2018-04-17 16:45:00.201668]: ====================
[2018-04-17 16:45:00.272857]: [Epoch: 469(31.287525016677787%): Data: 0.0%]:Running loss: 0.2175261676311493
[2018-04-17 16:45:01.560782]: [Epoch: 469(31.287525016677787%): Data: 25.333333333333336%]:Running loss: 4.350525200366974
[2018-04-17 16:45:02.828653]: [Epoch: 469(31.287525016677787%): Data: 50.66666666666667%]:Running loss: 8.483522832393646
[2018-04-17 16:45:06.272310]: Test set accuracy: 94.33962264150944% ,loss = 5.4381538182497025
[2018-04-17 16:45:06.379094]: ====================
[2018-04-17 16:45:06.384608]: Elapsed time since starting training: 0:49:51.780807
[2018-04-17 16:45:06.390123]: ====================
[2018-04-17 16:45:06.463317]: [Epoch: 470(31.354236157438294%): Data: 0.0%]:Running loss: 0.2175261527299881
[2018-04-17 16:45:07.714645]: [Epoch: 470(31.354236157438294%): Data: 25.333333333333336%]:Running loss: 4.350522488355637
[2018-04-17 16:45:08.980511]: [Epoch: 470(31.354236157438294%): Data: 50.66666666666667%]:Running loss: 8.48351775109768
[2018-04-17 16:45:12.427683]: Test set accuracy: 94.33962264150944% ,loss = 5.438151955604553
[2018-04-17 16:45:12.533464]: ====================
[2018-04-17 16:45:12.538980]: Elapsed time since starting training: 0:49:57.935179
[2018-04-17 16:45:12.544995]: ====================
[2018-04-17 16:45:12.614680]: [Epoch: 471(31.420947298198797%): Data: 0.0%]:Running loss: 0.21752607822418213
[2018-04-17 16:45:13.861496]: [Epoch: 471(31.420947298198797%): Data: 25.333333333333336%]:Running loss: 4.35051953792572
[2018-04-17 16:45:15.143405]: [Epoch: 471(31.420947298198797%): Data: 50.66666666666667%]:Running loss: 8.483511880040169
[2018-04-17 16:45:18.554475]: Test set accuracy: 94.33962264150944% ,loss = 5.438145622611046
[2018-04-17 16:45:18.651232]: ====================
[2018-04-17 16:45:18.656245]: Elapsed time since starting training: 0:50:04.052444
[2018-04-17 16:45:18.661259]: ====================
[2018-04-17 16:45:18.723925]: [Epoch: 472(31.487658438959304%): Data: 0.0%]:Running loss: 0.21752582490444183
[2018-04-17 16:45:20.019370]: [Epoch: 472(31.487658438959304%): Data: 25.333333333333336%]:Running loss: 4.350516960024834
[2018-04-17 16:45:21.277715]: [Epoch: 472(31.487658438959304%): Data: 50.66666666666667%]:Running loss: 8.483506932854652
[2018-04-17 16:45:24.697308]: Test set accuracy: 94.33962264150944% ,loss = 5.438147857785225
[2018-04-17 16:45:24.799581]: ====================
[2018-04-17 16:45:24.805095]: Elapsed time since starting training: 0:50:10.200792
[2018-04-17 16:45:24.810109]: ====================
[2018-04-17 16:45:24.886318]: [Epoch: 473(31.554369579719815%): Data: 0.0%]:Running loss: 0.217525914311409
[2018-04-17 16:45:26.130118]: [Epoch: 473(31.554369579719815%): Data: 25.333333333333336%]:Running loss: 4.350513964891434
[2018-04-17 16:45:27.390470]: [Epoch: 473(31.554369579719815%): Data: 50.66666666666667%]:Running loss: 8.48350204527378
[2018-04-17 16:45:30.865710]: Test set accuracy: 94.33962264150944% ,loss = 5.438141152262688
[2018-04-17 16:45:30.970990]: ====================
[2018-04-17 16:45:30.976506]: Elapsed time since starting training: 0:50:16.372203
[2018-04-17 16:45:30.982020]: ====================
[2018-04-17 16:45:31.053710]: [Epoch: 474(31.62108072048032%): Data: 0.0%]:Running loss: 0.2175256460905075
[2018-04-17 16:45:32.305049]: [Epoch: 474(31.62108072048032%): Data: 25.333333333333336%]:Running loss: 4.35051192343235
[2018-04-17 16:45:33.598476]: [Epoch: 474(31.62108072048032%): Data: 50.66666666666667%]:Running loss: 8.483498260378838
[2018-04-17 16:45:37.063690]: Test set accuracy: 94.33962264150944% ,loss = 5.4381344467401505
[2018-04-17 16:45:37.163957]: ====================
[2018-04-17 16:45:37.168971]: Elapsed time since starting training: 0:50:22.565170
[2018-04-17 16:45:37.173984]: ====================
[2018-04-17 16:45:37.244170]: [Epoch: 475(31.68779186124083%): Data: 0.0%]:Running loss: 0.21752537786960602
[2018-04-17 16:45:38.528586]: [Epoch: 475(31.68779186124083%): Data: 25.333333333333336%]:Running loss: 4.350509360432625
[2018-04-17 16:45:39.774398]: [Epoch: 475(31.68779186124083%): Data: 50.66666666666667%]:Running loss: 8.483492776751518
[2018-04-17 16:45:43.166417]: Test set accuracy: 94.33962264150944% ,loss = 5.438137799501419
[2018-04-17 16:45:43.263175]: ====================
[2018-04-17 16:45:43.268690]: Elapsed time since starting training: 0:50:28.664889
[2018-04-17 16:45:43.274204]: ====================
[2018-04-17 16:45:43.343890]: [Epoch: 476(31.754503002001332%): Data: 0.0%]:Running loss: 0.21752551198005676
[2018-04-17 16:45:44.594716]: [Epoch: 476(31.754503002001332%): Data: 25.333333333333336%]:Running loss: 4.350507318973541
[2018-04-17 16:45:45.841029]: [Epoch: 476(31.754503002001332%): Data: 50.66666666666667%]:Running loss: 8.483488410711288
[2018-04-17 16:45:49.267640]: Test set accuracy: 94.33962264150944% ,loss = 5.438129976391792
[2018-04-17 16:45:49.376430]: ====================
[2018-04-17 16:45:49.381945]: Elapsed time since starting training: 0:50:34.778144
[2018-04-17 16:45:49.387460]: ====================
[2018-04-17 16:45:49.459651]: [Epoch: 477(31.82121414276184%): Data: 0.0%]:Running loss: 0.2175251990556717
[2018-04-17 16:45:50.723010]: [Epoch: 477(31.82121414276184%): Data: 25.333333333333336%]:Running loss: 4.350504502654076
[2018-04-17 16:45:51.987373]: [Epoch: 477(31.82121414276184%): Data: 50.66666666666667%]:Running loss: 8.483483612537384
[2018-04-17 16:45:55.431029]: Test set accuracy: 94.33962264150944% ,loss = 5.4381318390369415
[2018-04-17 16:45:55.537312]: ====================
[2018-04-17 16:45:55.542827]: Elapsed time since starting training: 0:50:40.938524
[2018-04-17 16:45:55.547840]: ====================
[2018-04-17 16:45:55.620532]: [Epoch: 478(31.88792528352235%): Data: 0.0%]:Running loss: 0.21752527356147766
[2018-04-17 16:45:56.883391]: [Epoch: 478(31.88792528352235%): Data: 25.333333333333336%]:Running loss: 4.35050305724144
[2018-04-17 16:45:58.142739]: [Epoch: 478(31.88792528352235%): Data: 50.66666666666667%]:Running loss: 8.483479499816895
[2018-04-17 16:46:01.582886]: Test set accuracy: 94.33962264150944% ,loss = 5.438125506043434
[2018-04-17 16:46:01.692679]: ====================
[2018-04-17 16:46:01.698194]: Elapsed time since starting training: 0:50:47.094393
[2018-04-17 16:46:01.704209]: ====================
[2018-04-17 16:46:01.773895]: [Epoch: 479(31.954636424282857%): Data: 0.0%]:Running loss: 0.21752502024173737
[2018-04-17 16:46:03.018203]: [Epoch: 479(31.954636424282857%): Data: 25.333333333333336%]:Running loss: 4.350500017404556
[2018-04-17 16:46:04.293093]: [Epoch: 479(31.954636424282857%): Data: 50.66666666666667%]:Running loss: 8.483474358916283
[2018-04-17 16:46:07.704665]: Test set accuracy: 94.33962264150944% ,loss = 5.438127741217613
[2018-04-17 16:46:07.811449]: ====================
[2018-04-17 16:46:07.816964]: Elapsed time since starting training: 0:50:53.212661
[2018-04-17 16:46:07.821976]: ====================
[2018-04-17 16:46:07.894669]: [Epoch: 480(32.021347565043364%): Data: 0.0%]:Running loss: 0.21752510964870453
[2018-04-17 16:46:09.133965]: [Epoch: 480(32.021347565043364%): Data: 25.333333333333336%]:Running loss: 4.350498095154762
[2018-04-17 16:46:10.384290]: [Epoch: 480(32.021347565043364%): Data: 50.66666666666667%]:Running loss: 8.483470141887665
[2018-04-17 16:46:13.838474]: Test set accuracy: 94.33962264150944% ,loss = 5.438119173049927
[2018-04-17 16:46:14.038506]: ====================
[2018-04-17 16:46:14.045024]: Elapsed time since starting training: 0:50:59.440722
[2018-04-17 16:46:14.050037]: ====================
[2018-04-17 16:46:14.125738]: [Epoch: 481(32.08805870580387%): Data: 0.0%]:Running loss: 0.21752476692199707
[2018-04-17 16:46:15.402633]: [Epoch: 481(32.08805870580387%): Data: 25.333333333333336%]:Running loss: 4.3504958152771
[2018-04-17 16:46:16.702590]: [Epoch: 481(32.08805870580387%): Data: 50.66666666666667%]:Running loss: 8.483466163277626
[2018-04-17 16:46:20.126694]: Test set accuracy: 94.33962264150944% ,loss = 5.43811060488224
[2018-04-17 16:46:20.233479]: ====================
[2018-04-17 16:46:20.239495]: Elapsed time since starting training: 0:51:05.635192
[2018-04-17 16:46:20.244508]: ====================
[2018-04-17 16:46:20.308177]: [Epoch: 482(32.15476984656437%): Data: 0.0%]:Running loss: 0.2175244241952896
[2018-04-17 16:46:21.590587]: [Epoch: 482(32.15476984656437%): Data: 25.333333333333336%]:Running loss: 4.350493207573891
[2018-04-17 16:46:22.839909]: [Epoch: 482(32.15476984656437%): Data: 50.66666666666667%]:Running loss: 8.483461037278175
[2018-04-17 16:46:26.292088]: Test set accuracy: 94.33962264150944% ,loss = 5.438112840056419
[2018-04-17 16:46:26.397869]: ====================
[2018-04-17 16:46:26.403384]: Elapsed time since starting training: 0:51:11.799082
[2018-04-17 16:46:26.408398]: ====================
[2018-04-17 16:46:26.474573]: [Epoch: 483(32.22148098732489%): Data: 0.0%]:Running loss: 0.21752451360225677
[2018-04-17 16:46:27.766007]: [Epoch: 483(32.22148098732489%): Data: 25.333333333333336%]:Running loss: 4.3504912704229355
[2018-04-17 16:46:29.031873]: [Epoch: 483(32.22148098732489%): Data: 50.66666666666667%]:Running loss: 8.48345710337162
[2018-04-17 16:46:32.455978]: Test set accuracy: 94.33962264150944% ,loss = 5.438116192817688
[2018-04-17 16:46:32.567775]: ====================
[2018-04-17 16:46:32.573289]: Elapsed time since starting training: 0:51:17.969488
[2018-04-17 16:46:32.578805]: ====================
[2018-04-17 16:46:32.649994]: [Epoch: 484(32.28819212808539%): Data: 0.0%]:Running loss: 0.21752464771270752
[2018-04-17 16:46:33.912350]: [Epoch: 484(32.28819212808539%): Data: 25.333333333333336%]:Running loss: 4.350488841533661
[2018-04-17 16:46:35.182729]: [Epoch: 484(32.28819212808539%): Data: 50.66666666666667%]:Running loss: 8.483452945947647
[2018-04-17 16:46:38.587782]: Test set accuracy: 94.33962264150944% ,loss = 5.438107997179031
[2018-04-17 16:46:38.698087]: ====================
[2018-04-17 16:46:38.703591]: Elapsed time since starting training: 0:51:24.099288
[2018-04-17 16:46:38.708603]: ====================
[2018-04-17 16:46:38.780795]: [Epoch: 485(32.354903268845895%): Data: 0.0%]:Running loss: 0.21752431988716125
[2018-04-17 16:46:40.020091]: [Epoch: 485(32.354903268845895%): Data: 25.333333333333336%]:Running loss: 4.350486129522324
[2018-04-17 16:46:41.256879]: [Epoch: 485(32.354903268845895%): Data: 50.66666666666667%]:Running loss: 8.48344849050045
[2018-04-17 16:46:44.661933]: Test set accuracy: 94.33962264150944% ,loss = 5.438100174069405
[2018-04-17 16:46:44.767213]: ====================
[2018-04-17 16:46:44.776739]: Elapsed time since starting training: 0:51:30.172938
[2018-04-17 16:46:44.781752]: ====================
[2018-04-17 16:46:44.853944]: [Epoch: 486(32.421614409606406%): Data: 0.0%]:Running loss: 0.21752400696277618
[2018-04-17 16:46:46.099255]: [Epoch: 486(32.421614409606406%): Data: 25.333333333333336%]:Running loss: 4.350483998656273
[2018-04-17 16:46:47.361612]: [Epoch: 486(32.421614409606406%): Data: 50.66666666666667%]:Running loss: 8.483443900942802
[2018-04-17 16:46:50.842869]: Test set accuracy: 94.33962264150944% ,loss = 5.4381005465984344
[2018-04-17 16:46:50.952661]: ====================
[2018-04-17 16:46:50.958176]: Elapsed time since starting training: 0:51:36.354375
[2018-04-17 16:46:50.963691]: ====================
[2018-04-17 16:46:51.035882]: [Epoch: 487(32.48832555036691%): Data: 0.0%]:Running loss: 0.21752402186393738
[2018-04-17 16:46:52.279689]: [Epoch: 487(32.48832555036691%): Data: 25.333333333333336%]:Running loss: 4.35048221051693
[2018-04-17 16:46:53.518984]: [Epoch: 487(32.48832555036691%): Data: 50.66666666666667%]:Running loss: 8.483440458774567
[2018-04-17 16:46:56.980188]: Test set accuracy: 94.33962264150944% ,loss = 5.438099429011345
[2018-04-17 16:46:57.083964]: ====================
[2018-04-17 16:46:57.089980]: Elapsed time since starting training: 0:51:42.485678
[2018-04-17 16:46:57.095495]: ====================
[2018-04-17 16:46:57.171698]: [Epoch: 488(32.55503669112742%): Data: 0.0%]:Running loss: 0.2175239771604538
[2018-04-17 16:46:58.450096]: [Epoch: 488(32.55503669112742%): Data: 25.333333333333336%]:Running loss: 4.350480422377586
[2018-04-17 16:46:59.679365]: [Epoch: 488(32.55503669112742%): Data: 50.66666666666667%]:Running loss: 8.483436331152916
[2018-04-17 16:47:03.083917]: Test set accuracy: 94.33962264150944% ,loss = 5.438093468546867
[2018-04-17 16:47:03.199224]: ====================
[2018-04-17 16:47:03.205741]: Elapsed time since starting training: 0:51:48.601940
[2018-04-17 16:47:03.211757]: ====================
[2018-04-17 16:47:03.284952]: [Epoch: 489(32.62174783188792%): Data: 0.0%]:Running loss: 0.2175237387418747
[2018-04-17 16:47:04.543799]: [Epoch: 489(32.62174783188792%): Data: 25.333333333333336%]:Running loss: 4.350479066371918
[2018-04-17 16:47:05.803147]: [Epoch: 489(32.62174783188792%): Data: 50.66666666666667%]:Running loss: 8.483432799577713
[2018-04-17 16:47:09.239786]: Test set accuracy: 94.33962264150944% ,loss = 5.438100919127464
[2018-04-17 16:47:09.346068]: ====================
[2018-04-17 16:47:09.352084]: Elapsed time since starting training: 0:51:54.748283
[2018-04-17 16:47:09.358602]: ====================
[2018-04-17 16:47:09.430292]: [Epoch: 490(32.688458972648434%): Data: 0.0%]:Running loss: 0.21752403676509857
[2018-04-17 16:47:10.700169]: [Epoch: 490(32.688458972648434%): Data: 25.333333333333336%]:Running loss: 4.350476637482643
[2018-04-17 16:47:11.960520]: [Epoch: 490(32.688458972648434%): Data: 50.66666666666667%]:Running loss: 8.48342913389206
[2018-04-17 16:47:15.414204]: Test set accuracy: 94.33962264150944% ,loss = 5.438095331192017
[2018-04-17 16:47:15.524497]: ====================
[2018-04-17 16:47:15.529510]: Elapsed time since starting training: 0:52:00.925709
[2018-04-17 16:47:15.535527]: ====================
[2018-04-17 16:47:15.607718]: [Epoch: 491(32.75517011340894%): Data: 0.0%]:Running loss: 0.21752381324768066
[2018-04-17 16:47:16.887622]: [Epoch: 491(32.75517011340894%): Data: 25.333333333333336%]:Running loss: 4.350474983453751
[2018-04-17 16:47:18.151983]: [Epoch: 491(32.75517011340894%): Data: 50.66666666666667%]:Running loss: 8.483426034450531
[2018-04-17 16:47:21.554633]: Test set accuracy: 94.33962264150944% ,loss = 5.438093468546867
[2018-04-17 16:47:21.659411]: ====================
[2018-04-17 16:47:21.664926]: Elapsed time since starting training: 0:52:07.061125
[2018-04-17 16:47:21.669939]: ====================
[2018-04-17 16:47:21.740627]: [Epoch: 492(32.82188125416944%): Data: 0.0%]:Running loss: 0.2175237387418747
[2018-04-17 16:47:23.010504]: [Epoch: 492(32.82188125416944%): Data: 25.333333333333336%]:Running loss: 4.3504732847213745
[2018-04-17 16:47:24.265841]: [Epoch: 492(32.82188125416944%): Data: 50.66666666666667%]:Running loss: 8.483422756195068
[2018-04-17 16:47:27.727044]: Test set accuracy: 94.33962264150944% ,loss = 5.438090115785599
[2018-04-17 16:47:27.837338]: ====================
[2018-04-17 16:47:27.842865]: Elapsed time since starting training: 0:52:13.239064
[2018-04-17 16:47:27.848368]: ====================
[2018-04-17 16:47:27.914042]: [Epoch: 493(32.88859239492996%): Data: 0.0%]:Running loss: 0.21752360463142395
[2018-04-17 16:47:29.178403]: [Epoch: 493(32.88859239492996%): Data: 25.333333333333336%]:Running loss: 4.350471124053001
[2018-04-17 16:47:30.418702]: [Epoch: 493(32.88859239492996%): Data: 50.66666666666667%]:Running loss: 8.483418926596642
[2018-04-17 16:47:33.882913]: Test set accuracy: 94.33962264150944% ,loss = 5.438084527850151
[2018-04-17 16:47:33.992706]: ====================
[2018-04-17 16:47:33.997719]: Elapsed time since starting training: 0:52:19.393416
[2018-04-17 16:47:34.003233]: ====================
[2018-04-17 16:47:34.077431]: [Epoch: 494(32.95530353569046%): Data: 0.0%]:Running loss: 0.21752338111400604
[2018-04-17 16:47:35.374379]: [Epoch: 494(32.95530353569046%): Data: 25.333333333333336%]:Running loss: 4.350470706820488
[2018-04-17 16:47:36.655786]: [Epoch: 494(32.95530353569046%): Data: 50.66666666666667%]:Running loss: 8.483416512608528
[2018-04-17 16:47:40.052819]: Test set accuracy: 94.33962264150944% ,loss = 5.438091605901718
[2018-04-17 16:47:40.161608]: ====================
[2018-04-17 16:47:40.167624]: Elapsed time since starting training: 0:52:25.563823
[2018-04-17 16:47:40.173139]: ====================
[2018-04-17 16:47:40.237810]: [Epoch: 495(33.022014676450965%): Data: 0.0%]:Running loss: 0.21752366423606873
[2018-04-17 16:47:41.487634]: [Epoch: 495(33.022014676450965%): Data: 25.333333333333336%]:Running loss: 4.350468203425407
[2018-04-17 16:47:42.774060]: [Epoch: 495(33.022014676450965%): Data: 50.66666666666667%]:Running loss: 8.483411639928818
[2018-04-17 16:47:46.209194]: Test set accuracy: 94.33962264150944% ,loss = 5.438085272908211
[2018-04-17 16:47:46.310965]: ====================
[2018-04-17 16:47:46.316479]: Elapsed time since starting training: 0:52:31.712678
[2018-04-17 16:47:46.321492]: ====================
[2018-04-17 16:47:46.390676]: [Epoch: 496(33.088725817211476%): Data: 0.0%]:Running loss: 0.21752341091632843
[2018-04-17 16:47:47.662559]: [Epoch: 496(33.088725817211476%): Data: 25.333333333333336%]:Running loss: 4.350466221570969
[2018-04-17 16:47:48.945469]: [Epoch: 496(33.088725817211476%): Data: 50.66666666666667%]:Running loss: 8.483408778905869
[2018-04-17 16:47:52.366074]: Test set accuracy: 94.33962264150944% ,loss = 5.438082292675972
[2018-04-17 16:47:52.476368]: ====================
[2018-04-17 16:47:52.481883]: Elapsed time since starting training: 0:52:37.877580
[2018-04-17 16:47:52.486896]: ====================
[2018-04-17 16:47:52.553572]: [Epoch: 497(33.15543695797198%): Data: 0.0%]:Running loss: 0.21752329170703888
[2018-04-17 16:47:53.824953]: [Epoch: 497(33.15543695797198%): Data: 25.333333333333336%]:Running loss: 4.350464552640915
[2018-04-17 16:47:55.093827]: [Epoch: 497(33.15543695797198%): Data: 50.66666666666667%]:Running loss: 8.483406350016594
[2018-04-17 16:47:58.521441]: Test set accuracy: 94.33962264150944% ,loss = 5.438077822327614
[2018-04-17 16:47:58.628226]: ====================
[2018-04-17 16:47:58.633740]: Elapsed time since starting training: 0:52:44.029939
[2018-04-17 16:47:58.639255]: ====================
[2018-04-17 16:47:58.713452]: [Epoch: 498(33.22214809873249%): Data: 0.0%]:Running loss: 0.21752311289310455
[2018-04-17 16:47:59.942721]: [Epoch: 498(33.22214809873249%): Data: 25.333333333333336%]:Running loss: 4.3504627496004105
[2018-04-17 16:48:01.222624]: [Epoch: 498(33.22214809873249%): Data: 50.66666666666667%]:Running loss: 8.483402252197266
[2018-04-17 16:48:04.715913]: Test set accuracy: 94.33962264150944% ,loss = 5.438072606921196
[2018-04-17 16:48:04.826707]: ====================
[2018-04-17 16:48:04.832723]: Elapsed time since starting training: 0:52:50.228922
[2018-04-17 16:48:04.838238]: ====================
[2018-04-17 16:48:04.912937]: [Epoch: 499(33.28885923949299%): Data: 0.0%]:Running loss: 0.21752290427684784
[2018-04-17 16:48:06.206375]: [Epoch: 499(33.28885923949299%): Data: 25.333333333333336%]:Running loss: 4.350461930036545
[2018-04-17 16:48:07.475249]: [Epoch: 499(33.28885923949299%): Data: 50.66666666666667%]:Running loss: 8.48339918255806
[2018-04-17 16:48:10.943973]: Test set accuracy: 94.33962264150944% ,loss = 5.438078939914703
[2018-04-17 16:48:11.052262]: ====================
[2018-04-17 16:48:11.057274]: Elapsed time since starting training: 0:52:56.453473
[2018-04-17 16:48:11.062789]: ====================
[2018-04-17 16:48:11.136484]: [Epoch: 500(33.3555703802535%): Data: 0.0%]:Running loss: 0.21752315759658813
[2018-04-17 16:48:12.409877]: [Epoch: 500(33.3555703802535%): Data: 25.333333333333336%]:Running loss: 4.350459977984428
[2018-04-17 16:48:13.662702]: [Epoch: 500(33.3555703802535%): Data: 50.66666666666667%]:Running loss: 8.483396336436272
[2018-04-17 16:48:17.134934]: Test set accuracy: 94.33962264150944% ,loss = 5.438073351979256
[2018-04-17 16:48:17.243222]: ====================
[2018-04-17 16:48:17.248236]: Elapsed time since starting training: 0:53:02.643934
[2018-04-17 16:48:17.253750]: ====================
[2018-04-17 16:48:17.328449]: [Epoch: 501(33.42228152101401%): Data: 0.0%]:Running loss: 0.21752293407917023
[2018-04-17 16:48:18.598326]: [Epoch: 501(33.42228152101401%): Data: 25.333333333333336%]:Running loss: 4.350457727909088
[2018-04-17 16:48:19.859178]: [Epoch: 501(33.42228152101401%): Data: 50.66666666666667%]:Running loss: 8.483392775058746
[2018-04-17 16:48:23.323891]: Test set accuracy: 94.33962264150944% ,loss = 5.438068509101868
[2018-04-17 16:48:23.434685]: ====================
[2018-04-17 16:48:23.440200]: Elapsed time since starting training: 0:53:08.836399
[2018-04-17 16:48:23.446216]: ====================
[2018-04-17 16:48:23.520914]: [Epoch: 502(33.48899266177451%): Data: 0.0%]:Running loss: 0.2175227403640747
[2018-04-17 16:48:24.796306]: [Epoch: 502(33.48899266177451%): Data: 25.333333333333336%]:Running loss: 4.350456148386002
[2018-04-17 16:48:26.014545]: [Epoch: 502(33.48899266177451%): Data: 50.66666666666667%]:Running loss: 8.483389362692833
[2018-04-17 16:48:29.474746]: Test set accuracy: 94.33962264150944% ,loss = 5.438064783811569
[2018-04-17 16:48:29.589050]: ====================
[2018-04-17 16:48:29.595066]: Elapsed time since starting training: 0:53:14.990764
[2018-04-17 16:48:29.600581]: ====================
[2018-04-17 16:48:29.667759]: [Epoch: 503(33.55570380253503%): Data: 0.0%]:Running loss: 0.21752259135246277
[2018-04-17 16:48:30.929113]: [Epoch: 503(33.55570380253503%): Data: 25.333333333333336%]:Running loss: 4.350454747676849
[2018-04-17 16:48:32.196483]: [Epoch: 503(33.55570380253503%): Data: 50.66666666666667%]:Running loss: 8.483386233448982
[2018-04-17 16:48:35.605054]: Test set accuracy: 94.33962264150944% ,loss = 5.438069626688957
[2018-04-17 16:48:35.714345]: ====================
[2018-04-17 16:48:35.720361]: Elapsed time since starting training: 0:53:21.116059
[2018-04-17 16:48:35.727380]: ====================
[2018-04-17 16:48:35.799571]: [Epoch: 504(33.62241494329553%): Data: 0.0%]:Running loss: 0.2175227850675583
[2018-04-17 16:48:37.073459]: [Epoch: 504(33.62241494329553%): Data: 25.333333333333336%]:Running loss: 4.350453406572342
[2018-04-17 16:48:38.335314]: [Epoch: 504(33.62241494329553%): Data: 50.66666666666667%]:Running loss: 8.483383923768997
[2018-04-17 16:48:41.773456]: Test set accuracy: 94.33962264150944% ,loss = 5.43806329369545
[2018-04-17 16:48:41.883249]: ====================
[2018-04-17 16:48:41.888261]: Elapsed time since starting training: 0:53:27.284460
[2018-04-17 16:48:41.893274]: ====================
[2018-04-17 16:48:41.963461]: [Epoch: 505(33.689126084056035%): Data: 0.0%]:Running loss: 0.217522531747818
[2018-04-17 16:48:43.222309]: [Epoch: 505(33.689126084056035%): Data: 25.333333333333336%]:Running loss: 4.350451856851578
[2018-04-17 16:48:44.453582]: [Epoch: 505(33.689126084056035%): Data: 50.66666666666667%]:Running loss: 8.483379691839218
[2018-04-17 16:48:47.928823]: Test set accuracy: 94.33962264150944% ,loss = 5.438066273927689
[2018-04-17 16:48:48.030092]: ====================
[2018-04-17 16:48:48.035608]: Elapsed time since starting training: 0:53:33.431305
[2018-04-17 16:48:48.040620]: ====================
[2018-04-17 16:48:48.103788]: [Epoch: 506(33.755837224816545%): Data: 0.0%]:Running loss: 0.21752265095710754
[2018-04-17 16:48:49.243819]: [Epoch: 506(33.755837224816545%): Data: 25.333333333333336%]:Running loss: 4.35045000910759
[2018-04-17 16:48:50.409419]: [Epoch: 506(33.755837224816545%): Data: 50.66666666666667%]:Running loss: 8.48337721824646
[2018-04-17 16:48:53.749300]: Test set accuracy: 94.33962264150944% ,loss = 5.438064783811569
[2018-04-17 16:48:53.863604]: ====================
[2018-04-17 16:48:53.869118]: Elapsed time since starting training: 0:53:39.265317
[2018-04-17 16:48:53.874633]: ====================
[2018-04-17 16:48:53.948328]: [Epoch: 507(33.82254836557705%): Data: 0.0%]:Running loss: 0.21752259135246277
[2018-04-17 16:48:55.237256]: [Epoch: 507(33.82254836557705%): Data: 25.333333333333336%]:Running loss: 4.350449830293655
[2018-04-17 16:48:56.517661]: [Epoch: 507(33.82254836557705%): Data: 50.66666666666667%]:Running loss: 8.483375996351242
[2018-04-17 16:48:59.983877]: Test set accuracy: 94.33962264150944% ,loss = 5.43806292116642
[2018-04-17 16:49:00.095173]: ====================
[2018-04-17 16:49:00.102693]: Elapsed time since starting training: 0:53:45.498892
[2018-04-17 16:49:00.108208]: ====================
[2018-04-17 16:49:00.176890]: [Epoch: 508(33.88925950633756%): Data: 0.0%]:Running loss: 0.2175225168466568
[2018-04-17 16:49:01.419705]: [Epoch: 508(33.88925950633756%): Data: 25.333333333333336%]:Running loss: 4.350447729229927
[2018-04-17 16:49:02.693582]: [Epoch: 508(33.88925950633756%): Data: 50.66666666666667%]:Running loss: 8.483372539281845
[2018-04-17 16:49:06.120193]: Test set accuracy: 94.33962264150944% ,loss = 5.438061058521271
[2018-04-17 16:49:06.230487]: ====================
[2018-04-17 16:49:06.238008]: Elapsed time since starting training: 0:53:51.634207
[2018-04-17 16:49:06.243522]: ====================
[2018-04-17 16:49:06.319223]: [Epoch: 509(33.95597064709806%): Data: 0.0%]:Running loss: 0.21752244234085083
[2018-04-17 16:49:07.586593]: [Epoch: 509(33.95597064709806%): Data: 25.333333333333336%]:Running loss: 4.350446790456772
[2018-04-17 16:49:08.852459]: [Epoch: 509(33.95597064709806%): Data: 50.66666666666667%]:Running loss: 8.48336946964264
[2018-04-17 16:49:12.325193]: Test set accuracy: 94.33962264150944% ,loss = 5.438058450818062
[2018-04-17 16:49:12.430474]: ====================
[2018-04-17 16:49:12.436488]: Elapsed time since starting training: 0:53:57.832186
[2018-04-17 16:49:12.441502]: ====================
[2018-04-17 16:49:12.513694]: [Epoch: 510(34.02268178785857%): Data: 0.0%]:Running loss: 0.21752233803272247
[2018-04-17 16:49:13.774547]: [Epoch: 510(34.02268178785857%): Data: 25.333333333333336%]:Running loss: 4.3504446893930435
[2018-04-17 16:49:15.028381]: [Epoch: 510(34.02268178785857%): Data: 50.66666666666667%]:Running loss: 8.483366414904594
[2018-04-17 16:49:18.476048]: Test set accuracy: 94.33962264150944% ,loss = 5.438056588172913
[2018-04-17 16:49:18.585339]: ====================
[2018-04-17 16:49:18.590352]: Elapsed time since starting training: 0:54:03.986049
[2018-04-17 16:49:18.594864]: ====================
[2018-04-17 16:49:18.658031]: [Epoch: 511(34.08939292861908%): Data: 0.0%]:Running loss: 0.2175222635269165
[2018-04-17 16:49:19.936932]: [Epoch: 511(34.08939292861908%): Data: 25.333333333333336%]:Running loss: 4.350443869829178
[2018-04-17 16:49:21.187257]: [Epoch: 511(34.08939292861908%): Data: 50.66666666666667%]:Running loss: 8.483365327119827
[2018-04-17 16:49:24.570753]: Test set accuracy: 94.33962264150944% ,loss = 5.438054725527763
[2018-04-17 16:49:24.674028]: ====================
[2018-04-17 16:49:24.680044]: Elapsed time since starting training: 0:54:10.075742
[2018-04-17 16:49:24.685559]: ====================
[2018-04-17 16:49:24.760759]: [Epoch: 512(34.15610406937958%): Data: 0.0%]:Running loss: 0.21752218902111053
[2018-04-17 16:49:26.044172]: [Epoch: 512(34.15610406937958%): Data: 25.333333333333336%]:Running loss: 4.350442573428154
[2018-04-17 16:49:27.305532]: [Epoch: 512(34.15610406937958%): Data: 50.66666666666667%]:Running loss: 8.483362644910812
[2018-04-17 16:49:30.797815]: Test set accuracy: 94.33962264150944% ,loss = 5.438052117824554
[2018-04-17 16:49:30.908108]: ====================
[2018-04-17 16:49:30.913623]: Elapsed time since starting training: 0:54:16.309321
[2018-04-17 16:49:30.918135]: ====================
[2018-04-17 16:49:30.984311]: [Epoch: 513(34.2228152101401%): Data: 0.0%]:Running loss: 0.21752208471298218
[2018-04-17 16:49:32.238145]: [Epoch: 513(34.2228152101401%): Data: 25.333333333333336%]:Running loss: 4.3504417687654495
[2018-04-17 16:49:33.515542]: [Epoch: 513(34.2228152101401%): Data: 50.66666666666667%]:Running loss: 8.483361229300499
[2018-04-17 16:49:36.981758]: Test set accuracy: 94.33962264150944% ,loss = 5.438051745295525
[2018-04-17 16:49:37.095059]: ====================
[2018-04-17 16:49:37.100574]: Elapsed time since starting training: 0:54:22.496773
[2018-04-17 16:49:37.106095]: ====================
[2018-04-17 16:49:37.183801]: [Epoch: 514(34.2895263509006%): Data: 0.0%]:Running loss: 0.21752206981182098
[2018-04-17 16:49:38.466706]: [Epoch: 514(34.2895263509006%): Data: 25.333333333333336%]:Running loss: 4.350440606474876
[2018-04-17 16:49:39.750119]: [Epoch: 514(34.2895263509006%): Data: 50.66666666666667%]:Running loss: 8.483358606696129
[2018-04-17 16:49:43.193775]: Test set accuracy: 94.33962264150944% ,loss = 5.438046902418137
[2018-04-17 16:49:43.302064]: ====================
[2018-04-17 16:49:43.307579]: Elapsed time since starting training: 0:54:28.703778
[2018-04-17 16:49:43.313099]: ====================
[2018-04-17 16:49:43.387791]: [Epoch: 515(34.356237491661105%): Data: 0.0%]:Running loss: 0.21752187609672546
[2018-04-17 16:49:44.642628]: [Epoch: 515(34.356237491661105%): Data: 25.333333333333336%]:Running loss: 4.350439116358757
[2018-04-17 16:49:45.928047]: [Epoch: 515(34.356237491661105%): Data: 50.66666666666667%]:Running loss: 8.483356460928917
[2018-04-17 16:49:49.393761]: Test set accuracy: 94.33962264150944% ,loss = 5.438046157360077
[2018-04-17 16:49:49.504055]: ====================
[2018-04-17 16:49:49.509579]: Elapsed time since starting training: 0:54:34.905778
[2018-04-17 16:49:49.515084]: ====================
[2018-04-17 16:49:49.590284]: [Epoch: 516(34.422948632421615%): Data: 0.0%]:Running loss: 0.21752184629440308
[2018-04-17 16:49:50.872193]: [Epoch: 516(34.422948632421615%): Data: 25.333333333333336%]:Running loss: 4.3504385352134705
[2018-04-17 16:49:52.137332]: [Epoch: 516(34.422948632421615%): Data: 50.66666666666667%]:Running loss: 8.483354285359383
[2018-04-17 16:49:55.576978]: Test set accuracy: 94.33962264150944% ,loss = 5.4380446672439575
[2018-04-17 16:49:55.690280]: ====================
[2018-04-17 16:49:55.695795]: Elapsed time since starting training: 0:54:41.091492
[2018-04-17 16:49:55.700808]: ====================
[2018-04-17 16:49:55.776008]: [Epoch: 517(34.489659773182126%): Data: 0.0%]:Running loss: 0.2175217866897583
[2018-04-17 16:49:57.054407]: [Epoch: 517(34.489659773182126%): Data: 25.333333333333336%]:Running loss: 4.350436016917229
[2018-04-17 16:49:58.327794]: [Epoch: 517(34.489659773182126%): Data: 50.66666666666667%]:Running loss: 8.483350530266762
[2018-04-17 16:50:01.786490]: Test set accuracy: 94.33962264150944% ,loss = 5.438041314482689
[2018-04-17 16:50:01.897284]: ====================
[2018-04-17 16:50:01.902799]: Elapsed time since starting training: 0:54:47.298998
[2018-04-17 16:50:01.907813]: ====================
[2018-04-17 16:50:01.985017]: [Epoch: 518(34.55637091394263%): Data: 0.0%]:Running loss: 0.21752165257930756
[2018-04-17 16:50:03.274949]: [Epoch: 518(34.55637091394263%): Data: 25.333333333333336%]:Running loss: 4.350434586405754
[2018-04-17 16:50:04.533795]: [Epoch: 518(34.55637091394263%): Data: 50.66666666666667%]:Running loss: 8.483347460627556
[2018-04-17 16:50:08.063680]: Test set accuracy: 94.33962264150944% ,loss = 5.43803796172142
[2018-04-17 16:50:08.176983]: ====================
[2018-04-17 16:50:08.184502]: Elapsed time since starting training: 0:54:53.580701
[2018-04-17 16:50:08.190016]: ====================
[2018-04-17 16:50:08.265718]: [Epoch: 519(34.62308205470313%): Data: 0.0%]:Running loss: 0.2175215184688568
[2018-04-17 16:50:09.539104]: [Epoch: 519(34.62308205470313%): Data: 25.333333333333336%]:Running loss: 4.350434273481369
[2018-04-17 16:50:10.788425]: [Epoch: 519(34.62308205470313%): Data: 50.66666666666667%]:Running loss: 8.483346968889236
[2018-04-17 16:50:14.264168]: Test set accuracy: 94.33962264150944% ,loss = 5.438045412302017
[2018-04-17 16:50:14.376467]: ====================
[2018-04-17 16:50:14.382984]: Elapsed time since starting training: 0:54:59.778681
[2018-04-17 16:50:14.387997]: ====================
[2018-04-17 16:50:14.459687]: [Epoch: 520(34.68979319546364%): Data: 0.0%]:Running loss: 0.2175218164920807
[2018-04-17 16:50:15.751623]: [Epoch: 520(34.68979319546364%): Data: 25.333333333333336%]:Running loss: 4.3504336923360825
[2018-04-17 16:50:17.031025]: [Epoch: 520(34.68979319546364%): Data: 50.66666666666667%]:Running loss: 8.483344435691833
[2018-04-17 16:50:20.527823]: Test set accuracy: 94.33962264150944% ,loss = 5.438043549656868
[2018-04-17 16:50:20.724346]: ====================
[2018-04-17 16:50:20.730863]: Elapsed time since starting training: 0:55:06.127062
[2018-04-17 16:50:20.736879]: ====================
[2018-04-17 16:50:20.803556]: [Epoch: 521(34.75650433622415%): Data: 0.0%]:Running loss: 0.21752174198627472
[2018-04-17 16:50:22.107524]: [Epoch: 521(34.75650433622415%): Data: 25.333333333333336%]:Running loss: 4.350431993603706
[2018-04-17 16:50:23.395949]: [Epoch: 521(34.75650433622415%): Data: 50.66666666666667%]:Running loss: 8.483342230319977
[2018-04-17 16:50:26.878209]: Test set accuracy: 94.33962264150944% ,loss = 5.4380398243665695
[2018-04-17 16:50:26.984491]: ====================
[2018-04-17 16:50:26.990005]: Elapsed time since starting training: 0:55:12.386204
[2018-04-17 16:50:26.995019]: ====================
[2018-04-17 16:50:27.069717]: [Epoch: 522(34.82321547698466%): Data: 0.0%]:Running loss: 0.21752159297466278
[2018-04-17 16:50:28.358143]: [Epoch: 522(34.82321547698466%): Data: 25.333333333333336%]:Running loss: 4.350431874394417
[2018-04-17 16:50:29.598441]: [Epoch: 522(34.82321547698466%): Data: 50.66666666666667%]:Running loss: 8.483340963721275
[2018-04-17 16:50:33.079698]: Test set accuracy: 94.33962264150944% ,loss = 5.438035354018211
[2018-04-17 16:50:33.189991]: ====================
[2018-04-17 16:50:33.196009]: Elapsed time since starting training: 0:55:18.592208
[2018-04-17 16:50:33.201522]: ====================
[2018-04-17 16:50:33.276221]: [Epoch: 523(34.88992661774517%): Data: 0.0%]:Running loss: 0.21752141416072845
[2018-04-17 16:50:34.527047]: [Epoch: 523(34.88992661774517%): Data: 25.333333333333336%]:Running loss: 4.350430428981781
[2018-04-17 16:50:35.796923]: [Epoch: 523(34.88992661774517%): Data: 50.66666666666667%]:Running loss: 8.483339205384254
[2018-04-17 16:50:39.244591]: Test set accuracy: 94.33962264150944% ,loss = 5.4380349814891815
[2018-04-17 16:50:39.353881]: ====================
[2018-04-17 16:50:39.359396]: Elapsed time since starting training: 0:55:24.755595
[2018-04-17 16:50:39.364910]: ====================
[2018-04-17 16:50:39.437102]: [Epoch: 524(34.95663775850567%): Data: 0.0%]:Running loss: 0.21752139925956726
[2018-04-17 16:50:40.671385]: [Epoch: 524(34.95663775850567%): Data: 25.333333333333336%]:Running loss: 4.350429177284241
[2018-04-17 16:50:41.934242]: [Epoch: 524(34.95663775850567%): Data: 50.66666666666667%]:Running loss: 8.48333577811718
[2018-04-17 16:50:45.359850]: Test set accuracy: 94.33962264150944% ,loss = 5.438031256198883
[2018-04-17 16:50:45.467137]: ====================
[2018-04-17 16:50:45.474155]: Elapsed time since starting training: 0:55:30.869853
[2018-04-17 16:50:45.479669]: ====================
[2018-04-17 16:50:45.544842]: [Epoch: 525(35.023348899266175%): Data: 0.0%]:Running loss: 0.21752125024795532
[2018-04-17 16:50:46.795668]: [Epoch: 525(35.023348899266175%): Data: 25.333333333333336%]:Running loss: 4.35042679309845
[2018-04-17 16:50:48.065555]: [Epoch: 525(35.023348899266175%): Data: 50.66666666666667%]:Running loss: 8.483332842588425
[2018-04-17 16:50:51.507698]: Test set accuracy: 94.33962264150944% ,loss = 5.438027903437614
[2018-04-17 16:50:51.617991]: ====================
[2018-04-17 16:50:51.624007]: Elapsed time since starting training: 0:55:37.019705
[2018-04-17 16:50:51.629021]: ====================
[2018-04-17 16:50:51.705725]: [Epoch: 526(35.090060040026685%): Data: 0.0%]:Running loss: 0.21752111613750458
[2018-04-17 16:50:52.936998]: [Epoch: 526(35.090060040026685%): Data: 25.333333333333336%]:Running loss: 4.3504263907670975
[2018-04-17 16:50:54.218406]: [Epoch: 526(35.090060040026685%): Data: 50.66666666666667%]:Running loss: 8.483330428600311
[2018-04-17 16:50:57.664067]: Test set accuracy: 94.33962264150944% ,loss = 5.438036471605301
[2018-04-17 16:50:57.777370]: ====================
[2018-04-17 16:50:57.783886]: Elapsed time since starting training: 0:55:43.179584
[2018-04-17 16:50:57.788398]: ====================
[2018-04-17 16:50:57.860590]: [Epoch: 527(35.156771180787196%): Data: 0.0%]:Running loss: 0.21752145886421204
[2018-04-17 16:50:59.145005]: [Epoch: 527(35.156771180787196%): Data: 25.333333333333336%]:Running loss: 4.350425362586975
[2018-04-17 16:51:00.393325]: [Epoch: 527(35.156771180787196%): Data: 50.66666666666667%]:Running loss: 8.483329325914383
[2018-04-17 16:51:03.845006]: Test set accuracy: 94.33962264150944% ,loss = 5.438027158379555
[2018-04-17 16:51:03.951291]: ====================
[2018-04-17 16:51:03.957807]: Elapsed time since starting training: 0:55:49.354006
[2018-04-17 16:51:03.963321]: ====================
[2018-04-17 16:51:04.035513]: [Epoch: 528(35.2234823215477%): Data: 0.0%]:Running loss: 0.2175210863351822
[2018-04-17 16:51:05.293358]: [Epoch: 528(35.2234823215477%): Data: 25.333333333333336%]:Running loss: 4.350424975156784
[2018-04-17 16:51:06.532152]: [Epoch: 528(35.2234823215477%): Data: 50.66666666666667%]:Running loss: 8.483328863978386
[2018-04-17 16:51:09.959264]: Test set accuracy: 94.33962264150944% ,loss = 5.4380301386117935
[2018-04-17 16:51:10.071062]: ====================
[2018-04-17 16:51:10.076576]: Elapsed time since starting training: 0:55:55.472775
[2018-04-17 16:51:10.082091]: ====================
[2018-04-17 16:51:10.154784]: [Epoch: 529(35.2901934623082%): Data: 0.0%]:Running loss: 0.21752120554447174
[2018-04-17 16:51:11.427669]: [Epoch: 529(35.2901934623082%): Data: 25.333333333333336%]:Running loss: 4.3504233956336975
[2018-04-17 16:51:12.693535]: [Epoch: 529(35.2901934623082%): Data: 50.66666666666667%]:Running loss: 8.48332567512989
[2018-04-17 16:51:16.111623]: Test set accuracy: 94.33962264150944% ,loss = 5.438029393553734
[2018-04-17 16:51:16.221416]: ====================
[2018-04-17 16:51:16.226429]: Elapsed time since starting training: 0:56:01.622628
[2018-04-17 16:51:16.232946]: ====================
[2018-04-17 16:51:16.306140]: [Epoch: 530(35.35690460306871%): Data: 0.0%]:Running loss: 0.21752117574214935
[2018-04-17 16:51:17.560476]: [Epoch: 530(35.35690460306871%): Data: 25.333333333333336%]:Running loss: 4.350423142313957
[2018-04-17 16:51:18.847398]: [Epoch: 530(35.35690460306871%): Data: 50.66666666666667%]:Running loss: 8.483324065804482
[2018-04-17 16:51:22.347705]: Test set accuracy: 94.33962264150944% ,loss = 5.438031628727913
[2018-04-17 16:51:22.457497]: ====================
[2018-04-17 16:51:22.463012]: Elapsed time since starting training: 0:56:07.859211
[2018-04-17 16:51:22.468527]: ====================
[2018-04-17 16:51:22.542223]: [Epoch: 531(35.42361574382922%): Data: 0.0%]:Running loss: 0.21752126514911652
[2018-04-17 16:51:23.806584]: [Epoch: 531(35.42361574382922%): Data: 25.333333333333336%]:Running loss: 4.35042168200016
[2018-04-17 16:51:25.064930]: [Epoch: 531(35.42361574382922%): Data: 50.66666666666667%]:Running loss: 8.483322188258171
[2018-04-17 16:51:28.544181]: Test set accuracy: 94.33962264150944% ,loss = 5.438023805618286
[2018-04-17 16:51:28.655979]: ====================
[2018-04-17 16:51:28.661494]: Elapsed time since starting training: 0:56:14.057693
[2018-04-17 16:51:28.667008]: ====================
[2018-04-17 16:51:28.739701]: [Epoch: 532(35.49032688458973%): Data: 0.0%]:Running loss: 0.21752095222473145
[2018-04-17 16:51:29.998549]: [Epoch: 532(35.49032688458973%): Data: 25.333333333333336%]:Running loss: 4.35042130947113
[2018-04-17 16:51:31.299507]: [Epoch: 532(35.49032688458973%): Data: 50.66666666666667%]:Running loss: 8.48332193493843
[2018-04-17 16:51:34.795805]: Test set accuracy: 94.33962264150944% ,loss = 5.438023060560226
[2018-04-17 16:51:34.907101]: ====================
[2018-04-17 16:51:34.913117]: Elapsed time since starting training: 0:56:20.309316
[2018-04-17 16:51:34.918631]: ====================
[2018-04-17 16:51:34.992828]: [Epoch: 533(35.55703802535024%): Data: 0.0%]:Running loss: 0.21752092242240906
[2018-04-17 16:51:36.265212]: [Epoch: 533(35.55703802535024%): Data: 25.333333333333336%]:Running loss: 4.3504201620817184
[2018-04-17 16:51:37.508517]: [Epoch: 533(35.55703802535024%): Data: 50.66666666666667%]:Running loss: 8.483318641781807
[2018-04-17 16:51:40.967716]: Test set accuracy: 94.33962264150944% ,loss = 5.438026785850525
[2018-04-17 16:51:41.077007]: ====================
[2018-04-17 16:51:41.084527]: Elapsed time since starting training: 0:56:26.480224
[2018-04-17 16:51:41.090041]: ====================
[2018-04-17 16:51:41.158724]: [Epoch: 534(35.62374916611074%): Data: 0.0%]:Running loss: 0.217521071434021
[2018-04-17 16:51:42.405037]: [Epoch: 534(35.62374916611074%): Data: 25.333333333333336%]:Running loss: 4.35042043030262
[2018-04-17 16:51:43.655863]: [Epoch: 534(35.62374916611074%): Data: 50.66666666666667%]:Running loss: 8.483318343758583
[2018-04-17 16:51:47.057909]: Test set accuracy: 94.33962264150944% ,loss = 5.438026413321495
[2018-04-17 16:51:47.171211]: ====================
[2018-04-17 16:51:47.176726]: Elapsed time since starting training: 0:56:32.572925
[2018-04-17 16:51:47.182240]: ====================
[2018-04-17 16:51:47.254933]: [Epoch: 535(35.690460306871245%): Data: 0.0%]:Running loss: 0.2175210565328598
[2018-04-17 16:51:48.508767]: [Epoch: 535(35.690460306871245%): Data: 25.333333333333336%]:Running loss: 4.350417897105217
[2018-04-17 16:51:49.762610]: [Epoch: 535(35.690460306871245%): Data: 50.66666666666667%]:Running loss: 8.483315974473953
[2018-04-17 16:51:53.178190]: Test set accuracy: 94.33962264150944% ,loss = 5.4380156099796295
[2018-04-17 16:51:53.286479]: ====================
[2018-04-17 16:51:53.291993]: Elapsed time since starting training: 0:56:38.687690
[2018-04-17 16:51:53.297006]: ====================
[2018-04-17 16:51:53.367694]: [Epoch: 536(35.757171447631755%): Data: 0.0%]:Running loss: 0.21752062439918518
[2018-04-17 16:51:54.610499]: [Epoch: 536(35.757171447631755%): Data: 25.333333333333336%]:Running loss: 4.350417152047157
[2018-04-17 16:51:55.865836]: [Epoch: 536(35.757171447631755%): Data: 50.66666666666667%]:Running loss: 8.483313724398613
[2018-04-17 16:51:59.305483]: Test set accuracy: 94.33962264150944% ,loss = 5.438019335269928
[2018-04-17 16:51:59.419787]: ====================
[2018-04-17 16:51:59.425303]: Elapsed time since starting training: 0:56:44.821502
[2018-04-17 16:51:59.430816]: ====================
[2018-04-17 16:51:59.505515]: [Epoch: 537(35.823882588392266%): Data: 0.0%]:Running loss: 0.21752077341079712
[2018-04-17 16:52:00.794943]: [Epoch: 537(35.823882588392266%): Data: 25.333333333333336%]:Running loss: 4.35041743516922
[2018-04-17 16:52:02.060809]: [Epoch: 537(35.823882588392266%): Data: 50.66666666666667%]:Running loss: 8.483313903212547
[2018-04-17 16:52:05.531537]: Test set accuracy: 94.33962264150944% ,loss = 5.438018217682838
[2018-04-17 16:52:05.638823]: ====================
[2018-04-17 16:52:05.644345]: Elapsed time since starting training: 0:56:51.040544
[2018-04-17 16:52:05.650354]: ====================
[2018-04-17 16:52:05.722545]: [Epoch: 538(35.89059372915277%): Data: 0.0%]:Running loss: 0.21752072870731354
[2018-04-17 16:52:07.004955]: [Epoch: 538(35.89059372915277%): Data: 25.333333333333336%]:Running loss: 4.350416257977486
[2018-04-17 16:52:08.254278]: [Epoch: 538(35.89059372915277%): Data: 50.66666666666667%]:Running loss: 8.483312264084816
[2018-04-17 16:52:11.708963]: Test set accuracy: 94.33962264150944% ,loss = 5.438018217682838
[2018-04-17 16:52:11.820760]: ====================
[2018-04-17 16:52:11.826777]: Elapsed time since starting training: 0:56:57.222475
[2018-04-17 16:52:11.832291]: ====================
[2018-04-17 16:52:11.896462]: [Epoch: 539(35.95730486991327%): Data: 0.0%]:Running loss: 0.21752072870731354
[2018-04-17 16:52:13.149293]: [Epoch: 539(35.95730486991327%): Data: 25.333333333333336%]:Running loss: 4.350415855646133
[2018-04-17 16:52:14.386583]: [Epoch: 539(35.95730486991327%): Data: 50.66666666666667%]:Running loss: 8.483309805393219
[2018-04-17 16:52:17.826731]: Test set accuracy: 94.33962264150944% ,loss = 5.438020825386047
[2018-04-17 16:52:17.934016]: ====================
[2018-04-17 16:52:17.940032]: Elapsed time since starting training: 0:57:03.336231
[2018-04-17 16:52:17.945546]: ====================
[2018-04-17 16:52:18.016234]: [Epoch: 540(36.02401601067378%): Data: 0.0%]:Running loss: 0.2175208330154419
[2018-04-17 16:52:19.269567]: [Epoch: 540(36.02401601067378%): Data: 25.333333333333336%]:Running loss: 4.3504151701927185
[2018-04-17 16:52:20.553481]: [Epoch: 540(36.02401601067378%): Data: 50.66666666666667%]:Running loss: 8.483308970928192
[2018-04-17 16:52:23.981095]: Test set accuracy: 94.33962264150944% ,loss = 5.438022688031197
[2018-04-17 16:52:24.089383]: ====================
[2018-04-17 16:52:24.094396]: Elapsed time since starting training: 0:57:09.490595
[2018-04-17 16:52:24.099911]: ====================
[2018-04-17 16:52:24.168594]: [Epoch: 541(36.09072715143429%): Data: 0.0%]:Running loss: 0.21752090752124786
[2018-04-17 16:52:25.429947]: [Epoch: 541(36.09072715143429%): Data: 25.333333333333336%]:Running loss: 4.350413337349892
[2018-04-17 16:52:26.708848]: [Epoch: 541(36.09072715143429%): Data: 50.66666666666667%]:Running loss: 8.48330682516098
[2018-04-17 16:52:30.146488]: Test set accuracy: 94.33962264150944% ,loss = 5.43801337480545
[2018-04-17 16:52:30.254275]: ====================
[2018-04-17 16:52:30.259790]: Elapsed time since starting training: 0:57:15.655989
[2018-04-17 16:52:30.265305]: ====================
[2018-04-17 16:52:30.340504]: [Epoch: 542(36.1574382921948%): Data: 0.0%]:Running loss: 0.21752053499221802
[2018-04-17 16:52:31.605367]: [Epoch: 542(36.1574382921948%): Data: 25.333333333333336%]:Running loss: 4.3504132479429245
[2018-04-17 16:52:32.903319]: [Epoch: 542(36.1574382921948%): Data: 50.66666666666667%]:Running loss: 8.483305871486664
[2018-04-17 16:52:36.365024]: Test set accuracy: 94.33962264150944% ,loss = 5.438012629747391
[2018-04-17 16:52:36.476821]: ====================
[2018-04-17 16:52:36.482336]: Elapsed time since starting training: 0:57:21.878535
[2018-04-17 16:52:36.488352]: ====================
[2018-04-17 16:52:36.560543]: [Epoch: 543(36.22414943295531%): Data: 0.0%]:Running loss: 0.21752050518989563
[2018-04-17 16:52:37.808863]: [Epoch: 543(36.22414943295531%): Data: 25.333333333333336%]:Running loss: 4.350412666797638
[2018-04-17 16:52:39.060190]: [Epoch: 543(36.22414943295531%): Data: 50.66666666666667%]:Running loss: 8.48330433666706
[2018-04-17 16:52:42.469761]: Test set accuracy: 94.33962264150944% ,loss = 5.43801411986351
[2018-04-17 16:52:42.578550]: ====================
[2018-04-17 16:52:42.585068]: Elapsed time since starting training: 0:57:27.980766
[2018-04-17 16:52:42.590582]: ====================
[2018-04-17 16:52:42.662273]: [Epoch: 544(36.29086057371581%): Data: 0.0%]:Running loss: 0.2175205647945404
[2018-04-17 16:52:43.917610]: [Epoch: 544(36.29086057371581%): Data: 25.333333333333336%]:Running loss: 4.350412085652351
[2018-04-17 16:52:45.163924]: [Epoch: 544(36.29086057371581%): Data: 50.66666666666667%]:Running loss: 8.483303099870682
[2018-04-17 16:52:48.552434]: Test set accuracy: 94.33962264150944% ,loss = 5.43801337480545
[2018-04-17 16:52:48.665736]: ====================
[2018-04-17 16:52:48.673257]: Elapsed time since starting training: 0:57:34.068953
[2018-04-17 16:52:48.678269]: ====================
[2018-04-17 16:52:48.751965]: [Epoch: 545(36.357571714476315%): Data: 0.0%]:Running loss: 0.21752053499221802
[2018-04-17 16:52:50.000786]: [Epoch: 545(36.357571714476315%): Data: 25.333333333333336%]:Running loss: 4.350410893559456
[2018-04-17 16:52:51.266150]: [Epoch: 545(36.357571714476315%): Data: 50.66666666666667%]:Running loss: 8.4833013266325
[2018-04-17 16:52:54.695769]: Test set accuracy: 94.33962264150944% ,loss = 5.438015982508659
[2018-04-17 16:52:54.803556]: ====================
[2018-04-17 16:52:54.809071]: Elapsed time since starting training: 0:57:40.205270
[2018-04-17 16:52:54.814586]: ====================
[2018-04-17 16:52:54.884271]: [Epoch: 546(36.424282855236825%): Data: 0.0%]:Running loss: 0.21752063930034637
[2018-04-17 16:52:56.128078]: [Epoch: 546(36.424282855236825%): Data: 25.333333333333336%]:Running loss: 4.350409761071205
[2018-04-17 16:52:57.408984]: [Epoch: 546(36.424282855236825%): Data: 50.66666666666667%]:Running loss: 8.483298599720001
[2018-04-17 16:53:00.818049]: Test set accuracy: 94.33962264150944% ,loss = 5.43801411986351
[2018-04-17 16:53:00.924332]: ====================
[2018-04-17 16:53:00.929846]: Elapsed time since starting training: 0:57:46.326045
[2018-04-17 16:53:00.935862]: ====================
[2018-04-17 16:53:01.009057]: [Epoch: 547(36.490993995997336%): Data: 0.0%]:Running loss: 0.2175205647945404
[2018-04-17 16:53:02.280939]: [Epoch: 547(36.490993995997336%): Data: 25.333333333333336%]:Running loss: 4.350409224629402
[2018-04-17 16:53:03.507199]: [Epoch: 547(36.490993995997336%): Data: 50.66666666666667%]:Running loss: 8.4832983314991
[2018-04-17 16:53:06.939325]: Test set accuracy: 94.33962264150944% ,loss = 5.438016355037689
[2018-04-17 16:53:07.049117]: ====================
[2018-04-17 16:53:07.054632]: Elapsed time since starting training: 0:57:52.450831
[2018-04-17 16:53:07.059645]: ====================
[2018-04-17 16:53:07.129330]: [Epoch: 548(36.55770513675784%): Data: 0.0%]:Running loss: 0.21752065420150757
[2018-04-17 16:53:08.370130]: [Epoch: 548(36.55770513675784%): Data: 25.333333333333336%]:Running loss: 4.350408673286438
[2018-04-17 16:53:09.645521]: [Epoch: 548(36.55770513675784%): Data: 50.66666666666667%]:Running loss: 8.483297407627106
[2018-04-17 16:53:13.092687]: Test set accuracy: 94.33962264150944% ,loss = 5.438005179166794
[2018-04-17 16:53:13.203482]: ====================
[2018-04-17 16:53:13.210007]: Elapsed time since starting training: 0:57:58.606206
[2018-04-17 16:53:13.215514]: ====================
[2018-04-17 16:53:13.286703]: [Epoch: 549(36.62441627751834%): Data: 0.0%]:Running loss: 0.21752020716667175
[2018-04-17 16:53:14.536025]: [Epoch: 549(36.62441627751834%): Data: 25.333333333333336%]:Running loss: 4.350408554077148
[2018-04-17 16:53:15.807907]: [Epoch: 549(36.62441627751834%): Data: 50.66666666666667%]:Running loss: 8.48329547047615
[2018-04-17 16:53:19.202432]: Test set accuracy: 94.33962264150944% ,loss = 5.438006669282913
[2018-04-17 16:53:19.315232]: ====================
[2018-04-17 16:53:19.320748]: Elapsed time since starting training: 0:58:04.716445
[2018-04-17 16:53:19.326262]: ====================
[2018-04-17 16:53:19.398955]: [Epoch: 550(36.69112741827885%): Data: 0.0%]:Running loss: 0.21752026677131653
[2018-04-17 16:53:20.665824]: [Epoch: 550(36.69112741827885%): Data: 25.333333333333336%]:Running loss: 4.350407734513283
[2018-04-17 16:53:21.919156]: [Epoch: 550(36.69112741827885%): Data: 50.66666666666667%]:Running loss: 8.48329347372055
[2018-04-17 16:53:25.365320]: Test set accuracy: 94.33962264150944% ,loss = 5.438005551695824
[2018-04-17 16:53:25.475112]: ====================
[2018-04-17 16:53:25.480626]: Elapsed time since starting training: 0:58:10.876825
[2018-04-17 16:53:25.486148]: ====================
[2018-04-17 16:53:25.559837]: [Epoch: 551(36.75783855903936%): Data: 0.0%]:Running loss: 0.21752022206783295
[2018-04-17 16:53:26.816177]: [Epoch: 551(36.75783855903936%): Data: 25.333333333333336%]:Running loss: 4.350405767560005
[2018-04-17 16:53:28.101094]: [Epoch: 551(36.75783855903936%): Data: 50.66666666666667%]:Running loss: 8.483292758464813
[2018-04-17 16:53:31.539737]: Test set accuracy: 94.33962264150944% ,loss = 5.438007041811943
[2018-04-17 16:53:31.647022]: ====================
[2018-04-17 16:53:31.653039]: Elapsed time since starting training: 0:58:17.049238
[2018-04-17 16:53:31.659556]: ====================
[2018-04-17 16:53:31.731247]: [Epoch: 552(36.82454969979987%): Data: 0.0%]:Running loss: 0.21752028167247772
[2018-04-17 16:53:32.987587]: [Epoch: 552(36.82454969979987%): Data: 25.333333333333336%]:Running loss: 4.350405633449554
[2018-04-17 16:53:34.244432]: [Epoch: 552(36.82454969979987%): Data: 50.66666666666667%]:Running loss: 8.483291417360306
[2018-04-17 16:53:37.675552]: Test set accuracy: 94.33962264150944% ,loss = 5.438007414340973
[2018-04-17 16:53:37.791873]: ====================
[2018-04-17 16:53:37.797377]: Elapsed time since starting training: 0:58:23.193074
[2018-04-17 16:53:37.802892]: ====================
[2018-04-17 16:53:37.875083]: [Epoch: 553(36.89126084056038%): Data: 0.0%]:Running loss: 0.21752029657363892
[2018-04-17 16:53:39.102346]: [Epoch: 553(36.89126084056038%): Data: 25.333333333333336%]:Running loss: 4.350405722856522
[2018-04-17 16:53:40.346655]: [Epoch: 553(36.89126084056038%): Data: 50.66666666666667%]:Running loss: 8.483291625976562
[2018-04-17 16:53:43.729650]: Test set accuracy: 94.33962264150944% ,loss = 5.438007041811943
[2018-04-17 16:53:43.838440]: ====================
[2018-04-17 16:53:43.843955]: Elapsed time since starting training: 0:58:29.239653
[2018-04-17 16:53:43.849469]: ====================
[2018-04-17 16:53:43.922163]: [Epoch: 554(36.95797198132088%): Data: 0.0%]:Running loss: 0.21752028167247772
[2018-04-17 16:53:45.132881]: [Epoch: 554(36.95797198132088%): Data: 25.333333333333336%]:Running loss: 4.350404918193817
[2018-04-17 16:53:46.376689]: [Epoch: 554(36.95797198132088%): Data: 50.66666666666667%]:Running loss: 8.483289808034897
[2018-04-17 16:53:49.777732]: Test set accuracy: 94.33962264150944% ,loss = 5.438006669282913
[2018-04-17 16:53:49.889530]: ====================
[2018-04-17 16:53:49.895044]: Elapsed time since starting training: 0:58:35.291243
[2018-04-17 16:53:49.900559]: ====================
[2018-04-17 16:53:49.976762]: [Epoch: 555(37.024683122081385%): Data: 0.0%]:Running loss: 0.21752026677131653
[2018-04-17 16:53:51.274211]: [Epoch: 555(37.024683122081385%): Data: 25.333333333333336%]:Running loss: 4.350404322147369
[2018-04-17 16:53:52.522530]: [Epoch: 555(37.024683122081385%): Data: 50.66666666666667%]:Running loss: 8.483287960290909
[2018-04-17 16:53:55.996769]: Test set accuracy: 94.33962264150944% ,loss = 5.438007041811943
[2018-04-17 16:53:56.105558]: ====================
[2018-04-17 16:53:56.111072]: Elapsed time since starting training: 0:58:41.507271
[2018-04-17 16:53:56.116587]: ====================
[2018-04-17 16:53:56.189281]: [Epoch: 556(37.091394262841895%): Data: 0.0%]:Running loss: 0.21752028167247772
[2018-04-17 16:53:57.428074]: [Epoch: 556(37.091394262841895%): Data: 25.333333333333336%]:Running loss: 4.350403428077698
[2018-04-17 16:53:58.663860]: [Epoch: 556(37.091394262841895%): Data: 50.66666666666667%]:Running loss: 8.483286559581757
[2018-04-17 16:54:02.090471]: Test set accuracy: 94.33962264150944% ,loss = 5.438002571463585
[2018-04-17 16:54:02.202269]: ====================
[2018-04-17 16:54:02.207282]: Elapsed time since starting training: 0:58:47.603481
[2018-04-17 16:54:02.212797]: ====================
[2018-04-17 16:54:02.279976]: [Epoch: 557(37.158105403602406%): Data: 0.0%]:Running loss: 0.2175201028585434
[2018-04-17 16:54:03.565894]: [Epoch: 557(37.158105403602406%): Data: 25.333333333333336%]:Running loss: 4.350403338670731
[2018-04-17 16:54:04.828251]: [Epoch: 557(37.158105403602406%): Data: 50.66666666666667%]:Running loss: 8.483286246657372
[2018-04-17 16:54:08.226788]: Test set accuracy: 94.33962264150944% ,loss = 5.438007041811943
[2018-04-17 16:54:08.336079]: ====================
[2018-04-17 16:54:08.341092]: Elapsed time since starting training: 0:58:53.737291
[2018-04-17 16:54:08.346607]: ====================
[2018-04-17 16:54:08.417796]: [Epoch: 558(37.22481654436291%): Data: 0.0%]:Running loss: 0.21752028167247772
[2018-04-17 16:54:09.691683]: [Epoch: 558(37.22481654436291%): Data: 25.333333333333336%]:Running loss: 4.350403219461441
[2018-04-17 16:54:10.941005]: [Epoch: 558(37.22481654436291%): Data: 50.66666666666667%]:Running loss: 8.483285129070282
[2018-04-17 16:54:14.367115]: Test set accuracy: 94.33962264150944% ,loss = 5.437999218702316
[2018-04-17 16:54:14.479414]: ====================
[2018-04-17 16:54:14.485429]: Elapsed time since starting training: 0:58:59.881628
[2018-04-17 16:54:14.490944]: ====================
[2018-04-17 16:54:14.558123]: [Epoch: 559(37.29152768512341%): Data: 0.0%]:Running loss: 0.21751996874809265
[2018-04-17 16:54:15.782879]: [Epoch: 559(37.29152768512341%): Data: 25.333333333333336%]:Running loss: 4.35040220618248
[2018-04-17 16:54:17.060276]: [Epoch: 559(37.29152768512341%): Data: 50.66666666666667%]:Running loss: 8.483285039663315
[2018-04-17 16:54:20.478365]: Test set accuracy: 94.33962264150944% ,loss = 5.438004434108734
[2018-04-17 16:54:20.671879]: ====================
[2018-04-17 16:54:20.677895]: Elapsed time since starting training: 0:59:06.074094
[2018-04-17 16:54:20.684413]: ====================
[2018-04-17 16:54:20.754599]: [Epoch: 560(37.35823882588392%): Data: 0.0%]:Running loss: 0.21752017736434937
[2018-04-17 16:54:22.006441]: [Epoch: 560(37.35823882588392%): Data: 25.333333333333336%]:Running loss: 4.350400969386101
[2018-04-17 16:54:23.247227]: [Epoch: 560(37.35823882588392%): Data: 50.66666666666667%]:Running loss: 8.483282685279846
[2018-04-17 16:54:26.681358]: Test set accuracy: 94.33962264150944% ,loss = 5.437997728586197
[2018-04-17 16:54:26.792654]: ====================
[2018-04-17 16:54:26.798169]: Elapsed time since starting training: 0:59:12.194368
[2018-04-17 16:54:26.804185]: ====================
[2018-04-17 16:54:26.876878]: [Epoch: 561(37.42494996664443%): Data: 0.0%]:Running loss: 0.21751990914344788
[2018-04-17 16:54:28.138232]: [Epoch: 561(37.42494996664443%): Data: 25.333333333333336%]:Running loss: 4.350400224328041
[2018-04-17 16:54:29.409613]: [Epoch: 561(37.42494996664443%): Data: 50.66666666666667%]:Running loss: 8.483280748128891
[2018-04-17 16:54:32.855776]: Test set accuracy: 94.33962264150944% ,loss = 5.438000708818436
[2018-04-17 16:54:32.967574]: ====================
[2018-04-17 16:54:32.973089]: Elapsed time since starting training: 0:59:18.369288
[2018-04-17 16:54:32.978603]: ====================
[2018-04-17 16:54:33.049792]: [Epoch: 562(37.49166110740494%): Data: 0.0%]:Running loss: 0.21752002835273743
[2018-04-17 16:54:34.317162]: [Epoch: 562(37.49166110740494%): Data: 25.333333333333336%]:Running loss: 4.35040058195591
[2018-04-17 16:54:35.578014]: [Epoch: 562(37.49166110740494%): Data: 50.66666666666667%]:Running loss: 8.48328024148941
[2018-04-17 16:54:38.992594]: Test set accuracy: 94.33962264150944% ,loss = 5.438002943992615
[2018-04-17 16:54:39.107901]: ====================
[2018-04-17 16:54:39.113917]: Elapsed time since starting training: 0:59:24.510116
[2018-04-17 16:54:39.118429]: ====================
[2018-04-17 16:54:39.193127]: [Epoch: 563(37.55837224816545%): Data: 0.0%]:Running loss: 0.2175201177597046
[2018-04-17 16:54:40.411869]: [Epoch: 563(37.55837224816545%): Data: 25.333333333333336%]:Running loss: 4.3503991812467575
[2018-04-17 16:54:41.666704]: [Epoch: 563(37.55837224816545%): Data: 50.66666666666667%]:Running loss: 8.483278945088387
[2018-04-17 16:54:45.026639]: Test set accuracy: 94.33962264150944% ,loss = 5.437994748353958
[2018-04-17 16:54:45.139951]: ====================
[2018-04-17 16:54:45.145956]: Elapsed time since starting training: 0:59:30.541654
[2018-04-17 16:54:45.151470]: ====================
[2018-04-17 16:54:45.223161]: [Epoch: 564(37.62508338892595%): Data: 0.0%]:Running loss: 0.21751978993415833
[2018-04-17 16:54:46.461454]: [Epoch: 564(37.62508338892595%): Data: 25.333333333333336%]:Running loss: 4.350398436188698
[2018-04-17 16:54:47.719800]: [Epoch: 564(37.62508338892595%): Data: 50.66666666666667%]:Running loss: 8.483278304338455
[2018-04-17 16:54:51.139397]: Test set accuracy: 94.33962264150944% ,loss = 5.437999218702316
[2018-04-17 16:54:51.252699]: ====================
[2018-04-17 16:54:51.258213]: Elapsed time since starting training: 0:59:36.653911
[2018-04-17 16:54:51.263239]: ====================
[2018-04-17 16:54:51.337925]: [Epoch: 565(37.691794529686454%): Data: 0.0%]:Running loss: 0.21751996874809265
[2018-04-17 16:54:52.599279]: [Epoch: 565(37.691794529686454%): Data: 25.333333333333336%]:Running loss: 4.3503997921943665
[2018-04-17 16:54:53.855118]: [Epoch: 565(37.691794529686454%): Data: 50.66666666666667%]:Running loss: 8.48327787220478
[2018-04-17 16:54:57.281228]: Test set accuracy: 94.33962264150944% ,loss = 5.437999963760376
[2018-04-17 16:54:57.388514]: ====================
[2018-04-17 16:54:57.394028]: Elapsed time since starting training: 0:59:42.790227
[2018-04-17 16:54:57.399543]: ====================
[2018-04-17 16:54:57.472236]: [Epoch: 566(37.758505670446965%): Data: 0.0%]:Running loss: 0.21751999855041504
[2018-04-17 16:54:58.723564]: [Epoch: 566(37.758505670446965%): Data: 25.333333333333336%]:Running loss: 4.350400030612946
[2018-04-17 16:54:59.963360]: [Epoch: 566(37.758505670446965%): Data: 50.66666666666667%]:Running loss: 8.483278021216393
[2018-04-17 16:55:03.399998]: Test set accuracy: 94.33962264150944% ,loss = 5.437993630766869
[2018-04-17 16:55:03.508787]: ====================
[2018-04-17 16:55:03.514302]: Elapsed time since starting training: 0:59:48.910501
[2018-04-17 16:55:03.519817]: ====================
[2018-04-17 16:55:03.593512]: [Epoch: 567(37.825216811207476%): Data: 0.0%]:Running loss: 0.21751974523067474
[2018-04-17 16:55:04.841832]: [Epoch: 567(37.825216811207476%): Data: 25.333333333333336%]:Running loss: 4.35039784014225
[2018-04-17 16:55:06.095666]: [Epoch: 567(37.825216811207476%): Data: 50.66666666666667%]:Running loss: 8.483276814222336
[2018-04-17 16:55:09.505733]: Test set accuracy: 94.33962264150944% ,loss = 5.4379962384700775
[2018-04-17 16:55:09.615036]: ====================
[2018-04-17 16:55:09.620538]: Elapsed time since starting training: 0:59:55.016737
[2018-04-17 16:55:09.626060]: ====================
[2018-04-17 16:55:09.698746]: [Epoch: 568(37.89192795196798%): Data: 0.0%]:Running loss: 0.2175198495388031
[2018-04-17 16:55:10.958095]: [Epoch: 568(37.89192795196798%): Data: 25.333333333333336%]:Running loss: 4.350397810339928
[2018-04-17 16:55:12.206414]: [Epoch: 568(37.89192795196798%): Data: 50.66666666666667%]:Running loss: 8.483276665210724
[2018-04-17 16:55:15.631522]: Test set accuracy: 94.33962264150944% ,loss = 5.437999963760376
[2018-04-17 16:55:15.742316]: ====================
[2018-04-17 16:55:15.748332]: Elapsed time since starting training: 1:00:01.144531
[2018-04-17 16:55:15.753847]: ====================
[2018-04-17 16:55:15.826540]: [Epoch: 569(37.95863909272848%): Data: 0.0%]:Running loss: 0.21751999855041504
[2018-04-17 16:55:17.082880]: [Epoch: 569(37.95863909272848%): Data: 25.333333333333336%]:Running loss: 4.350397855043411
[2018-04-17 16:55:18.324682]: [Epoch: 569(37.95863909272848%): Data: 50.66666666666667%]:Running loss: 8.483274802565575
[2018-04-17 16:55:21.734750]: Test set accuracy: 94.33962264150944% ,loss = 5.437992513179779
[2018-04-17 16:55:21.846547]: ====================
[2018-04-17 16:55:21.852062]: Elapsed time since starting training: 1:00:07.247759
[2018-04-17 16:55:21.858078]: ====================
[2018-04-17 16:55:21.931272]: [Epoch: 570(38.02535023348899%): Data: 0.0%]:Running loss: 0.21751970052719116
[2018-04-17 16:55:23.175079]: [Epoch: 570(38.02535023348899%): Data: 25.333333333333336%]:Running loss: 4.3503971844911575
[2018-04-17 16:55:24.441447]: [Epoch: 570(38.02535023348899%): Data: 50.66666666666667%]:Running loss: 8.483274474740028
[2018-04-17 16:55:27.859535]: Test set accuracy: 94.33962264150944% ,loss = 5.437995865941048
[2018-04-17 16:55:27.971834]: ====================
[2018-04-17 16:55:27.977349]: Elapsed time since starting training: 1:00:13.373548
[2018-04-17 16:55:27.982864]: ====================
[2018-04-17 16:55:28.056058]: [Epoch: 571(38.0920613742495%): Data: 0.0%]:Running loss: 0.2175198346376419
[2018-04-17 16:55:29.297359]: [Epoch: 571(38.0920613742495%): Data: 25.333333333333336%]:Running loss: 4.350395888090134
[2018-04-17 16:55:30.563224]: [Epoch: 571(38.0920613742495%): Data: 50.66666666666667%]:Running loss: 8.483273312449455
[2018-04-17 16:55:33.969782]: Test set accuracy: 94.33962264150944% ,loss = 5.437998473644257
[2018-04-17 16:55:34.079074]: ====================
[2018-04-17 16:55:34.084588]: Elapsed time since starting training: 1:00:19.480787
[2018-04-17 16:55:34.090103]: ====================
[2018-04-17 16:55:34.162796]: [Epoch: 572(38.15877251501001%): Data: 0.0%]:Running loss: 0.21751993894577026
[2018-04-17 16:55:35.409611]: [Epoch: 572(38.15877251501001%): Data: 25.333333333333336%]:Running loss: 4.350395753979683
[2018-04-17 16:55:36.672469]: [Epoch: 572(38.15877251501001%): Data: 50.66666666666667%]:Running loss: 8.483271136879921
[2018-04-17 16:55:40.060979]: Test set accuracy: 94.33962264150944% ,loss = 5.437988787889481
[2018-04-17 16:55:40.176787]: ====================
[2018-04-17 16:55:40.182302]: Elapsed time since starting training: 1:00:25.578000
[2018-04-17 16:55:40.187327]: ====================
[2018-04-17 16:55:40.257000]: [Epoch: 573(38.22548365577052%): Data: 0.0%]:Running loss: 0.21751955151557922
[2018-04-17 16:55:41.489277]: [Epoch: 573(38.22548365577052%): Data: 25.333333333333336%]:Running loss: 4.350395008921623
[2018-04-17 16:55:42.707015]: [Epoch: 573(38.22548365577052%): Data: 50.66666666666667%]:Running loss: 8.483270347118378
[2018-04-17 16:55:46.105050]: Test set accuracy: 94.33962264150944% ,loss = 5.437993258237839
[2018-04-17 16:55:46.215844]: ====================
[2018-04-17 16:55:46.221360]: Elapsed time since starting training: 1:00:31.617559
[2018-04-17 16:55:46.226874]: ====================
[2018-04-17 16:55:46.299567]: [Epoch: 574(38.29219479653102%): Data: 0.0%]:Running loss: 0.21751973032951355
[2018-04-17 16:55:47.551909]: [Epoch: 574(38.29219479653102%): Data: 25.333333333333336%]:Running loss: 4.35039459168911
[2018-04-17 16:55:48.795716]: [Epoch: 574(38.29219479653102%): Data: 50.66666666666667%]:Running loss: 8.48327000439167
[2018-04-17 16:55:52.244386]: Test set accuracy: 94.33962264150944% ,loss = 5.437994748353958
[2018-04-17 16:55:52.358191]: ====================
[2018-04-17 16:55:52.364205]: Elapsed time since starting training: 1:00:37.759903
[2018-04-17 16:55:52.369218]: ====================
[2018-04-17 16:55:52.435896]: [Epoch: 575(38.358905937291524%): Data: 0.0%]:Running loss: 0.21751978993415833
[2018-04-17 16:55:53.691233]: [Epoch: 575(38.358905937291524%): Data: 25.333333333333336%]:Running loss: 4.350395560264587
[2018-04-17 16:55:54.928523]: [Epoch: 575(38.358905937291524%): Data: 50.66666666666667%]:Running loss: 8.483270093798637
[2018-04-17 16:55:58.335582]: Test set accuracy: 94.33962264150944% ,loss = 5.437998473644257
[2018-04-17 16:55:58.448383]: ====================
[2018-04-17 16:55:58.454399]: Elapsed time since starting training: 1:00:43.850598
[2018-04-17 16:55:58.460423]: ====================
[2018-04-17 16:55:58.534618]: [Epoch: 576(38.425617078052035%): Data: 0.0%]:Running loss: 0.21751993894577026
[2018-04-17 16:55:59.778920]: [Epoch: 576(38.425617078052035%): Data: 25.333333333333336%]:Running loss: 4.350395128130913
[2018-04-17 16:56:01.012199]: [Epoch: 576(38.425617078052035%): Data: 50.66666666666667%]:Running loss: 8.483269348740578
[2018-04-17 16:56:04.447334]: Test set accuracy: 94.33962264150944% ,loss = 5.437988042831421
[2018-04-17 16:56:04.561642]: ====================
[2018-04-17 16:56:04.567152]: Elapsed time since starting training: 1:00:49.962850
[2018-04-17 16:56:04.572667]: ====================
[2018-04-17 16:56:04.647867]: [Epoch: 577(38.492328218812546%): Data: 0.0%]:Running loss: 0.21751952171325684
[2018-04-17 16:56:05.912730]: [Epoch: 577(38.492328218812546%): Data: 25.333333333333336%]:Running loss: 4.3503933399915695
[2018-04-17 16:56:07.150528]: [Epoch: 577(38.492328218812546%): Data: 50.66666666666667%]:Running loss: 8.48326887190342
[2018-04-17 16:56:10.561591]: Test set accuracy: 94.33962264150944% ,loss = 5.437991768121719
[2018-04-17 16:56:10.672889]: ====================
[2018-04-17 16:56:10.678402]: Elapsed time since starting training: 1:00:56.074100
[2018-04-17 16:56:10.683415]: ====================
[2018-04-17 16:56:10.757112]: [Epoch: 578(38.55903935957305%): Data: 0.0%]:Running loss: 0.21751967072486877
[2018-04-17 16:56:12.021974]: [Epoch: 578(38.55903935957305%): Data: 25.333333333333336%]:Running loss: 4.350393399596214
[2018-04-17 16:56:13.294859]: [Epoch: 578(38.55903935957305%): Data: 50.66666666666667%]:Running loss: 8.483267158269882
[2018-04-17 16:56:16.719966]: Test set accuracy: 94.33962264150944% ,loss = 5.437993630766869
[2018-04-17 16:56:16.840286]: ====================
[2018-04-17 16:56:16.846303]: Elapsed time since starting training: 1:01:02.242000
[2018-04-17 16:56:16.851818]: ====================
[2018-04-17 16:56:16.926023]: [Epoch: 579(38.62575050033355%): Data: 0.0%]:Running loss: 0.21751974523067474
[2018-04-17 16:56:18.184360]: [Epoch: 579(38.62575050033355%): Data: 25.333333333333336%]:Running loss: 4.350393012166023
[2018-04-17 16:56:19.429170]: [Epoch: 579(38.62575050033355%): Data: 50.66666666666667%]:Running loss: 8.483265712857246
[2018-04-17 16:56:22.874331]: Test set accuracy: 94.33962264150944% ,loss = 5.437986180186272
[2018-04-17 16:56:22.986128]: ====================
[2018-04-17 16:56:22.992145]: Elapsed time since starting training: 1:01:08.387842
[2018-04-17 16:56:22.997157]: ====================
[2018-04-17 16:56:23.071856]: [Epoch: 580(38.69246164109406%): Data: 0.0%]:Running loss: 0.21751944720745087
[2018-04-17 16:56:24.333210]: [Epoch: 580(38.69246164109406%): Data: 25.333333333333336%]:Running loss: 4.350392296910286
[2018-04-17 16:56:25.579524]: [Epoch: 580(38.69246164109406%): Data: 50.66666666666667%]:Running loss: 8.483265578746796
[2018-04-17 16:56:29.005634]: Test set accuracy: 94.33962264150944% ,loss = 5.43798916041851
[2018-04-17 16:56:29.115426]: ====================
[2018-04-17 16:56:29.120941]: Elapsed time since starting training: 1:01:14.517140
[2018-04-17 16:56:29.126456]: ====================
[2018-04-17 16:56:29.198647]: [Epoch: 581(38.759172781854566%): Data: 0.0%]:Running loss: 0.21751956641674042
[2018-04-17 16:56:30.440950]: [Epoch: 581(38.759172781854566%): Data: 25.333333333333336%]:Running loss: 4.350392207503319
[2018-04-17 16:56:31.687765]: [Epoch: 581(38.759172781854566%): Data: 50.66666666666667%]:Running loss: 8.483265534043312
[2018-04-17 16:56:35.098338]: Test set accuracy: 94.33962264150944% ,loss = 5.437991768121719
[2018-04-17 16:56:35.211640]: ====================
[2018-04-17 16:56:35.217154]: Elapsed time since starting training: 1:01:20.613353
[2018-04-17 16:56:35.222167]: ====================
[2018-04-17 16:56:35.287340]: [Epoch: 582(38.82588392261508%): Data: 0.0%]:Running loss: 0.21751967072486877
[2018-04-17 16:56:36.543681]: [Epoch: 582(38.82588392261508%): Data: 25.333333333333336%]:Running loss: 4.350392237305641
[2018-04-17 16:56:37.795008]: [Epoch: 582(38.82588392261508%): Data: 50.66666666666667%]:Running loss: 8.48326325416565
[2018-04-17 16:56:41.011561]: Test set accuracy: 94.33962264150944% ,loss = 5.437993258237839
[2018-04-17 16:56:41.127870]: ====================
[2018-04-17 16:56:41.133386]: Elapsed time since starting training: 1:01:26.529585
[2018-04-17 16:56:41.142409]: ====================
[2018-04-17 16:56:41.207081]: [Epoch: 583(38.89259506337559%): Data: 0.0%]:Running loss: 0.21751973032951355
[2018-04-17 16:56:42.395742]: [Epoch: 583(38.89259506337559%): Data: 25.333333333333336%]:Running loss: 4.3503928780555725
[2018-04-17 16:56:43.637544]: [Epoch: 583(38.89259506337559%): Data: 50.66666666666667%]:Running loss: 8.48326413333416
[2018-04-17 16:56:47.058139]: Test set accuracy: 94.33962264150944% ,loss = 5.437985435128212
[2018-04-17 16:56:47.175451]: ====================
[2018-04-17 16:56:47.180966]: Elapsed time since starting training: 1:01:32.577165
[2018-04-17 16:56:47.186481]: ====================
[2018-04-17 16:56:47.258176]: [Epoch: 584(38.95930620413609%): Data: 0.0%]:Running loss: 0.21751941740512848
[2018-04-17 16:56:48.495964]: [Epoch: 584(38.95930620413609%): Data: 25.333333333333336%]:Running loss: 4.350390687584877
[2018-04-17 16:56:49.742276]: [Epoch: 584(38.95930620413609%): Data: 50.66666666666667%]:Running loss: 8.483263239264488
[2018-04-17 16:56:53.135298]: Test set accuracy: 94.33962264150944% ,loss = 5.437987297773361
[2018-04-17 16:56:53.251106]: ====================
[2018-04-17 16:56:53.257123]: Elapsed time since starting training: 1:01:38.652820
[2018-04-17 16:56:53.262636]: ====================
[2018-04-17 16:56:53.333830]: [Epoch: 585(39.026017344896594%): Data: 0.0%]:Running loss: 0.21751949191093445
[2018-04-17 16:56:54.585153]: [Epoch: 585(39.026017344896594%): Data: 25.333333333333336%]:Running loss: 4.350390613079071
[2018-04-17 16:56:55.842496]: [Epoch: 585(39.026017344896594%): Data: 50.66666666666667%]:Running loss: 8.483262866735458
[2018-04-17 16:56:59.263092]: Test set accuracy: 94.33962264150944% ,loss = 5.43798953294754
[2018-04-17 16:56:59.372884]: ====================
[2018-04-17 16:56:59.378398]: Elapsed time since starting training: 1:01:44.774097
[2018-04-17 16:56:59.383914]: ====================
[2018-04-17 16:56:59.457609]: [Epoch: 586(39.092728485657105%): Data: 0.0%]:Running loss: 0.2175195813179016
[2018-04-17 16:57:00.691389]: [Epoch: 586(39.092728485657105%): Data: 25.333333333333336%]:Running loss: 4.350391671061516
[2018-04-17 16:57:01.947229]: [Epoch: 586(39.092728485657105%): Data: 50.66666666666667%]:Running loss: 8.483262211084366
[2018-04-17 16:57:05.349784]: Test set accuracy: 94.33962264150944% ,loss = 5.437981337308884
[2018-04-17 16:57:05.467598]: ====================
[2018-04-17 16:57:05.473112]: Elapsed time since starting training: 1:01:50.869311
[2018-04-17 16:57:05.479129]: ====================
[2018-04-17 16:57:05.554328]: [Epoch: 587(39.159439626417615%): Data: 0.0%]:Running loss: 0.21751925349235535
[2018-04-17 16:57:06.798136]: [Epoch: 587(39.159439626417615%): Data: 25.333333333333336%]:Running loss: 4.350389838218689
[2018-04-17 16:57:08.063500]: [Epoch: 587(39.159439626417615%): Data: 50.66666666666667%]:Running loss: 8.483260035514832
[2018-04-17 16:57:11.502144]: Test set accuracy: 94.33962264150944% ,loss = 5.437983572483063
[2018-04-17 16:57:11.614442]: ====================
[2018-04-17 16:57:11.619957]: Elapsed time since starting training: 1:01:57.015655
[2018-04-17 16:57:11.624971]: ====================
[2018-04-17 16:57:11.699168]: [Epoch: 588(39.22615076717812%): Data: 0.0%]:Running loss: 0.2175193428993225
[2018-04-17 16:57:12.979748]: [Epoch: 588(39.22615076717812%): Data: 25.333333333333336%]:Running loss: 4.3503885716199875
[2018-04-17 16:57:14.285219]: [Epoch: 588(39.22615076717812%): Data: 50.66666666666667%]:Running loss: 8.483259916305542
[2018-04-17 16:57:17.807084]: Test set accuracy: 94.33962264150944% ,loss = 5.437985062599182
[2018-04-17 16:57:17.924396]: ====================
[2018-04-17 16:57:17.930412]: Elapsed time since starting training: 1:02:03.326611
[2018-04-17 16:57:17.936429]: ====================
[2018-04-17 16:57:18.006614]: [Epoch: 589(39.29286190793862%): Data: 0.0%]:Running loss: 0.21751940250396729
[2018-04-17 16:57:19.292033]: [Epoch: 589(39.29286190793862%): Data: 25.333333333333336%]:Running loss: 4.350389406085014
[2018-04-17 16:57:20.576949]: [Epoch: 589(39.29286190793862%): Data: 50.66666666666667%]:Running loss: 8.483258798718452
[2018-04-17 16:57:24.102824]: Test set accuracy: 94.33962264150944% ,loss = 5.437986925244331
[2018-04-17 16:57:24.215123]: ====================
[2018-04-17 16:57:24.220638]: Elapsed time since starting training: 1:02:09.616837
[2018-04-17 16:57:24.225651]: ====================
[2018-04-17 16:57:24.299848]: [Epoch: 590(39.35957304869913%): Data: 0.0%]:Running loss: 0.21751947700977325
[2018-04-17 16:57:25.557192]: [Epoch: 590(39.35957304869913%): Data: 25.333333333333336%]:Running loss: 4.350389197468758
[2018-04-17 16:57:26.841606]: [Epoch: 590(39.35957304869913%): Data: 50.66666666666667%]:Running loss: 8.483257830142975
[2018-04-17 16:57:30.361967]: Test set accuracy: 94.33962264150944% ,loss = 5.437988042831421
[2018-04-17 16:57:30.481286]: ====================
[2018-04-17 16:57:30.486812]: Elapsed time since starting training: 1:02:15.883011
[2018-04-17 16:57:30.492816]: ====================
[2018-04-17 16:57:30.566512]: [Epoch: 591(39.426284189459636%): Data: 0.0%]:Running loss: 0.21751952171325684
[2018-04-17 16:57:31.850926]: [Epoch: 591(39.426284189459636%): Data: 25.333333333333336%]:Running loss: 4.350388929247856
[2018-04-17 16:57:33.148877]: [Epoch: 591(39.426284189459636%): Data: 50.66666666666667%]:Running loss: 8.483258292078972
[2018-04-17 16:57:36.670743]: Test set accuracy: 94.33962264150944% ,loss = 5.437980592250824
[2018-04-17 16:57:36.781538]: ====================
[2018-04-17 16:57:36.787052]: Elapsed time since starting training: 1:02:22.183251
[2018-04-17 16:57:36.793068]: ====================
[2018-04-17 16:57:36.865761]: [Epoch: 592(39.49299533022015%): Data: 0.0%]:Running loss: 0.21751922369003296
[2018-04-17 16:57:38.122101]: [Epoch: 592(39.49299533022015%): Data: 25.333333333333336%]:Running loss: 4.350388243794441
[2018-04-17 16:57:39.408021]: [Epoch: 592(39.49299533022015%): Data: 50.66666666666667%]:Running loss: 8.483256831765175
[2018-04-17 16:57:42.877245]: Test set accuracy: 94.33962264150944% ,loss = 5.437979474663734
[2018-04-17 16:57:42.994557]: ====================
[2018-04-17 16:57:42.999571]: Elapsed time since starting training: 1:02:28.395770
[2018-04-17 16:57:43.008093]: ====================
[2018-04-17 16:57:43.080786]: [Epoch: 593(39.55970647098066%): Data: 0.0%]:Running loss: 0.21751917898654938
[2018-04-17 16:57:44.338631]: [Epoch: 593(39.55970647098066%): Data: 25.333333333333336%]:Running loss: 4.350387871265411
[2018-04-17 16:57:45.620038]: [Epoch: 593(39.55970647098066%): Data: 50.66666666666667%]:Running loss: 8.483256340026855
[2018-04-17 16:57:49.138394]: Test set accuracy: 94.33962264150944% ,loss = 5.437986925244331
[2018-04-17 16:57:49.252698]: ====================
[2018-04-17 16:57:49.257711]: Elapsed time since starting training: 1:02:34.653910
[2018-04-17 16:57:49.263226]: ====================
[2018-04-17 16:57:49.337423]: [Epoch: 594(39.62641761174116%): Data: 0.0%]:Running loss: 0.21751947700977325
[2018-04-17 16:57:50.613817]: [Epoch: 594(39.62641761174116%): Data: 25.333333333333336%]:Running loss: 4.35038860142231
[2018-04-17 16:57:51.896728]: [Epoch: 594(39.62641761174116%): Data: 50.66666666666667%]:Running loss: 8.48325628042221
[2018-04-17 16:57:55.411574]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 16:57:55.527382]: ====================
[2018-04-17 16:57:55.532897]: Elapsed time since starting training: 1:02:40.928594
[2018-04-17 16:57:55.538411]: ====================
[2018-04-17 16:57:55.612108]: [Epoch: 595(39.693128752501664%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 16:57:56.898528]: [Epoch: 595(39.693128752501664%): Data: 25.333333333333336%]:Running loss: 4.350388526916504
[2018-04-17 16:57:58.179935]: [Epoch: 595(39.693128752501664%): Data: 50.66666666666667%]:Running loss: 8.483256593346596
[2018-04-17 16:58:01.688765]: Test set accuracy: 94.33962264150944% ,loss = 5.437987297773361
[2018-04-17 16:58:01.801064]: ====================
[2018-04-17 16:58:01.806077]: Elapsed time since starting training: 1:02:47.202276
[2018-04-17 16:58:01.811592]: ====================
[2018-04-17 16:58:01.885288]: [Epoch: 596(39.759839893262175%): Data: 0.0%]:Running loss: 0.21751949191093445
[2018-04-17 16:58:03.176721]: [Epoch: 596(39.759839893262175%): Data: 25.333333333333336%]:Running loss: 4.350386843085289
[2018-04-17 16:58:04.461137]: [Epoch: 596(39.759839893262175%): Data: 50.66666666666667%]:Running loss: 8.483254373073578
[2018-04-17 16:58:08.032633]: Test set accuracy: 94.33962264150944% ,loss = 5.437982827425003
[2018-04-17 16:58:08.243194]: ====================
[2018-04-17 16:58:08.249209]: Elapsed time since starting training: 1:02:53.644908
[2018-04-17 16:58:08.255225]: ====================
[2018-04-17 16:58:08.326415]: [Epoch: 597(39.826551034022685%): Data: 0.0%]:Running loss: 0.21751931309700012
[2018-04-17 16:58:09.599800]: [Epoch: 597(39.826551034022685%): Data: 25.333333333333336%]:Running loss: 4.350386619567871
[2018-04-17 16:58:10.885720]: [Epoch: 597(39.826551034022685%): Data: 50.66666666666667%]:Running loss: 8.483253419399261
[2018-04-17 16:58:14.427136]: Test set accuracy: 94.33962264150944% ,loss = 5.437978729605675
[2018-04-17 16:58:14.539436]: ====================
[2018-04-17 16:58:14.544950]: Elapsed time since starting training: 1:02:59.940647
[2018-04-17 16:58:14.549962]: ====================
[2018-04-17 16:58:14.626667]: [Epoch: 598(39.89326217478319%): Data: 0.0%]:Running loss: 0.217519149184227
[2018-04-17 16:58:15.925620]: [Epoch: 598(39.89326217478319%): Data: 25.333333333333336%]:Running loss: 4.350385755300522
[2018-04-17 16:58:17.200009]: [Epoch: 598(39.89326217478319%): Data: 50.66666666666667%]:Running loss: 8.48325315117836
[2018-04-17 16:58:20.713351]: Test set accuracy: 94.33962264150944% ,loss = 5.437986180186272
[2018-04-17 16:58:20.828658]: ====================
[2018-04-17 16:58:20.835175]: Elapsed time since starting training: 1:03:06.231374
[2018-04-17 16:58:20.840690]: ====================
[2018-04-17 16:58:20.915891]: [Epoch: 599(39.95997331554369%): Data: 0.0%]:Running loss: 0.21751944720745087
[2018-04-17 16:58:22.206321]: [Epoch: 599(39.95997331554369%): Data: 25.333333333333336%]:Running loss: 4.350385740399361
[2018-04-17 16:58:23.490235]: [Epoch: 599(39.95997331554369%): Data: 50.66666666666667%]:Running loss: 8.483252853155136
[2018-04-17 16:58:26.990542]: Test set accuracy: 94.33962264150944% ,loss = 5.437981337308884
[2018-04-17 16:58:27.105850]: ====================
[2018-04-17 16:58:27.111364]: Elapsed time since starting training: 1:03:12.507061
[2018-04-17 16:58:27.116878]: ====================
[2018-04-17 16:58:27.191076]: [Epoch: 600(40.0266844563042%): Data: 0.0%]:Running loss: 0.21751925349235535
[2018-04-17 16:58:28.482515]: [Epoch: 600(40.0266844563042%): Data: 25.333333333333336%]:Running loss: 4.3503874987363815
[2018-04-17 16:58:29.764418]: [Epoch: 600(40.0266844563042%): Data: 50.66666666666667%]:Running loss: 8.483255550265312
[2018-04-17 16:58:33.252192]: Test set accuracy: 94.33962264150944% ,loss = 5.437986180186272
[2018-04-17 16:58:33.365493]: ====================
[2018-04-17 16:58:33.371008]: Elapsed time since starting training: 1:03:18.767207
[2018-04-17 16:58:33.376523]: ====================
[2018-04-17 16:58:33.448213]: [Epoch: 601(40.093395597064706%): Data: 0.0%]:Running loss: 0.21751944720745087
[2018-04-17 16:58:34.745161]: [Epoch: 601(40.093395597064706%): Data: 25.333333333333336%]:Running loss: 4.350386157631874
[2018-04-17 16:58:36.047625]: [Epoch: 601(40.093395597064706%): Data: 50.66666666666667%]:Running loss: 8.48325303196907
[2018-04-17 16:58:39.519858]: Test set accuracy: 94.33962264150944% ,loss = 5.437983945012093
[2018-04-17 16:58:39.632156]: ====================
[2018-04-17 16:58:39.638172]: Elapsed time since starting training: 1:03:25.034371
[2018-04-17 16:58:39.643687]: ====================
[2018-04-17 16:58:39.715879]: [Epoch: 602(40.16010673782522%): Data: 0.0%]:Running loss: 0.2175193578004837
[2018-04-17 16:58:40.987768]: [Epoch: 602(40.16010673782522%): Data: 25.333333333333336%]:Running loss: 4.350386336445808
[2018-04-17 16:58:42.240091]: [Epoch: 602(40.16010673782522%): Data: 50.66666666666667%]:Running loss: 8.483252331614494
[2018-04-17 16:58:45.703801]: Test set accuracy: 94.33962264150944% ,loss = 5.437977984547615
[2018-04-17 16:58:45.821113]: ====================
[2018-04-17 16:58:45.826627]: Elapsed time since starting training: 1:03:31.222826
[2018-04-17 16:58:45.832644]: ====================
[2018-04-17 16:58:45.903836]: [Epoch: 603(40.22681787858573%): Data: 0.0%]:Running loss: 0.2175191193819046
[2018-04-17 16:58:47.215821]: [Epoch: 603(40.22681787858573%): Data: 25.333333333333336%]:Running loss: 4.350385293364525
[2018-04-17 16:58:48.512769]: [Epoch: 603(40.22681787858573%): Data: 50.66666666666667%]:Running loss: 8.483251258730888
[2018-04-17 16:58:52.096799]: Test set accuracy: 94.33962264150944% ,loss = 5.437984690070152
[2018-04-17 16:58:52.210102]: ====================
[2018-04-17 16:58:52.215114]: Elapsed time since starting training: 1:03:37.611313
[2018-04-17 16:58:52.220629]: ====================
[2018-04-17 16:58:52.292319]: [Epoch: 604(40.29352901934623%): Data: 0.0%]:Running loss: 0.2175193876028061
[2018-04-17 16:58:53.618345]: [Epoch: 604(40.29352901934623%): Data: 25.333333333333336%]:Running loss: 4.350385174155235
[2018-04-17 16:58:54.908275]: [Epoch: 604(40.29352901934623%): Data: 50.66666666666667%]:Running loss: 8.483249917626381
[2018-04-17 16:58:58.460721]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 16:58:58.570513]: ====================
[2018-04-17 16:58:58.576529]: Elapsed time since starting training: 1:03:43.972728
[2018-04-17 16:58:58.581542]: ====================
[2018-04-17 16:58:58.655238]: [Epoch: 605(40.360240160106734%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 16:58:59.957702]: [Epoch: 605(40.360240160106734%): Data: 25.333333333333336%]:Running loss: 4.350385025143623
[2018-04-17 16:59:01.248133]: [Epoch: 605(40.360240160106734%): Data: 50.66666666666667%]:Running loss: 8.483251944184303
[2018-04-17 16:59:04.821635]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 16:59:04.936942]: ====================
[2018-04-17 16:59:04.942456]: Elapsed time since starting training: 1:03:50.338655
[2018-04-17 16:59:04.947971]: ====================
[2018-04-17 16:59:05.022670]: [Epoch: 606(40.426951300867245%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 16:59:06.325634]: [Epoch: 606(40.426951300867245%): Data: 25.333333333333336%]:Running loss: 4.350383952260017
[2018-04-17 16:59:07.610550]: [Epoch: 606(40.426951300867245%): Data: 50.66666666666667%]:Running loss: 8.483250260353088
[2018-04-17 16:59:11.134420]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 16:59:11.248725]: ====================
[2018-04-17 16:59:11.254239]: Elapsed time since starting training: 1:03:56.650438
[2018-04-17 16:59:11.259754]: ====================
[2018-04-17 16:59:11.337462]: [Epoch: 607(40.493662441627755%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 16:59:12.642932]: [Epoch: 607(40.493662441627755%): Data: 25.333333333333336%]:Running loss: 4.350385710597038
[2018-04-17 16:59:13.937874]: [Epoch: 607(40.493662441627755%): Data: 50.66666666666667%]:Running loss: 8.483251139521599
[2018-04-17 16:59:17.495835]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 16:59:17.610140]: ====================
[2018-04-17 16:59:17.615655]: Elapsed time since starting training: 1:04:03.011352
[2018-04-17 16:59:17.620677]: ====================
[2018-04-17 16:59:17.694864]: [Epoch: 608(40.56037358238826%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 16:59:18.987301]: [Epoch: 608(40.56037358238826%): Data: 25.333333333333336%]:Running loss: 4.350384294986725
[2018-04-17 16:59:20.289764]: [Epoch: 608(40.56037358238826%): Data: 50.66666666666667%]:Running loss: 8.483249321579933
[2018-04-17 16:59:23.823160]: Test set accuracy: 94.33962264150944% ,loss = 5.437983572483063
[2018-04-17 16:59:23.938968]: ====================
[2018-04-17 16:59:23.945485]: Elapsed time since starting training: 1:04:09.341183
[2018-04-17 16:59:23.951000]: ====================
[2018-04-17 16:59:24.025698]: [Epoch: 609(40.62708472314876%): Data: 0.0%]:Running loss: 0.2175193428993225
[2018-04-17 16:59:25.306103]: [Epoch: 609(40.62708472314876%): Data: 25.333333333333336%]:Running loss: 4.3503845781087875
[2018-04-17 16:59:26.608566]: [Epoch: 609(40.62708472314876%): Data: 50.66666666666667%]:Running loss: 8.483248382806778
[2018-04-17 16:59:30.180063]: Test set accuracy: 94.33962264150944% ,loss = 5.437978729605675
[2018-04-17 16:59:30.297876]: ====================
[2018-04-17 16:59:30.303892]: Elapsed time since starting training: 1:04:15.699589
[2018-04-17 16:59:30.309407]: ====================
[2018-04-17 16:59:30.383604]: [Epoch: 610(40.69379586390927%): Data: 0.0%]:Running loss: 0.217519149184227
[2018-04-17 16:59:31.663507]: [Epoch: 610(40.69379586390927%): Data: 25.333333333333336%]:Running loss: 4.350384503602982
[2018-04-17 16:59:32.978002]: [Epoch: 610(40.69379586390927%): Data: 50.66666666666667%]:Running loss: 8.483250513672829
[2018-04-17 16:59:36.538474]: Test set accuracy: 94.33962264150944% ,loss = 5.437973141670227
[2018-04-17 16:59:36.650773]: ====================
[2018-04-17 16:59:36.656287]: Elapsed time since starting training: 1:04:22.052486
[2018-04-17 16:59:36.662303]: ====================
[2018-04-17 16:59:36.737002]: [Epoch: 611(40.76050700466978%): Data: 0.0%]:Running loss: 0.21751892566680908
[2018-04-17 16:59:38.019412]: [Epoch: 611(40.76050700466978%): Data: 25.333333333333336%]:Running loss: 4.35038261115551
[2018-04-17 16:59:39.316360]: [Epoch: 611(40.76050700466978%): Data: 50.66666666666667%]:Running loss: 8.483248442411423
[2018-04-17 16:59:42.813664]: Test set accuracy: 94.33962264150944% ,loss = 5.437978357076645
[2018-04-17 16:59:42.929473]: ====================
[2018-04-17 16:59:42.934987]: Elapsed time since starting training: 1:04:28.331186
[2018-04-17 16:59:42.940000]: ====================
[2018-04-17 16:59:43.013697]: [Epoch: 612(40.82721814543029%): Data: 0.0%]:Running loss: 0.2175191342830658
[2018-04-17 16:59:44.301119]: [Epoch: 612(40.82721814543029%): Data: 25.333333333333336%]:Running loss: 4.350382924079895
[2018-04-17 16:59:45.599070]: [Epoch: 612(40.82721814543029%): Data: 50.66666666666667%]:Running loss: 8.483247801661491
[2018-04-17 16:59:49.089351]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 16:59:49.205661]: ====================
[2018-04-17 16:59:49.211175]: Elapsed time since starting training: 1:04:34.607374
[2018-04-17 16:59:49.216691]: ====================
[2018-04-17 16:59:49.288882]: [Epoch: 613(40.8939292861908%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 16:59:50.582321]: [Epoch: 613(40.8939292861908%): Data: 25.333333333333336%]:Running loss: 4.350383967161179
[2018-04-17 16:59:51.877766]: [Epoch: 613(40.8939292861908%): Data: 50.66666666666667%]:Running loss: 8.483248010277748
[2018-04-17 16:59:55.402143]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 16:59:55.517451]: ====================
[2018-04-17 16:59:55.522964]: Elapsed time since starting training: 1:04:40.919163
[2018-04-17 16:59:55.528479]: ====================
[2018-04-17 16:59:55.602676]: [Epoch: 614(40.9606404269513%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 16:59:56.922686]: [Epoch: 614(40.9606404269513%): Data: 25.333333333333336%]:Running loss: 4.3503841161727905
[2018-04-17 16:59:58.220637]: [Epoch: 614(40.9606404269513%): Data: 50.66666666666667%]:Running loss: 8.4832474142313
[2018-04-17 17:00:01.742000]: Test set accuracy: 94.33962264150944% ,loss = 5.437976494431496
[2018-04-17 17:00:01.860816]: ====================
[2018-04-17 17:00:01.866331]: Elapsed time since starting training: 1:04:47.262530
[2018-04-17 17:00:01.872347]: ====================
[2018-04-17 17:00:01.945541]: [Epoch: 615(41.027351567711804%): Data: 0.0%]:Running loss: 0.21751905977725983
[2018-04-17 17:00:03.253018]: [Epoch: 615(41.027351567711804%): Data: 25.333333333333336%]:Running loss: 4.3503841161727905
[2018-04-17 17:00:04.564004]: [Epoch: 615(41.027351567711804%): Data: 50.66666666666667%]:Running loss: 8.48324804008007
[2018-04-17 17:00:08.085368]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 17:00:08.195159]: ====================
[2018-04-17 17:00:08.200674]: Elapsed time since starting training: 1:04:53.596372
[2018-04-17 17:00:08.206189]: ====================
[2018-04-17 17:00:08.277879]: [Epoch: 616(41.094062708472315%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 17:00:09.571820]: [Epoch: 616(41.094062708472315%): Data: 25.333333333333336%]:Running loss: 4.350382387638092
[2018-04-17 17:00:10.887819]: [Epoch: 616(41.094062708472315%): Data: 50.66666666666667%]:Running loss: 8.483245700597763
[2018-04-17 17:00:14.426227]: Test set accuracy: 94.33962264150944% ,loss = 5.437976494431496
[2018-04-17 17:00:14.539530]: ====================
[2018-04-17 17:00:14.545545]: Elapsed time since starting training: 1:04:59.941744
[2018-04-17 17:00:14.551070]: ====================
[2018-04-17 17:00:14.626761]: [Epoch: 617(41.160773849232825%): Data: 0.0%]:Running loss: 0.21751905977725983
[2018-04-17 17:00:15.937746]: [Epoch: 617(41.160773849232825%): Data: 25.333333333333336%]:Running loss: 4.3503823429346085
[2018-04-17 17:00:17.250237]: [Epoch: 617(41.160773849232825%): Data: 50.66666666666667%]:Running loss: 8.483246579766273
[2018-04-17 17:00:20.828251]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 17:00:20.940047]: ====================
[2018-04-17 17:00:20.945563]: Elapsed time since starting training: 1:05:06.341762
[2018-04-17 17:00:20.951078]: ====================
[2018-04-17 17:00:21.024773]: [Epoch: 618(41.22748498999333%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 17:00:22.326735]: [Epoch: 618(41.22748498999333%): Data: 25.333333333333336%]:Running loss: 4.350381329655647
[2018-04-17 17:00:23.639726]: [Epoch: 618(41.22748498999333%): Data: 50.66666666666667%]:Running loss: 8.483244746923447
[2018-04-17 17:00:27.238295]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 17:00:27.354604]: ====================
[2018-04-17 17:00:27.360118]: Elapsed time since starting training: 1:05:12.756317
[2018-04-17 17:00:27.365633]: ====================
[2018-04-17 17:00:27.433814]: [Epoch: 619(41.29419613075383%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 17:00:28.751317]: [Epoch: 619(41.29419613075383%): Data: 25.333333333333336%]:Running loss: 4.35038161277771
[2018-04-17 17:00:30.044758]: [Epoch: 619(41.29419613075383%): Data: 50.66666666666667%]:Running loss: 8.483244583010674
[2018-04-17 17:00:33.549075]: Test set accuracy: 94.33962264150944% ,loss = 5.437974631786346
[2018-04-17 17:00:33.662878]: ====================
[2018-04-17 17:00:33.668392]: Elapsed time since starting training: 1:05:19.064090
[2018-04-17 17:00:33.673907]: ====================
[2018-04-17 17:00:33.749107]: [Epoch: 620(41.36090727151434%): Data: 0.0%]:Running loss: 0.21751898527145386
[2018-04-17 17:00:35.072632]: [Epoch: 620(41.36090727151434%): Data: 25.333333333333336%]:Running loss: 4.350383371114731
[2018-04-17 17:00:36.385121]: [Epoch: 620(41.36090727151434%): Data: 50.66666666666667%]:Running loss: 8.483246952295303
[2018-04-17 17:00:39.910496]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 17:00:40.486027]: ====================
[2018-04-17 17:00:40.491541]: Elapsed time since starting training: 1:05:25.887740
[2018-04-17 17:00:40.496554]: ====================
[2018-04-17 17:00:40.572756]: [Epoch: 621(41.42761841227485%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 17:00:41.881235]: [Epoch: 621(41.42761841227485%): Data: 25.333333333333336%]:Running loss: 4.350381508469582
[2018-04-17 17:00:43.191218]: [Epoch: 621(41.42761841227485%): Data: 50.66666666666667%]:Running loss: 8.483244195580482
[2018-04-17 17:00:46.706064]: Test set accuracy: 94.33962264150944% ,loss = 5.4379768669605255
[2018-04-17 17:00:46.815857]: ====================
[2018-04-17 17:00:46.821372]: Elapsed time since starting training: 1:05:32.217069
[2018-04-17 17:00:46.826886]: ====================
[2018-04-17 17:00:46.902086]: [Epoch: 622(41.49432955303536%): Data: 0.0%]:Running loss: 0.21751907467842102
[2018-04-17 17:00:48.212570]: [Epoch: 622(41.49432955303536%): Data: 25.333333333333336%]:Running loss: 4.350382059812546
[2018-04-17 17:00:49.542607]: [Epoch: 622(41.49432955303536%): Data: 50.66666666666667%]:Running loss: 8.483243703842163
[2018-04-17 17:00:53.127640]: Test set accuracy: 94.33962264150944% ,loss = 5.437982827425003
[2018-04-17 17:00:53.243447]: ====================
[2018-04-17 17:00:53.248461]: Elapsed time since starting training: 1:05:38.644660
[2018-04-17 17:00:53.253976]: ====================
[2018-04-17 17:00:53.328674]: [Epoch: 623(41.56104069379587%): Data: 0.0%]:Running loss: 0.21751931309700012
[2018-04-17 17:00:54.634647]: [Epoch: 623(41.56104069379587%): Data: 25.333333333333336%]:Running loss: 4.350381568074226
[2018-04-17 17:00:55.954657]: [Epoch: 623(41.56104069379587%): Data: 50.66666666666667%]:Running loss: 8.48324291408062
[2018-04-17 17:00:59.503593]: Test set accuracy: 94.33962264150944% ,loss = 5.4379768669605255
[2018-04-17 17:00:59.617396]: ====================
[2018-04-17 17:00:59.622911]: Elapsed time since starting training: 1:05:45.019110
[2018-04-17 17:00:59.628425]: ====================
[2018-04-17 17:00:59.704627]: [Epoch: 624(41.62775183455637%): Data: 0.0%]:Running loss: 0.21751907467842102
[2018-04-17 17:01:01.006589]: [Epoch: 624(41.62775183455637%): Data: 25.333333333333336%]:Running loss: 4.350380718708038
[2018-04-17 17:01:02.321586]: [Epoch: 624(41.62775183455637%): Data: 50.66666666666667%]:Running loss: 8.483242869377136
[2018-04-17 17:01:05.887067]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:01:06.002875]: ====================
[2018-04-17 17:01:06.009392]: Elapsed time since starting training: 1:05:51.405591
[2018-04-17 17:01:06.014906]: ====================
[2018-04-17 17:01:06.091109]: [Epoch: 625(41.694462975316874%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:01:07.400604]: [Epoch: 625(41.694462975316874%): Data: 25.333333333333336%]:Running loss: 4.350380957126617
[2018-04-17 17:01:08.724110]: [Epoch: 625(41.694462975316874%): Data: 50.66666666666667%]:Running loss: 8.483244329690933
[2018-04-17 17:01:12.266028]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 17:01:12.390359]: ====================
[2018-04-17 17:01:12.395873]: Elapsed time since starting training: 1:05:57.792072
[2018-04-17 17:01:12.401397]: ====================
[2018-04-17 17:01:12.477592]: [Epoch: 626(41.761174116077385%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 17:01:13.788577]: [Epoch: 626(41.761174116077385%): Data: 25.333333333333336%]:Running loss: 4.35037949681282
[2018-04-17 17:01:15.092544]: [Epoch: 626(41.761174116077385%): Data: 50.66666666666667%]:Running loss: 8.483241751790047
[2018-04-17 17:01:18.654014]: Test set accuracy: 94.33962264150944% ,loss = 5.437974259257317
[2018-04-17 17:01:18.769321]: ====================
[2018-04-17 17:01:18.775337]: Elapsed time since starting training: 1:06:04.171035
[2018-04-17 17:01:18.780350]: ====================
[2018-04-17 17:01:18.855550]: [Epoch: 627(41.827885256837895%): Data: 0.0%]:Running loss: 0.21751897037029266
[2018-04-17 17:01:20.195111]: [Epoch: 627(41.827885256837895%): Data: 25.333333333333336%]:Running loss: 4.350381717085838
[2018-04-17 17:01:21.502093]: [Epoch: 627(41.827885256837895%): Data: 50.66666666666667%]:Running loss: 8.483243316411972
[2018-04-17 17:01:25.103669]: Test set accuracy: 94.33962264150944% ,loss = 5.437978729605675
[2018-04-17 17:01:25.226997]: ====================
[2018-04-17 17:01:25.233014]: Elapsed time since starting training: 1:06:10.629213
[2018-04-17 17:01:25.238528]: ====================
[2018-04-17 17:01:25.308714]: [Epoch: 628(41.8945963975984%): Data: 0.0%]:Running loss: 0.217519149184227
[2018-04-17 17:01:26.629225]: [Epoch: 628(41.8945963975984%): Data: 25.333333333333336%]:Running loss: 4.350381389260292
[2018-04-17 17:01:27.932691]: [Epoch: 628(41.8945963975984%): Data: 50.66666666666667%]:Running loss: 8.483242228627205
[2018-04-17 17:01:31.515217]: Test set accuracy: 94.33962264150944% ,loss = 5.437973141670227
[2018-04-17 17:01:31.630023]: ====================
[2018-04-17 17:01:31.635537]: Elapsed time since starting training: 1:06:17.031235
[2018-04-17 17:01:31.641052]: ====================
[2018-04-17 17:01:31.719761]: [Epoch: 629(41.9613075383589%): Data: 0.0%]:Running loss: 0.21751892566680908
[2018-04-17 17:01:33.052805]: [Epoch: 629(41.9613075383589%): Data: 25.333333333333336%]:Running loss: 4.350380405783653
[2018-04-17 17:01:34.359781]: [Epoch: 629(41.9613075383589%): Data: 50.66666666666667%]:Running loss: 8.48324079811573
[2018-04-17 17:01:37.879640]: Test set accuracy: 94.33962264150944% ,loss = 5.437979474663734
[2018-04-17 17:01:37.993944]: ====================
[2018-04-17 17:01:37.999459]: Elapsed time since starting training: 1:06:23.395658
[2018-04-17 17:01:38.006477]: ====================
[2018-04-17 17:01:38.072653]: [Epoch: 630(42.02801867911941%): Data: 0.0%]:Running loss: 0.21751917898654938
[2018-04-17 17:01:39.360578]: [Epoch: 630(42.02801867911941%): Data: 25.333333333333336%]:Running loss: 4.350379586219788
[2018-04-17 17:01:40.617921]: [Epoch: 630(42.02801867911941%): Data: 50.66666666666667%]:Running loss: 8.483240768313408
[2018-04-17 17:01:44.439582]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 17:01:44.694761]: ====================
[2018-04-17 17:01:44.701781]: Elapsed time since starting training: 1:06:30.097478
[2018-04-17 17:01:44.710804]: ====================
[2018-04-17 17:01:44.794026]: [Epoch: 631(42.09472981987992%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 17:01:46.306046]: [Epoch: 631(42.09472981987992%): Data: 25.333333333333336%]:Running loss: 4.350379183888435
[2018-04-17 17:01:47.649619]: [Epoch: 631(42.09472981987992%): Data: 50.66666666666667%]:Running loss: 8.483241513371468
[2018-04-17 17:01:51.260721]: Test set accuracy: 94.33962264150944% ,loss = 5.437979474663734
[2018-04-17 17:01:51.384551]: ====================
[2018-04-17 17:01:51.390064]: Elapsed time since starting training: 1:06:36.785763
[2018-04-17 17:01:51.396582]: ====================
[2018-04-17 17:01:51.469776]: [Epoch: 632(42.16144096064043%): Data: 0.0%]:Running loss: 0.21751917898654938
[2018-04-17 17:01:52.741658]: [Epoch: 632(42.16144096064043%): Data: 25.333333333333336%]:Running loss: 4.350379824638367
[2018-04-17 17:01:54.016548]: [Epoch: 632(42.16144096064043%): Data: 50.66666666666667%]:Running loss: 8.483241647481918
[2018-04-17 17:01:57.598071]: Test set accuracy: 94.33962264150944% ,loss = 5.437974631786346
[2018-04-17 17:01:57.715885]: ====================
[2018-04-17 17:01:57.720898]: Elapsed time since starting training: 1:06:43.117097
[2018-04-17 17:01:57.726413]: ====================
[2018-04-17 17:01:57.796098]: [Epoch: 633(42.22815210140094%): Data: 0.0%]:Running loss: 0.21751898527145386
[2018-04-17 17:01:59.077004]: [Epoch: 633(42.22815210140094%): Data: 25.333333333333336%]:Running loss: 4.350380584597588
[2018-04-17 17:02:00.348384]: [Epoch: 633(42.22815210140094%): Data: 50.66666666666667%]:Running loss: 8.483241587877274
[2018-04-17 17:02:03.913364]: Test set accuracy: 94.33962264150944% ,loss = 5.437982454895973
[2018-04-17 17:02:04.025161]: ====================
[2018-04-17 17:02:04.030676]: Elapsed time since starting training: 1:06:49.426875
[2018-04-17 17:02:04.036692]: ====================
[2018-04-17 17:02:04.108382]: [Epoch: 634(42.29486324216144%): Data: 0.0%]:Running loss: 0.21751929819583893
[2018-04-17 17:02:05.398813]: [Epoch: 634(42.29486324216144%): Data: 25.333333333333336%]:Running loss: 4.350380286574364
[2018-04-17 17:02:06.668691]: [Epoch: 634(42.29486324216144%): Data: 50.66666666666667%]:Running loss: 8.483240187168121
[2018-04-17 17:02:10.245200]: Test set accuracy: 94.33962264150944% ,loss = 5.437976494431496
[2018-04-17 17:02:10.376048]: ====================
[2018-04-17 17:02:10.383066]: Elapsed time since starting training: 1:06:55.779265
[2018-04-17 17:02:10.391088]: ====================
[2018-04-17 17:02:10.466789]: [Epoch: 635(42.361574382921944%): Data: 0.0%]:Running loss: 0.21751905977725983
[2018-04-17 17:02:11.739674]: [Epoch: 635(42.361574382921944%): Data: 25.333333333333336%]:Running loss: 4.350379794836044
[2018-04-17 17:02:13.033113]: [Epoch: 635(42.361574382921944%): Data: 50.66666666666667%]:Running loss: 8.483240813016891
[2018-04-17 17:02:16.602604]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:02:16.727937]: ====================
[2018-04-17 17:02:16.734455]: Elapsed time since starting training: 1:07:02.130654
[2018-04-17 17:02:16.739970]: ====================
[2018-04-17 17:02:16.814167]: [Epoch: 636(42.428285523682455%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:02:18.101590]: [Epoch: 636(42.428285523682455%): Data: 25.333333333333336%]:Running loss: 4.350378602743149
[2018-04-17 17:02:19.369461]: [Epoch: 636(42.428285523682455%): Data: 50.66666666666667%]:Running loss: 8.483239024877548
[2018-04-17 17:02:22.899848]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 17:02:23.027688]: ====================
[2018-04-17 17:02:23.033705]: Elapsed time since starting training: 1:07:08.429904
[2018-04-17 17:02:23.038718]: ====================
[2018-04-17 17:02:23.112915]: [Epoch: 637(42.494996664442965%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 17:02:24.444957]: [Epoch: 637(42.494996664442965%): Data: 25.333333333333336%]:Running loss: 4.350379765033722
[2018-04-17 17:02:25.696284]: [Epoch: 637(42.494996664442965%): Data: 50.66666666666667%]:Running loss: 8.483239114284515
[2018-04-17 17:02:29.189573]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:02:29.303375]: ====================
[2018-04-17 17:02:29.309392]: Elapsed time since starting training: 1:07:14.705089
[2018-04-17 17:02:29.314906]: ====================
[2018-04-17 17:02:29.383087]: [Epoch: 638(42.56170780520347%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:02:30.721647]: [Epoch: 638(42.56170780520347%): Data: 25.333333333333336%]:Running loss: 4.350378587841988
[2018-04-17 17:02:31.984505]: [Epoch: 638(42.56170780520347%): Data: 50.66666666666667%]:Running loss: 8.483239635825157
[2018-04-17 17:02:35.550988]: Test set accuracy: 94.33962264150944% ,loss = 5.4379768669605255
[2018-04-17 17:02:35.682337]: ====================
[2018-04-17 17:02:35.689355]: Elapsed time since starting training: 1:07:21.085554
[2018-04-17 17:02:35.694870]: ====================
[2018-04-17 17:02:35.772577]: [Epoch: 639(42.62841894596397%): Data: 0.0%]:Running loss: 0.21751907467842102
[2018-04-17 17:02:37.056992]: [Epoch: 639(42.62841894596397%): Data: 25.333333333333336%]:Running loss: 4.350378111004829
[2018-04-17 17:02:38.315338]: [Epoch: 639(42.62841894596397%): Data: 50.66666666666667%]:Running loss: 8.483238652348518
[2018-04-17 17:02:41.795592]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:02:41.907891]: ====================
[2018-04-17 17:02:41.913405]: Elapsed time since starting training: 1:07:27.309604
[2018-04-17 17:02:41.919923]: ====================
[2018-04-17 17:02:41.991613]: [Epoch: 640(42.69513008672448%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:02:43.251964]: [Epoch: 640(42.69513008672448%): Data: 25.333333333333336%]:Running loss: 4.3503792732954025
[2018-04-17 17:02:44.535878]: [Epoch: 640(42.69513008672448%): Data: 50.66666666666667%]:Running loss: 8.483240216970444
[2018-04-17 17:02:48.068271]: Test set accuracy: 94.33962264150944% ,loss = 5.4379768669605255
[2018-04-17 17:02:48.185082]: ====================
[2018-04-17 17:02:48.192601]: Elapsed time since starting training: 1:07:33.588800
[2018-04-17 17:02:48.199119]: ====================
[2018-04-17 17:02:48.268303]: [Epoch: 641(42.76184122748499%): Data: 0.0%]:Running loss: 0.21751907467842102
[2018-04-17 17:02:49.525647]: [Epoch: 641(42.76184122748499%): Data: 25.333333333333336%]:Running loss: 4.350378930568695
[2018-04-17 17:02:50.764440]: [Epoch: 641(42.76184122748499%): Data: 50.66666666666667%]:Running loss: 8.483237713575363
[2018-04-17 17:02:54.305355]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 17:02:54.415649]: ====================
[2018-04-17 17:02:54.421163]: Elapsed time since starting training: 1:07:39.817362
[2018-04-17 17:02:54.426177]: ====================
[2018-04-17 17:02:54.493355]: [Epoch: 642(42.8285523682455%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 17:02:55.765237]: [Epoch: 642(42.8285523682455%): Data: 25.333333333333336%]:Running loss: 4.3503798097372055
[2018-04-17 17:02:57.040629]: [Epoch: 642(42.8285523682455%): Data: 50.66666666666667%]:Running loss: 8.483239859342575
[2018-04-17 17:03:00.577533]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 17:03:00.694345]: ====================
[2018-04-17 17:03:00.699859]: Elapsed time since starting training: 1:07:46.096058
[2018-04-17 17:03:00.706376]: ====================
[2018-04-17 17:03:00.782578]: [Epoch: 643(42.89526350900601%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 17:03:02.053959]: [Epoch: 643(42.89526350900601%): Data: 25.333333333333336%]:Running loss: 4.350377768278122
[2018-04-17 17:03:03.348401]: [Epoch: 643(42.89526350900601%): Data: 50.66666666666667%]:Running loss: 8.48323680460453
[2018-04-17 17:03:06.860740]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:03:06.976047]: ====================
[2018-04-17 17:03:06.982564]: Elapsed time since starting training: 1:07:52.378262
[2018-04-17 17:03:06.988079]: ====================
[2018-04-17 17:03:07.058266]: [Epoch: 644(42.96197464976651%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:03:08.321625]: [Epoch: 644(42.96197464976651%): Data: 25.333333333333336%]:Running loss: 4.350378125905991
[2018-04-17 17:03:09.589997]: [Epoch: 644(42.96197464976651%): Data: 50.66666666666667%]:Running loss: 8.48323641717434
[2018-04-17 17:03:13.117890]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 17:03:13.236206]: ====================
[2018-04-17 17:03:13.242222]: Elapsed time since starting training: 1:07:58.637918
[2018-04-17 17:03:13.247736]: ====================
[2018-04-17 17:03:13.317421]: [Epoch: 645(43.028685790527014%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 17:03:14.614369]: [Epoch: 645(43.028685790527014%): Data: 25.333333333333336%]:Running loss: 4.350378185510635
[2018-04-17 17:03:15.881238]: [Epoch: 645(43.028685790527014%): Data: 50.66666666666667%]:Running loss: 8.483236029744148
[2018-04-17 17:03:19.451732]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:03:19.569044]: ====================
[2018-04-17 17:03:19.575061]: Elapsed time since starting training: 1:08:04.970758
[2018-04-17 17:03:19.580574]: ====================
[2018-04-17 17:03:19.647753]: [Epoch: 646(43.095396931287524%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:03:20.940191]: [Epoch: 646(43.095396931287524%): Data: 25.333333333333336%]:Running loss: 4.350377008318901
[2018-04-17 17:03:22.204552]: [Epoch: 646(43.095396931287524%): Data: 50.66666666666667%]:Running loss: 8.483235940337181
[2018-04-17 17:03:25.723408]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 17:03:25.844230]: ====================
[2018-04-17 17:03:25.850245]: Elapsed time since starting training: 1:08:11.246444
[2018-04-17 17:03:25.856763]: ====================
[2018-04-17 17:03:25.931461]: [Epoch: 647(43.162108072048035%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 17:03:27.213871]: [Epoch: 647(43.162108072048035%): Data: 25.333333333333336%]:Running loss: 4.3503763526678085
[2018-04-17 17:03:28.476730]: [Epoch: 647(43.162108072048035%): Data: 50.66666666666667%]:Running loss: 8.483236446976662
[2018-04-17 17:03:31.991074]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:03:32.112898]: ====================
[2018-04-17 17:03:32.120418]: Elapsed time since starting training: 1:08:17.516115
[2018-04-17 17:03:32.127938]: ====================
[2018-04-17 17:03:32.200130]: [Epoch: 648(43.22881921280854%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:03:33.476023]: [Epoch: 648(43.22881921280854%): Data: 25.333333333333336%]:Running loss: 4.350377589464188
[2018-04-17 17:03:34.759435]: [Epoch: 648(43.22881921280854%): Data: 50.66666666666667%]:Running loss: 8.483236983418465
[2018-04-17 17:03:38.302356]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:03:38.421673]: ====================
[2018-04-17 17:03:38.427187]: Elapsed time since starting training: 1:08:23.823386
[2018-04-17 17:03:38.434206]: ====================
[2018-04-17 17:03:38.505395]: [Epoch: 649(43.29553035356904%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:03:39.753714]: [Epoch: 649(43.29553035356904%): Data: 25.333333333333336%]:Running loss: 4.350376293063164
[2018-04-17 17:03:41.019580]: [Epoch: 649(43.29553035356904%): Data: 50.66666666666667%]:Running loss: 8.483237266540527
[2018-04-17 17:03:44.611130]: Test set accuracy: 94.33962264150944% ,loss = 5.437979102134705
[2018-04-17 17:03:44.724432]: ====================
[2018-04-17 17:03:44.730448]: Elapsed time since starting training: 1:08:30.126647
[2018-04-17 17:03:44.736464]: ====================
[2018-04-17 17:03:44.806148]: [Epoch: 650(43.36224149432955%): Data: 0.0%]:Running loss: 0.21751916408538818
[2018-04-17 17:03:46.079540]: [Epoch: 650(43.36224149432955%): Data: 25.333333333333336%]:Running loss: 4.350375860929489
[2018-04-17 17:03:47.350419]: [Epoch: 650(43.36224149432955%): Data: 50.66666666666667%]:Running loss: 8.483235031366348
[2018-04-17 17:03:50.881814]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:03:50.998123]: ====================
[2018-04-17 17:03:51.004139]: Elapsed time since starting training: 1:08:36.400338
[2018-04-17 17:03:51.010656]: ====================
[2018-04-17 17:03:51.078837]: [Epoch: 651(43.42895263509006%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:03:52.402858]: [Epoch: 651(43.42895263509006%): Data: 25.333333333333336%]:Running loss: 4.3503755778074265
[2018-04-17 17:03:53.771998]: [Epoch: 651(43.42895263509006%): Data: 50.66666666666667%]:Running loss: 8.483235448598862
[2018-04-17 17:03:57.306897]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 17:03:57.422204]: ====================
[2018-04-17 17:03:57.430226]: Elapsed time since starting training: 1:08:42.826425
[2018-04-17 17:03:57.436743]: ====================
[2018-04-17 17:03:57.508935]: [Epoch: 652(43.495663775850566%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 17:03:58.772294]: [Epoch: 652(43.495663775850566%): Data: 25.333333333333336%]:Running loss: 4.350375413894653
[2018-04-17 17:04:00.038661]: [Epoch: 652(43.495663775850566%): Data: 50.66666666666667%]:Running loss: 8.483233869075775
[2018-04-17 17:04:03.567044]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 17:04:03.683854]: ====================
[2018-04-17 17:04:03.690873]: Elapsed time since starting training: 1:08:49.086570
[2018-04-17 17:04:03.696388]: ====================
[2018-04-17 17:04:03.767577]: [Epoch: 653(43.56237491661108%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 17:04:05.032941]: [Epoch: 653(43.56237491661108%): Data: 25.333333333333336%]:Running loss: 4.350378528237343
[2018-04-17 17:04:06.305324]: [Epoch: 653(43.56237491661108%): Data: 50.66666666666667%]:Running loss: 8.483236610889435
[2018-04-17 17:04:09.820672]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 17:04:09.935979]: ====================
[2018-04-17 17:04:09.941994]: Elapsed time since starting training: 1:08:55.338193
[2018-04-17 17:04:09.947016]: ====================
[2018-04-17 17:04:10.019199]: [Epoch: 654(43.62908605737158%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 17:04:11.285065]: [Epoch: 654(43.62908605737158%): Data: 25.333333333333336%]:Running loss: 4.35037499666214
[2018-04-17 17:04:12.552436]: [Epoch: 654(43.62908605737158%): Data: 50.66666666666667%]:Running loss: 8.483232706785202
[2018-04-17 17:04:16.090342]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 17:04:16.216179]: ====================
[2018-04-17 17:04:16.223196]: Elapsed time since starting training: 1:09:01.618894
[2018-04-17 17:04:16.228720]: ====================
[2018-04-17 17:04:16.303911]: [Epoch: 655(43.695797198132084%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 17:04:17.555739]: [Epoch: 655(43.695797198132084%): Data: 25.333333333333336%]:Running loss: 4.350378319621086
[2018-04-17 17:04:18.822609]: [Epoch: 655(43.695797198132084%): Data: 50.66666666666667%]:Running loss: 8.483234733343124
[2018-04-17 17:04:22.351992]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:04:22.464292]: ====================
[2018-04-17 17:04:22.470307]: Elapsed time since starting training: 1:09:07.866005
[2018-04-17 17:04:22.475822]: ====================
[2018-04-17 17:04:22.548515]: [Epoch: 656(43.762508338892594%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:04:23.820898]: [Epoch: 656(43.762508338892594%): Data: 25.333333333333336%]:Running loss: 4.3503784239292145
[2018-04-17 17:04:25.098295]: [Epoch: 656(43.762508338892594%): Data: 50.66666666666667%]:Running loss: 8.48323592543602
[2018-04-17 17:04:28.655253]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:04:28.770559]: ====================
[2018-04-17 17:04:28.777578]: Elapsed time since starting training: 1:09:14.173276
[2018-04-17 17:04:28.782591]: ====================
[2018-04-17 17:04:28.857290]: [Epoch: 657(43.829219479653105%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:04:30.139198]: [Epoch: 657(43.829219479653105%): Data: 25.333333333333336%]:Running loss: 4.350377008318901
[2018-04-17 17:04:31.423613]: [Epoch: 657(43.829219479653105%): Data: 50.66666666666667%]:Running loss: 8.483231857419014
[2018-04-17 17:04:34.974054]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:04:35.087356]: ====================
[2018-04-17 17:04:35.092870]: Elapsed time since starting training: 1:09:20.489069
[2018-04-17 17:04:35.098385]: ====================
[2018-04-17 17:04:35.175093]: [Epoch: 658(43.89593062041361%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:04:36.439451]: [Epoch: 658(43.89593062041361%): Data: 25.333333333333336%]:Running loss: 4.350376546382904
[2018-04-17 17:04:37.706320]: [Epoch: 658(43.89593062041361%): Data: 50.66666666666667%]:Running loss: 8.483233913779259
[2018-04-17 17:04:41.197602]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:04:41.313410]: ====================
[2018-04-17 17:04:41.318926]: Elapsed time since starting training: 1:09:26.714624
[2018-04-17 17:04:41.324440]: ====================
[2018-04-17 17:04:41.392621]: [Epoch: 659(43.96264176117411%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:04:42.639938]: [Epoch: 659(43.96264176117411%): Data: 25.333333333333336%]:Running loss: 4.350375279784203
[2018-04-17 17:04:43.873217]: [Epoch: 659(43.96264176117411%): Data: 50.66666666666667%]:Running loss: 8.483236089348793
[2018-04-17 17:04:47.460756]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:04:47.567541]: ====================
[2018-04-17 17:04:47.573056]: Elapsed time since starting training: 1:09:32.968753
[2018-04-17 17:04:47.578570]: ====================
[2018-04-17 17:04:47.654271]: [Epoch: 660(44.02935290193462%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:04:48.958238]: [Epoch: 660(44.02935290193462%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:04:50.302312]: [Epoch: 660(44.02935290193462%): Data: 50.66666666666667%]:Running loss: 8.483231991529465
[2018-04-17 17:04:54.279888]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 17:04:54.399708]: ====================
[2018-04-17 17:04:54.406225]: Elapsed time since starting training: 1:09:39.802424
[2018-04-17 17:04:54.412240]: ====================
[2018-04-17 17:04:54.480421]: [Epoch: 661(44.09606404269513%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 17:04:55.792912]: [Epoch: 661(44.09606404269513%): Data: 25.333333333333336%]:Running loss: 4.350377634167671
[2018-04-17 17:04:57.070308]: [Epoch: 661(44.09606404269513%): Data: 50.66666666666667%]:Running loss: 8.483236342668533
[2018-04-17 17:05:00.863895]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:05:01.000258]: ====================
[2018-04-17 17:05:01.009283]: Elapsed time since starting training: 1:09:46.404979
[2018-04-17 17:05:01.014796]: ====================
[2018-04-17 17:05:01.085987]: [Epoch: 662(44.162775183455636%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:05:02.385942]: [Epoch: 662(44.162775183455636%): Data: 25.333333333333336%]:Running loss: 4.3503768146038055
[2018-04-17 17:05:03.698432]: [Epoch: 662(44.162775183455636%): Data: 50.66666666666667%]:Running loss: 8.483233630657196
[2018-04-17 17:05:07.366686]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 17:05:07.502047]: ====================
[2018-04-17 17:05:07.510067]: Elapsed time since starting training: 1:09:52.906266
[2018-04-17 17:05:07.518591]: ====================
[2018-04-17 17:05:07.591284]: [Epoch: 663(44.22948632421615%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 17:05:08.871688]: [Epoch: 663(44.22948632421615%): Data: 25.333333333333336%]:Running loss: 4.350378006696701
[2018-04-17 17:05:10.140060]: [Epoch: 663(44.22948632421615%): Data: 50.66666666666667%]:Running loss: 8.483234390616417
[2018-04-17 17:05:14.065999]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:05:14.245477]: ====================
[2018-04-17 17:05:14.250991]: Elapsed time since starting training: 1:09:59.647190
[2018-04-17 17:05:14.258511]: ====================
[2018-04-17 17:05:14.338223]: [Epoch: 664(44.29619746497665%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:05:15.704858]: [Epoch: 664(44.29619746497665%): Data: 25.333333333333336%]:Running loss: 4.350377857685089
[2018-04-17 17:05:16.990275]: [Epoch: 664(44.29619746497665%): Data: 50.66666666666667%]:Running loss: 8.48323567211628
[2018-04-17 17:05:20.608396]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:05:20.737739]: ====================
[2018-04-17 17:05:20.743756]: Elapsed time since starting training: 1:10:06.139453
[2018-04-17 17:05:20.749271]: ====================
[2018-04-17 17:05:20.821964]: [Epoch: 665(44.362908605737154%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:05:22.098859]: [Epoch: 665(44.362908605737154%): Data: 25.333333333333336%]:Running loss: 4.350376710295677
[2018-04-17 17:05:23.390794]: [Epoch: 665(44.362908605737154%): Data: 50.66666666666667%]:Running loss: 8.483234524726868
[2018-04-17 17:05:27.017938]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:05:27.137256]: ====================
[2018-04-17 17:05:27.143272]: Elapsed time since starting training: 1:10:12.539471
[2018-04-17 17:05:27.149288]: ====================
[2018-04-17 17:05:27.225491]: [Epoch: 666(44.429619746497664%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:05:28.492860]: [Epoch: 666(44.429619746497664%): Data: 25.333333333333336%]:Running loss: 4.350375935435295
[2018-04-17 17:05:29.792316]: [Epoch: 666(44.429619746497664%): Data: 50.66666666666667%]:Running loss: 8.483233764767647
[2018-04-17 17:05:33.415951]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:05:33.565349]: ====================
[2018-04-17 17:05:33.572367]: Elapsed time since starting training: 1:10:18.968566
[2018-04-17 17:05:33.577882]: ====================
[2018-04-17 17:05:33.649071]: [Epoch: 667(44.496330887258175%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:05:34.992142]: [Epoch: 667(44.496330887258175%): Data: 25.333333333333336%]:Running loss: 4.350374698638916
[2018-04-17 17:05:36.301624]: [Epoch: 667(44.496330887258175%): Data: 50.66666666666667%]:Running loss: 8.483232647180557
[2018-04-17 17:05:39.995952]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 17:05:40.148860]: ====================
[2018-04-17 17:05:40.154374]: Elapsed time since starting training: 1:10:25.550070
[2018-04-17 17:05:40.159888]: ====================
[2018-04-17 17:05:40.232580]: [Epoch: 668(44.56304202801868%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 17:05:41.534543]: [Epoch: 668(44.56304202801868%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:05:42.834499]: [Epoch: 668(44.56304202801868%): Data: 50.66666666666667%]:Running loss: 8.48323318362236
[2018-04-17 17:05:46.447106]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 17:05:46.576449]: ====================
[2018-04-17 17:05:46.582967]: Elapsed time since starting training: 1:10:31.979166
[2018-04-17 17:05:46.591991]: ====================
[2018-04-17 17:05:46.660172]: [Epoch: 669(44.62975316877918%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 17:05:47.960630]: [Epoch: 669(44.62975316877918%): Data: 25.333333333333336%]:Running loss: 4.350374057888985
[2018-04-17 17:05:49.264095]: [Epoch: 669(44.62975316877918%): Data: 50.66666666666667%]:Running loss: 8.483232036232948
[2018-04-17 17:05:52.903273]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:05:53.026600]: ====================
[2018-04-17 17:05:53.031614]: Elapsed time since starting training: 1:10:38.427813
[2018-04-17 17:05:53.036125]: ====================
[2018-04-17 17:05:53.110323]: [Epoch: 670(44.69646430953969%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:05:54.415293]: [Epoch: 670(44.69646430953969%): Data: 25.333333333333336%]:Running loss: 4.35037425160408
[2018-04-17 17:05:55.693191]: [Epoch: 670(44.69646430953969%): Data: 50.66666666666667%]:Running loss: 8.483230769634247
[2018-04-17 17:05:59.374479]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:05:59.501818]: ====================
[2018-04-17 17:05:59.506832]: Elapsed time since starting training: 1:10:44.902529
[2018-04-17 17:05:59.511343]: ====================
[2018-04-17 17:05:59.583535]: [Epoch: 671(44.7631754503002%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:06:00.905049]: [Epoch: 671(44.7631754503002%): Data: 25.333333333333336%]:Running loss: 4.350378409028053
[2018-04-17 17:06:02.206008]: [Epoch: 671(44.7631754503002%): Data: 50.66666666666667%]:Running loss: 8.483234390616417
[2018-04-17 17:06:05.815606]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:06:05.940438]: ====================
[2018-04-17 17:06:05.944950]: Elapsed time since starting training: 1:10:51.341149
[2018-04-17 17:06:05.949462]: ====================
[2018-04-17 17:06:06.022657]: [Epoch: 672(44.829886591060706%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:06:07.339157]: [Epoch: 672(44.829886591060706%): Data: 25.333333333333336%]:Running loss: 4.350377127528191
[2018-04-17 17:06:08.672202]: [Epoch: 672(44.829886591060706%): Data: 50.66666666666667%]:Running loss: 8.4832314401865
[2018-04-17 17:06:12.277287]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:06:12.408136]: ====================
[2018-04-17 17:06:12.413650]: Elapsed time since starting training: 1:10:57.809849
[2018-04-17 17:06:12.418664]: ====================
[2018-04-17 17:06:12.492860]: [Epoch: 673(44.89659773182122%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:06:13.786801]: [Epoch: 673(44.89659773182122%): Data: 25.333333333333336%]:Running loss: 4.35037636756897
[2018-04-17 17:06:15.068710]: [Epoch: 673(44.89659773182122%): Data: 50.66666666666667%]:Running loss: 8.483231782913208
[2018-04-17 17:06:18.669785]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:06:18.803140]: ====================
[2018-04-17 17:06:18.807652]: Elapsed time since starting training: 1:11:04.203851
[2018-04-17 17:06:18.812666]: ====================
[2018-04-17 17:06:18.893380]: [Epoch: 674(44.96330887258172%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:06:20.172782]: [Epoch: 674(44.96330887258172%): Data: 25.333333333333336%]:Running loss: 4.350374922156334
[2018-04-17 17:06:21.478754]: [Epoch: 674(44.96330887258172%): Data: 50.66666666666667%]:Running loss: 8.483232989907265
[2018-04-17 17:06:25.158037]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 17:06:25.291893]: ====================
[2018-04-17 17:06:25.297409]: Elapsed time since starting training: 1:11:10.693608
[2018-04-17 17:06:25.301920]: ====================
[2018-04-17 17:06:25.374112]: [Epoch: 675(45.030020013342224%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 17:06:26.683092]: [Epoch: 675(45.030020013342224%): Data: 25.333333333333336%]:Running loss: 4.350374653935432
[2018-04-17 17:06:27.994580]: [Epoch: 675(45.030020013342224%): Data: 50.66666666666667%]:Running loss: 8.48323267698288
[2018-04-17 17:06:31.661329]: Test set accuracy: 94.33962264150944% ,loss = 5.437974259257317
[2018-04-17 17:06:31.914503]: ====================
[2018-04-17 17:06:31.920017]: Elapsed time since starting training: 1:11:17.316216
[2018-04-17 17:06:31.925031]: ====================
[2018-04-17 17:06:31.995217]: [Epoch: 676(45.096731154102734%): Data: 0.0%]:Running loss: 0.21751897037029266
[2018-04-17 17:06:33.235515]: [Epoch: 676(45.096731154102734%): Data: 25.333333333333336%]:Running loss: 4.350375086069107
[2018-04-17 17:06:34.567056]: [Epoch: 676(45.096731154102734%): Data: 50.66666666666667%]:Running loss: 8.483233079314232
[2018-04-17 17:06:38.219768]: Test set accuracy: 94.33962264150944% ,loss = 5.437972769141197
[2018-04-17 17:06:38.350616]: ====================
[2018-04-17 17:06:38.355629]: Elapsed time since starting training: 1:11:23.751828
[2018-04-17 17:06:38.360643]: ====================
[2018-04-17 17:06:38.429827]: [Epoch: 677(45.163442294863245%): Data: 0.0%]:Running loss: 0.2175189107656479
[2018-04-17 17:06:39.724269]: [Epoch: 677(45.163442294863245%): Data: 25.333333333333336%]:Running loss: 4.350374549627304
[2018-04-17 17:06:41.010188]: [Epoch: 677(45.163442294863245%): Data: 50.66666666666667%]:Running loss: 8.483231291174889
[2018-04-17 17:06:44.638341]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:06:44.779717]: ====================
[2018-04-17 17:06:44.784731]: Elapsed time since starting training: 1:11:30.180428
[2018-04-17 17:06:44.789242]: ====================
[2018-04-17 17:06:44.858928]: [Epoch: 678(45.23015343562375%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:06:46.148857]: [Epoch: 678(45.23015343562375%): Data: 25.333333333333336%]:Running loss: 4.350377723574638
[2018-04-17 17:06:47.439290]: [Epoch: 678(45.23015343562375%): Data: 50.66666666666667%]:Running loss: 8.483233630657196
[2018-04-17 17:06:51.041367]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:06:51.189761]: ====================
[2018-04-17 17:06:51.195777]: Elapsed time since starting training: 1:11:36.591976
[2018-04-17 17:06:51.199788]: ====================
[2018-04-17 17:06:51.267469]: [Epoch: 679(45.29686457638425%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:06:52.557399]: [Epoch: 679(45.29686457638425%): Data: 25.333333333333336%]:Running loss: 4.350376740098
[2018-04-17 17:06:53.863871]: [Epoch: 679(45.29686457638425%): Data: 50.66666666666667%]:Running loss: 8.483232468366623
[2018-04-17 17:06:57.457928]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:06:57.595294]: ====================
[2018-04-17 17:06:57.599805]: Elapsed time since starting training: 1:11:42.996004
[2018-04-17 17:06:57.605320]: ====================
[2018-04-17 17:06:57.676510]: [Epoch: 680(45.36357571714476%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:06:58.952402]: [Epoch: 680(45.36357571714476%): Data: 25.333333333333336%]:Running loss: 4.350376099348068
[2018-04-17 17:07:00.308007]: [Epoch: 680(45.36357571714476%): Data: 50.66666666666667%]:Running loss: 8.483231142163277
[2018-04-17 17:07:03.938661]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:07:04.070009]: ====================
[2018-04-17 17:07:04.075023]: Elapsed time since starting training: 1:11:49.471222
[2018-04-17 17:07:04.080538]: ====================
[2018-04-17 17:07:04.155236]: [Epoch: 681(45.43028685790527%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:07:05.453187]: [Epoch: 681(45.43028685790527%): Data: 25.333333333333336%]:Running loss: 4.350375548005104
[2018-04-17 17:07:06.790744]: [Epoch: 681(45.43028685790527%): Data: 50.66666666666667%]:Running loss: 8.483234241604805
[2018-04-17 17:07:10.485067]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:07:10.611403]: ====================
[2018-04-17 17:07:10.615915]: Elapsed time since starting training: 1:11:56.012114
[2018-04-17 17:07:10.620428]: ====================
[2018-04-17 17:07:10.691617]: [Epoch: 682(45.496997998665776%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:07:12.023658]: [Epoch: 682(45.496997998665776%): Data: 25.333333333333336%]:Running loss: 4.350373461842537
[2018-04-17 17:07:13.325119]: [Epoch: 682(45.496997998665776%): Data: 50.66666666666667%]:Running loss: 8.483229905366898
[2018-04-17 17:07:16.955773]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:07:17.095648]: ====================
[2018-04-17 17:07:17.100157]: Elapsed time since starting training: 1:12:02.496356
[2018-04-17 17:07:17.104669]: ====================
[2018-04-17 17:07:17.178866]: [Epoch: 683(45.56370913942629%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:07:18.506396]: [Epoch: 683(45.56370913942629%): Data: 25.333333333333336%]:Running loss: 4.350373402237892
[2018-04-17 17:07:19.836433]: [Epoch: 683(45.56370913942629%): Data: 50.66666666666667%]:Running loss: 8.483231008052826
[2018-04-17 17:07:23.540782]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 17:07:23.660099]: ====================
[2018-04-17 17:07:23.664612]: Elapsed time since starting training: 1:12:09.060811
[2018-04-17 17:07:23.669123]: ====================
[2018-04-17 17:07:23.740313]: [Epoch: 684(45.63042028018679%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 17:07:25.049795]: [Epoch: 684(45.63042028018679%): Data: 25.333333333333336%]:Running loss: 4.350372344255447
[2018-04-17 17:07:26.349249]: [Epoch: 684(45.63042028018679%): Data: 50.66666666666667%]:Running loss: 8.483229517936707
[2018-04-17 17:07:30.001962]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:07:30.136822]: ====================
[2018-04-17 17:07:30.141835]: Elapsed time since starting training: 1:12:15.537532
[2018-04-17 17:07:30.145845]: ====================
[2018-04-17 17:07:30.215531]: [Epoch: 685(45.697131420947294%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:07:31.551583]: [Epoch: 685(45.697131420947294%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:07:32.869588]: [Epoch: 685(45.697131420947294%): Data: 50.66666666666667%]:Running loss: 8.483231395483017
[2018-04-17 17:07:36.529319]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:07:36.652146]: ====================
[2018-04-17 17:07:36.656657]: Elapsed time since starting training: 1:12:22.052856
[2018-04-17 17:07:36.661671]: ====================
[2018-04-17 17:07:36.735367]: [Epoch: 686(45.763842561707804%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:07:38.002235]: [Epoch: 686(45.763842561707804%): Data: 25.333333333333336%]:Running loss: 4.350375980138779
[2018-04-17 17:07:39.303194]: [Epoch: 686(45.763842561707804%): Data: 50.66666666666667%]:Running loss: 8.483231037855148
[2018-04-17 17:07:42.921816]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:07:43.043139]: ====================
[2018-04-17 17:07:43.047651]: Elapsed time since starting training: 1:12:28.443850
[2018-04-17 17:07:43.052664]: ====================
[2018-04-17 17:07:43.124355]: [Epoch: 687(45.830553702468315%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:07:44.413282]: [Epoch: 687(45.830553702468315%): Data: 25.333333333333336%]:Running loss: 4.350376293063164
[2018-04-17 17:07:45.687177]: [Epoch: 687(45.830553702468315%): Data: 50.66666666666667%]:Running loss: 8.483229741454124
[2018-04-17 17:07:49.247143]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:07:49.366962]: ====================
[2018-04-17 17:07:49.371474]: Elapsed time since starting training: 1:12:34.767673
[2018-04-17 17:07:49.375986]: ====================
[2018-04-17 17:07:49.448177]: [Epoch: 688(45.89726484322882%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:07:50.703526]: [Epoch: 688(45.89726484322882%): Data: 25.333333333333336%]:Running loss: 4.350375100970268
[2018-04-17 17:07:51.975398]: [Epoch: 688(45.89726484322882%): Data: 50.66666666666667%]:Running loss: 8.483231723308563
[2018-04-17 17:07:55.531353]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:07:55.656185]: ====================
[2018-04-17 17:07:55.661700]: Elapsed time since starting training: 1:12:41.057899
[2018-04-17 17:07:55.666211]: ====================
[2018-04-17 17:07:55.737902]: [Epoch: 689(45.96397598398932%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:07:57.010787]: [Epoch: 689(45.96397598398932%): Data: 25.333333333333336%]:Running loss: 4.3503727465868
[2018-04-17 17:07:58.290693]: [Epoch: 689(45.96397598398932%): Data: 50.66666666666667%]:Running loss: 8.483229875564575
[2018-04-17 17:08:01.866698]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:08:01.988022]: ====================
[2018-04-17 17:08:01.993034]: Elapsed time since starting training: 1:12:47.388732
[2018-04-17 17:08:01.997045]: ====================
[2018-04-17 17:08:02.070239]: [Epoch: 690(46.03068712474983%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:08:03.354154]: [Epoch: 690(46.03068712474983%): Data: 25.333333333333336%]:Running loss: 4.350375607609749
[2018-04-17 17:08:04.614004]: [Epoch: 690(46.03068712474983%): Data: 50.66666666666667%]:Running loss: 8.483231022953987
[2018-04-17 17:08:08.182993]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:08:08.324871]: ====================
[2018-04-17 17:08:08.329884]: Elapsed time since starting training: 1:12:53.726083
[2018-04-17 17:08:08.334396]: ====================
[2018-04-17 17:08:08.406588]: [Epoch: 691(46.09739826551034%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:08:09.659921]: [Epoch: 691(46.09739826551034%): Data: 25.333333333333336%]:Running loss: 4.350375756621361
[2018-04-17 17:08:10.933306]: [Epoch: 691(46.09739826551034%): Data: 50.66666666666667%]:Running loss: 8.483233332633972
[2018-04-17 17:08:14.615597]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:08:14.732408]: ====================
[2018-04-17 17:08:14.736921]: Elapsed time since starting training: 1:13:00.133120
[2018-04-17 17:08:14.747949]: ====================
[2018-04-17 17:08:14.817133]: [Epoch: 692(46.164109406270846%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:08:16.091522]: [Epoch: 692(46.164109406270846%): Data: 25.333333333333336%]:Running loss: 4.350374102592468
[2018-04-17 17:08:17.356385]: [Epoch: 692(46.164109406270846%): Data: 50.66666666666667%]:Running loss: 8.48322930932045
[2018-04-17 17:08:20.894293]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:08:21.022634]: ====================
[2018-04-17 17:08:21.027647]: Elapsed time since starting training: 1:13:06.423846
[2018-04-17 17:08:21.032662]: ====================
[2018-04-17 17:08:21.102847]: [Epoch: 693(46.23082054703136%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:08:22.415337]: [Epoch: 693(46.23082054703136%): Data: 25.333333333333336%]:Running loss: 4.350372731685638
[2018-04-17 17:08:23.689725]: [Epoch: 693(46.23082054703136%): Data: 50.66666666666667%]:Running loss: 8.483229711651802
[2018-04-17 17:08:27.262229]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:08:27.407616]: ====================
[2018-04-17 17:08:27.412128]: Elapsed time since starting training: 1:13:12.808327
[2018-04-17 17:08:27.417142]: ====================
[2018-04-17 17:08:27.486827]: [Epoch: 694(46.29753168779186%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:08:28.760213]: [Epoch: 694(46.29753168779186%): Data: 25.333333333333336%]:Running loss: 4.350374191999435
[2018-04-17 17:08:30.041118]: [Epoch: 694(46.29753168779186%): Data: 50.66666666666667%]:Running loss: 8.483228892087936
[2018-04-17 17:08:33.549948]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:08:33.674280]: ====================
[2018-04-17 17:08:33.680296]: Elapsed time since starting training: 1:13:19.075993
[2018-04-17 17:08:33.684807]: ====================
[2018-04-17 17:08:33.755996]: [Epoch: 695(46.364242828552364%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:08:34.999302]: [Epoch: 695(46.364242828552364%): Data: 25.333333333333336%]:Running loss: 4.350375860929489
[2018-04-17 17:08:36.249627]: [Epoch: 695(46.364242828552364%): Data: 50.66666666666667%]:Running loss: 8.48323169350624
[2018-04-17 17:08:39.728878]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:08:39.846693]: ====================
[2018-04-17 17:08:39.851204]: Elapsed time since starting training: 1:13:25.247403
[2018-04-17 17:08:39.855715]: ====================
[2018-04-17 17:08:39.925401]: [Epoch: 696(46.430953969312874%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:08:41.163693]: [Epoch: 696(46.430953969312874%): Data: 25.333333333333336%]:Running loss: 4.350373193621635
[2018-04-17 17:08:42.424044]: [Epoch: 696(46.430953969312874%): Data: 50.66666666666667%]:Running loss: 8.483227178454399
[2018-04-17 17:08:45.988522]: Test set accuracy: 94.33962264150944% ,loss = 5.437972769141197
[2018-04-17 17:08:46.116864]: ====================
[2018-04-17 17:08:46.121877]: Elapsed time since starting training: 1:13:31.518076
[2018-04-17 17:08:46.126891]: ====================
[2018-04-17 17:08:46.197579]: [Epoch: 697(46.497665110073385%): Data: 0.0%]:Running loss: 0.2175189107656479
[2018-04-17 17:08:47.463946]: [Epoch: 697(46.497665110073385%): Data: 25.333333333333336%]:Running loss: 4.350374802947044
[2018-04-17 17:08:48.718782]: [Epoch: 697(46.497665110073385%): Data: 50.66666666666667%]:Running loss: 8.483230963349342
[2018-04-17 17:08:52.192018]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:08:52.314844]: ====================
[2018-04-17 17:08:52.319356]: Elapsed time since starting training: 1:13:37.715555
[2018-04-17 17:08:52.323868]: ====================
[2018-04-17 17:08:52.395057]: [Epoch: 698(46.56437625083389%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:08:53.683483]: [Epoch: 698(46.56437625083389%): Data: 25.333333333333336%]:Running loss: 4.350375726819038
[2018-04-17 17:08:54.951355]: [Epoch: 698(46.56437625083389%): Data: 50.66666666666667%]:Running loss: 8.48323018848896
[2018-04-17 17:08:58.516334]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:08:58.634648]: ====================
[2018-04-17 17:08:58.639662]: Elapsed time since starting training: 1:13:44.035861
[2018-04-17 17:08:58.644174]: ====================
[2018-04-17 17:08:58.713859]: [Epoch: 699(46.63108739159439%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:08:59.991757]: [Epoch: 699(46.63108739159439%): Data: 25.333333333333336%]:Running loss: 4.3503748923540115
[2018-04-17 17:09:01.258626]: [Epoch: 699(46.63108739159439%): Data: 50.66666666666667%]:Running loss: 8.483229726552963
[2018-04-17 17:09:04.862709]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:09:04.977013]: ====================
[2018-04-17 17:09:04.986538]: Elapsed time since starting training: 1:13:50.382737
[2018-04-17 17:09:04.994559]: ====================
[2018-04-17 17:09:05.067253]: [Epoch: 700(46.6977985323549%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:09:06.363199]: [Epoch: 700(46.6977985323549%): Data: 25.333333333333336%]:Running loss: 4.350372895598412
[2018-04-17 17:09:07.647113]: [Epoch: 700(46.6977985323549%): Data: 50.66666666666667%]:Running loss: 8.483230352401733
[2018-04-17 17:09:11.229638]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 17:09:11.350961]: ====================
[2018-04-17 17:09:11.355473]: Elapsed time since starting training: 1:13:56.751672
[2018-04-17 17:09:11.360486]: ====================
[2018-04-17 17:09:11.430172]: [Epoch: 701(46.76450967311541%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 17:09:12.710075]: [Epoch: 701(46.76450967311541%): Data: 25.333333333333336%]:Running loss: 4.350373342633247
[2018-04-17 17:09:13.980453]: [Epoch: 701(46.76450967311541%): Data: 50.66666666666667%]:Running loss: 8.483228355646133
[2018-04-17 17:09:17.572504]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:09:17.689816]: ====================
[2018-04-17 17:09:17.694329]: Elapsed time since starting training: 1:14:03.090528
[2018-04-17 17:09:17.699342]: ====================
[2018-04-17 17:09:17.770029]: [Epoch: 702(46.831220813875916%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:09:19.060962]: [Epoch: 702(46.831220813875916%): Data: 25.333333333333336%]:Running loss: 4.350376084446907
[2018-04-17 17:09:20.349387]: [Epoch: 702(46.831220813875916%): Data: 50.66666666666667%]:Running loss: 8.483231544494629
[2018-04-17 17:09:23.931412]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:09:24.060255]: ====================
[2018-04-17 17:09:24.064767]: Elapsed time since starting training: 1:14:09.460966
[2018-04-17 17:09:24.069780]: ====================
[2018-04-17 17:09:24.141972]: [Epoch: 703(46.89793195463643%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:09:25.426888]: [Epoch: 703(46.89793195463643%): Data: 25.333333333333336%]:Running loss: 4.350373685359955
[2018-04-17 17:09:26.707796]: [Epoch: 703(46.89793195463643%): Data: 50.66666666666667%]:Running loss: 8.483227089047432
[2018-04-17 17:09:30.331932]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 17:09:30.448743]: ====================
[2018-04-17 17:09:30.453254]: Elapsed time since starting training: 1:14:15.849453
[2018-04-17 17:09:30.457264]: ====================
[2018-04-17 17:09:30.524944]: [Epoch: 704(46.96464309539693%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 17:09:31.761237]: [Epoch: 704(46.96464309539693%): Data: 25.333333333333336%]:Running loss: 4.3503735810518265
[2018-04-17 17:09:32.996516]: [Epoch: 704(46.96464309539693%): Data: 50.66666666666667%]:Running loss: 8.483230322599411
[2018-04-17 17:09:36.567010]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:09:36.688834]: ====================
[2018-04-17 17:09:36.694349]: Elapsed time since starting training: 1:14:22.090548
[2018-04-17 17:09:36.699363]: ====================
[2018-04-17 17:09:36.774061]: [Epoch: 705(47.03135423615744%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:09:38.056974]: [Epoch: 705(47.03135423615744%): Data: 25.333333333333336%]:Running loss: 4.350375145673752
[2018-04-17 17:09:39.355425]: [Epoch: 705(47.03135423615744%): Data: 50.66666666666667%]:Running loss: 8.483229011297226
[2018-04-17 17:09:42.960010]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:09:43.082334]: ====================
[2018-04-17 17:09:43.086346]: Elapsed time since starting training: 1:14:28.482043
[2018-04-17 17:09:43.090356]: ====================
[2018-04-17 17:09:43.159038]: [Epoch: 706(47.098065376917944%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:09:44.425907]: [Epoch: 706(47.098065376917944%): Data: 25.333333333333336%]:Running loss: 4.35037536919117
[2018-04-17 17:09:45.679240]: [Epoch: 706(47.098065376917944%): Data: 50.66666666666667%]:Running loss: 8.483229726552963
[2018-04-17 17:09:49.181553]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:09:49.296358]: ====================
[2018-04-17 17:09:49.301873]: Elapsed time since starting training: 1:14:34.698072
[2018-04-17 17:09:49.305882]: ====================
[2018-04-17 17:09:49.377582]: [Epoch: 707(47.164776517678455%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:09:50.652964]: [Epoch: 707(47.164776517678455%): Data: 25.333333333333336%]:Running loss: 4.350372463464737
[2018-04-17 17:09:51.913817]: [Epoch: 707(47.164776517678455%): Data: 50.66666666666667%]:Running loss: 8.483229994773865
[2018-04-17 17:09:55.414626]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:09:55.529431]: ====================
[2018-04-17 17:09:55.534946]: Elapsed time since starting training: 1:14:40.931145
[2018-04-17 17:09:55.539458]: ====================
[2018-04-17 17:09:55.608140]: [Epoch: 708(47.23148765843896%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:09:56.862988]: [Epoch: 708(47.23148765843896%): Data: 25.333333333333336%]:Running loss: 4.350373163819313
[2018-04-17 17:09:58.124832]: [Epoch: 708(47.23148765843896%): Data: 50.66666666666667%]:Running loss: 8.483228370547295
[2018-04-17 17:10:01.629150]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:10:01.749470]: ====================
[2018-04-17 17:10:01.753983]: Elapsed time since starting training: 1:14:47.150182
[2018-04-17 17:10:01.758494]: ====================
[2018-04-17 17:10:01.824670]: [Epoch: 709(47.29819879919946%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:10:03.080008]: [Epoch: 709(47.29819879919946%): Data: 25.333333333333336%]:Running loss: 4.350375026464462
[2018-04-17 17:10:04.362418]: [Epoch: 709(47.29819879919946%): Data: 50.66666666666667%]:Running loss: 8.483229145407677
[2018-04-17 17:10:07.926896]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:10:08.043205]: ====================
[2018-04-17 17:10:08.047717]: Elapsed time since starting training: 1:14:53.443916
[2018-04-17 17:10:08.052730]: ====================
[2018-04-17 17:10:08.120411]: [Epoch: 710(47.36490993995998%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:10:09.370735]: [Epoch: 710(47.36490993995998%): Data: 25.333333333333336%]:Running loss: 4.350373864173889
[2018-04-17 17:10:10.641614]: [Epoch: 710(47.36490993995998%): Data: 50.66666666666667%]:Running loss: 8.483227401971817
[2018-04-17 17:10:14.202081]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:10:14.324407]: ====================
[2018-04-17 17:10:14.328919]: Elapsed time since starting training: 1:14:59.725118
[2018-04-17 17:10:14.334935]: ====================
[2018-04-17 17:10:14.405121]: [Epoch: 711(47.43162108072048%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:10:15.653441]: [Epoch: 711(47.43162108072048%): Data: 25.333333333333336%]:Running loss: 4.350371032953262
[2018-04-17 17:10:16.916299]: [Epoch: 711(47.43162108072048%): Data: 50.66666666666667%]:Running loss: 8.483227849006653
[2018-04-17 17:10:20.438163]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:10:20.555977]: ====================
[2018-04-17 17:10:20.560489]: Elapsed time since starting training: 1:15:05.956688
[2018-04-17 17:10:20.565502]: ====================
[2018-04-17 17:10:20.637193]: [Epoch: 712(47.498332221480986%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:10:21.900050]: [Epoch: 712(47.498332221480986%): Data: 25.333333333333336%]:Running loss: 4.350375190377235
[2018-04-17 17:10:23.150375]: [Epoch: 712(47.498332221480986%): Data: 50.66666666666667%]:Running loss: 8.483229160308838
[2018-04-17 17:10:26.601553]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:10:26.722373]: ====================
[2018-04-17 17:10:26.726885]: Elapsed time since starting training: 1:15:12.123084
[2018-04-17 17:10:26.731899]: ====================
[2018-04-17 17:10:26.802085]: [Epoch: 713(47.5650433622415%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:10:28.030351]: [Epoch: 713(47.5650433622415%): Data: 25.333333333333336%]:Running loss: 4.3503755033016205
[2018-04-17 17:10:29.271651]: [Epoch: 713(47.5650433622415%): Data: 50.66666666666667%]:Running loss: 8.483229845762253
[2018-04-17 17:10:32.735863]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:10:32.858188]: ====================
[2018-04-17 17:10:32.864706]: Elapsed time since starting training: 1:15:18.260404
[2018-04-17 17:10:32.869719]: ====================
[2018-04-17 17:10:32.941410]: [Epoch: 714(47.631754503002%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:10:34.148118]: [Epoch: 714(47.631754503002%): Data: 25.333333333333336%]:Running loss: 4.350372686982155
[2018-04-17 17:10:35.390421]: [Epoch: 714(47.631754503002%): Data: 50.66666666666667%]:Running loss: 8.48322819173336
[2018-04-17 17:10:38.877694]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:10:39.108307]: ====================
[2018-04-17 17:10:39.113823]: Elapsed time since starting training: 1:15:24.510022
[2018-04-17 17:10:39.118334]: ====================
[2018-04-17 17:10:39.185011]: [Epoch: 715(47.69846564376251%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:10:40.434834]: [Epoch: 715(47.69846564376251%): Data: 25.333333333333336%]:Running loss: 4.350373223423958
[2018-04-17 17:10:41.681148]: [Epoch: 715(47.69846564376251%): Data: 50.66666666666667%]:Running loss: 8.483228534460068
[2018-04-17 17:10:45.133829]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:10:45.248634]: ====================
[2018-04-17 17:10:45.253146]: Elapsed time since starting training: 1:15:30.649345
[2018-04-17 17:10:45.257157]: ====================
[2018-04-17 17:10:45.326842]: [Epoch: 716(47.765176784523014%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:10:46.559620]: [Epoch: 716(47.765176784523014%): Data: 25.333333333333336%]:Running loss: 4.350374594330788
[2018-04-17 17:10:47.804430]: [Epoch: 716(47.765176784523014%): Data: 50.66666666666667%]:Running loss: 8.483226791024208
[2018-04-17 17:10:51.305239]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:10:51.429069]: ====================
[2018-04-17 17:10:51.434082]: Elapsed time since starting training: 1:15:36.830281
[2018-04-17 17:10:51.439094]: ====================
[2018-04-17 17:10:51.508780]: [Epoch: 717(47.831887925283525%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:10:52.740555]: [Epoch: 717(47.831887925283525%): Data: 25.333333333333336%]:Running loss: 4.350373953580856
[2018-04-17 17:10:53.984362]: [Epoch: 717(47.831887925283525%): Data: 50.66666666666667%]:Running loss: 8.483227461576462
[2018-04-17 17:10:57.442056]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:10:57.575411]: ====================
[2018-04-17 17:10:57.579923]: Elapsed time since starting training: 1:15:42.976122
[2018-04-17 17:10:57.584435]: ====================
[2018-04-17 17:10:57.655624]: [Epoch: 718(47.89859906604403%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:10:58.921991]: [Epoch: 718(47.89859906604403%): Data: 25.333333333333336%]:Running loss: 4.350370600819588
[2018-04-17 17:11:00.187858]: [Epoch: 718(47.89859906604403%): Data: 50.66666666666667%]:Running loss: 8.483227357268333
[2018-04-17 17:11:03.710724]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:11:03.833552]: ====================
[2018-04-17 17:11:03.838565]: Elapsed time since starting training: 1:15:49.234262
[2018-04-17 17:11:03.844581]: ====================
[2018-04-17 17:11:03.915269]: [Epoch: 719(47.96531020680453%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:11:05.183641]: [Epoch: 719(47.96531020680453%): Data: 25.333333333333336%]:Running loss: 4.350375190377235
[2018-04-17 17:11:06.431960]: [Epoch: 719(47.96531020680453%): Data: 50.66666666666667%]:Running loss: 8.483229279518127
[2018-04-17 17:11:09.911212]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:11:10.030028]: ====================
[2018-04-17 17:11:10.034038]: Elapsed time since starting training: 1:15:55.430237
[2018-04-17 17:11:10.038550]: ====================
[2018-04-17 17:11:10.107233]: [Epoch: 720(48.03202134756505%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:11:11.350038]: [Epoch: 720(48.03202134756505%): Data: 25.333333333333336%]:Running loss: 4.350375175476074
[2018-04-17 17:11:12.606879]: [Epoch: 720(48.03202134756505%): Data: 50.66666666666667%]:Running loss: 8.483229100704193
[2018-04-17 17:11:16.056050]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:11:16.197928]: ====================
[2018-04-17 17:11:16.202941]: Elapsed time since starting training: 1:16:01.599140
[2018-04-17 17:11:16.207955]: ====================
[2018-04-17 17:11:16.274632]: [Epoch: 721(48.09873248832555%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:11:17.532978]: [Epoch: 721(48.09873248832555%): Data: 25.333333333333336%]:Running loss: 4.350372716784477
[2018-04-17 17:11:18.773276]: [Epoch: 721(48.09873248832555%): Data: 50.66666666666667%]:Running loss: 8.483229011297226
[2018-04-17 17:11:22.267567]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:11:22.387887]: ====================
[2018-04-17 17:11:22.392900]: Elapsed time since starting training: 1:16:07.789099
[2018-04-17 17:11:22.397412]: ====================
[2018-04-17 17:11:22.466096]: [Epoch: 722(48.165443629086056%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:11:23.748004]: [Epoch: 722(48.165443629086056%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:11:25.003843]: [Epoch: 722(48.165443629086056%): Data: 50.66666666666667%]:Running loss: 8.483228877186775
[2018-04-17 17:11:28.600406]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:11:28.719723]: ====================
[2018-04-17 17:11:28.724235]: Elapsed time since starting training: 1:16:14.120434
[2018-04-17 17:11:28.729249]: ====================
[2018-04-17 17:11:28.801441]: [Epoch: 723(48.23215476984657%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:11:30.111926]: [Epoch: 723(48.23215476984657%): Data: 25.333333333333336%]:Running loss: 4.350375398993492
[2018-04-17 17:11:31.392330]: [Epoch: 723(48.23215476984657%): Data: 50.66666666666667%]:Running loss: 8.483226984739304
[2018-04-17 17:11:34.961320]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:11:35.081640]: ====================
[2018-04-17 17:11:35.086653]: Elapsed time since starting training: 1:16:20.482350
[2018-04-17 17:11:35.091165]: ====================
[2018-04-17 17:11:35.162354]: [Epoch: 724(48.29886591060707%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:11:36.433735]: [Epoch: 724(48.29886591060707%): Data: 25.333333333333336%]:Running loss: 4.350373268127441
[2018-04-17 17:11:37.693084]: [Epoch: 724(48.29886591060707%): Data: 50.66666666666667%]:Running loss: 8.483227968215942
[2018-04-17 17:11:41.274607]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:11:41.395428]: ====================
[2018-04-17 17:11:41.400442]: Elapsed time since starting training: 1:16:26.796139
[2018-04-17 17:11:41.405455]: ====================
[2018-04-17 17:11:41.474137]: [Epoch: 725(48.36557705136758%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:11:42.740504]: [Epoch: 725(48.36557705136758%): Data: 25.333333333333336%]:Running loss: 4.35037162899971
[2018-04-17 17:11:44.046979]: [Epoch: 725(48.36557705136758%): Data: 50.66666666666667%]:Running loss: 8.483226910233498
[2018-04-17 17:11:47.629003]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:11:47.745313]: ====================
[2018-04-17 17:11:47.749824]: Elapsed time since starting training: 1:16:33.146023
[2018-04-17 17:11:47.754337]: ====================
[2018-04-17 17:11:47.825024]: [Epoch: 726(48.432288192128084%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:11:49.132008]: [Epoch: 726(48.432288192128084%): Data: 25.333333333333336%]:Running loss: 4.35037562251091
[2018-04-17 17:11:50.403388]: [Epoch: 726(48.432288192128084%): Data: 50.66666666666667%]:Running loss: 8.483230292797089
[2018-04-17 17:11:53.980901]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:11:54.108240]: ====================
[2018-04-17 17:11:54.113253]: Elapsed time since starting training: 1:16:39.508951
[2018-04-17 17:11:54.117765]: ====================
[2018-04-17 17:11:54.190967]: [Epoch: 727(48.498999332888594%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:11:55.461338]: [Epoch: 727(48.498999332888594%): Data: 25.333333333333336%]:Running loss: 4.350373357534409
[2018-04-17 17:11:56.722190]: [Epoch: 727(48.498999332888594%): Data: 50.66666666666667%]:Running loss: 8.483225375413895
[2018-04-17 17:12:00.266614]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:12:00.383425]: ====================
[2018-04-17 17:12:00.386934]: Elapsed time since starting training: 1:16:45.783133
[2018-04-17 17:12:00.391948]: ====================
[2018-04-17 17:12:00.463638]: [Epoch: 728(48.5657104736491%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:12:01.741537]: [Epoch: 728(48.5657104736491%): Data: 25.333333333333336%]:Running loss: 4.350371599197388
[2018-04-17 17:12:03.037482]: [Epoch: 728(48.5657104736491%): Data: 50.66666666666667%]:Running loss: 8.483227103948593
[2018-04-17 17:12:06.558344]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:12:06.680673]: ====================
[2018-04-17 17:12:06.685183]: Elapsed time since starting training: 1:16:52.081382
[2018-04-17 17:12:06.690195]: ====================
[2018-04-17 17:12:06.765395]: [Epoch: 729(48.6324216144096%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:12:08.008701]: [Epoch: 729(48.6324216144096%): Data: 25.333333333333336%]:Running loss: 4.350371763110161
[2018-04-17 17:12:09.292614]: [Epoch: 729(48.6324216144096%): Data: 50.66666666666667%]:Running loss: 8.483225673437119
[2018-04-17 17:12:12.874138]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:12:12.995461]: ====================
[2018-04-17 17:12:12.999972]: Elapsed time since starting training: 1:16:58.396171
[2018-04-17 17:12:13.005487]: ====================
[2018-04-17 17:12:13.077679]: [Epoch: 730(48.69913275517012%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:12:14.331514]: [Epoch: 730(48.69913275517012%): Data: 25.333333333333336%]:Running loss: 4.350373953580856
[2018-04-17 17:12:15.585849]: [Epoch: 730(48.69913275517012%): Data: 50.66666666666667%]:Running loss: 8.483227998018265
[2018-04-17 17:12:19.115734]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:12:19.233548]: ====================
[2018-04-17 17:12:19.237558]: Elapsed time since starting training: 1:17:04.633757
[2018-04-17 17:12:19.242571]: ====================
[2018-04-17 17:12:19.312257]: [Epoch: 731(48.76584389593062%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:12:20.558571]: [Epoch: 731(48.76584389593062%): Data: 25.333333333333336%]:Running loss: 4.350371703505516
[2018-04-17 17:12:21.810399]: [Epoch: 731(48.76584389593062%): Data: 50.66666666666667%]:Running loss: 8.48322793841362
[2018-04-17 17:12:25.308200]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:12:25.424008]: ====================
[2018-04-17 17:12:25.428520]: Elapsed time since starting training: 1:17:10.824218
[2018-04-17 17:12:25.434035]: ====================
[2018-04-17 17:12:25.503720]: [Epoch: 732(48.832555036691126%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:12:26.764573]: [Epoch: 732(48.832555036691126%): Data: 25.333333333333336%]:Running loss: 4.350372865796089
[2018-04-17 17:12:28.018407]: [Epoch: 732(48.832555036691126%): Data: 50.66666666666667%]:Running loss: 8.483226627111435
[2018-04-17 17:12:31.521721]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:12:31.648058]: ====================
[2018-04-17 17:12:31.652569]: Elapsed time since starting training: 1:17:17.048768
[2018-04-17 17:12:31.657082]: ====================
[2018-04-17 17:12:31.725263]: [Epoch: 733(48.899266177451636%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:12:33.006168]: [Epoch: 733(48.899266177451636%): Data: 25.333333333333336%]:Running loss: 4.35037437081337
[2018-04-17 17:12:34.278552]: [Epoch: 733(48.899266177451636%): Data: 50.66666666666667%]:Running loss: 8.483229890465736
[2018-04-17 17:12:37.845537]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:12:37.967361]: ====================
[2018-04-17 17:12:37.972876]: Elapsed time since starting training: 1:17:23.368573
[2018-04-17 17:12:37.977387]: ====================
[2018-04-17 17:12:38.050080]: [Epoch: 734(48.96597731821214%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:12:39.344021]: [Epoch: 734(48.96597731821214%): Data: 25.333333333333336%]:Running loss: 4.350371733307838
[2018-04-17 17:12:40.637461]: [Epoch: 734(48.96597731821214%): Data: 50.66666666666667%]:Running loss: 8.483226135373116
[2018-04-17 17:12:44.181893]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:12:44.306725]: ====================
[2018-04-17 17:12:44.311238]: Elapsed time since starting training: 1:17:29.707437
[2018-04-17 17:12:44.316251]: ====================
[2018-04-17 17:12:44.388442]: [Epoch: 735(49.03268845897265%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:12:45.627737]: [Epoch: 735(49.03268845897265%): Data: 25.333333333333336%]:Running loss: 4.350372105836868
[2018-04-17 17:12:46.912153]: [Epoch: 735(49.03268845897265%): Data: 50.66666666666667%]:Running loss: 8.483226582407951
[2018-04-17 17:12:50.464598]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:12:50.583415]: ====================
[2018-04-17 17:12:50.587927]: Elapsed time since starting training: 1:17:35.984126
[2018-04-17 17:12:50.591937]: ====================
[2018-04-17 17:12:50.663127]: [Epoch: 736(49.099399599733154%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:12:51.923478]: [Epoch: 736(49.099399599733154%): Data: 25.333333333333336%]:Running loss: 4.350374028086662
[2018-04-17 17:12:53.210400]: [Epoch: 736(49.099399599733154%): Data: 50.66666666666667%]:Running loss: 8.483225971460342
[2018-04-17 17:12:56.756328]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:12:56.876147]: ====================
[2018-04-17 17:12:56.880659]: Elapsed time since starting training: 1:17:42.276858
[2018-04-17 17:12:56.885673]: ====================
[2018-04-17 17:12:56.962376]: [Epoch: 737(49.166110740493664%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:12:58.216711]: [Epoch: 737(49.166110740493664%): Data: 25.333333333333336%]:Running loss: 4.35037299990654
[2018-04-17 17:12:59.468540]: [Epoch: 737(49.166110740493664%): Data: 50.66666666666667%]:Running loss: 8.483229398727417
[2018-04-17 17:13:03.066615]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 17:13:03.183927]: ====================
[2018-04-17 17:13:03.188940]: Elapsed time since starting training: 1:17:48.584639
[2018-04-17 17:13:03.194455]: ====================
[2018-04-17 17:13:03.262135]: [Epoch: 738(49.23282188125417%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 17:13:04.517974]: [Epoch: 738(49.23282188125417%): Data: 25.333333333333336%]:Running loss: 4.350369647145271
[2018-04-17 17:13:05.777323]: [Epoch: 738(49.23282188125417%): Data: 50.66666666666667%]:Running loss: 8.483223766088486
[2018-04-17 17:13:09.294174]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:13:09.432542]: ====================
[2018-04-17 17:13:09.437556]: Elapsed time since starting training: 1:17:54.833254
[2018-04-17 17:13:09.442568]: ====================
[2018-04-17 17:13:09.512756]: [Epoch: 739(49.29953302201467%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:13:10.770099]: [Epoch: 739(49.29953302201467%): Data: 25.333333333333336%]:Running loss: 4.350375339388847
[2018-04-17 17:13:12.020932]: [Epoch: 739(49.29953302201467%): Data: 50.66666666666667%]:Running loss: 8.483227297663689
[2018-04-17 17:13:15.595930]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:13:15.729285]: ====================
[2018-04-17 17:13:15.734299]: Elapsed time since starting training: 1:18:01.130498
[2018-04-17 17:13:15.739312]: ====================
[2018-04-17 17:13:15.804987]: [Epoch: 740(49.36624416277519%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:13:17.216239]: [Epoch: 740(49.36624416277519%): Data: 25.333333333333336%]:Running loss: 4.3503725826740265
[2018-04-17 17:13:18.474585]: [Epoch: 740(49.36624416277519%): Data: 50.66666666666667%]:Running loss: 8.483229354023933
[2018-04-17 17:13:22.053100]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 17:13:22.178433]: ====================
[2018-04-17 17:13:22.183948]: Elapsed time since starting training: 1:18:07.580147
[2018-04-17 17:13:22.188961]: ====================
[2018-04-17 17:13:22.260652]: [Epoch: 741(49.43295530353569%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 17:13:23.517995]: [Epoch: 741(49.43295530353569%): Data: 25.333333333333336%]:Running loss: 4.350371286273003
[2018-04-17 17:13:24.767317]: [Epoch: 741(49.43295530353569%): Data: 50.66666666666667%]:Running loss: 8.48322682082653
[2018-04-17 17:13:28.320265]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:13:28.446601]: ====================
[2018-04-17 17:13:28.452115]: Elapsed time since starting training: 1:18:13.848314
[2018-04-17 17:13:28.456125]: ====================
[2018-04-17 17:13:28.526813]: [Epoch: 742(49.499666444296196%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:13:29.751570]: [Epoch: 742(49.499666444296196%): Data: 25.333333333333336%]:Running loss: 4.35037025809288
[2018-04-17 17:13:30.961788]: [Epoch: 742(49.499666444296196%): Data: 50.66666666666667%]:Running loss: 8.483223766088486
[2018-04-17 17:13:34.372361]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:13:34.598462]: ====================
[2018-04-17 17:13:34.602473]: Elapsed time since starting training: 1:18:19.998672
[2018-04-17 17:13:34.609993]: ====================
[2018-04-17 17:13:34.696222]: [Epoch: 743(49.566377585056706%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:13:36.059346]: [Epoch: 743(49.566377585056706%): Data: 25.333333333333336%]:Running loss: 4.350373446941376
[2018-04-17 17:13:37.384871]: [Epoch: 743(49.566377585056706%): Data: 50.66666666666667%]:Running loss: 8.48322582244873
[2018-04-17 17:13:41.186479]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:13:41.339887]: ====================
[2018-04-17 17:13:41.346405]: Elapsed time since starting training: 1:18:26.742604
[2018-04-17 17:13:41.352421]: ====================
[2018-04-17 17:13:41.421103]: [Epoch: 744(49.63308872581721%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:13:42.705017]: [Epoch: 744(49.63308872581721%): Data: 25.333333333333336%]:Running loss: 4.35037125647068
[2018-04-17 17:13:44.005475]: [Epoch: 744(49.63308872581721%): Data: 50.66666666666667%]:Running loss: 8.483226954936981
[2018-04-17 17:13:47.871756]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:13:48.030678]: ====================
[2018-04-17 17:13:48.037697]: Elapsed time since starting training: 1:18:33.433395
[2018-04-17 17:13:48.044214]: ====================
[2018-04-17 17:13:48.113900]: [Epoch: 745(49.69979986657772%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:13:49.491061]: [Epoch: 745(49.69979986657772%): Data: 25.333333333333336%]:Running loss: 4.350372031331062
[2018-04-17 17:13:50.897300]: [Epoch: 745(49.69979986657772%): Data: 50.66666666666667%]:Running loss: 8.483224987983704
[2018-04-17 17:13:54.735506]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:13:54.858333]: ====================
[2018-04-17 17:13:54.863847]: Elapsed time since starting training: 1:18:40.260046
[2018-04-17 17:13:54.868359]: ====================
[2018-04-17 17:13:54.939047]: [Epoch: 746(49.766511007338224%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:13:56.203409]: [Epoch: 746(49.766511007338224%): Data: 25.333333333333336%]:Running loss: 4.3503738939762115
[2018-04-17 17:13:57.426662]: [Epoch: 746(49.766511007338224%): Data: 50.66666666666667%]:Running loss: 8.483228638768196
[2018-04-17 17:14:01.091406]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:14:01.223759]: ====================
[2018-04-17 17:14:01.229774]: Elapsed time since starting training: 1:18:46.625472
[2018-04-17 17:14:01.235289]: ====================
[2018-04-17 17:14:01.302468]: [Epoch: 747(49.833222148098734%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:14:02.635011]: [Epoch: 747(49.833222148098734%): Data: 25.333333333333336%]:Running loss: 4.350371152162552
[2018-04-17 17:14:03.991117]: [Epoch: 747(49.833222148098734%): Data: 50.66666666666667%]:Running loss: 8.48322606086731
[2018-04-17 17:14:07.637312]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:14:07.753120]: ====================
[2018-04-17 17:14:07.757632]: Elapsed time since starting training: 1:18:53.153831
[2018-04-17 17:14:07.762646]: ====================
[2018-04-17 17:14:07.836342]: [Epoch: 748(49.89993328885924%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:14:09.151839]: [Epoch: 748(49.89993328885924%): Data: 25.333333333333336%]:Running loss: 4.350374400615692
[2018-04-17 17:14:10.466836]: [Epoch: 748(49.89993328885924%): Data: 50.66666666666667%]:Running loss: 8.483227595686913
[2018-04-17 17:14:14.015271]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:14:14.132583]: ====================
[2018-04-17 17:14:14.137095]: Elapsed time since starting training: 1:18:59.532792
[2018-04-17 17:14:14.141607]: ====================
[2018-04-17 17:14:14.207783]: [Epoch: 749(49.96664442961974%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:14:15.512764]: [Epoch: 749(49.96664442961974%): Data: 25.333333333333336%]:Running loss: 4.350372478365898
[2018-04-17 17:14:16.820730]: [Epoch: 749(49.96664442961974%): Data: 50.66666666666667%]:Running loss: 8.483223587274551
[2018-04-17 17:14:20.299481]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:14:20.420804]: ====================
[2018-04-17 17:14:20.425315]: Elapsed time since starting training: 1:19:05.821514
[2018-04-17 17:14:20.430830]: ====================
[2018-04-17 17:14:20.499512]: [Epoch: 750(50.03335557038026%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:14:21.787437]: [Epoch: 750(50.03335557038026%): Data: 25.333333333333336%]:Running loss: 4.350371107459068
[2018-04-17 17:14:23.094412]: [Epoch: 750(50.03335557038026%): Data: 50.66666666666667%]:Running loss: 8.48322680592537
[2018-04-17 17:14:26.603243]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:14:26.826336]: ====================
[2018-04-17 17:14:26.831349]: Elapsed time since starting training: 1:19:12.227548
[2018-04-17 17:14:26.835861]: ====================
[2018-04-17 17:14:26.903541]: [Epoch: 751(50.100066711140755%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:14:28.208010]: [Epoch: 751(50.100066711140755%): Data: 25.333333333333336%]:Running loss: 4.350372284650803
[2018-04-17 17:14:29.540051]: [Epoch: 751(50.100066711140755%): Data: 50.66666666666667%]:Running loss: 8.483225464820862
[2018-04-17 17:14:33.162182]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:14:33.272977]: ====================
[2018-04-17 17:14:33.277489]: Elapsed time since starting training: 1:19:18.673688
[2018-04-17 17:14:33.282001]: ====================
[2018-04-17 17:14:33.362222]: [Epoch: 752(50.166777851901266%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:14:34.653146]: [Epoch: 752(50.166777851901266%): Data: 25.333333333333336%]:Running loss: 4.350374728441238
[2018-04-17 17:14:35.943077]: [Epoch: 752(50.166777851901266%): Data: 50.66666666666667%]:Running loss: 8.483226090669632
[2018-04-17 17:14:39.482488]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:14:39.593284]: ====================
[2018-04-17 17:14:39.598296]: Elapsed time since starting training: 1:19:24.994495
[2018-04-17 17:14:39.602808]: ====================
[2018-04-17 17:14:39.683524]: [Epoch: 753(50.233488992661776%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:14:40.997015]: [Epoch: 753(50.233488992661776%): Data: 25.333333333333336%]:Running loss: 4.350371271371841
[2018-04-17 17:14:42.299980]: [Epoch: 753(50.233488992661776%): Data: 50.66666666666667%]:Running loss: 8.48322793841362
[2018-04-17 17:14:46.254996]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:14:46.397876]: ====================
[2018-04-17 17:14:46.402889]: Elapsed time since starting training: 1:19:31.799088
[2018-04-17 17:14:46.407401]: ====================
[2018-04-17 17:14:46.484607]: [Epoch: 754(50.30020013342228%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:14:47.828682]: [Epoch: 754(50.30020013342228%): Data: 25.333333333333336%]:Running loss: 4.350371316075325
[2018-04-17 17:14:49.155709]: [Epoch: 754(50.30020013342228%): Data: 50.66666666666667%]:Running loss: 8.483224987983704
[2018-04-17 17:14:52.696123]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:14:52.821958]: ====================
[2018-04-17 17:14:52.826470]: Elapsed time since starting training: 1:19:38.222167
[2018-04-17 17:14:52.830983]: ====================
[2018-04-17 17:14:52.902171]: [Epoch: 755(50.36691127418279%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:14:54.188090]: [Epoch: 755(50.36691127418279%): Data: 25.333333333333336%]:Running loss: 4.3503738939762115
[2018-04-17 17:14:55.456462]: [Epoch: 755(50.36691127418279%): Data: 50.66666666666667%]:Running loss: 8.483228296041489
[2018-04-17 17:14:59.016429]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:14:59.132739]: ====================
[2018-04-17 17:14:59.137250]: Elapsed time since starting training: 1:19:44.532947
[2018-04-17 17:14:59.143265]: ====================
[2018-04-17 17:14:59.214957]: [Epoch: 756(50.433622414943294%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:15:00.482840]: [Epoch: 756(50.433622414943294%): Data: 25.333333333333336%]:Running loss: 4.35037137567997
[2018-04-17 17:15:01.752709]: [Epoch: 756(50.433622414943294%): Data: 50.66666666666667%]:Running loss: 8.483224749565125
[2018-04-17 17:15:05.342254]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:15:05.478616]: ====================
[2018-04-17 17:15:05.483630]: Elapsed time since starting training: 1:19:50.879829
[2018-04-17 17:15:05.488142]: ====================
[2018-04-17 17:15:05.559833]: [Epoch: 757(50.500333555703804%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:15:06.823693]: [Epoch: 757(50.500333555703804%): Data: 25.333333333333336%]:Running loss: 4.350370556116104
[2018-04-17 17:15:08.076023]: [Epoch: 757(50.500333555703804%): Data: 50.66666666666667%]:Running loss: 8.483223617076874
[2018-04-17 17:15:11.592373]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:15:11.713695]: ====================
[2018-04-17 17:15:11.718208]: Elapsed time since starting training: 1:19:57.114407
[2018-04-17 17:15:11.723221]: ====================
[2018-04-17 17:15:11.788394]: [Epoch: 758(50.567044696464315%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:15:13.075817]: [Epoch: 758(50.567044696464315%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:15:14.340180]: [Epoch: 758(50.567044696464315%): Data: 50.66666666666667%]:Running loss: 8.483227044343948
[2018-04-17 17:15:17.901650]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:15:18.024977]: ====================
[2018-04-17 17:15:18.029991]: Elapsed time since starting training: 1:20:03.426190
[2018-04-17 17:15:18.034503]: ====================
[2018-04-17 17:15:18.105191]: [Epoch: 759(50.63375583722481%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:15:19.406150]: [Epoch: 759(50.63375583722481%): Data: 25.333333333333336%]:Running loss: 4.350370019674301
[2018-04-17 17:15:20.675024]: [Epoch: 759(50.63375583722481%): Data: 50.66666666666667%]:Running loss: 8.483225628733635
[2018-04-17 17:15:24.242017]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:15:24.360833]: ====================
[2018-04-17 17:15:24.365847]: Elapsed time since starting training: 1:20:09.762046
[2018-04-17 17:15:24.370860]: ====================
[2018-04-17 17:15:24.439542]: [Epoch: 760(50.70046697798533%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:15:25.725468]: [Epoch: 760(50.70046697798533%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:15:27.001361]: [Epoch: 760(50.70046697798533%): Data: 50.66666666666667%]:Running loss: 8.483223110437393
[2018-04-17 17:15:30.587396]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:15:30.709722]: ====================
[2018-04-17 17:15:30.714735]: Elapsed time since starting training: 1:20:16.110934
[2018-04-17 17:15:30.719247]: ====================
[2018-04-17 17:15:30.789935]: [Epoch: 761(50.767178118745825%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:15:32.051288]: [Epoch: 761(50.767178118745825%): Data: 25.333333333333336%]:Running loss: 4.3503727465868
[2018-04-17 17:15:33.318158]: [Epoch: 761(50.767178118745825%): Data: 50.66666666666667%]:Running loss: 8.483227252960205
[2018-04-17 17:15:36.861579]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:15:36.982902]: ====================
[2018-04-17 17:15:36.986912]: Elapsed time since starting training: 1:20:22.383111
[2018-04-17 17:15:36.991425]: ====================
[2018-04-17 17:15:37.059606]: [Epoch: 762(50.833889259506336%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:15:38.320459]: [Epoch: 762(50.833889259506336%): Data: 25.333333333333336%]:Running loss: 4.350368410348892
[2018-04-17 17:15:39.757279]: [Epoch: 762(50.833889259506336%): Data: 50.66666666666667%]:Running loss: 8.483218654990196
[2018-04-17 17:15:43.456114]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:15:43.594482]: ====================
[2018-04-17 17:15:43.599997]: Elapsed time since starting training: 1:20:28.996196
[2018-04-17 17:15:43.604509]: ====================
[2018-04-17 17:15:43.676199]: [Epoch: 763(50.900600400266846%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:15:44.978161]: [Epoch: 763(50.900600400266846%): Data: 25.333333333333336%]:Running loss: 4.350368902087212
[2018-04-17 17:15:46.310705]: [Epoch: 763(50.900600400266846%): Data: 50.66666666666667%]:Running loss: 8.483219429850578
[2018-04-17 17:15:49.933838]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:15:50.060174]: ====================
[2018-04-17 17:15:50.065188]: Elapsed time since starting training: 1:20:35.461387
[2018-04-17 17:15:50.069699]: ====================
[2018-04-17 17:15:50.139887]: [Epoch: 764(50.96731154102735%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:15:51.426307]: [Epoch: 764(50.96731154102735%): Data: 25.333333333333336%]:Running loss: 4.350369215011597
[2018-04-17 17:15:52.707714]: [Epoch: 764(50.96731154102735%): Data: 50.66666666666667%]:Running loss: 8.483220309019089
[2018-04-17 17:15:56.267680]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:15:56.394016]: ====================
[2018-04-17 17:15:56.400032]: Elapsed time since starting training: 1:20:41.795730
[2018-04-17 17:15:56.404544]: ====================
[2018-04-17 17:15:56.474229]: [Epoch: 765(51.03402268178786%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:15:57.736087]: [Epoch: 765(51.03402268178786%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:15:59.011977]: [Epoch: 765(51.03402268178786%): Data: 50.66666666666667%]:Running loss: 8.483220905065536
[2018-04-17 17:16:02.602023]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:16:02.722343]: ====================
[2018-04-17 17:16:02.726855]: Elapsed time since starting training: 1:20:48.123054
[2018-04-17 17:16:02.732370]: ====================
[2018-04-17 17:16:02.799047]: [Epoch: 766(51.100733822548364%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:16:04.071931]: [Epoch: 766(51.100733822548364%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:16:05.353840]: [Epoch: 766(51.100733822548364%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:16:08.932857]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:16:09.056185]: ====================
[2018-04-17 17:16:09.060696]: Elapsed time since starting training: 1:20:54.456895
[2018-04-17 17:16:09.066712]: ====================
[2018-04-17 17:16:09.139406]: [Epoch: 767(51.167444963308874%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:16:10.423821]: [Epoch: 767(51.167444963308874%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:16:11.685677]: [Epoch: 767(51.167444963308874%): Data: 50.66666666666667%]:Running loss: 8.483223259449005
[2018-04-17 17:16:15.300288]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:16:15.422613]: ====================
[2018-04-17 17:16:15.427626]: Elapsed time since starting training: 1:21:00.823324
[2018-04-17 17:16:15.432640]: ====================
[2018-04-17 17:16:15.500319]: [Epoch: 768(51.234156104069385%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:16:16.756158]: [Epoch: 768(51.234156104069385%): Data: 25.333333333333336%]:Running loss: 4.3503711223602295
[2018-04-17 17:16:18.040574]: [Epoch: 768(51.234156104069385%): Data: 50.66666666666667%]:Running loss: 8.483223915100098
[2018-04-17 17:16:21.571964]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:16:21.696796]: ====================
[2018-04-17 17:16:21.701810]: Elapsed time since starting training: 1:21:07.097507
[2018-04-17 17:16:21.705820]: ====================
[2018-04-17 17:16:21.772999]: [Epoch: 769(51.30086724482988%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:16:23.076464]: [Epoch: 769(51.30086724482988%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:16:24.347343]: [Epoch: 769(51.30086724482988%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:16:27.879234]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:16:28.016600]: ====================
[2018-04-17 17:16:28.022616]: Elapsed time since starting training: 1:21:13.418815
[2018-04-17 17:16:28.026627]: ====================
[2018-04-17 17:16:28.104334]: [Epoch: 770(51.3675783855904%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:16:29.373207]: [Epoch: 770(51.3675783855904%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:16:30.638572]: [Epoch: 770(51.3675783855904%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:16:34.242655]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:16:34.370495]: ====================
[2018-04-17 17:16:34.375008]: Elapsed time since starting training: 1:21:19.771207
[2018-04-17 17:16:34.379530]: ====================
[2018-04-17 17:16:34.455723]: [Epoch: 771(51.434289526350895%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:16:35.743145]: [Epoch: 771(51.434289526350895%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:16:37.052627]: [Epoch: 771(51.434289526350895%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:16:40.562459]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:16:40.680273]: ====================
[2018-04-17 17:16:40.685787]: Elapsed time since starting training: 1:21:26.081986
[2018-04-17 17:16:40.690299]: ====================
[2018-04-17 17:16:40.758480]: [Epoch: 772(51.501000667111406%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:16:42.025853]: [Epoch: 772(51.501000667111406%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:16:43.283194]: [Epoch: 772(51.501000667111406%): Data: 50.66666666666667%]:Running loss: 8.483226835727692
[2018-04-17 17:16:46.821602]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:16:46.949944]: ====================
[2018-04-17 17:16:46.955960]: Elapsed time since starting training: 1:21:32.352159
[2018-04-17 17:16:46.960973]: ====================
[2018-04-17 17:16:47.041689]: [Epoch: 773(51.567711807871916%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:16:48.333623]: [Epoch: 773(51.567711807871916%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:16:49.665164]: [Epoch: 773(51.567711807871916%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:16:53.284287]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:16:53.405609]: ====================
[2018-04-17 17:16:53.410121]: Elapsed time since starting training: 1:21:38.806320
[2018-04-17 17:16:53.414132]: ====================
[2018-04-17 17:16:53.482814]: [Epoch: 774(51.63442294863242%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:16:54.792296]: [Epoch: 774(51.63442294863242%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:16:56.079720]: [Epoch: 774(51.63442294863242%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:16:59.641691]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:16:59.769030]: ====================
[2018-04-17 17:16:59.773542]: Elapsed time since starting training: 1:21:45.169741
[2018-04-17 17:16:59.777552]: ====================
[2018-04-17 17:16:59.847739]: [Epoch: 775(51.70113408939293%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:17:01.177274]: [Epoch: 775(51.70113408939293%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:17:02.442138]: [Epoch: 775(51.70113408939293%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:17:05.981549]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:17:06.104876]: ====================
[2018-04-17 17:17:06.109890]: Elapsed time since starting training: 1:21:51.505587
[2018-04-17 17:17:06.114903]: ====================
[2018-04-17 17:17:06.185091]: [Epoch: 776(51.76784523015343%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:17:07.476524]: [Epoch: 776(51.76784523015343%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:17:08.761441]: [Epoch: 776(51.76784523015343%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:17:12.365022]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:17:12.513416]: ====================
[2018-04-17 17:17:12.518430]: Elapsed time since starting training: 1:21:57.914629
[2018-04-17 17:17:12.522942]: ====================
[2018-04-17 17:17:12.591625]: [Epoch: 777(51.834556370913944%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:17:13.886067]: [Epoch: 777(51.834556370913944%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:17:15.155943]: [Epoch: 777(51.834556370913944%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:17:18.678810]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:17:18.795622]: ====================
[2018-04-17 17:17:18.800133]: Elapsed time since starting training: 1:22:04.196332
[2018-04-17 17:17:18.805648]: ====================
[2018-04-17 17:17:18.874330]: [Epoch: 778(51.901267511674455%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:17:20.158745]: [Epoch: 778(51.901267511674455%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:17:21.423107]: [Epoch: 778(51.901267511674455%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:17:25.025185]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:17:25.148513]: ====================
[2018-04-17 17:17:25.155532]: Elapsed time since starting training: 1:22:10.551230
[2018-04-17 17:17:25.160045]: ====================
[2018-04-17 17:17:25.232237]: [Epoch: 779(51.96797865243495%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:17:26.522166]: [Epoch: 779(51.96797865243495%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:17:27.814602]: [Epoch: 779(51.96797865243495%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:17:31.381645]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:17:31.512493]: ====================
[2018-04-17 17:17:31.517005]: Elapsed time since starting training: 1:22:16.912703
[2018-04-17 17:17:31.522019]: ====================
[2018-04-17 17:17:31.598723]: [Epoch: 780(52.03468979319547%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:17:32.874118]: [Epoch: 780(52.03468979319547%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:17:34.147500]: [Epoch: 780(52.03468979319547%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:17:37.718996]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:17:37.845834]: ====================
[2018-04-17 17:17:37.850346]: Elapsed time since starting training: 1:22:23.246545
[2018-04-17 17:17:37.854857]: ====================
[2018-04-17 17:17:37.936576]: [Epoch: 781(52.101400933955965%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:17:39.211465]: [Epoch: 781(52.101400933955965%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:17:40.479838]: [Epoch: 781(52.101400933955965%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:17:44.035793]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:17:44.158118]: ====================
[2018-04-17 17:17:44.162630]: Elapsed time since starting training: 1:22:29.558829
[2018-04-17 17:17:44.166641]: ====================
[2018-04-17 17:17:44.240838]: [Epoch: 782(52.168112074716475%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:17:45.528261]: [Epoch: 782(52.168112074716475%): Data: 25.333333333333336%]:Running loss: 4.350375697016716
[2018-04-17 17:17:46.791622]: [Epoch: 782(52.168112074716475%): Data: 50.66666666666667%]:Running loss: 8.483232736587524
[2018-04-17 17:17:50.367629]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:17:50.493464]: ====================
[2018-04-17 17:17:50.498477]: Elapsed time since starting training: 1:22:35.894174
[2018-04-17 17:17:50.503991]: ====================
[2018-04-17 17:17:50.577688]: [Epoch: 783(52.234823215476986%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:17:51.878647]: [Epoch: 783(52.234823215476986%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:17:53.159553]: [Epoch: 783(52.234823215476986%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:17:56.667380]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:17:56.894986]: ====================
[2018-04-17 17:17:56.899999]: Elapsed time since starting training: 1:22:42.295696
[2018-04-17 17:17:56.904511]: ====================
[2018-04-17 17:17:56.974697]: [Epoch: 784(52.30153435623749%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:17:58.261119]: [Epoch: 784(52.30153435623749%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:17:59.561575]: [Epoch: 784(52.30153435623749%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:18:03.112017]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:18:03.234342]: ====================
[2018-04-17 17:18:03.239355]: Elapsed time since starting training: 1:22:48.635053
[2018-04-17 17:18:03.243365]: ====================
[2018-04-17 17:18:03.316059]: [Epoch: 785(52.368245496998%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:18:04.612506]: [Epoch: 785(52.368245496998%): Data: 25.333333333333336%]:Running loss: 4.350369215011597
[2018-04-17 17:18:05.873358]: [Epoch: 785(52.368245496998%): Data: 50.66666666666667%]:Running loss: 8.483220309019089
[2018-04-17 17:18:09.414273]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:18:09.534595]: ====================
[2018-04-17 17:18:09.539106]: Elapsed time since starting training: 1:22:54.935305
[2018-04-17 17:18:09.544621]: ====================
[2018-04-17 17:18:09.614306]: [Epoch: 786(52.4349566377585%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:18:10.908748]: [Epoch: 786(52.4349566377585%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:18:12.176619]: [Epoch: 786(52.4349566377585%): Data: 50.66666666666667%]:Running loss: 8.483220890164375
[2018-04-17 17:18:15.735582]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:18:15.859913]: ====================
[2018-04-17 17:18:15.864425]: Elapsed time since starting training: 1:23:01.260624
[2018-04-17 17:18:15.868936]: ====================
[2018-04-17 17:18:15.943636]: [Epoch: 787(52.501667778519014%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:18:17.209501]: [Epoch: 787(52.501667778519014%): Data: 25.333333333333336%]:Running loss: 4.350370019674301
[2018-04-17 17:18:18.473864]: [Epoch: 787(52.501667778519014%): Data: 50.66666666666667%]:Running loss: 8.483221963047981
[2018-04-17 17:18:22.049371]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:18:22.173701]: ====================
[2018-04-17 17:18:22.178213]: Elapsed time since starting training: 1:23:07.574412
[2018-04-17 17:18:22.182725]: ====================
[2018-04-17 17:18:22.254917]: [Epoch: 788(52.568378919279525%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:18:23.525295]: [Epoch: 788(52.568378919279525%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:18:24.793667]: [Epoch: 788(52.568378919279525%): Data: 50.66666666666667%]:Running loss: 8.48322294652462
[2018-04-17 17:18:28.386220]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:18:28.516066]: ====================
[2018-04-17 17:18:28.521580]: Elapsed time since starting training: 1:23:13.917779
[2018-04-17 17:18:28.525591]: ====================
[2018-04-17 17:18:28.600289]: [Epoch: 789(52.63509006004002%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:18:29.896737]: [Epoch: 789(52.63509006004002%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 17:18:31.158095]: [Epoch: 789(52.63509006004002%): Data: 50.66666666666667%]:Running loss: 8.483221381902695
[2018-04-17 17:18:34.699005]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:18:34.815315]: ====================
[2018-04-17 17:18:34.819827]: Elapsed time since starting training: 1:23:20.216026
[2018-04-17 17:18:34.824840]: ====================
[2018-04-17 17:18:34.897534]: [Epoch: 790(52.70180120080054%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:18:36.164406]: [Epoch: 790(52.70180120080054%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:18:37.445314]: [Epoch: 790(52.70180120080054%): Data: 50.66666666666667%]:Running loss: 8.48322343826294
[2018-04-17 17:18:40.998260]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:18:41.123092]: ====================
[2018-04-17 17:18:41.129609]: Elapsed time since starting training: 1:23:26.525808
[2018-04-17 17:18:41.134121]: ====================
[2018-04-17 17:18:41.204308]: [Epoch: 791(52.768512341561035%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:18:42.508776]: [Epoch: 791(52.768512341561035%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:18:43.809234]: [Epoch: 791(52.768512341561035%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:18:47.389754]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:18:47.511579]: ====================
[2018-04-17 17:18:47.516091]: Elapsed time since starting training: 1:23:32.912290
[2018-04-17 17:18:47.521104]: ====================
[2018-04-17 17:18:47.589286]: [Epoch: 792(52.835223482321545%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:18:48.959930]: [Epoch: 792(52.835223482321545%): Data: 25.333333333333336%]:Running loss: 4.350371494889259
[2018-04-17 17:18:50.313028]: [Epoch: 792(52.835223482321545%): Data: 50.66666666666667%]:Running loss: 8.483225136995316
[2018-04-17 17:18:53.952705]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:18:54.071020]: ====================
[2018-04-17 17:18:54.076034]: Elapsed time since starting training: 1:23:39.471732
[2018-04-17 17:18:54.080044]: ====================
[2018-04-17 17:18:54.156247]: [Epoch: 793(52.901934623082056%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:18:55.506337]: [Epoch: 793(52.901934623082056%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:18:56.850912]: [Epoch: 793(52.901934623082056%): Data: 50.66666666666667%]:Running loss: 8.483222529292107
[2018-04-17 17:19:00.475549]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:19:00.595369]: ====================
[2018-04-17 17:19:00.599881]: Elapsed time since starting training: 1:23:45.995578
[2018-04-17 17:19:00.603891]: ====================
[2018-04-17 17:19:00.680094]: [Epoch: 794(52.96864576384256%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:19:02.019161]: [Epoch: 794(52.96864576384256%): Data: 25.333333333333336%]:Running loss: 4.350370824337006
[2018-04-17 17:19:03.363235]: [Epoch: 794(52.96864576384256%): Data: 50.66666666666667%]:Running loss: 8.483223333954811
[2018-04-17 17:19:07.208460]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:19:07.333291]: ====================
[2018-04-17 17:19:07.337804]: Elapsed time since starting training: 1:23:52.734003
[2018-04-17 17:19:07.342316]: ====================
[2018-04-17 17:19:07.416012]: [Epoch: 795(53.03535690460307%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:19:08.761088]: [Epoch: 795(53.03535690460307%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:19:10.100651]: [Epoch: 795(53.03535690460307%): Data: 50.66666666666667%]:Running loss: 8.48322406411171
[2018-04-17 17:19:13.784947]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:19:13.897746]: ====================
[2018-04-17 17:19:13.902760]: Elapsed time since starting training: 1:23:59.298458
[2018-04-17 17:19:13.907272]: ====================
[2018-04-17 17:19:13.980967]: [Epoch: 796(53.10206804536357%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:19:15.328049]: [Epoch: 796(53.10206804536357%): Data: 25.333333333333336%]:Running loss: 4.350372165441513
[2018-04-17 17:19:16.666107]: [Epoch: 796(53.10206804536357%): Data: 50.66666666666667%]:Running loss: 8.483226090669632
[2018-04-17 17:19:20.305284]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:19:20.426606]: ====================
[2018-04-17 17:19:20.431119]: Elapsed time since starting training: 1:24:05.826816
[2018-04-17 17:19:20.435129]: ====================
[2018-04-17 17:19:20.509828]: [Epoch: 797(53.168779186124084%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:19:21.849891]: [Epoch: 797(53.168779186124084%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:19:23.182434]: [Epoch: 797(53.168779186124084%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:19:26.813589]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:19:26.933910]: ====================
[2018-04-17 17:19:26.938422]: Elapsed time since starting training: 1:24:12.334621
[2018-04-17 17:19:26.943434]: ====================
[2018-04-17 17:19:27.016128]: [Epoch: 798(53.235490326884594%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:19:28.356692]: [Epoch: 798(53.235490326884594%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:19:29.694755]: [Epoch: 798(53.235490326884594%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:19:33.369521]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:19:33.485831]: ====================
[2018-04-17 17:19:33.490344]: Elapsed time since starting training: 1:24:18.886041
[2018-04-17 17:19:33.494855]: ====================
[2018-04-17 17:19:33.569065]: [Epoch: 799(53.30220146764509%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:19:34.891569]: [Epoch: 799(53.30220146764509%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:19:36.206064]: [Epoch: 799(53.30220146764509%): Data: 50.66666666666667%]:Running loss: 8.483228117227554
[2018-04-17 17:19:39.805635]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:19:39.919438]: ====================
[2018-04-17 17:19:39.923950]: Elapsed time since starting training: 1:24:25.320149
[2018-04-17 17:19:39.928964]: ====================
[2018-04-17 17:19:40.001657]: [Epoch: 800(53.36891260840561%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:19:41.346232]: [Epoch: 800(53.36891260840561%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:19:42.675767]: [Epoch: 800(53.36891260840561%): Data: 50.66666666666667%]:Running loss: 8.483229398727417
[2018-04-17 17:19:46.290378]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:19:46.405184]: ====================
[2018-04-17 17:19:46.409696]: Elapsed time since starting training: 1:24:31.805895
[2018-04-17 17:19:46.414208]: ====================
[2018-04-17 17:19:46.491413]: [Epoch: 801(53.435623749166105%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:19:47.819945]: [Epoch: 801(53.435623749166105%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:19:49.170536]: [Epoch: 801(53.435623749166105%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:19:53.248881]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:19:53.384241]: ====================
[2018-04-17 17:19:53.388754]: Elapsed time since starting training: 1:24:38.784953
[2018-04-17 17:19:53.394769]: ====================
[2018-04-17 17:19:53.472475]: [Epoch: 802(53.502334889926615%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:19:54.853648]: [Epoch: 802(53.502334889926615%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:19:56.170149]: [Epoch: 802(53.502334889926615%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:19:59.779746]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:19:59.906584]: ====================
[2018-04-17 17:19:59.911096]: Elapsed time since starting training: 1:24:45.307295
[2018-04-17 17:19:59.916109]: ====================
[2018-04-17 17:19:59.992813]: [Epoch: 803(53.569046030687126%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:20:01.294786]: [Epoch: 803(53.569046030687126%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:20:02.567158]: [Epoch: 803(53.569046030687126%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:20:06.110078]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:20:06.231902]: ====================
[2018-04-17 17:20:06.236415]: Elapsed time since starting training: 1:24:51.632614
[2018-04-17 17:20:06.241428]: ====================
[2018-04-17 17:20:06.309108]: [Epoch: 804(53.63575717144763%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:20:07.594526]: [Epoch: 804(53.63575717144763%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:20:08.868413]: [Epoch: 804(53.63575717144763%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:20:12.415344]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:20:12.548699]: ====================
[2018-04-17 17:20:12.553713]: Elapsed time since starting training: 1:24:57.949410
[2018-04-17 17:20:12.560731]: ====================
[2018-04-17 17:20:12.643451]: [Epoch: 805(53.70246831220814%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:20:13.915834]: [Epoch: 805(53.70246831220814%): Data: 25.333333333333336%]:Running loss: 4.350376203656197
[2018-04-17 17:20:15.189721]: [Epoch: 805(53.70246831220814%): Data: 50.66666666666667%]:Running loss: 8.483224183321
[2018-04-17 17:20:18.746686]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:20:18.866004]: ====================
[2018-04-17 17:20:18.871518]: Elapsed time since starting training: 1:25:04.267216
[2018-04-17 17:20:18.876031]: ====================
[2018-04-17 17:20:18.951230]: [Epoch: 806(53.76917945296864%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:20:20.213587]: [Epoch: 806(53.76917945296864%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:20:21.513543]: [Epoch: 806(53.76917945296864%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:20:25.036912]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:20:25.180293]: ====================
[2018-04-17 17:20:25.185306]: Elapsed time since starting training: 1:25:10.581505
[2018-04-17 17:20:25.190822]: ====================
[2018-04-17 17:20:25.256496]: [Epoch: 807(53.835890593729154%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:20:26.570490]: [Epoch: 807(53.835890593729154%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:20:27.874971]: [Epoch: 807(53.835890593729154%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:20:31.449463]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:20:31.567778]: ====================
[2018-04-17 17:20:31.572791]: Elapsed time since starting training: 1:25:16.968488
[2018-04-17 17:20:31.576801]: ====================
[2018-04-17 17:20:31.652001]: [Epoch: 808(53.902601734489664%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:20:32.970005]: [Epoch: 808(53.902601734489664%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:20:34.226847]: [Epoch: 808(53.902601734489664%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:20:37.737683]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:20:37.862515]: ====================
[2018-04-17 17:20:37.867027]: Elapsed time since starting training: 1:25:23.262725
[2018-04-17 17:20:37.871539]: ====================
[2018-04-17 17:20:37.942728]: [Epoch: 809(53.96931287525016%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:20:39.198066]: [Epoch: 809(53.96931287525016%): Data: 25.333333333333336%]:Running loss: 4.350368410348892
[2018-04-17 17:20:40.458919]: [Epoch: 809(53.96931287525016%): Data: 50.66666666666667%]:Running loss: 8.483217805624008
[2018-04-17 17:20:44.011866]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:20:44.137701]: ====================
[2018-04-17 17:20:44.141210]: Elapsed time since starting training: 1:25:29.537409
[2018-04-17 17:20:44.146224]: ====================
[2018-04-17 17:20:44.216411]: [Epoch: 810(54.03602401601068%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:20:45.510851]: [Epoch: 810(54.03602401601068%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:20:46.771203]: [Epoch: 810(54.03602401601068%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:20:50.326657]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:20:50.456503]: ====================
[2018-04-17 17:20:50.462519]: Elapsed time since starting training: 1:25:35.858216
[2018-04-17 17:20:50.467031]: ====================
[2018-04-17 17:20:50.538220]: [Epoch: 811(54.102735156771175%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:20:51.820128]: [Epoch: 811(54.102735156771175%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:20:53.140138]: [Epoch: 811(54.102735156771175%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:20:56.737202]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:20:56.875571]: ====================
[2018-04-17 17:20:56.880083]: Elapsed time since starting training: 1:25:42.276282
[2018-04-17 17:20:56.884595]: ====================
[2018-04-17 17:20:56.954782]: [Epoch: 812(54.169446297531685%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:20:58.219649]: [Epoch: 812(54.169446297531685%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:20:59.480000]: [Epoch: 812(54.169446297531685%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:21:03.043978]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:21:03.170314]: ====================
[2018-04-17 17:21:03.174824]: Elapsed time since starting training: 1:25:48.571023
[2018-04-17 17:21:03.180841]: ====================
[2018-04-17 17:21:03.251531]: [Epoch: 813(54.236157438292196%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:21:04.542461]: [Epoch: 813(54.236157438292196%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 17:21:05.809831]: [Epoch: 813(54.236157438292196%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 17:21:09.408406]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:21:09.546774]: ====================
[2018-04-17 17:21:09.551287]: Elapsed time since starting training: 1:25:54.947486
[2018-04-17 17:21:09.555798]: ====================
[2018-04-17 17:21:09.633003]: [Epoch: 814(54.3028685790527%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:21:10.908395]: [Epoch: 814(54.3028685790527%): Data: 25.333333333333336%]:Running loss: 4.350370287895203
[2018-04-17 17:21:12.189300]: [Epoch: 814(54.3028685790527%): Data: 50.66666666666667%]:Running loss: 8.483222231268883
[2018-04-17 17:21:15.721692]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:21:15.846023]: ====================
[2018-04-17 17:21:15.850535]: Elapsed time since starting training: 1:26:01.246734
[2018-04-17 17:21:15.855048]: ====================
[2018-04-17 17:21:15.928242]: [Epoch: 815(54.36957971981321%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:21:17.201628]: [Epoch: 815(54.36957971981321%): Data: 25.333333333333336%]:Running loss: 4.350370675325394
[2018-04-17 17:21:18.470001]: [Epoch: 815(54.36957971981321%): Data: 50.66666666666667%]:Running loss: 8.48322306573391
[2018-04-17 17:21:21.984847]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:21:22.110681]: ====================
[2018-04-17 17:21:22.115695]: Elapsed time since starting training: 1:26:07.511392
[2018-04-17 17:21:22.119705]: ====================
[2018-04-17 17:21:22.187886]: [Epoch: 816(54.43629086057371%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:21:23.453752]: [Epoch: 816(54.43629086057371%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:21:24.747192]: [Epoch: 816(54.43629086057371%): Data: 50.66666666666667%]:Running loss: 8.48322468996048
[2018-04-17 17:21:28.305653]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:21:28.431989]: ====================
[2018-04-17 17:21:28.436000]: Elapsed time since starting training: 1:26:13.832199
[2018-04-17 17:21:28.443019]: ====================
[2018-04-17 17:21:28.514709]: [Epoch: 817(54.503002001334224%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:21:29.783779]: [Epoch: 817(54.503002001334224%): Data: 25.333333333333336%]:Running loss: 4.350372031331062
[2018-04-17 17:21:31.045634]: [Epoch: 817(54.503002001334224%): Data: 50.66666666666667%]:Running loss: 8.483225673437119
[2018-04-17 17:21:34.595072]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:21:34.820171]: ====================
[2018-04-17 17:21:34.824682]: Elapsed time since starting training: 1:26:20.220881
[2018-04-17 17:21:34.829194]: ====================
[2018-04-17 17:21:34.901887]: [Epoch: 818(54.569713142094734%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:21:36.148201]: [Epoch: 818(54.569713142094734%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:21:37.405043]: [Epoch: 818(54.569713142094734%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:21:40.937937]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:21:41.074301]: ====================
[2018-04-17 17:21:41.078310]: Elapsed time since starting training: 1:26:26.474509
[2018-04-17 17:21:41.083324]: ====================
[2018-04-17 17:21:41.155521]: [Epoch: 819(54.63642428285523%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:21:42.429917]: [Epoch: 819(54.63642428285523%): Data: 25.333333333333336%]:Running loss: 4.350372910499573
[2018-04-17 17:21:43.703290]: [Epoch: 819(54.63642428285523%): Data: 50.66666666666667%]:Running loss: 8.483227401971817
[2018-04-17 17:21:47.210616]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:21:47.315896]: ====================
[2018-04-17 17:21:47.320409]: Elapsed time since starting training: 1:26:32.716608
[2018-04-17 17:21:47.325422]: ====================
[2018-04-17 17:21:47.402627]: [Epoch: 820(54.70313542361575%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:21:48.696567]: [Epoch: 820(54.70313542361575%): Data: 25.333333333333336%]:Running loss: 4.350373819470406
[2018-04-17 17:21:49.966444]: [Epoch: 820(54.70313542361575%): Data: 50.66666666666667%]:Running loss: 8.483229160308838
[2018-04-17 17:21:53.523903]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:21:53.634197]: ====================
[2018-04-17 17:21:53.639210]: Elapsed time since starting training: 1:26:39.035409
[2018-04-17 17:21:53.646229]: ====================
[2018-04-17 17:21:53.714411]: [Epoch: 821(54.769846564376245%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:21:55.020382]: [Epoch: 821(54.769846564376245%): Data: 25.333333333333336%]:Running loss: 4.350374296307564
[2018-04-17 17:21:56.305311]: [Epoch: 821(54.769846564376245%): Data: 50.66666666666667%]:Running loss: 8.483229920268059
[2018-04-17 17:21:59.906374]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:22:00.033713]: ====================
[2018-04-17 17:22:00.038726]: Elapsed time since starting training: 1:26:45.434925
[2018-04-17 17:22:00.043740]: ====================
[2018-04-17 17:22:00.115932]: [Epoch: 822(54.836557705136755%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:22:01.384805]: [Epoch: 822(54.836557705136755%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:22:02.672730]: [Epoch: 822(54.836557705136755%): Data: 50.66666666666667%]:Running loss: 8.48323018848896
[2018-04-17 17:22:06.209635]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:22:06.323437]: ====================
[2018-04-17 17:22:06.327949]: Elapsed time since starting training: 1:26:51.723648
[2018-04-17 17:22:06.332461]: ====================
[2018-04-17 17:22:06.399639]: [Epoch: 823(54.903268845897266%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:22:07.690071]: [Epoch: 823(54.903268845897266%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:22:08.948417]: [Epoch: 823(54.903268845897266%): Data: 50.66666666666667%]:Running loss: 8.483231037855148
[2018-04-17 17:22:12.473790]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:22:12.582580]: ====================
[2018-04-17 17:22:12.586591]: Elapsed time since starting training: 1:26:57.982790
[2018-04-17 17:22:12.591604]: ====================
[2018-04-17 17:22:12.663796]: [Epoch: 824(54.96997998665777%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:22:13.936681]: [Epoch: 824(54.96997998665777%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:22:15.201043]: [Epoch: 824(54.96997998665777%): Data: 50.66666666666667%]:Running loss: 8.483232825994492
[2018-04-17 17:22:18.766523]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:22:18.875313]: ====================
[2018-04-17 17:22:18.879323]: Elapsed time since starting training: 1:27:04.275522
[2018-04-17 17:22:18.884838]: ====================
[2018-04-17 17:22:18.957029]: [Epoch: 825(55.03669112741828%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:22:20.229413]: [Epoch: 825(55.03669112741828%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:22:21.504804]: [Epoch: 825(55.03669112741828%): Data: 50.66666666666667%]:Running loss: 8.483233705163002
[2018-04-17 17:22:25.059255]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:22:25.165538]: ====================
[2018-04-17 17:22:25.170050]: Elapsed time since starting training: 1:27:10.565748
[2018-04-17 17:22:25.174562]: ====================
[2018-04-17 17:22:25.238733]: [Epoch: 826(55.10340226817878%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:22:26.537185]: [Epoch: 826(55.10340226817878%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:22:27.799542]: [Epoch: 826(55.10340226817878%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:22:31.347486]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:22:31.454771]: ====================
[2018-04-17 17:22:31.459283]: Elapsed time since starting training: 1:27:16.854980
[2018-04-17 17:22:31.463795]: ====================
[2018-04-17 17:22:31.534985]: [Epoch: 827(55.170113408939294%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:22:32.879058]: [Epoch: 827(55.170113408939294%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:22:34.236167]: [Epoch: 827(55.170113408939294%): Data: 50.66666666666667%]:Running loss: 8.483233377337456
[2018-04-17 17:22:37.833732]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:22:37.931994]: ====================
[2018-04-17 17:22:37.936004]: Elapsed time since starting training: 1:27:23.332203
[2018-04-17 17:22:37.940015]: ====================
[2018-04-17 17:22:38.013711]: [Epoch: 828(55.236824549699804%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:22:39.308655]: [Epoch: 828(55.236824549699804%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:22:40.614626]: [Epoch: 828(55.236824549699804%): Data: 50.66666666666667%]:Running loss: 8.483234211802483
[2018-04-17 17:22:44.186624]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:22:44.289900]: ====================
[2018-04-17 17:22:44.293910]: Elapsed time since starting training: 1:27:29.690109
[2018-04-17 17:22:44.297921]: ====================
[2018-04-17 17:22:44.373121]: [Epoch: 829(55.3035356904603%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:22:45.677589]: [Epoch: 829(55.3035356904603%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 17:22:46.994591]: [Epoch: 829(55.3035356904603%): Data: 50.66666666666667%]:Running loss: 8.483235955238342
[2018-04-17 17:22:50.593159]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 17:22:50.692424]: ====================
[2018-04-17 17:22:50.696434]: Elapsed time since starting training: 1:27:36.092633
[2018-04-17 17:22:50.700946]: ====================
[2018-04-17 17:22:50.775645]: [Epoch: 830(55.37024683122082%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 17:22:52.113702]: [Epoch: 830(55.37024683122082%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 17:22:53.454768]: [Epoch: 830(55.37024683122082%): Data: 50.66666666666667%]:Running loss: 8.483216747641563
[2018-04-17 17:22:57.055342]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:22:57.161124]: ====================
[2018-04-17 17:22:57.165636]: Elapsed time since starting training: 1:27:42.561835
[2018-04-17 17:22:57.170649]: ====================
[2018-04-17 17:22:57.245849]: [Epoch: 831(55.436957971981315%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:22:58.577389]: [Epoch: 831(55.436957971981315%): Data: 25.333333333333336%]:Running loss: 4.350368171930313
[2018-04-17 17:22:59.931490]: [Epoch: 831(55.436957971981315%): Data: 50.66666666666667%]:Running loss: 8.48321869969368
[2018-04-17 17:23:03.514016]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:23:03.611276]: ====================
[2018-04-17 17:23:03.615285]: Elapsed time since starting training: 1:27:49.011484
[2018-04-17 17:23:03.619797]: ====================
[2018-04-17 17:23:03.692490]: [Epoch: 832(55.503669112741825%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:23:05.026036]: [Epoch: 832(55.503669112741825%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:23:06.354569]: [Epoch: 832(55.503669112741825%): Data: 50.66666666666667%]:Running loss: 8.483219638466835
[2018-04-17 17:23:09.947630]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:23:10.053412]: ====================
[2018-04-17 17:23:10.057924]: Elapsed time since starting training: 1:27:55.453622
[2018-04-17 17:23:10.061935]: ====================
[2018-04-17 17:23:10.136633]: [Epoch: 833(55.570380253502336%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:23:11.453635]: [Epoch: 833(55.570380253502336%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:23:12.778663]: [Epoch: 833(55.570380253502336%): Data: 50.66666666666667%]:Running loss: 8.483220353722572
[2018-04-17 17:23:16.377728]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:23:16.476992]: ====================
[2018-04-17 17:23:16.481002]: Elapsed time since starting training: 1:28:01.877201
[2018-04-17 17:23:16.485515]: ====================
[2018-04-17 17:23:16.560714]: [Epoch: 834(55.63709139426284%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:23:17.902282]: [Epoch: 834(55.63709139426284%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:23:19.230814]: [Epoch: 834(55.63709139426284%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:23:22.829383]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:23:22.932156]: ====================
[2018-04-17 17:23:22.936167]: Elapsed time since starting training: 1:28:08.331864
[2018-04-17 17:23:22.939676]: ====================
[2018-04-17 17:23:23.012369]: [Epoch: 835(55.70380253502335%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:23:24.344913]: [Epoch: 835(55.70380253502335%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:23:25.666426]: [Epoch: 835(55.70380253502335%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:23:29.298089]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:23:29.401865]: ====================
[2018-04-17 17:23:29.405876]: Elapsed time since starting training: 1:28:14.802075
[2018-04-17 17:23:29.410388]: ====================
[2018-04-17 17:23:29.485086]: [Epoch: 836(55.77051367578385%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:23:30.815625]: [Epoch: 836(55.77051367578385%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:23:32.142653]: [Epoch: 836(55.77051367578385%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:23:35.889115]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:23:36.006928]: ====================
[2018-04-17 17:23:36.011441]: Elapsed time since starting training: 1:28:21.407640
[2018-04-17 17:23:36.015451]: ====================
[2018-04-17 17:23:36.092155]: [Epoch: 837(55.837224816544364%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:23:37.403642]: [Epoch: 837(55.837224816544364%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:23:38.705102]: [Epoch: 837(55.837224816544364%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:23:42.333250]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:23:42.446551]: ====================
[2018-04-17 17:23:42.452066]: Elapsed time since starting training: 1:28:27.848265
[2018-04-17 17:23:42.456577]: ====================
[2018-04-17 17:23:42.535287]: [Epoch: 838(55.903935957304874%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:23:43.809174]: [Epoch: 838(55.903935957304874%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:23:45.106624]: [Epoch: 838(55.903935957304874%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:23:48.751817]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:23:48.866121]: ====================
[2018-04-17 17:23:48.871636]: Elapsed time since starting training: 1:28:34.267835
[2018-04-17 17:23:48.876147]: ====================
[2018-04-17 17:23:48.951348]: [Epoch: 839(55.97064709806537%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:23:50.266845]: [Epoch: 839(55.97064709806537%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:23:51.557276]: [Epoch: 839(55.97064709806537%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:23:55.228036]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:23:55.348858]: ====================
[2018-04-17 17:23:55.354373]: Elapsed time since starting training: 1:28:40.750572
[2018-04-17 17:23:55.359386]: ====================
[2018-04-17 17:23:55.427567]: [Epoch: 840(56.03735823882589%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:23:56.696943]: [Epoch: 840(56.03735823882589%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:23:58.023971]: [Epoch: 840(56.03735823882589%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:24:01.737846]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:24:01.855660]: ====================
[2018-04-17 17:24:01.860172]: Elapsed time since starting training: 1:28:47.256371
[2018-04-17 17:24:01.864684]: ====================
[2018-04-17 17:24:01.936374]: [Epoch: 841(56.104069379586385%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:24:03.236832]: [Epoch: 841(56.104069379586385%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:24:04.529770]: [Epoch: 841(56.104069379586385%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:24:08.156413]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:24:08.268713]: ====================
[2018-04-17 17:24:08.273725]: Elapsed time since starting training: 1:28:53.669423
[2018-04-17 17:24:08.279240]: ====================
[2018-04-17 17:24:08.350931]: [Epoch: 842(56.170780520346895%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:24:09.658407]: [Epoch: 842(56.170780520346895%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:24:10.952849]: [Epoch: 842(56.170780520346895%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:24:14.558938]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:24:14.674747]: ====================
[2018-04-17 17:24:14.679257]: Elapsed time since starting training: 1:29:00.074955
[2018-04-17 17:24:14.683769]: ====================
[2018-04-17 17:24:14.752452]: [Epoch: 843(56.237491661107406%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:24:16.041379]: [Epoch: 843(56.237491661107406%): Data: 25.333333333333336%]:Running loss: 4.350372731685638
[2018-04-17 17:24:17.344344]: [Epoch: 843(56.237491661107406%): Data: 50.66666666666667%]:Running loss: 8.48322694003582
[2018-04-17 17:24:20.871723]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:24:21.003073]: ====================
[2018-04-17 17:24:21.007585]: Elapsed time since starting training: 1:29:06.403784
[2018-04-17 17:24:21.012096]: ====================
[2018-04-17 17:24:21.081280]: [Epoch: 844(56.30420280186791%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:24:22.387754]: [Epoch: 844(56.30420280186791%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:24:23.677684]: [Epoch: 844(56.30420280186791%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:24:27.228125]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:24:27.351453]: ====================
[2018-04-17 17:24:27.355965]: Elapsed time since starting training: 1:29:12.752164
[2018-04-17 17:24:27.360978]: ====================
[2018-04-17 17:24:27.431165]: [Epoch: 845(56.37091394262842%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:24:28.727612]: [Epoch: 845(56.37091394262842%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:24:30.025062]: [Epoch: 845(56.37091394262842%): Data: 50.66666666666667%]:Running loss: 8.483228325843811
[2018-04-17 17:24:33.597561]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:24:33.713871]: ====================
[2018-04-17 17:24:33.717881]: Elapsed time since starting training: 1:29:19.114080
[2018-04-17 17:24:33.723396]: ====================
[2018-04-17 17:24:33.792580]: [Epoch: 846(56.43762508338893%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:24:35.101059]: [Epoch: 846(56.43762508338893%): Data: 25.333333333333336%]:Running loss: 4.350372940301895
[2018-04-17 17:24:36.399511]: [Epoch: 846(56.43762508338893%): Data: 50.66666666666667%]:Running loss: 8.48322743177414
[2018-04-17 17:24:40.066261]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:24:40.180064]: ====================
[2018-04-17 17:24:40.184576]: Elapsed time since starting training: 1:29:25.580775
[2018-04-17 17:24:40.190090]: ====================
[2018-04-17 17:24:40.261280]: [Epoch: 847(56.504336224149434%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:24:41.570260]: [Epoch: 847(56.504336224149434%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:24:42.887263]: [Epoch: 847(56.504336224149434%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:24:46.583591]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:24:46.694386]: ====================
[2018-04-17 17:24:46.698898]: Elapsed time since starting training: 1:29:32.095097
[2018-04-17 17:24:46.703410]: ====================
[2018-04-17 17:24:46.775601]: [Epoch: 848(56.571047364909944%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:24:48.074555]: [Epoch: 848(56.571047364909944%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:24:49.375013]: [Epoch: 848(56.571047364909944%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:24:53.017699]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:24:53.136014]: ====================
[2018-04-17 17:24:53.142531]: Elapsed time since starting training: 1:29:38.538730
[2018-04-17 17:24:53.146542]: ====================
[2018-04-17 17:24:53.216728]: [Epoch: 849(56.63775850567044%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:24:54.562307]: [Epoch: 849(56.63775850567044%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:24:55.927436]: [Epoch: 849(56.63775850567044%): Data: 50.66666666666667%]:Running loss: 8.483225703239441
[2018-04-17 17:24:59.616244]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:24:59.729546]: ====================
[2018-04-17 17:24:59.734058]: Elapsed time since starting training: 1:29:45.130257
[2018-04-17 17:24:59.738570]: ====================
[2018-04-17 17:24:59.809258]: [Epoch: 850(56.70446964643096%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:25:01.119241]: [Epoch: 850(56.70446964643096%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:25:02.411176]: [Epoch: 850(56.70446964643096%): Data: 50.66666666666667%]:Running loss: 8.4832161962986
[2018-04-17 17:25:06.135078]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:25:06.248380]: ====================
[2018-04-17 17:25:06.252891]: Elapsed time since starting training: 1:29:51.649090
[2018-04-17 17:25:06.257905]: ====================
[2018-04-17 17:25:06.328597]: [Epoch: 851(56.77118078719147%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:25:07.656624]: [Epoch: 851(56.77118078719147%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:25:08.938533]: [Epoch: 851(56.77118078719147%): Data: 50.66666666666667%]:Running loss: 8.483217850327492
[2018-04-17 17:25:12.596760]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:25:12.712568]: ====================
[2018-04-17 17:25:12.717079]: Elapsed time since starting training: 1:29:58.112777
[2018-04-17 17:25:12.723096]: ====================
[2018-04-17 17:25:12.792280]: [Epoch: 852(56.837891927951965%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:25:14.126828]: [Epoch: 852(56.837891927951965%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:25:15.427787]: [Epoch: 852(56.837891927951965%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:25:19.003294]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:25:19.119606]: ====================
[2018-04-17 17:25:19.125118]: Elapsed time since starting training: 1:30:04.521317
[2018-04-17 17:25:19.129631]: ====================
[2018-04-17 17:25:19.199316]: [Epoch: 853(56.904603068712476%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:25:20.482728]: [Epoch: 853(56.904603068712476%): Data: 25.333333333333336%]:Running loss: 4.350369185209274
[2018-04-17 17:25:21.779677]: [Epoch: 853(56.904603068712476%): Data: 50.66666666666667%]:Running loss: 8.483219996094704
[2018-04-17 17:25:25.332624]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:25:25.444422]: ====================
[2018-04-17 17:25:25.448934]: Elapsed time since starting training: 1:30:10.845133
[2018-04-17 17:25:25.453446]: ====================
[2018-04-17 17:25:25.522129]: [Epoch: 854(56.97131420947298%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:25:26.821082]: [Epoch: 854(56.97131420947298%): Data: 25.333333333333336%]:Running loss: 4.350369080901146
[2018-04-17 17:25:28.113017]: [Epoch: 854(56.97131420947298%): Data: 50.66666666666667%]:Running loss: 8.483219757676125
[2018-04-17 17:25:31.766732]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:25:31.880536]: ====================
[2018-04-17 17:25:31.885048]: Elapsed time since starting training: 1:30:17.280744
[2018-04-17 17:25:31.889058]: ====================
[2018-04-17 17:25:31.961751]: [Epoch: 855(57.03802535023349%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:25:33.278252]: [Epoch: 855(57.03802535023349%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:25:34.579713]: [Epoch: 855(57.03802535023349%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:25:38.216382]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:25:38.332691]: ====================
[2018-04-17 17:25:38.336702]: Elapsed time since starting training: 1:30:23.732400
[2018-04-17 17:25:38.343219]: ====================
[2018-04-17 17:25:38.423433]: [Epoch: 856(57.104736490994%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:25:39.750962]: [Epoch: 856(57.104736490994%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:25:41.037383]: [Epoch: 856(57.104736490994%): Data: 50.66666666666667%]:Running loss: 8.483222499489784
[2018-04-17 17:25:44.665029]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:25:44.782341]: ====================
[2018-04-17 17:25:44.786853]: Elapsed time since starting training: 1:30:30.183052
[2018-04-17 17:25:44.793871]: ====================
[2018-04-17 17:25:44.864559]: [Epoch: 857(57.1714476317545%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:25:46.231695]: [Epoch: 857(57.1714476317545%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:25:47.540174]: [Epoch: 857(57.1714476317545%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:25:51.166321]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:25:51.292657]: ====================
[2018-04-17 17:25:51.297671]: Elapsed time since starting training: 1:30:36.693368
[2018-04-17 17:25:51.302183]: ====================
[2018-04-17 17:25:51.374878]: [Epoch: 858(57.238158772515014%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:25:52.708422]: [Epoch: 858(57.238158772515014%): Data: 25.333333333333336%]:Running loss: 4.350369930267334
[2018-04-17 17:25:53.976306]: [Epoch: 858(57.238158772515014%): Data: 50.66666666666667%]:Running loss: 8.483221665024757
[2018-04-17 17:25:57.629506]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:25:57.749326]: ====================
[2018-04-17 17:25:57.754339]: Elapsed time since starting training: 1:30:43.150037
[2018-04-17 17:25:57.764867]: ====================
[2018-04-17 17:25:57.836557]: [Epoch: 859(57.30486991327551%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:25:59.176620]: [Epoch: 859(57.30486991327551%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:26:00.498636]: [Epoch: 859(57.30486991327551%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:26:04.100213]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:26:04.211007]: ====================
[2018-04-17 17:26:04.215519]: Elapsed time since starting training: 1:30:49.611216
[2018-04-17 17:26:04.220031]: ====================
[2018-04-17 17:26:04.294729]: [Epoch: 860(57.37158105403603%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:26:05.621261]: [Epoch: 860(57.37158105403603%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:26:06.908179]: [Epoch: 860(57.37158105403603%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:26:10.560390]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:26:10.687227]: ====================
[2018-04-17 17:26:10.693243]: Elapsed time since starting training: 1:30:56.088941
[2018-04-17 17:26:10.697254]: ====================
[2018-04-17 17:26:10.766438]: [Epoch: 861(57.43829219479654%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:26:12.109509]: [Epoch: 861(57.43829219479654%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:26:13.464111]: [Epoch: 861(57.43829219479654%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:26:17.110808]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:26:17.223106]: ====================
[2018-04-17 17:26:17.228119]: Elapsed time since starting training: 1:31:02.623817
[2018-04-17 17:26:17.232632]: ====================
[2018-04-17 17:26:17.302316]: [Epoch: 862(57.505003335557035%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:26:18.636865]: [Epoch: 862(57.505003335557035%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:26:19.986954]: [Epoch: 862(57.505003335557035%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:26:23.800596]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:26:23.999124]: ====================
[2018-04-17 17:26:24.014163]: Elapsed time since starting training: 1:31:09.409861
[2018-04-17 17:26:24.023689]: ====================
[2018-04-17 17:26:24.105406]: [Epoch: 863(57.571714476317545%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:26:25.565789]: [Epoch: 863(57.571714476317545%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:26:26.897831]: [Epoch: 863(57.571714476317545%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:26:30.771131]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:26:30.892453]: ====================
[2018-04-17 17:26:30.896966]: Elapsed time since starting training: 1:31:16.292662
[2018-04-17 17:26:30.901979]: ====================
[2018-04-17 17:26:30.982693]: [Epoch: 864(57.63842561707805%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:26:32.339300]: [Epoch: 864(57.63842561707805%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:26:33.625219]: [Epoch: 864(57.63842561707805%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:26:37.304502]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:26:37.422316]: ====================
[2018-04-17 17:26:37.429836]: Elapsed time since starting training: 1:31:22.825533
[2018-04-17 17:26:37.434347]: ====================
[2018-04-17 17:26:37.501526]: [Epoch: 865(57.70513675783856%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:26:38.803990]: [Epoch: 865(57.70513675783856%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:26:40.075872]: [Epoch: 865(57.70513675783856%): Data: 50.66666666666667%]:Running loss: 8.483225375413895
[2018-04-17 17:26:43.647869]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:26:43.761672]: ====================
[2018-04-17 17:26:43.765682]: Elapsed time since starting training: 1:31:29.161881
[2018-04-17 17:26:43.770696]: ====================
[2018-04-17 17:26:43.845896]: [Epoch: 866(57.77184789859907%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:26:45.175933]: [Epoch: 866(57.77184789859907%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:26:46.452841]: [Epoch: 866(57.77184789859907%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:26:50.039364]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:26:50.156174]: ====================
[2018-04-17 17:26:50.161188]: Elapsed time since starting training: 1:31:35.557387
[2018-04-17 17:26:50.165199]: ====================
[2018-04-17 17:26:50.233380]: [Epoch: 867(57.83855903935957%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:26:51.527822]: [Epoch: 867(57.83855903935957%): Data: 25.333333333333336%]:Running loss: 4.350373089313507
[2018-04-17 17:26:52.798200]: [Epoch: 867(57.83855903935957%): Data: 50.66666666666667%]:Running loss: 8.483227580785751
[2018-04-17 17:26:56.383232]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:26:56.501046]: ====================
[2018-04-17 17:26:56.505558]: Elapsed time since starting training: 1:31:41.901757
[2018-04-17 17:26:56.510070]: ====================
[2018-04-17 17:26:56.583264]: [Epoch: 868(57.905270180120084%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:26:57.884725]: [Epoch: 868(57.905270180120084%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:26:59.235316]: [Epoch: 868(57.905270180120084%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:27:02.869479]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:27:03.107117]: ====================
[2018-04-17 17:27:03.112124]: Elapsed time since starting training: 1:31:48.508323
[2018-04-17 17:27:03.116135]: ====================
[2018-04-17 17:27:03.188828]: [Epoch: 869(57.97198132088058%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:27:04.461212]: [Epoch: 869(57.97198132088058%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:27:05.731590]: [Epoch: 869(57.97198132088058%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:27:09.327652]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:27:09.440452]: ====================
[2018-04-17 17:27:09.445465]: Elapsed time since starting training: 1:31:54.841664
[2018-04-17 17:27:09.450478]: ====================
[2018-04-17 17:27:09.520664]: [Epoch: 870(58.0386924616411%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:27:10.824632]: [Epoch: 870(58.0386924616411%): Data: 25.333333333333336%]:Running loss: 4.350374162197113
[2018-04-17 17:27:12.110050]: [Epoch: 870(58.0386924616411%): Data: 50.66666666666667%]:Running loss: 8.48323006927967
[2018-04-17 17:27:15.755744]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:27:15.880576]: ====================
[2018-04-17 17:27:15.885099]: Elapsed time since starting training: 1:32:01.281298
[2018-04-17 17:27:15.889600]: ====================
[2018-04-17 17:27:15.960288]: [Epoch: 871(58.10540360240161%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:27:17.266761]: [Epoch: 871(58.10540360240161%): Data: 25.333333333333336%]:Running loss: 4.350375488400459
[2018-04-17 17:27:18.547668]: [Epoch: 871(58.10540360240161%): Data: 50.66666666666667%]:Running loss: 8.483232244849205
[2018-04-17 17:27:22.225447]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:27:22.336743]: ====================
[2018-04-17 17:27:22.341757]: Elapsed time since starting training: 1:32:07.737454
[2018-04-17 17:27:22.361810]: ====================
[2018-04-17 17:27:22.437010]: [Epoch: 872(58.172114743162105%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:27:23.749499]: [Epoch: 872(58.172114743162105%): Data: 25.333333333333336%]:Running loss: 4.350375592708588
[2018-04-17 17:27:25.058981]: [Epoch: 872(58.172114743162105%): Data: 50.66666666666667%]:Running loss: 8.483232632279396
[2018-04-17 17:27:28.772856]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:27:28.898691]: ====================
[2018-04-17 17:27:28.903203]: Elapsed time since starting training: 1:32:14.299402
[2018-04-17 17:27:28.908216]: ====================
[2018-04-17 17:27:28.984419]: [Epoch: 873(58.238825883922615%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:27:30.271842]: [Epoch: 873(58.238825883922615%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:27:31.573804]: [Epoch: 873(58.238825883922615%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:27:35.141791]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 17:27:35.252586]: ====================
[2018-04-17 17:27:35.257097]: Elapsed time since starting training: 1:32:20.653296
[2018-04-17 17:27:35.262112]: ====================
[2018-04-17 17:27:35.334303]: [Epoch: 874(58.30553702468312%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 17:27:36.635262]: [Epoch: 874(58.30553702468312%): Data: 25.333333333333336%]:Running loss: 4.350366517901421
[2018-04-17 17:27:37.939229]: [Epoch: 874(58.30553702468312%): Data: 50.66666666666667%]:Running loss: 8.483215346932411
[2018-04-17 17:27:41.469617]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:27:41.581414]: ====================
[2018-04-17 17:27:41.585425]: Elapsed time since starting training: 1:32:26.981624
[2018-04-17 17:27:41.589936]: ====================
[2018-04-17 17:27:41.658620]: [Epoch: 875(58.37224816544363%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:27:42.936517]: [Epoch: 875(58.37224816544363%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:27:44.281092]: [Epoch: 875(58.37224816544363%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:27:47.852088]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:27:47.967896]: ====================
[2018-04-17 17:27:47.973410]: Elapsed time since starting training: 1:32:33.369609
[2018-04-17 17:27:47.977922]: ====================
[2018-04-17 17:27:48.076184]: [Epoch: 876(58.43895930620414%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:27:49.388673]: [Epoch: 876(58.43895930620414%): Data: 25.333333333333336%]:Running loss: 4.350367605686188
[2018-04-17 17:27:50.685121]: [Epoch: 876(58.43895930620414%): Data: 50.66666666666667%]:Running loss: 8.483217000961304
[2018-04-17 17:27:54.256618]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:27:54.373428]: ====================
[2018-04-17 17:27:54.377940]: Elapsed time since starting training: 1:32:39.773638
[2018-04-17 17:27:54.382953]: ====================
[2018-04-17 17:27:54.456649]: [Epoch: 877(58.50567044696464%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:27:55.743070]: [Epoch: 877(58.50567044696464%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:27:57.058568]: [Epoch: 877(58.50567044696464%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:28:00.688219]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:28:00.796508]: ====================
[2018-04-17 17:28:00.801520]: Elapsed time since starting training: 1:32:46.197719
[2018-04-17 17:28:00.806032]: ====================
[2018-04-17 17:28:00.878224]: [Epoch: 878(58.572381587725154%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:28:02.220292]: [Epoch: 878(58.572381587725154%): Data: 25.333333333333336%]:Running loss: 4.350368946790695
[2018-04-17 17:28:03.495684]: [Epoch: 878(58.572381587725154%): Data: 50.66666666666667%]:Running loss: 8.483219757676125
[2018-04-17 17:28:07.119319]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:28:07.238636]: ====================
[2018-04-17 17:28:07.243148]: Elapsed time since starting training: 1:32:52.639347
[2018-04-17 17:28:07.247661]: ====================
[2018-04-17 17:28:07.319852]: [Epoch: 879(58.63909272848565%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:28:08.668939]: [Epoch: 879(58.63909272848565%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:28:09.943829]: [Epoch: 879(58.63909272848565%): Data: 50.66666666666667%]:Running loss: 8.483218118548393
[2018-04-17 17:28:13.553427]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:28:13.680766]: ====================
[2018-04-17 17:28:13.685278]: Elapsed time since starting training: 1:32:59.081477
[2018-04-17 17:28:13.689289]: ====================
[2018-04-17 17:28:13.765992]: [Epoch: 880(58.70580386924617%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:28:15.104551]: [Epoch: 880(58.70580386924617%): Data: 25.333333333333336%]:Running loss: 4.350368827581406
[2018-04-17 17:28:16.413032]: [Epoch: 880(58.70580386924617%): Data: 50.66666666666667%]:Running loss: 8.483219355344772
[2018-04-17 17:28:19.981519]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:28:20.101840]: ====================
[2018-04-17 17:28:20.105852]: Elapsed time since starting training: 1:33:05.502051
[2018-04-17 17:28:20.109861]: ====================
[2018-04-17 17:28:20.183557]: [Epoch: 881(58.77251501000668%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:28:21.470479]: [Epoch: 881(58.77251501000668%): Data: 25.333333333333336%]:Running loss: 4.350369215011597
[2018-04-17 17:28:22.795001]: [Epoch: 881(58.77251501000668%): Data: 50.66666666666667%]:Running loss: 8.483220309019089
[2018-04-17 17:28:26.358977]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:28:26.468269]: ====================
[2018-04-17 17:28:26.473782]: Elapsed time since starting training: 1:33:11.869981
[2018-04-17 17:28:26.477793]: ====================
[2018-04-17 17:28:26.546475]: [Epoch: 882(58.839226150767175%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:28:27.820864]: [Epoch: 882(58.839226150767175%): Data: 25.333333333333336%]:Running loss: 4.350370064377785
[2018-04-17 17:28:29.123328]: [Epoch: 882(58.839226150767175%): Data: 50.66666666666667%]:Running loss: 8.483221918344498
[2018-04-17 17:28:32.659731]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:28:32.774538]: ====================
[2018-04-17 17:28:32.780051]: Elapsed time since starting training: 1:33:18.176250
[2018-04-17 17:28:32.784563]: ====================
[2018-04-17 17:28:32.853747]: [Epoch: 883(58.905937291527685%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:28:34.154705]: [Epoch: 883(58.905937291527685%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:28:35.454662]: [Epoch: 883(58.905937291527685%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:28:39.013125]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:28:39.132943]: ====================
[2018-04-17 17:28:39.137956]: Elapsed time since starting training: 1:33:24.534155
[2018-04-17 17:28:39.142469]: ====================
[2018-04-17 17:28:39.210650]: [Epoch: 884(58.97264843228819%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:28:40.512110]: [Epoch: 884(58.97264843228819%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:28:41.787501]: [Epoch: 884(58.97264843228819%): Data: 50.66666666666667%]:Running loss: 8.483223021030426
[2018-04-17 17:28:45.330925]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:28:45.445728]: ====================
[2018-04-17 17:28:45.451744]: Elapsed time since starting training: 1:33:30.847943
[2018-04-17 17:28:45.455755]: ====================
[2018-04-17 17:28:45.521931]: [Epoch: 885(59.0393595730487%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:28:46.802837]: [Epoch: 885(59.0393595730487%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:28:48.074218]: [Epoch: 885(59.0393595730487%): Data: 50.66666666666667%]:Running loss: 8.483223795890808
[2018-04-17 17:28:51.693843]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:28:51.807144]: ====================
[2018-04-17 17:28:51.811657]: Elapsed time since starting training: 1:33:37.207353
[2018-04-17 17:28:51.815667]: ====================
[2018-04-17 17:28:51.889362]: [Epoch: 886(59.10607071380921%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:28:53.203858]: [Epoch: 886(59.10607071380921%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:28:54.522363]: [Epoch: 886(59.10607071380921%): Data: 50.66666666666667%]:Running loss: 8.483225539326668
[2018-04-17 17:28:58.137476]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:28:58.255289]: ====================
[2018-04-17 17:28:58.259802]: Elapsed time since starting training: 1:33:43.656001
[2018-04-17 17:28:58.264815]: ====================
[2018-04-17 17:28:58.331492]: [Epoch: 887(59.17278185456971%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:28:59.661529]: [Epoch: 887(59.17278185456971%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:29:01.000589]: [Epoch: 887(59.17278185456971%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:29:04.641269]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:29:04.741035]: ====================
[2018-04-17 17:29:04.745547]: Elapsed time since starting training: 1:33:50.141746
[2018-04-17 17:29:04.749557]: ====================
[2018-04-17 17:29:04.820747]: [Epoch: 888(59.239492995330224%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:29:06.156799]: [Epoch: 888(59.239492995330224%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:29:07.492852]: [Epoch: 888(59.239492995330224%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:29:11.156600]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:29:11.273411]: ====================
[2018-04-17 17:29:11.277421]: Elapsed time since starting training: 1:33:56.673620
[2018-04-17 17:29:11.281934]: ====================
[2018-04-17 17:29:11.356131]: [Epoch: 889(59.30620413609072%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:29:12.705719]: [Epoch: 889(59.30620413609072%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:29:14.042273]: [Epoch: 889(59.30620413609072%): Data: 50.66666666666667%]:Running loss: 8.483228117227554
[2018-04-17 17:29:17.707018]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:29:17.804277]: ====================
[2018-04-17 17:29:17.808789]: Elapsed time since starting training: 1:34:03.204486
[2018-04-17 17:29:17.812799]: ====================
[2018-04-17 17:29:17.885993]: [Epoch: 890(59.37291527685124%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:29:19.211518]: [Epoch: 890(59.37291527685124%): Data: 25.333333333333336%]:Running loss: 4.350374162197113
[2018-04-17 17:29:20.603720]: [Epoch: 890(59.37291527685124%): Data: 50.66666666666667%]:Running loss: 8.483229786157608
[2018-04-17 17:29:24.518630]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:29:24.634439]: ====================
[2018-04-17 17:29:24.639953]: Elapsed time since starting training: 1:34:10.035650
[2018-04-17 17:29:24.643963]: ====================
[2018-04-17 17:29:24.718160]: [Epoch: 891(59.43962641761175%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:29:26.072762]: [Epoch: 891(59.43962641761175%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:29:27.357681]: [Epoch: 891(59.43962641761175%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:29:30.917143]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:29:31.024429]: ====================
[2018-04-17 17:29:31.028439]: Elapsed time since starting training: 1:34:16.424638
[2018-04-17 17:29:31.033453]: ====================
[2018-04-17 17:29:31.103639]: [Epoch: 892(59.506337558372245%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:29:32.387052]: [Epoch: 892(59.506337558372245%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:29:33.654421]: [Epoch: 892(59.506337558372245%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:29:37.154729]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:29:37.267530]: ====================
[2018-04-17 17:29:37.272042]: Elapsed time since starting training: 1:34:22.667739
[2018-04-17 17:29:37.276052]: ====================
[2018-04-17 17:29:37.346739]: [Epoch: 893(59.573048699132755%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:29:38.602580]: [Epoch: 893(59.573048699132755%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:29:39.864936]: [Epoch: 893(59.573048699132755%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:29:43.373765]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:29:43.478544]: ====================
[2018-04-17 17:29:43.484059]: Elapsed time since starting training: 1:34:28.879757
[2018-04-17 17:29:43.488571]: ====================
[2018-04-17 17:29:43.557253]: [Epoch: 894(59.63975983989326%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:29:44.803567]: [Epoch: 894(59.63975983989326%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:29:46.070436]: [Epoch: 894(59.63975983989326%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:29:49.597315]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:29:49.706604]: ====================
[2018-04-17 17:29:49.711117]: Elapsed time since starting training: 1:34:35.107316
[2018-04-17 17:29:49.715128]: ====================
[2018-04-17 17:29:49.782807]: [Epoch: 895(59.70647098065377%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:29:51.062208]: [Epoch: 895(59.70647098065377%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:29:52.339104]: [Epoch: 895(59.70647098065377%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:29:55.925139]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:29:56.034431]: ====================
[2018-04-17 17:29:56.038942]: Elapsed time since starting training: 1:34:41.435141
[2018-04-17 17:29:56.043956]: ====================
[2018-04-17 17:29:56.113640]: [Epoch: 896(59.77318212141428%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:29:57.388029]: [Epoch: 896(59.77318212141428%): Data: 25.333333333333336%]:Running loss: 4.350376397371292
[2018-04-17 17:29:58.652391]: [Epoch: 896(59.77318212141428%): Data: 50.66666666666667%]:Running loss: 8.483234003186226
[2018-04-17 17:30:02.177765]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:30:02.297083]: ====================
[2018-04-17 17:30:02.303099]: Elapsed time since starting training: 1:34:47.698796
[2018-04-17 17:30:02.307109]: ====================
[2018-04-17 17:30:02.377296]: [Epoch: 897(59.83989326217478%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:30:03.648175]: [Epoch: 897(59.83989326217478%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:30:04.919054]: [Epoch: 897(59.83989326217478%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:30:08.441921]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:30:08.551714]: ====================
[2018-04-17 17:30:08.555725]: Elapsed time since starting training: 1:34:53.951924
[2018-04-17 17:30:08.560236]: ====================
[2018-04-17 17:30:08.632929]: [Epoch: 898(59.906604402935294%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:30:09.892283]: [Epoch: 898(59.906604402935294%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 17:30:11.158650]: [Epoch: 898(59.906604402935294%): Data: 50.66666666666667%]:Running loss: 8.48323479294777
[2018-04-17 17:30:14.667480]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:30:14.778276]: ====================
[2018-04-17 17:30:14.782788]: Elapsed time since starting training: 1:35:00.178987
[2018-04-17 17:30:14.787801]: ====================
[2018-04-17 17:30:14.862499]: [Epoch: 899(59.97331554369579%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:30:16.136887]: [Epoch: 899(59.97331554369579%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:30:17.399745]: [Epoch: 899(59.97331554369579%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:30:20.961215]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:30:21.073013]: ====================
[2018-04-17 17:30:21.077023]: Elapsed time since starting training: 1:35:06.473222
[2018-04-17 17:30:21.081535]: ====================
[2018-04-17 17:30:21.151220]: [Epoch: 900(60.04002668445631%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:30:22.412575]: [Epoch: 900(60.04002668445631%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:30:23.675432]: [Epoch: 900(60.04002668445631%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:30:27.254950]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:30:27.371761]: ====================
[2018-04-17 17:30:27.376273]: Elapsed time since starting training: 1:35:12.772472
[2018-04-17 17:30:27.380785]: ====================
[2018-04-17 17:30:27.446961]: [Epoch: 901(60.10673782521682%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:30:28.768977]: [Epoch: 901(60.10673782521682%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:30:30.055397]: [Epoch: 901(60.10673782521682%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:30:33.649453]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:30:33.763256]: ====================
[2018-04-17 17:30:33.767768]: Elapsed time since starting training: 1:35:19.163967
[2018-04-17 17:30:33.774285]: ====================
[2018-04-17 17:30:33.852994]: [Epoch: 902(60.173448965977315%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:30:35.152450]: [Epoch: 902(60.173448965977315%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:30:36.425838]: [Epoch: 902(60.173448965977315%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:30:39.964244]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:30:40.076042]: ====================
[2018-04-17 17:30:40.081556]: Elapsed time since starting training: 1:35:25.477755
[2018-04-17 17:30:40.087071]: ====================
[2018-04-17 17:30:40.155252]: [Epoch: 903(60.240160106737825%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:30:41.431145]: [Epoch: 903(60.240160106737825%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:30:42.707037]: [Epoch: 903(60.240160106737825%): Data: 50.66666666666667%]:Running loss: 8.483220919966698
[2018-04-17 17:30:46.264496]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:30:46.369777]: ====================
[2018-04-17 17:30:46.374288]: Elapsed time since starting training: 1:35:31.770487
[2018-04-17 17:30:46.378801]: ====================
[2018-04-17 17:30:46.445979]: [Epoch: 904(60.30687124749833%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:30:47.746436]: [Epoch: 904(60.30687124749833%): Data: 25.333333333333336%]:Running loss: 4.35037025809288
[2018-04-17 17:30:49.021327]: [Epoch: 904(60.30687124749833%): Data: 50.66666666666667%]:Running loss: 8.48322220146656
[2018-04-17 17:30:52.564748]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:30:52.678552]: ====================
[2018-04-17 17:30:52.683565]: Elapsed time since starting training: 1:35:38.079764
[2018-04-17 17:30:52.688076]: ====================
[2018-04-17 17:30:52.758765]: [Epoch: 905(60.37358238825884%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:30:54.074777]: [Epoch: 905(60.37358238825884%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:30:55.343638]: [Epoch: 905(60.37358238825884%): Data: 50.66666666666667%]:Running loss: 8.483223274350166
[2018-04-17 17:30:58.921651]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:30:59.034452]: ====================
[2018-04-17 17:30:59.038462]: Elapsed time since starting training: 1:35:44.434661
[2018-04-17 17:30:59.043978]: ====================
[2018-04-17 17:30:59.120180]: [Epoch: 906(60.44029352901935%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:31:00.411613]: [Epoch: 906(60.44029352901935%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:31:01.712573]: [Epoch: 906(60.44029352901935%): Data: 50.66666666666667%]:Running loss: 8.483224719762802
[2018-04-17 17:31:05.281563]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:31:05.392357]: ====================
[2018-04-17 17:31:05.396869]: Elapsed time since starting training: 1:35:50.793068
[2018-04-17 17:31:05.401381]: ====================
[2018-04-17 17:31:05.469062]: [Epoch: 907(60.50700466977985%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:31:06.761999]: [Epoch: 907(60.50700466977985%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:31:08.023353]: [Epoch: 907(60.50700466977985%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:31:11.637464]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:31:11.743244]: ====================
[2018-04-17 17:31:11.748257]: Elapsed time since starting training: 1:35:57.144456
[2018-04-17 17:31:11.752770]: ====================
[2018-04-17 17:31:11.826465]: [Epoch: 908(60.573715810540364%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:31:13.125419]: [Epoch: 908(60.573715810540364%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:31:14.393792]: [Epoch: 908(60.573715810540364%): Data: 50.66666666666667%]:Running loss: 8.483225971460342
[2018-04-17 17:31:17.958771]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:31:18.073075]: ====================
[2018-04-17 17:31:18.077587]: Elapsed time since starting training: 1:36:03.473786
[2018-04-17 17:31:18.082099]: ====================
[2018-04-17 17:31:18.156798]: [Epoch: 909(60.64042695130086%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:31:19.427677]: [Epoch: 909(60.64042695130086%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:31:20.691036]: [Epoch: 909(60.64042695130086%): Data: 50.66666666666667%]:Running loss: 8.483226835727692
[2018-04-17 17:31:24.287599]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:31:24.394383]: ====================
[2018-04-17 17:31:24.398895]: Elapsed time since starting training: 1:36:09.795094
[2018-04-17 17:31:24.403407]: ====================
[2018-04-17 17:31:24.474095]: [Epoch: 910(60.70713809206138%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:31:25.750991]: [Epoch: 910(60.70713809206138%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:31:27.041923]: [Epoch: 910(60.70713809206138%): Data: 50.66666666666667%]:Running loss: 8.483227729797363
[2018-04-17 17:31:30.594871]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:31:30.705164]: ====================
[2018-04-17 17:31:30.709676]: Elapsed time since starting training: 1:36:16.105374
[2018-04-17 17:31:30.713185]: ====================
[2018-04-17 17:31:30.783372]: [Epoch: 911(60.77384923282189%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:31:32.106891]: [Epoch: 911(60.77384923282189%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:31:33.408354]: [Epoch: 911(60.77384923282189%): Data: 50.66666666666667%]:Running loss: 8.483227327466011
[2018-04-17 17:31:36.991880]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:31:37.099667]: ====================
[2018-04-17 17:31:37.105182]: Elapsed time since starting training: 1:36:22.501381
[2018-04-17 17:31:37.111699]: ====================
[2018-04-17 17:31:37.181885]: [Epoch: 912(60.840560373582385%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:31:38.456775]: [Epoch: 912(60.840560373582385%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:31:39.756732]: [Epoch: 912(60.840560373582385%): Data: 50.66666666666667%]:Running loss: 8.483226045966148
[2018-04-17 17:31:43.304164]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:31:43.418971]: ====================
[2018-04-17 17:31:43.423983]: Elapsed time since starting training: 1:36:28.820182
[2018-04-17 17:31:43.427994]: ====================
[2018-04-17 17:31:43.497177]: [Epoch: 913(60.907271514342895%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:31:44.763545]: [Epoch: 913(60.907271514342895%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:31:46.024397]: [Epoch: 913(60.907271514342895%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:31:49.541249]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:31:49.645526]: ====================
[2018-04-17 17:31:49.650540]: Elapsed time since starting training: 1:36:35.046739
[2018-04-17 17:31:49.654550]: ====================
[2018-04-17 17:31:49.725238]: [Epoch: 914(60.9739826551034%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:31:51.026197]: [Epoch: 914(60.9739826551034%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:31:52.292565]: [Epoch: 914(60.9739826551034%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:31:55.858546]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:31:55.968840]: ====================
[2018-04-17 17:31:55.973853]: Elapsed time since starting training: 1:36:41.369551
[2018-04-17 17:31:55.977864]: ====================
[2018-04-17 17:31:56.046045]: [Epoch: 915(61.04069379586391%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:31:57.313917]: [Epoch: 915(61.04069379586391%): Data: 25.333333333333336%]:Running loss: 4.350373566150665
[2018-04-17 17:31:58.590310]: [Epoch: 915(61.04069379586391%): Data: 50.66666666666667%]:Running loss: 8.483227774500847
[2018-04-17 17:32:02.202415]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:32:02.320729]: ====================
[2018-04-17 17:32:02.325241]: Elapsed time since starting training: 1:36:47.721440
[2018-04-17 17:32:02.329753]: ====================
[2018-04-17 17:32:02.397434]: [Epoch: 916(61.10740493662442%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:32:03.676334]: [Epoch: 916(61.10740493662442%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:32:04.950221]: [Epoch: 916(61.10740493662442%): Data: 50.66666666666667%]:Running loss: 8.483227908611298
[2018-04-17 17:32:08.728268]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:32:08.865131]: ====================
[2018-04-17 17:32:08.870645]: Elapsed time since starting training: 1:36:54.266844
[2018-04-17 17:32:08.875659]: ====================
[2018-04-17 17:32:08.944341]: [Epoch: 917(61.17411607738492%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:32:10.233770]: [Epoch: 917(61.17411607738492%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:32:11.547764]: [Epoch: 917(61.17411607738492%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:32:15.270162]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:32:15.507794]: ====================
[2018-04-17 17:32:15.513308]: Elapsed time since starting training: 1:37:00.909507
[2018-04-17 17:32:15.518324]: ====================
[2018-04-17 17:32:15.590012]: [Epoch: 918(61.240827218145434%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:32:16.905009]: [Epoch: 918(61.240827218145434%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:32:18.189925]: [Epoch: 918(61.240827218145434%): Data: 50.66666666666667%]:Running loss: 8.483230635523796
[2018-04-17 17:32:21.809049]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:32:21.936387]: ====================
[2018-04-17 17:32:21.941902]: Elapsed time since starting training: 1:37:07.337600
[2018-04-17 17:32:21.946414]: ====================
[2018-04-17 17:32:22.019608]: [Epoch: 919(61.30753835890593%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:32:23.393262]: [Epoch: 919(61.30753835890593%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:32:24.689207]: [Epoch: 919(61.30753835890593%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:32:28.307327]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:32:28.415615]: ====================
[2018-04-17 17:32:28.420629]: Elapsed time since starting training: 1:37:13.816828
[2018-04-17 17:32:28.424639]: ====================
[2018-04-17 17:32:28.495828]: [Epoch: 920(61.37424949966645%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:32:29.764201]: [Epoch: 920(61.37424949966645%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:32:31.061651]: [Epoch: 920(61.37424949966645%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:32:34.669243]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:32:34.802599]: ====================
[2018-04-17 17:32:34.810118]: Elapsed time since starting training: 1:37:20.205822
[2018-04-17 17:32:34.815133]: ====================
[2018-04-17 17:32:34.890833]: [Epoch: 921(61.44096064042696%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:32:36.210342]: [Epoch: 921(61.44096064042696%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:32:37.508794]: [Epoch: 921(61.44096064042696%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:32:41.196098]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:32:41.307395]: ====================
[2018-04-17 17:32:41.311907]: Elapsed time since starting training: 1:37:26.708106
[2018-04-17 17:32:41.316419]: ====================
[2018-04-17 17:32:41.387608]: [Epoch: 922(61.507671781187454%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:32:42.703106]: [Epoch: 922(61.507671781187454%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:32:43.992534]: [Epoch: 922(61.507671781187454%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:32:47.611156]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:32:47.725460]: ====================
[2018-04-17 17:32:47.729972]: Elapsed time since starting training: 1:37:33.126171
[2018-04-17 17:32:47.734985]: ====================
[2018-04-17 17:32:47.805173]: [Epoch: 923(61.574382921947965%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:32:49.107635]: [Epoch: 923(61.574382921947965%): Data: 25.333333333333336%]:Running loss: 4.350369036197662
[2018-04-17 17:32:50.391048]: [Epoch: 923(61.574382921947965%): Data: 50.66666666666667%]:Running loss: 8.483219847083092
[2018-04-17 17:32:54.040752]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:32:54.146534]: ====================
[2018-04-17 17:32:54.150544]: Elapsed time since starting training: 1:37:39.546743
[2018-04-17 17:32:54.155056]: ====================
[2018-04-17 17:32:54.230256]: [Epoch: 924(61.64109406270847%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:32:55.554277]: [Epoch: 924(61.64109406270847%): Data: 25.333333333333336%]:Running loss: 4.350369438529015
[2018-04-17 17:32:56.845209]: [Epoch: 924(61.64109406270847%): Data: 50.66666666666667%]:Running loss: 8.483220532536507
[2018-04-17 17:33:00.452301]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:33:00.570114]: ====================
[2018-04-17 17:33:00.575127]: Elapsed time since starting training: 1:37:45.970825
[2018-04-17 17:33:00.579640]: ====================
[2018-04-17 17:33:00.651831]: [Epoch: 925(61.70780520346898%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:33:01.903660]: [Epoch: 925(61.70780520346898%): Data: 25.333333333333336%]:Running loss: 4.3503697514534
[2018-04-17 17:33:03.194091]: [Epoch: 925(61.70780520346898%): Data: 50.66666666666667%]:Running loss: 8.48322169482708
[2018-04-17 17:33:06.795670]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:33:06.899947]: ====================
[2018-04-17 17:33:06.903958]: Elapsed time since starting training: 1:37:52.300157
[2018-04-17 17:33:06.908972]: ====================
[2018-04-17 17:33:06.981163]: [Epoch: 926(61.77451634422949%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:33:08.280619]: [Epoch: 926(61.77451634422949%): Data: 25.333333333333336%]:Running loss: 4.35037100315094
[2018-04-17 17:33:09.566036]: [Epoch: 926(61.77451634422949%): Data: 50.66666666666667%]:Running loss: 8.483223512768745
[2018-04-17 17:33:13.165608]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:33:13.277405]: ====================
[2018-04-17 17:33:13.282419]: Elapsed time since starting training: 1:37:58.678618
[2018-04-17 17:33:13.288435]: ====================
[2018-04-17 17:33:13.361128]: [Epoch: 927(61.84122748498999%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:33:14.665596]: [Epoch: 927(61.84122748498999%): Data: 25.333333333333336%]:Running loss: 4.350371107459068
[2018-04-17 17:33:15.961041]: [Epoch: 927(61.84122748498999%): Data: 50.66666666666667%]:Running loss: 8.483223900198936
[2018-04-17 17:33:19.551588]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:33:19.660879]: ====================
[2018-04-17 17:33:19.665892]: Elapsed time since starting training: 1:38:05.062091
[2018-04-17 17:33:19.670404]: ====================
[2018-04-17 17:33:19.740591]: [Epoch: 928(61.9079386257505%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:33:21.028014]: [Epoch: 928(61.9079386257505%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:33:22.308923]: [Epoch: 928(61.9079386257505%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:33:25.954617]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:33:26.065412]: ====================
[2018-04-17 17:33:26.070426]: Elapsed time since starting training: 1:38:11.466123
[2018-04-17 17:33:26.074937]: ====================
[2018-04-17 17:33:26.146628]: [Epoch: 929(61.974649766511%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:33:27.437560]: [Epoch: 929(61.974649766511%): Data: 25.333333333333336%]:Running loss: 4.35037088394165
[2018-04-17 17:33:28.721474]: [Epoch: 929(61.974649766511%): Data: 50.66666666666667%]:Running loss: 8.483223676681519
[2018-04-17 17:33:32.322048]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:33:32.446379]: ====================
[2018-04-17 17:33:32.451895]: Elapsed time since starting training: 1:38:17.847591
[2018-04-17 17:33:32.455905]: ====================
[2018-04-17 17:33:32.529600]: [Epoch: 930(62.04136090727152%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:33:33.831060]: [Epoch: 930(62.04136090727152%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:33:35.114473]: [Epoch: 930(62.04136090727152%): Data: 50.66666666666667%]:Running loss: 8.483224511146545
[2018-04-17 17:33:38.714044]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:33:38.828850]: ====================
[2018-04-17 17:33:38.833865]: Elapsed time since starting training: 1:38:24.230064
[2018-04-17 17:33:38.838375]: ====================
[2018-04-17 17:33:38.909063]: [Epoch: 931(62.10807204803203%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:33:40.191473]: [Epoch: 931(62.10807204803203%): Data: 25.333333333333336%]:Running loss: 4.350372344255447
[2018-04-17 17:33:41.489926]: [Epoch: 931(62.10807204803203%): Data: 50.66666666666667%]:Running loss: 8.483226552605629
[2018-04-17 17:33:45.079972]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:33:45.188259]: ====================
[2018-04-17 17:33:45.192771]: Elapsed time since starting training: 1:38:30.588970
[2018-04-17 17:33:45.197785]: ====================
[2018-04-17 17:33:45.267470]: [Epoch: 932(62.174783188792524%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:33:46.559907]: [Epoch: 932(62.174783188792524%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:33:47.844823]: [Epoch: 932(62.174783188792524%): Data: 50.66666666666667%]:Running loss: 8.483222708106041
[2018-04-17 17:33:51.467456]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:33:51.587776]: ====================
[2018-04-17 17:33:51.592288]: Elapsed time since starting training: 1:38:36.987985
[2018-04-17 17:33:51.596800]: ====================
[2018-04-17 17:33:51.668992]: [Epoch: 933(62.241494329553035%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:33:52.990005]: [Epoch: 933(62.241494329553035%): Data: 25.333333333333336%]:Running loss: 4.350371330976486
[2018-04-17 17:33:54.277929]: [Epoch: 933(62.241494329553035%): Data: 50.66666666666667%]:Running loss: 8.48322468996048
[2018-04-17 17:33:57.891036]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:33:57.993308]: ====================
[2018-04-17 17:33:57.997821]: Elapsed time since starting training: 1:38:43.394020
[2018-04-17 17:33:58.001831]: ====================
[2018-04-17 17:33:58.076028]: [Epoch: 934(62.30820547031354%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:33:59.374982]: [Epoch: 934(62.30820547031354%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:34:00.698501]: [Epoch: 934(62.30820547031354%): Data: 50.66666666666667%]:Running loss: 8.4832254499197
[2018-04-17 17:34:04.356728]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:34:04.468025]: ====================
[2018-04-17 17:34:04.473539]: Elapsed time since starting training: 1:38:49.869738
[2018-04-17 17:34:04.479555]: ====================
[2018-04-17 17:34:04.547736]: [Epoch: 935(62.37491661107405%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:34:05.814605]: [Epoch: 935(62.37491661107405%): Data: 25.333333333333336%]:Running loss: 4.350372314453125
[2018-04-17 17:34:07.069441]: [Epoch: 935(62.37491661107405%): Data: 50.66666666666667%]:Running loss: 8.483226239681244
[2018-04-17 17:34:10.627402]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:34:10.732181]: ====================
[2018-04-17 17:34:10.736192]: Elapsed time since starting training: 1:38:56.132391
[2018-04-17 17:34:10.740703]: ====================
[2018-04-17 17:34:10.805876]: [Epoch: 936(62.44162775183456%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:34:12.068233]: [Epoch: 936(62.44162775183456%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:34:13.363678]: [Epoch: 936(62.44162775183456%): Data: 50.66666666666667%]:Running loss: 8.483226612210274
[2018-04-17 17:34:16.920134]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:34:17.035942]: ====================
[2018-04-17 17:34:17.040956]: Elapsed time since starting training: 1:39:02.437155
[2018-04-17 17:34:17.048977]: ====================
[2018-04-17 17:34:17.121169]: [Epoch: 937(62.50833889259506%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:34:18.386032]: [Epoch: 937(62.50833889259506%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:34:19.683983]: [Epoch: 937(62.50833889259506%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:34:23.253474]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:34:23.366275]: ====================
[2018-04-17 17:34:23.371288]: Elapsed time since starting training: 1:39:08.767487
[2018-04-17 17:34:23.375800]: ====================
[2018-04-17 17:34:23.445986]: [Epoch: 938(62.57505003335557%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:34:24.730903]: [Epoch: 938(62.57505003335557%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:34:26.010806]: [Epoch: 938(62.57505003335557%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:34:29.562751]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:34:29.681567]: ====================
[2018-04-17 17:34:29.686580]: Elapsed time since starting training: 1:39:15.082779
[2018-04-17 17:34:29.691093]: ====================
[2018-04-17 17:34:29.769300]: [Epoch: 939(62.64176117411607%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:34:31.039177]: [Epoch: 939(62.64176117411607%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:34:32.286493]: [Epoch: 939(62.64176117411607%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:34:35.851973]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:34:35.967280]: ====================
[2018-04-17 17:34:35.972795]: Elapsed time since starting training: 1:39:21.368493
[2018-04-17 17:34:35.977307]: ====================
[2018-04-17 17:34:36.045990]: [Epoch: 940(62.70847231487659%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:34:37.336922]: [Epoch: 940(62.70847231487659%): Data: 25.333333333333336%]:Running loss: 4.35037462413311
[2018-04-17 17:34:38.654425]: [Epoch: 940(62.70847231487659%): Data: 50.66666666666667%]:Running loss: 8.483230531215668
[2018-04-17 17:34:42.482103]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:34:42.672610]: ====================
[2018-04-17 17:34:42.678125]: Elapsed time since starting training: 1:39:28.074324
[2018-04-17 17:34:42.686146]: ====================
[2018-04-17 17:34:42.758839]: [Epoch: 941(62.7751834556371%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:34:44.125974]: [Epoch: 941(62.7751834556371%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:34:45.442475]: [Epoch: 941(62.7751834556371%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:34:49.206985]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:34:49.325299]: ====================
[2018-04-17 17:34:49.330313]: Elapsed time since starting training: 1:39:34.726512
[2018-04-17 17:34:49.335327]: ====================
[2018-04-17 17:34:49.403507]: [Epoch: 942(62.841894596397594%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:34:50.797247]: [Epoch: 942(62.841894596397594%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:34:52.090673]: [Epoch: 942(62.841894596397594%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:34:55.689242]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:34:55.794022]: ====================
[2018-04-17 17:34:55.798533]: Elapsed time since starting training: 1:39:41.194732
[2018-04-17 17:34:55.802543]: ====================
[2018-04-17 17:34:55.874735]: [Epoch: 943(62.908605737158105%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:34:57.206777]: [Epoch: 943(62.908605737158105%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:34:58.530798]: [Epoch: 943(62.908605737158105%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:35:02.111819]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:35:02.211585]: ====================
[2018-04-17 17:35:02.215595]: Elapsed time since starting training: 1:39:47.611794
[2018-04-17 17:35:02.220108]: ====================
[2018-04-17 17:35:02.290294]: [Epoch: 944(62.97531687791861%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:35:03.600277]: [Epoch: 944(62.97531687791861%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:35:04.929311]: [Epoch: 944(62.97531687791861%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:35:08.488776]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:35:08.598568]: ====================
[2018-04-17 17:35:08.603080]: Elapsed time since starting training: 1:39:53.998778
[2018-04-17 17:35:08.607090]: ====================
[2018-04-17 17:35:08.674771]: [Epoch: 945(63.04202801867912%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:35:09.993778]: [Epoch: 945(63.04202801867912%): Data: 25.333333333333336%]:Running loss: 4.350367397069931
[2018-04-17 17:35:11.328326]: [Epoch: 945(63.04202801867912%): Data: 50.66666666666667%]:Running loss: 8.483216792345047
[2018-04-17 17:35:14.887289]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:35:14.988058]: ====================
[2018-04-17 17:35:14.992570]: Elapsed time since starting training: 1:40:00.388267
[2018-04-17 17:35:14.997082]: ====================
[2018-04-17 17:35:15.068772]: [Epoch: 946(63.10873915943963%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:35:16.398808]: [Epoch: 946(63.10873915943963%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:35:17.715811]: [Epoch: 946(63.10873915943963%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:35:21.271265]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:35:21.375541]: ====================
[2018-04-17 17:35:21.380054]: Elapsed time since starting training: 1:40:06.776253
[2018-04-17 17:35:21.384064]: ====================
[2018-04-17 17:35:21.455755]: [Epoch: 947(63.17545030020013%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:35:22.768746]: [Epoch: 947(63.17545030020013%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:35:24.088254]: [Epoch: 947(63.17545030020013%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:35:27.653234]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:35:27.768541]: ====================
[2018-04-17 17:35:27.773053]: Elapsed time since starting training: 1:40:13.168751
[2018-04-17 17:35:27.777063]: ====================
[2018-04-17 17:35:27.848754]: [Epoch: 948(63.24216144096064%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:35:29.173777]: [Epoch: 948(63.24216144096064%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:35:30.494789]: [Epoch: 948(63.24216144096064%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:35:34.033198]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:35:34.143993]: ====================
[2018-04-17 17:35:34.148004]: Elapsed time since starting training: 1:40:19.544203
[2018-04-17 17:35:34.152516]: ====================
[2018-04-17 17:35:34.225710]: [Epoch: 949(63.30887258172114%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:35:35.557753]: [Epoch: 949(63.30887258172114%): Data: 25.333333333333336%]:Running loss: 4.350368842482567
[2018-04-17 17:35:36.893303]: [Epoch: 949(63.30887258172114%): Data: 50.66666666666667%]:Running loss: 8.483219370245934
[2018-04-17 17:35:40.533483]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:35:40.632245]: ====================
[2018-04-17 17:35:40.636757]: Elapsed time since starting training: 1:40:26.032956
[2018-04-17 17:35:40.641771]: ====================
[2018-04-17 17:35:40.715968]: [Epoch: 950(63.37558372248166%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:35:42.064553]: [Epoch: 950(63.37558372248166%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:35:43.419155]: [Epoch: 950(63.37558372248166%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:35:47.074876]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:35:47.181660]: ====================
[2018-04-17 17:35:47.185671]: Elapsed time since starting training: 1:40:32.581369
[2018-04-17 17:35:47.190182]: ====================
[2018-04-17 17:35:47.261873]: [Epoch: 951(63.44229486324217%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:35:48.606457]: [Epoch: 951(63.44229486324217%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:35:49.954532]: [Epoch: 951(63.44229486324217%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:35:53.578168]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:35:53.677933]: ====================
[2018-04-17 17:35:53.682446]: Elapsed time since starting training: 1:40:39.078645
[2018-04-17 17:35:53.686957]: ====================
[2018-04-17 17:35:53.772686]: [Epoch: 952(63.509006004002664%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:35:55.108236]: [Epoch: 952(63.509006004002664%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:35:56.439276]: [Epoch: 952(63.509006004002664%): Data: 50.66666666666667%]:Running loss: 8.48322232067585
[2018-04-17 17:36:00.045866]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:36:00.154655]: ====================
[2018-04-17 17:36:00.158666]: Elapsed time since starting training: 1:40:45.554865
[2018-04-17 17:36:00.163178]: ====================
[2018-04-17 17:36:00.239381]: [Epoch: 953(63.575717144763175%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:36:01.589470]: [Epoch: 953(63.575717144763175%): Data: 25.333333333333336%]:Running loss: 4.350370600819588
[2018-04-17 17:36:02.920509]: [Epoch: 953(63.575717144763175%): Data: 50.66666666666667%]:Running loss: 8.48322282731533
[2018-04-17 17:36:06.913627]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:36:07.047984]: ====================
[2018-04-17 17:36:07.056005]: Elapsed time since starting training: 1:40:52.452204
[2018-04-17 17:36:07.061520]: ====================
[2018-04-17 17:36:07.132208]: [Epoch: 954(63.64242828552368%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:36:08.446202]: [Epoch: 954(63.64242828552368%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:36:09.739140]: [Epoch: 954(63.64242828552368%): Data: 50.66666666666667%]:Running loss: 8.483223751187325
[2018-04-17 17:36:13.319159]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:36:13.454520]: ====================
[2018-04-17 17:36:13.459032]: Elapsed time since starting training: 1:40:58.854729
[2018-04-17 17:36:13.463042]: ====================
[2018-04-17 17:36:13.535735]: [Epoch: 955(63.70913942628419%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:36:14.821654]: [Epoch: 955(63.70913942628419%): Data: 25.333333333333336%]:Running loss: 4.3503716588020325
[2018-04-17 17:36:16.087520]: [Epoch: 955(63.70913942628419%): Data: 50.66666666666667%]:Running loss: 8.483225017786026
[2018-04-17 17:36:19.637961]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:36:19.755273]: ====================
[2018-04-17 17:36:19.759785]: Elapsed time since starting training: 1:41:05.155482
[2018-04-17 17:36:19.764297]: ====================
[2018-04-17 17:36:19.836991]: [Epoch: 956(63.7758505670447%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:36:21.125917]: [Epoch: 956(63.7758505670447%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:36:22.379250]: [Epoch: 956(63.7758505670447%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:36:25.899110]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:36:26.023440]: ====================
[2018-04-17 17:36:26.027451]: Elapsed time since starting training: 1:41:11.423650
[2018-04-17 17:36:26.031963]: ====================
[2018-04-17 17:36:26.101147]: [Epoch: 957(63.8425617078052%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:36:27.387066]: [Epoch: 957(63.8425617078052%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:36:28.689529]: [Epoch: 957(63.8425617078052%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:36:32.231447]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:36:32.341239]: ====================
[2018-04-17 17:36:32.345250]: Elapsed time since starting training: 1:41:17.741449
[2018-04-17 17:36:32.349761]: ====================
[2018-04-17 17:36:32.423457]: [Epoch: 958(63.90927284856571%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:36:33.739958]: [Epoch: 958(63.90927284856571%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:36:35.004821]: [Epoch: 958(63.90927284856571%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:36:38.527188]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:36:38.640488]: ====================
[2018-04-17 17:36:38.644500]: Elapsed time since starting training: 1:41:24.040699
[2018-04-17 17:36:38.649512]: ====================
[2018-04-17 17:36:38.717193]: [Epoch: 959(63.97598398932621%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:36:39.970525]: [Epoch: 959(63.97598398932621%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:36:41.242407]: [Epoch: 959(63.97598398932621%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:36:44.798864]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:36:44.909658]: ====================
[2018-04-17 17:36:44.914170]: Elapsed time since starting training: 1:41:30.310369
[2018-04-17 17:36:44.919190]: ====================
[2018-04-17 17:36:44.986863]: [Epoch: 960(64.04269513008673%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:36:46.237188]: [Epoch: 960(64.04269513008673%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:36:47.503555]: [Epoch: 960(64.04269513008673%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:36:51.020908]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:36:51.143233]: ====================
[2018-04-17 17:36:51.147244]: Elapsed time since starting training: 1:41:36.543443
[2018-04-17 17:36:51.151756]: ====================
[2018-04-17 17:36:51.218433]: [Epoch: 961(64.10940627084723%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:36:52.525910]: [Epoch: 961(64.10940627084723%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:36:53.785760]: [Epoch: 961(64.10940627084723%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:36:57.349235]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:36:57.458024]: ====================
[2018-04-17 17:36:57.462536]: Elapsed time since starting training: 1:41:42.858234
[2018-04-17 17:36:57.466045]: ====================
[2018-04-17 17:36:57.537235]: [Epoch: 962(64.17611741160773%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:36:58.821148]: [Epoch: 962(64.17611741160773%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:37:00.095537]: [Epoch: 962(64.17611741160773%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:37:03.614895]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:37:03.728698]: ====================
[2018-04-17 17:37:03.733210]: Elapsed time since starting training: 1:41:49.129409
[2018-04-17 17:37:03.737722]: ====================
[2018-04-17 17:37:03.805904]: [Epoch: 963(64.24282855236825%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:37:05.091322]: [Epoch: 963(64.24282855236825%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:37:06.363704]: [Epoch: 963(64.24282855236825%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:37:09.912641]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:37:10.025943]: ====================
[2018-04-17 17:37:10.030455]: Elapsed time since starting training: 1:41:55.426654
[2018-04-17 17:37:10.034978]: ====================
[2018-04-17 17:37:10.106155]: [Epoch: 964(64.30953969312874%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:37:11.385056]: [Epoch: 964(64.30953969312874%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:37:12.671477]: [Epoch: 964(64.30953969312874%): Data: 50.66666666666667%]:Running loss: 8.483231529593468
[2018-04-17 17:37:16.261522]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:37:16.483112]: ====================
[2018-04-17 17:37:16.488126]: Elapsed time since starting training: 1:42:01.883823
[2018-04-17 17:37:16.493139]: ====================
[2018-04-17 17:37:16.567837]: [Epoch: 965(64.37625083388926%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:37:17.841227]: [Epoch: 965(64.37625083388926%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:37:19.110602]: [Epoch: 965(64.37625083388926%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:37:22.685106]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:37:22.794398]: ====================
[2018-04-17 17:37:22.798910]: Elapsed time since starting training: 1:42:08.195109
[2018-04-17 17:37:22.804424]: ====================
[2018-04-17 17:37:22.877624]: [Epoch: 966(64.44296197464978%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:37:24.180584]: [Epoch: 966(64.44296197464978%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:37:25.510620]: [Epoch: 966(64.44296197464978%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:37:29.071087]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:37:29.189903]: ====================
[2018-04-17 17:37:29.194415]: Elapsed time since starting training: 1:42:14.590113
[2018-04-17 17:37:29.198426]: ====================
[2018-04-17 17:37:29.267610]: [Epoch: 967(64.50967311541027%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:37:30.559545]: [Epoch: 967(64.50967311541027%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 17:37:31.822403]: [Epoch: 967(64.50967311541027%): Data: 50.66666666666667%]:Running loss: 8.483235776424408
[2018-04-17 17:37:35.358813]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:37:35.473618]: ====================
[2018-04-17 17:37:35.478130]: Elapsed time since starting training: 1:42:20.874329
[2018-04-17 17:37:35.482642]: ====================
[2018-04-17 17:37:35.557842]: [Epoch: 968(64.57638425617078%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:37:36.855793]: [Epoch: 968(64.57638425617078%): Data: 25.333333333333336%]:Running loss: 4.350376337766647
[2018-04-17 17:37:38.157760]: [Epoch: 968(64.57638425617078%): Data: 50.66666666666667%]:Running loss: 8.4832254499197
[2018-04-17 17:37:41.690153]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:37:41.806463]: ====================
[2018-04-17 17:37:41.810474]: Elapsed time since starting training: 1:42:27.206673
[2018-04-17 17:37:41.814484]: ====================
[2018-04-17 17:37:41.886174]: [Epoch: 969(64.64309539693129%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:37:43.174600]: [Epoch: 969(64.64309539693129%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:37:44.437458]: [Epoch: 969(64.64309539693129%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:37:47.967344]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:37:48.079643]: ====================
[2018-04-17 17:37:48.083654]: Elapsed time since starting training: 1:42:33.479853
[2018-04-17 17:37:48.088166]: ====================
[2018-04-17 17:37:48.155344]: [Epoch: 970(64.70980653769179%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:37:49.451791]: [Epoch: 970(64.70980653769179%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:37:50.707129]: [Epoch: 970(64.70980653769179%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:37:54.260578]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:37:54.377890]: ====================
[2018-04-17 17:37:54.382402]: Elapsed time since starting training: 1:42:39.778099
[2018-04-17 17:37:54.386413]: ====================
[2018-04-17 17:37:54.459112]: [Epoch: 971(64.77651767845231%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:37:55.742029]: [Epoch: 971(64.77651767845231%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:37:57.011393]: [Epoch: 971(64.77651767845231%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:38:00.537268]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:38:00.646558]: ====================
[2018-04-17 17:38:00.651070]: Elapsed time since starting training: 1:42:46.047269
[2018-04-17 17:38:00.656084]: ====================
[2018-04-17 17:38:00.725268]: [Epoch: 972(64.84322881921281%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:38:01.996152]: [Epoch: 972(64.84322881921281%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:38:03.302620]: [Epoch: 972(64.84322881921281%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:38:06.836016]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:38:06.951825]: ====================
[2018-04-17 17:38:06.957840]: Elapsed time since starting training: 1:42:52.353538
[2018-04-17 17:38:06.961851]: ====================
[2018-04-17 17:38:07.035045]: [Epoch: 973(64.90993995997331%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:38:08.326980]: [Epoch: 973(64.90993995997331%): Data: 25.333333333333336%]:Running loss: 4.35037025809288
[2018-04-17 17:38:09.588334]: [Epoch: 973(64.90993995997331%): Data: 50.66666666666667%]:Running loss: 8.48322220146656
[2018-04-17 17:38:13.085132]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:38:13.202946]: ====================
[2018-04-17 17:38:13.207959]: Elapsed time since starting training: 1:42:58.604158
[2018-04-17 17:38:13.212471]: ====================
[2018-04-17 17:38:13.279148]: [Epoch: 974(64.97665110073382%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:38:14.560556]: [Epoch: 974(64.97665110073382%): Data: 25.333333333333336%]:Running loss: 4.350370720028877
[2018-04-17 17:38:15.826923]: [Epoch: 974(64.97665110073382%): Data: 50.66666666666667%]:Running loss: 8.48322294652462
[2018-04-17 17:38:19.363827]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:38:19.480137]: ====================
[2018-04-17 17:38:19.484649]: Elapsed time since starting training: 1:43:04.880346
[2018-04-17 17:38:19.489662]: ====================
[2018-04-17 17:38:19.556840]: [Epoch: 975(65.04336224149434%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:38:20.841757]: [Epoch: 975(65.04336224149434%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:38:22.105618]: [Epoch: 975(65.04336224149434%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:38:25.604922]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:38:25.717221]: ====================
[2018-04-17 17:38:25.723738]: Elapsed time since starting training: 1:43:11.119937
[2018-04-17 17:38:25.728251]: ====================
[2018-04-17 17:38:25.798938]: [Epoch: 976(65.11007338225484%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:38:27.098393]: [Epoch: 976(65.11007338225484%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:38:28.372280]: [Epoch: 976(65.11007338225484%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:38:31.935756]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:38:32.051564]: ====================
[2018-04-17 17:38:32.058081]: Elapsed time since starting training: 1:43:17.454280
[2018-04-17 17:38:32.063094]: ====================
[2018-04-17 17:38:32.134785]: [Epoch: 977(65.17678452301534%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:38:33.409173]: [Epoch: 977(65.17678452301534%): Data: 25.333333333333336%]:Running loss: 4.3503721952438354
[2018-04-17 17:38:34.662507]: [Epoch: 977(65.17678452301534%): Data: 50.66666666666667%]:Running loss: 8.483226120471954
[2018-04-17 17:38:38.200915]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:38:38.323742]: ====================
[2018-04-17 17:38:38.328253]: Elapsed time since starting training: 1:43:23.724452
[2018-04-17 17:38:38.332766]: ====================
[2018-04-17 17:38:38.406963]: [Epoch: 978(65.24349566377585%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:38:39.722461]: [Epoch: 978(65.24349566377585%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:38:40.993340]: [Epoch: 978(65.24349566377585%): Data: 50.66666666666667%]:Running loss: 8.483226731419563
[2018-04-17 17:38:44.508687]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:38:44.627002]: ====================
[2018-04-17 17:38:44.631514]: Elapsed time since starting training: 1:43:30.027713
[2018-04-17 17:38:44.635525]: ====================
[2018-04-17 17:38:44.702703]: [Epoch: 979(65.31020680453635%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:38:45.991632]: [Epoch: 979(65.31020680453635%): Data: 25.333333333333336%]:Running loss: 4.350372925400734
[2018-04-17 17:38:47.260003]: [Epoch: 979(65.31020680453635%): Data: 50.66666666666667%]:Running loss: 8.483227416872978
[2018-04-17 17:38:50.777857]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:38:50.893665]: ====================
[2018-04-17 17:38:50.898177]: Elapsed time since starting training: 1:43:36.293875
[2018-04-17 17:38:50.902690]: ====================
[2018-04-17 17:38:50.982902]: [Epoch: 980(65.37691794529687%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:38:52.274837]: [Epoch: 980(65.37691794529687%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:38:53.543209]: [Epoch: 980(65.37691794529687%): Data: 50.66666666666667%]:Running loss: 8.483228489756584
[2018-04-17 17:38:57.102674]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:38:57.217480]: ====================
[2018-04-17 17:38:57.221490]: Elapsed time since starting training: 1:43:42.617689
[2018-04-17 17:38:57.226003]: ====================
[2018-04-17 17:38:57.298696]: [Epoch: 981(65.44362908605737%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:38:58.581106]: [Epoch: 981(65.44362908605737%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:38:59.874044]: [Epoch: 981(65.44362908605737%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:39:03.415460]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:39:03.540292]: ====================
[2018-04-17 17:39:03.544804]: Elapsed time since starting training: 1:43:48.941003
[2018-04-17 17:39:03.548815]: ====================
[2018-04-17 17:39:03.614990]: [Epoch: 982(65.51034022681787%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:39:04.907929]: [Epoch: 982(65.51034022681787%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:39:06.175800]: [Epoch: 982(65.51034022681787%): Data: 50.66666666666667%]:Running loss: 8.483226463198662
[2018-04-17 17:39:09.711200]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:39:09.822998]: ====================
[2018-04-17 17:39:09.827510]: Elapsed time since starting training: 1:43:55.223709
[2018-04-17 17:39:09.832022]: ====================
[2018-04-17 17:39:09.900203]: [Epoch: 983(65.57705136757839%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:39:11.164578]: [Epoch: 983(65.57705136757839%): Data: 25.333333333333336%]:Running loss: 4.3503734320402145
[2018-04-17 17:39:12.427423]: [Epoch: 983(65.57705136757839%): Data: 50.66666666666667%]:Running loss: 8.483228489756584
[2018-04-17 17:39:15.938759]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:39:16.049554]: ====================
[2018-04-17 17:39:16.053565]: Elapsed time since starting training: 1:44:01.449764
[2018-04-17 17:39:16.058578]: ====================
[2018-04-17 17:39:16.130270]: [Epoch: 984(65.64376250833888%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:39:17.389617]: [Epoch: 984(65.64376250833888%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:39:18.716144]: [Epoch: 984(65.64376250833888%): Data: 50.66666666666667%]:Running loss: 8.483229219913483
[2018-04-17 17:39:22.225977]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:39:22.339780]: ====================
[2018-04-17 17:39:22.344794]: Elapsed time since starting training: 1:44:07.740993
[2018-04-17 17:39:22.349306]: ====================
[2018-04-17 17:39:22.427012]: [Epoch: 985(65.7104736490994%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:39:23.694382]: [Epoch: 985(65.7104736490994%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:39:24.961250]: [Epoch: 985(65.7104736490994%): Data: 50.66666666666667%]:Running loss: 8.483227699995041
[2018-04-17 17:39:28.518208]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:39:28.634518]: ====================
[2018-04-17 17:39:28.639029]: Elapsed time since starting training: 1:44:14.035228
[2018-04-17 17:39:28.645045]: ====================
[2018-04-17 17:39:28.711723]: [Epoch: 986(65.77718478985992%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:39:29.991125]: [Epoch: 986(65.77718478985992%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:39:31.278553]: [Epoch: 986(65.77718478985992%): Data: 50.66666666666667%]:Running loss: 8.48322907090187
[2018-04-17 17:39:34.824482]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:39:34.940290]: ====================
[2018-04-17 17:39:34.946307]: Elapsed time since starting training: 1:44:20.342506
[2018-04-17 17:39:34.950316]: ====================
[2018-04-17 17:39:35.017495]: [Epoch: 987(65.8438959306204%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:39:36.309942]: [Epoch: 987(65.8438959306204%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:39:37.613397]: [Epoch: 987(65.8438959306204%): Data: 50.66666666666667%]:Running loss: 8.48322956264019
[2018-04-17 17:39:41.130750]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:39:41.247561]: ====================
[2018-04-17 17:39:41.252574]: Elapsed time since starting training: 1:44:26.648272
[2018-04-17 17:39:41.256585]: ====================
[2018-04-17 17:39:41.323262]: [Epoch: 988(65.91060707138092%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:39:42.565565]: [Epoch: 988(65.91060707138092%): Data: 25.333333333333336%]:Running loss: 4.350374683737755
[2018-04-17 17:39:43.796338]: [Epoch: 988(65.91060707138092%): Data: 50.66666666666667%]:Running loss: 8.4832314401865
[2018-04-17 17:39:47.238491]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:39:47.354800]: ====================
[2018-04-17 17:39:47.359813]: Elapsed time since starting training: 1:44:32.756012
[2018-04-17 17:39:47.363825]: ====================
[2018-04-17 17:39:47.430501]: [Epoch: 989(65.97731821214143%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:39:48.723940]: [Epoch: 989(65.97731821214143%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:39:49.993315]: [Epoch: 989(65.97731821214143%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:39:53.497634]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:39:53.604919]: ====================
[2018-04-17 17:39:53.609432]: Elapsed time since starting training: 1:44:39.005128
[2018-04-17 17:39:53.613943]: ====================
[2018-04-17 17:39:53.684129]: [Epoch: 990(66.04402935290193%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:39:54.951500]: [Epoch: 990(66.04402935290193%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:39:56.194805]: [Epoch: 990(66.04402935290193%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:39:59.647988]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:39:59.755273]: ====================
[2018-04-17 17:39:59.761289]: Elapsed time since starting training: 1:44:45.157488
[2018-04-17 17:39:59.765299]: ====================
[2018-04-17 17:39:59.835486]: [Epoch: 991(66.11074049366245%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:40:01.076786]: [Epoch: 991(66.11074049366245%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:40:02.343154]: [Epoch: 991(66.11074049366245%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:40:05.795835]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:40:05.901616]: ====================
[2018-04-17 17:40:05.905627]: Elapsed time since starting training: 1:44:51.301826
[2018-04-17 17:40:05.911141]: ====================
[2018-04-17 17:40:05.985840]: [Epoch: 992(66.17745163442295%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:40:07.224132]: [Epoch: 992(66.17745163442295%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:40:08.443876]: [Epoch: 992(66.17745163442295%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:40:11.882519]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:40:12.001837]: ====================
[2018-04-17 17:40:12.006850]: Elapsed time since starting training: 1:44:57.402547
[2018-04-17 17:40:12.011863]: ====================
[2018-04-17 17:40:12.079041]: [Epoch: 993(66.24416277518345%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:40:13.308811]: [Epoch: 993(66.24416277518345%): Data: 25.333333333333336%]:Running loss: 4.350369453430176
[2018-04-17 17:40:14.582197]: [Epoch: 993(66.24416277518345%): Data: 50.66666666666667%]:Running loss: 8.483220547437668
[2018-04-17 17:40:18.054931]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:40:18.166228]: ====================
[2018-04-17 17:40:18.170238]: Elapsed time since starting training: 1:45:03.566437
[2018-04-17 17:40:18.174750]: ====================
[2018-04-17 17:40:18.246441]: [Epoch: 994(66.31087391594396%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:40:19.499280]: [Epoch: 994(66.31087391594396%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 17:40:20.746589]: [Epoch: 994(66.31087391594396%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 17:40:24.261935]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:40:24.370725]: ====================
[2018-04-17 17:40:24.375237]: Elapsed time since starting training: 1:45:09.770935
[2018-04-17 17:40:24.379749]: ====================
[2018-04-17 17:40:24.452943]: [Epoch: 995(66.37758505670448%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:40:25.732345]: [Epoch: 995(66.37758505670448%): Data: 25.333333333333336%]:Running loss: 4.350370347499847
[2018-04-17 17:40:26.961614]: [Epoch: 995(66.37758505670448%): Data: 50.66666666666667%]:Running loss: 8.483222290873528
[2018-04-17 17:40:30.453398]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:40:30.553164]: ====================
[2018-04-17 17:40:30.557676]: Elapsed time since starting training: 1:45:15.953875
[2018-04-17 17:40:30.562189]: ====================
[2018-04-17 17:40:30.634881]: [Epoch: 996(66.44429619746498%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:40:31.951883]: [Epoch: 996(66.44429619746498%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:40:33.269386]: [Epoch: 996(66.44429619746498%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:40:36.796766]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:40:36.901544]: ====================
[2018-04-17 17:40:36.902547]: Elapsed time since starting training: 1:45:22.298746
[2018-04-17 17:40:36.906557]: ====================
[2018-04-17 17:40:36.973736]: [Epoch: 997(66.51100733822548%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:40:38.284722]: [Epoch: 997(66.51100733822548%): Data: 25.333333333333336%]:Running loss: 4.350370496511459
[2018-04-17 17:40:39.559612]: [Epoch: 997(66.51100733822548%): Data: 50.66666666666667%]:Running loss: 8.483222723007202
[2018-04-17 17:40:43.056912]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:40:43.161190]: ====================
[2018-04-17 17:40:43.165200]: Elapsed time since starting training: 1:45:28.561399
[2018-04-17 17:40:43.169210]: ====================
[2018-04-17 17:40:43.239898]: [Epoch: 998(66.57771847898599%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:40:44.551385]: [Epoch: 998(66.57771847898599%): Data: 25.333333333333336%]:Running loss: 4.350370854139328
[2018-04-17 17:40:45.845325]: [Epoch: 998(66.57771847898599%): Data: 50.66666666666667%]:Running loss: 8.483223646879196
[2018-04-17 17:40:49.378219]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:40:49.479489]: ====================
[2018-04-17 17:40:49.484001]: Elapsed time since starting training: 1:45:34.880200
[2018-04-17 17:40:49.489014]: ====================
[2018-04-17 17:40:49.558699]: [Epoch: 999(66.64442961974649%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:40:50.874197]: [Epoch: 999(66.64442961974649%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:40:52.191701]: [Epoch: 999(66.64442961974649%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:40:55.747656]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:40:55.856947]: ====================
[2018-04-17 17:40:55.864466]: Elapsed time since starting training: 1:45:41.260665
[2018-04-17 17:40:55.868979]: ====================
[2018-04-17 17:40:55.949192]: [Epoch: 1000(66.711140760507%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:40:57.330865]: [Epoch: 1000(66.711140760507%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:40:58.751142]: [Epoch: 1000(66.711140760507%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:41:02.450479]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:41:02.572303]: ====================
[2018-04-17 17:41:02.576313]: Elapsed time since starting training: 1:45:47.972512
[2018-04-17 17:41:02.581327]: ====================
[2018-04-17 17:41:02.654522]: [Epoch: 1001(66.77785190126751%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:41:03.959491]: [Epoch: 1001(66.77785190126751%): Data: 25.333333333333336%]:Running loss: 4.350372791290283
[2018-04-17 17:41:05.262455]: [Epoch: 1001(66.77785190126751%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:41:08.831446]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:41:08.965803]: ====================
[2018-04-17 17:41:08.970816]: Elapsed time since starting training: 1:45:54.367015
[2018-04-17 17:41:08.975328]: ====================
[2018-04-17 17:41:09.047019]: [Epoch: 1002(66.84456304202801%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:41:10.323413]: [Epoch: 1002(66.84456304202801%): Data: 25.333333333333336%]:Running loss: 4.350370794534683
[2018-04-17 17:41:11.584766]: [Epoch: 1002(66.84456304202801%): Data: 50.66666666666667%]:Running loss: 8.483223304152489
[2018-04-17 17:41:15.111645]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:41:15.232968]: ====================
[2018-04-17 17:41:15.236978]: Elapsed time since starting training: 1:46:00.633177
[2018-04-17 17:41:15.241490]: ====================
[2018-04-17 17:41:15.311175]: [Epoch: 1003(66.91127418278853%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:41:16.598097]: [Epoch: 1003(66.91127418278853%): Data: 25.333333333333336%]:Running loss: 4.350371912121773
[2018-04-17 17:41:17.857957]: [Epoch: 1003(66.91127418278853%): Data: 50.66666666666667%]:Running loss: 8.483225271105766
[2018-04-17 17:41:21.383321]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:41:21.504644]: ====================
[2018-04-17 17:41:21.505647]: Elapsed time since starting training: 1:46:06.901846
[2018-04-17 17:41:21.509657]: ====================
[2018-04-17 17:41:21.577337]: [Epoch: 1004(66.97798532354902%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:41:22.862253]: [Epoch: 1004(66.97798532354902%): Data: 25.333333333333336%]:Running loss: 4.350372463464737
[2018-04-17 17:41:24.157197]: [Epoch: 1004(66.97798532354902%): Data: 50.66666666666667%]:Running loss: 8.483226388692856
[2018-04-17 17:41:27.748245]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:41:27.865056]: ====================
[2018-04-17 17:41:27.870069]: Elapsed time since starting training: 1:46:13.266268
[2018-04-17 17:41:27.875082]: ====================
[2018-04-17 17:41:27.949781]: [Epoch: 1005(67.04469646430954%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:41:29.242719]: [Epoch: 1005(67.04469646430954%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:41:30.519113]: [Epoch: 1005(67.04469646430954%): Data: 50.66666666666667%]:Running loss: 8.483226999640465
[2018-04-17 17:41:34.073063]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:41:34.191879]: ====================
[2018-04-17 17:41:34.196391]: Elapsed time since starting training: 1:46:19.592590
[2018-04-17 17:41:34.200902]: ====================
[2018-04-17 17:41:34.269084]: [Epoch: 1006(67.11140760507006%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:41:35.635216]: [Epoch: 1006(67.11140760507006%): Data: 25.333333333333336%]:Running loss: 4.35037288069725
[2018-04-17 17:41:36.924645]: [Epoch: 1006(67.11140760507006%): Data: 50.66666666666667%]:Running loss: 8.483227372169495
[2018-04-17 17:41:40.510680]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:41:40.639022]: ====================
[2018-04-17 17:41:40.644035]: Elapsed time since starting training: 1:46:26.039733
[2018-04-17 17:41:40.649048]: ====================
[2018-04-17 17:41:40.728760]: [Epoch: 1007(67.17811874583055%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:41:42.002146]: [Epoch: 1007(67.17811874583055%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:41:43.248961]: [Epoch: 1007(67.17811874583055%): Data: 50.66666666666667%]:Running loss: 8.483228102326393
[2018-04-17 17:41:46.751775]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:41:46.970357]: ====================
[2018-04-17 17:41:46.975370]: Elapsed time since starting training: 1:46:32.371068
[2018-04-17 17:41:46.979882]: ====================
[2018-04-17 17:41:47.048063]: [Epoch: 1008(67.24482988659106%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:41:48.310921]: [Epoch: 1008(67.24482988659106%): Data: 25.333333333333336%]:Running loss: 4.3503741174936295
[2018-04-17 17:41:49.585310]: [Epoch: 1008(67.24482988659106%): Data: 50.66666666666667%]:Running loss: 8.483229741454124
[2018-04-17 17:41:53.138759]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:41:53.260583]: ====================
[2018-04-17 17:41:53.265095]: Elapsed time since starting training: 1:46:38.661294
[2018-04-17 17:41:53.269606]: ====================
[2018-04-17 17:41:53.342300]: [Epoch: 1009(67.31154102735157%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:41:54.615184]: [Epoch: 1009(67.31154102735157%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:41:55.887066]: [Epoch: 1009(67.31154102735157%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:41:59.429986]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:41:59.545294]: ====================
[2018-04-17 17:41:59.549805]: Elapsed time since starting training: 1:46:44.946004
[2018-04-17 17:41:59.554317]: ====================
[2018-04-17 17:41:59.629517]: [Epoch: 1010(67.37825216811207%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:42:00.927469]: [Epoch: 1010(67.37825216811207%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:42:02.221409]: [Epoch: 1010(67.37825216811207%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:42:05.788894]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:42:05.909716]: ====================
[2018-04-17 17:42:05.915732]: Elapsed time since starting training: 1:46:51.311931
[2018-04-17 17:42:05.920245]: ====================
[2018-04-17 17:42:05.990932]: [Epoch: 1011(67.44496330887259%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:42:07.274846]: [Epoch: 1011(67.44496330887259%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:42:08.563272]: [Epoch: 1011(67.44496330887259%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:42:12.080625]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:42:12.199441]: ====================
[2018-04-17 17:42:12.203451]: Elapsed time since starting training: 1:46:57.599650
[2018-04-17 17:42:12.207963]: ====================
[2018-04-17 17:42:12.281659]: [Epoch: 1012(67.51167444963309%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:42:13.556549]: [Epoch: 1012(67.51167444963309%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:42:14.834447]: [Epoch: 1012(67.51167444963309%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:42:18.370850]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:42:18.490669]: ====================
[2018-04-17 17:42:18.495682]: Elapsed time since starting training: 1:47:03.891380
[2018-04-17 17:42:18.500194]: ====================
[2018-04-17 17:42:18.579906]: [Epoch: 1013(67.5783855903936%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:42:19.846273]: [Epoch: 1013(67.5783855903936%): Data: 25.333333333333336%]:Running loss: 4.350376725196838
[2018-04-17 17:42:21.100112]: [Epoch: 1013(67.5783855903936%): Data: 50.66666666666667%]:Running loss: 8.483229920268059
[2018-04-17 17:42:24.608943]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:42:24.726757]: ====================
[2018-04-17 17:42:24.731769]: Elapsed time since starting training: 1:47:10.127467
[2018-04-17 17:42:24.735780]: ====================
[2018-04-17 17:42:24.802456]: [Epoch: 1014(67.6450967311541%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:42:26.077346]: [Epoch: 1014(67.6450967311541%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:42:27.343714]: [Epoch: 1014(67.6450967311541%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:42:30.916217]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:42:31.037540]: ====================
[2018-04-17 17:42:31.041551]: Elapsed time since starting training: 1:47:16.437750
[2018-04-17 17:42:31.045561]: ====================
[2018-04-17 17:42:31.121263]: [Epoch: 1015(67.71180787191462%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:42:32.393144]: [Epoch: 1015(67.71180787191462%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:42:33.678562]: [Epoch: 1015(67.71180787191462%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:42:37.239030]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:42:37.353835]: ====================
[2018-04-17 17:42:37.357846]: Elapsed time since starting training: 1:47:22.754045
[2018-04-17 17:42:37.362358]: ====================
[2018-04-17 17:42:37.442070]: [Epoch: 1016(67.77851901267512%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:42:38.735009]: [Epoch: 1016(67.77851901267512%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:42:40.011902]: [Epoch: 1016(67.77851901267512%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:42:43.544296]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:42:43.670631]: ====================
[2018-04-17 17:42:43.676146]: Elapsed time since starting training: 1:47:29.071843
[2018-04-17 17:42:43.680658]: ====================
[2018-04-17 17:42:43.755357]: [Epoch: 1017(67.84523015343562%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:42:45.056316]: [Epoch: 1017(67.84523015343562%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:42:46.503173]: [Epoch: 1017(67.84523015343562%): Data: 50.66666666666667%]:Running loss: 8.483218565583229
[2018-04-17 17:42:50.137827]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:42:50.254136]: ====================
[2018-04-17 17:42:50.258147]: Elapsed time since starting training: 1:47:35.653845
[2018-04-17 17:42:50.262159]: ====================
[2018-04-17 17:42:50.333347]: [Epoch: 1018(67.91194129419613%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:42:51.635309]: [Epoch: 1018(67.91194129419613%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:42:52.911703]: [Epoch: 1018(67.91194129419613%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:42:56.514783]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:42:56.636107]: ====================
[2018-04-17 17:42:56.640618]: Elapsed time since starting training: 1:47:42.036817
[2018-04-17 17:42:56.645130]: ====================
[2018-04-17 17:42:56.717824]: [Epoch: 1019(67.97865243495663%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:42:58.004244]: [Epoch: 1019(67.97865243495663%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:42:59.322249]: [Epoch: 1019(67.97865243495663%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:43:02.922823]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:43:03.039634]: ====================
[2018-04-17 17:43:03.043644]: Elapsed time since starting training: 1:47:48.439843
[2018-04-17 17:43:03.048658]: ====================
[2018-04-17 17:43:03.121351]: [Epoch: 1020(68.04536357571715%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:43:04.418299]: [Epoch: 1020(68.04536357571715%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:43:05.725274]: [Epoch: 1020(68.04536357571715%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:43:09.318328]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:43:09.440153]: ====================
[2018-04-17 17:43:09.445165]: Elapsed time since starting training: 1:47:54.840863
[2018-04-17 17:43:09.449177]: ====================
[2018-04-17 17:43:09.518360]: [Epoch: 1021(68.11207471647765%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:43:10.805783]: [Epoch: 1021(68.11207471647765%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 17:43:12.075660]: [Epoch: 1021(68.11207471647765%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 17:43:15.748426]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:43:15.897322]: ====================
[2018-04-17 17:43:15.902837]: Elapsed time since starting training: 1:48:01.298534
[2018-04-17 17:43:15.906847]: ====================
[2018-04-17 17:43:15.972021]: [Epoch: 1022(68.17878585723815%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:43:17.250921]: [Epoch: 1022(68.17878585723815%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:43:18.543357]: [Epoch: 1022(68.17878585723815%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:43:22.097809]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:43:22.219633]: ====================
[2018-04-17 17:43:22.224145]: Elapsed time since starting training: 1:48:07.620344
[2018-04-17 17:43:22.228657]: ====================
[2018-04-17 17:43:22.296337]: [Epoch: 1023(68.24549699799867%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:43:23.594288]: [Epoch: 1023(68.24549699799867%): Data: 25.333333333333336%]:Running loss: 4.350370794534683
[2018-04-17 17:43:24.875695]: [Epoch: 1023(68.24549699799867%): Data: 50.66666666666667%]:Running loss: 8.483223304152489
[2018-04-17 17:43:28.504343]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:43:28.623661]: ====================
[2018-04-17 17:43:28.629176]: Elapsed time since starting training: 1:48:14.025375
[2018-04-17 17:43:28.634189]: ====================
[2018-04-17 17:43:28.702370]: [Epoch: 1024(68.31220813875916%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:43:29.983777]: [Epoch: 1024(68.31220813875916%): Data: 25.333333333333336%]:Running loss: 4.350371599197388
[2018-04-17 17:43:31.272203]: [Epoch: 1024(68.31220813875916%): Data: 50.66666666666667%]:Running loss: 8.483224958181381
[2018-04-17 17:43:34.809108]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:43:34.947977]: ====================
[2018-04-17 17:43:34.953993]: Elapsed time since starting training: 1:48:20.350192
[2018-04-17 17:43:34.960009]: ====================
[2018-04-17 17:43:35.032201]: [Epoch: 1025(68.37891927951968%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:43:36.298067]: [Epoch: 1025(68.37891927951968%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:43:37.571453]: [Epoch: 1025(68.37891927951968%): Data: 50.66666666666667%]:Running loss: 8.483225494623184
[2018-04-17 17:43:41.073264]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:43:41.189073]: ====================
[2018-04-17 17:43:41.194587]: Elapsed time since starting training: 1:48:26.590786
[2018-04-17 17:43:41.199099]: ====================
[2018-04-17 17:43:41.272293]: [Epoch: 1026(68.4456304202802%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:43:42.545680]: [Epoch: 1026(68.4456304202802%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:43:43.857167]: [Epoch: 1026(68.4456304202802%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:43:47.392066]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:43:47.511885]: ====================
[2018-04-17 17:43:47.515895]: Elapsed time since starting training: 1:48:32.912094
[2018-04-17 17:43:47.520408]: ====================
[2018-04-17 17:43:47.594103]: [Epoch: 1027(68.51234156104069%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:43:48.872502]: [Epoch: 1027(68.51234156104069%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:43:50.154912]: [Epoch: 1027(68.51234156104069%): Data: 50.66666666666667%]:Running loss: 8.48322680592537
[2018-04-17 17:43:53.653214]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:43:53.769022]: ====================
[2018-04-17 17:43:53.774035]: Elapsed time since starting training: 1:48:39.169733
[2018-04-17 17:43:53.778046]: ====================
[2018-04-17 17:43:53.851241]: [Epoch: 1028(68.5790527018012%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:43:55.122120]: [Epoch: 1028(68.5790527018012%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:43:56.397511]: [Epoch: 1028(68.5790527018012%): Data: 50.66666666666667%]:Running loss: 8.483228042721748
[2018-04-17 17:43:59.954469]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:44:00.076795]: ====================
[2018-04-17 17:44:00.081307]: Elapsed time since starting training: 1:48:45.477506
[2018-04-17 17:44:00.085818]: ====================
[2018-04-17 17:44:00.161521]: [Epoch: 1029(68.6457638425617%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:44:01.446938]: [Epoch: 1029(68.6457638425617%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:44:02.757423]: [Epoch: 1029(68.6457638425617%): Data: 50.66666666666667%]:Running loss: 8.48322956264019
[2018-04-17 17:44:06.328417]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:44:06.445729]: ====================
[2018-04-17 17:44:06.449740]: Elapsed time since starting training: 1:48:51.845939
[2018-04-17 17:44:06.454754]: ====================
[2018-04-17 17:44:06.525441]: [Epoch: 1030(68.71247498332221%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:44:07.796822]: [Epoch: 1030(68.71247498332221%): Data: 25.333333333333336%]:Running loss: 4.350374013185501
[2018-04-17 17:44:09.096277]: [Epoch: 1030(68.71247498332221%): Data: 50.66666666666667%]:Running loss: 8.483229756355286
[2018-04-17 17:44:12.644211]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:44:12.762527]: ====================
[2018-04-17 17:44:12.766537]: Elapsed time since starting training: 1:48:58.162736
[2018-04-17 17:44:12.772553]: ====================
[2018-04-17 17:44:12.839230]: [Epoch: 1031(68.77918612408273%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:44:14.130664]: [Epoch: 1031(68.77918612408273%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:44:15.408562]: [Epoch: 1031(68.77918612408273%): Data: 50.66666666666667%]:Running loss: 8.483230337500572
[2018-04-17 17:44:19.032698]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:44:19.155525]: ====================
[2018-04-17 17:44:19.159536]: Elapsed time since starting training: 1:49:04.555735
[2018-04-17 17:44:19.164048]: ====================
[2018-04-17 17:44:19.235739]: [Epoch: 1032(68.84589726484323%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:44:20.556250]: [Epoch: 1032(68.84589726484323%): Data: 25.333333333333336%]:Running loss: 4.35037499666214
[2018-04-17 17:44:21.839160]: [Epoch: 1032(68.84589726484323%): Data: 50.66666666666667%]:Running loss: 8.483230620622635
[2018-04-17 17:44:25.528972]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:44:25.673357]: ====================
[2018-04-17 17:44:25.678870]: Elapsed time since starting training: 1:49:11.074568
[2018-04-17 17:44:25.683382]: ====================
[2018-04-17 17:44:25.750060]: [Epoch: 1033(68.91260840560373%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:44:27.052031]: [Epoch: 1033(68.91260840560373%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:44:28.420661]: [Epoch: 1033(68.91260840560373%): Data: 50.66666666666667%]:Running loss: 8.483231946825981
[2018-04-17 17:44:32.071869]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:44:32.240819]: ====================
[2018-04-17 17:44:32.245330]: Elapsed time since starting training: 1:49:17.641028
[2018-04-17 17:44:32.249341]: ====================
[2018-04-17 17:44:32.323538]: [Epoch: 1034(68.97931954636425%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:44:33.644554]: [Epoch: 1034(68.97931954636425%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:44:34.947014]: [Epoch: 1034(68.97931954636425%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:44:38.642340]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:44:38.755140]: ====================
[2018-04-17 17:44:38.759652]: Elapsed time since starting training: 1:49:24.155349
[2018-04-17 17:44:38.763662]: ====================
[2018-04-17 17:44:38.833348]: [Epoch: 1035(69.04603068712476%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:44:40.113251]: [Epoch: 1035(69.04603068712476%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:44:41.401176]: [Epoch: 1035(69.04603068712476%): Data: 50.66666666666667%]:Running loss: 8.483233287930489
[2018-04-17 17:44:44.904992]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:44:45.015286]: ====================
[2018-04-17 17:44:45.019798]: Elapsed time since starting training: 1:49:30.415997
[2018-04-17 17:44:45.025313]: ====================
[2018-04-17 17:44:45.097003]: [Epoch: 1036(69.11274182788526%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:44:46.357855]: [Epoch: 1036(69.11274182788526%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:44:47.640767]: [Epoch: 1036(69.11274182788526%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:44:51.186194]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 17:44:51.303004]: ====================
[2018-04-17 17:44:51.307516]: Elapsed time since starting training: 1:49:36.703715
[2018-04-17 17:44:51.312530]: ====================
[2018-04-17 17:44:51.385223]: [Epoch: 1037(69.17945296864576%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 17:44:52.683175]: [Epoch: 1037(69.17945296864576%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 17:44:53.972102]: [Epoch: 1037(69.17945296864576%): Data: 50.66666666666667%]:Running loss: 8.483236134052277
[2018-04-17 17:44:57.525550]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 17:44:57.635343]: ====================
[2018-04-17 17:44:57.639855]: Elapsed time since starting training: 1:49:43.036054
[2018-04-17 17:44:57.641358]: ====================
[2018-04-17 17:44:57.712047]: [Epoch: 1038(69.24616410940627%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 17:44:58.984430]: [Epoch: 1038(69.24616410940627%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 17:45:00.257815]: [Epoch: 1038(69.24616410940627%): Data: 50.66666666666667%]:Running loss: 8.483216598629951
[2018-04-17 17:45:03.812769]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:45:03.941109]: ====================
[2018-04-17 17:45:03.945120]: Elapsed time since starting training: 1:49:49.341319
[2018-04-17 17:45:03.949130]: ====================
[2018-04-17 17:45:04.020823]: [Epoch: 1039(69.31287525016678%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:45:05.335818]: [Epoch: 1039(69.31287525016678%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:45:06.610207]: [Epoch: 1039(69.31287525016678%): Data: 50.66666666666667%]:Running loss: 8.483218431472778
[2018-04-17 17:45:10.202796]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:45:10.333644]: ====================
[2018-04-17 17:45:10.338156]: Elapsed time since starting training: 1:49:55.734355
[2018-04-17 17:45:10.344172]: ====================
[2018-04-17 17:45:10.427393]: [Epoch: 1040(69.37958639092729%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:45:11.718827]: [Epoch: 1040(69.37958639092729%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:45:13.005247]: [Epoch: 1040(69.37958639092729%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:45:16.576744]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:45:16.692051]: ====================
[2018-04-17 17:45:16.696061]: Elapsed time since starting training: 1:50:02.092260
[2018-04-17 17:45:16.700574]: ====================
[2018-04-17 17:45:16.768253]: [Epoch: 1041(69.44629753168779%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:45:18.047655]: [Epoch: 1041(69.44629753168779%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:45:19.334076]: [Epoch: 1041(69.44629753168779%): Data: 50.66666666666667%]:Running loss: 8.483220309019089
[2018-04-17 17:45:22.920619]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:45:23.046955]: ====================
[2018-04-17 17:45:23.051467]: Elapsed time since starting training: 1:50:08.447165
[2018-04-17 17:45:23.056982]: ====================
[2018-04-17 17:45:23.128171]: [Epoch: 1042(69.5130086724483%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:45:24.475253]: [Epoch: 1042(69.5130086724483%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:45:25.751145]: [Epoch: 1042(69.5130086724483%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:45:29.313117]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:45:29.426418]: ====================
[2018-04-17 17:45:29.430429]: Elapsed time since starting training: 1:50:14.826628
[2018-04-17 17:45:29.434940]: ====================
[2018-04-17 17:45:29.508135]: [Epoch: 1043(69.57971981320881%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:45:30.864241]: [Epoch: 1043(69.57971981320881%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:45:32.191270]: [Epoch: 1043(69.57971981320881%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:45:35.779310]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:45:35.885593]: ====================
[2018-04-17 17:45:35.890105]: Elapsed time since starting training: 1:50:21.286304
[2018-04-17 17:45:35.894617]: ====================
[2018-04-17 17:45:35.966809]: [Epoch: 1044(69.64643095396931%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:45:37.275789]: [Epoch: 1044(69.64643095396931%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:45:38.598306]: [Epoch: 1044(69.64643095396931%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:45:42.158272]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:45:42.273077]: ====================
[2018-04-17 17:45:42.279093]: Elapsed time since starting training: 1:50:27.675292
[2018-04-17 17:45:42.283605]: ====================
[2018-04-17 17:45:42.363317]: [Epoch: 1045(69.71314209472982%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:45:43.660771]: [Epoch: 1045(69.71314209472982%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:45:44.982281]: [Epoch: 1045(69.71314209472982%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:45:48.624466]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:45:48.727741]: ====================
[2018-04-17 17:45:48.731750]: Elapsed time since starting training: 1:50:34.127949
[2018-04-17 17:45:48.736263]: ====================
[2018-04-17 17:45:48.805446]: [Epoch: 1046(69.77985323549034%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:45:50.137990]: [Epoch: 1046(69.77985323549034%): Data: 25.333333333333336%]:Running loss: 4.350371569395065
[2018-04-17 17:45:51.472037]: [Epoch: 1046(69.77985323549034%): Data: 50.66666666666667%]:Running loss: 8.483224928379059
[2018-04-17 17:45:55.146809]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:45:55.261613]: ====================
[2018-04-17 17:45:55.265624]: Elapsed time since starting training: 1:50:40.661823
[2018-04-17 17:45:55.269635]: ====================
[2018-04-17 17:45:55.341325]: [Epoch: 1047(69.84656437625083%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:45:56.694925]: [Epoch: 1047(69.84656437625083%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:45:58.003905]: [Epoch: 1047(69.84656437625083%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:46:02.147924]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:46:02.282783]: ====================
[2018-04-17 17:46:02.286793]: Elapsed time since starting training: 1:50:47.682992
[2018-04-17 17:46:02.294314]: ====================
[2018-04-17 17:46:02.363498]: [Epoch: 1048(69.91327551701134%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:46:03.700051]: [Epoch: 1048(69.91327551701134%): Data: 25.333333333333336%]:Running loss: 4.350372731685638
[2018-04-17 17:46:04.975443]: [Epoch: 1048(69.91327551701134%): Data: 50.66666666666667%]:Running loss: 8.483227223157883
[2018-04-17 17:46:08.591559]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:46:08.706865]: ====================
[2018-04-17 17:46:08.711877]: Elapsed time since starting training: 1:50:54.108076
[2018-04-17 17:46:08.716892]: ====================
[2018-04-17 17:46:08.787078]: [Epoch: 1049(69.97998665777186%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:46:10.084026]: [Epoch: 1049(69.97998665777186%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:46:11.377466]: [Epoch: 1049(69.97998665777186%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:46:14.925400]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:46:15.043212]: ====================
[2018-04-17 17:46:15.047224]: Elapsed time since starting training: 1:51:00.443423
[2018-04-17 17:46:15.051735]: ====================
[2018-04-17 17:46:15.119415]: [Epoch: 1050(70.04669779853235%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:46:16.431411]: [Epoch: 1050(70.04669779853235%): Data: 25.333333333333336%]:Running loss: 4.350373908877373
[2018-04-17 17:46:17.719335]: [Epoch: 1050(70.04669779853235%): Data: 50.66666666666667%]:Running loss: 8.483229249715805
[2018-04-17 17:46:21.310885]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:46:21.534981]: ====================
[2018-04-17 17:46:21.539994]: Elapsed time since starting training: 1:51:06.935692
[2018-04-17 17:46:21.545008]: ====================
[2018-04-17 17:46:21.612687]: [Epoch: 1051(70.11340893929287%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:46:22.926180]: [Epoch: 1051(70.11340893929287%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:46:24.231651]: [Epoch: 1051(70.11340893929287%): Data: 50.66666666666667%]:Running loss: 8.483226135373116
[2018-04-17 17:46:27.772065]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:46:27.888374]: ====================
[2018-04-17 17:46:27.893395]: Elapsed time since starting training: 1:51:13.289594
[2018-04-17 17:46:27.897900]: ====================
[2018-04-17 17:46:27.968588]: [Epoch: 1052(70.18012008005337%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:46:29.232950]: [Epoch: 1052(70.18012008005337%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:46:30.523381]: [Epoch: 1052(70.18012008005337%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:46:34.131976]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:46:34.243773]: ====================
[2018-04-17 17:46:34.247784]: Elapsed time since starting training: 1:51:19.643983
[2018-04-17 17:46:34.252296]: ====================
[2018-04-17 17:46:34.328499]: [Epoch: 1053(70.24683122081387%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:46:35.596370]: [Epoch: 1053(70.24683122081387%): Data: 25.333333333333336%]:Running loss: 4.350373610854149
[2018-04-17 17:46:36.862236]: [Epoch: 1053(70.24683122081387%): Data: 50.66666666666667%]:Running loss: 8.483228668570518
[2018-04-17 17:46:40.408666]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:46:40.519962]: ====================
[2018-04-17 17:46:40.524474]: Elapsed time since starting training: 1:51:25.920172
[2018-04-17 17:46:40.528986]: ====================
[2018-04-17 17:46:40.600175]: [Epoch: 1054(70.31354236157439%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:46:41.882585]: [Epoch: 1054(70.31354236157439%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:46:43.151459]: [Epoch: 1054(70.31354236157439%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:46:46.728971]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:46:46.854806]: ====================
[2018-04-17 17:46:46.859318]: Elapsed time since starting training: 1:51:32.255016
[2018-04-17 17:46:46.863830]: ====================
[2018-04-17 17:46:46.934518]: [Epoch: 1055(70.3802535023349%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:46:48.251019]: [Epoch: 1055(70.3802535023349%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:46:49.517386]: [Epoch: 1055(70.3802535023349%): Data: 50.66666666666667%]:Running loss: 8.4832284450531
[2018-04-17 17:46:53.052285]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:46:53.164584]: ====================
[2018-04-17 17:46:53.168595]: Elapsed time since starting training: 1:51:38.564794
[2018-04-17 17:46:53.173608]: ====================
[2018-04-17 17:46:53.247303]: [Epoch: 1056(70.4469646430954%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:46:54.570823]: [Epoch: 1056(70.4469646430954%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:46:55.884315]: [Epoch: 1056(70.4469646430954%): Data: 50.66666666666667%]:Running loss: 8.483229652047157
[2018-04-17 17:46:59.442777]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:46:59.559087]: ====================
[2018-04-17 17:46:59.563599]: Elapsed time since starting training: 1:51:44.959798
[2018-04-17 17:46:59.567610]: ====================
[2018-04-17 17:46:59.637295]: [Epoch: 1057(70.5136757838559%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:47:00.968333]: [Epoch: 1057(70.5136757838559%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:47:02.260268]: [Epoch: 1057(70.5136757838559%): Data: 50.66666666666667%]:Running loss: 8.483230218291283
[2018-04-17 17:47:05.858337]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:47:05.971638]: ====================
[2018-04-17 17:47:05.975648]: Elapsed time since starting training: 1:51:51.371847
[2018-04-17 17:47:05.981664]: ====================
[2018-04-17 17:47:06.063883]: [Epoch: 1058(70.5803869246164%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:47:07.348298]: [Epoch: 1058(70.5803869246164%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:47:08.667306]: [Epoch: 1058(70.5803869246164%): Data: 50.66666666666667%]:Running loss: 8.483231216669083
[2018-04-17 17:47:12.321020]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:47:12.435325]: ====================
[2018-04-17 17:47:12.440338]: Elapsed time since starting training: 1:51:57.836537
[2018-04-17 17:47:12.445352]: ====================
[2018-04-17 17:47:12.518044]: [Epoch: 1059(70.64709806537692%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:47:13.838556]: [Epoch: 1059(70.64709806537692%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:47:15.115952]: [Epoch: 1059(70.64709806537692%): Data: 50.66666666666667%]:Running loss: 8.483231216669083
[2018-04-17 17:47:18.665390]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:47:18.778190]: ====================
[2018-04-17 17:47:18.783203]: Elapsed time since starting training: 1:52:04.179402
[2018-04-17 17:47:18.789721]: ====================
[2018-04-17 17:47:18.879459]: [Epoch: 1060(70.71380920613743%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:47:20.177410]: [Epoch: 1060(70.71380920613743%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:47:21.450796]: [Epoch: 1060(70.71380920613743%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:47:24.995221]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:47:25.110026]: ====================
[2018-04-17 17:47:25.115039]: Elapsed time since starting training: 1:52:10.511238
[2018-04-17 17:47:25.119050]: ====================
[2018-04-17 17:47:25.189237]: [Epoch: 1061(70.78052034689793%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:47:26.454100]: [Epoch: 1061(70.78052034689793%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:47:27.716456]: [Epoch: 1061(70.78052034689793%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:47:31.230802]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:47:31.342600]: ====================
[2018-04-17 17:47:31.348614]: Elapsed time since starting training: 1:52:16.744813
[2018-04-17 17:47:31.352626]: ====================
[2018-04-17 17:47:31.421308]: [Epoch: 1062(70.84723148765843%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:47:32.698203]: [Epoch: 1062(70.84723148765843%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:47:33.964069]: [Epoch: 1062(70.84723148765843%): Data: 50.66666666666667%]:Running loss: 8.48322956264019
[2018-04-17 17:47:37.480420]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:47:37.594223]: ====================
[2018-04-17 17:47:37.599235]: Elapsed time since starting training: 1:52:22.995434
[2018-04-17 17:47:37.603748]: ====================
[2018-04-17 17:47:37.676440]: [Epoch: 1063(70.91394262841895%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:47:38.929272]: [Epoch: 1063(70.91394262841895%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:47:40.194636]: [Epoch: 1063(70.91394262841895%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:47:43.734549]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:47:43.844341]: ====================
[2018-04-17 17:47:43.849354]: Elapsed time since starting training: 1:52:29.245051
[2018-04-17 17:47:43.853866]: ====================
[2018-04-17 17:47:43.923551]: [Epoch: 1064(70.98065376917945%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:47:45.207466]: [Epoch: 1064(70.98065376917945%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:47:46.470824]: [Epoch: 1064(70.98065376917945%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:47:49.994694]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:47:50.109500]: ====================
[2018-04-17 17:47:50.114513]: Elapsed time since starting training: 1:52:35.510712
[2018-04-17 17:47:50.120529]: ====================
[2018-04-17 17:47:50.192220]: [Epoch: 1065(71.04736490993996%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:47:51.483654]: [Epoch: 1065(71.04736490993996%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:47:52.793636]: [Epoch: 1065(71.04736490993996%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:47:56.338562]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:47:56.450862]: ====================
[2018-04-17 17:47:56.454872]: Elapsed time since starting training: 1:52:41.851071
[2018-04-17 17:47:56.459384]: ====================
[2018-04-17 17:47:56.527566]: [Epoch: 1066(71.11407605070048%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:47:57.831032]: [Epoch: 1066(71.11407605070048%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:47:59.128982]: [Epoch: 1066(71.11407605070048%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:48:02.721535]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:48:02.832831]: ====================
[2018-04-17 17:48:02.836842]: Elapsed time since starting training: 1:52:48.233041
[2018-04-17 17:48:02.841354]: ====================
[2018-04-17 17:48:02.913546]: [Epoch: 1067(71.18078719146096%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:48:04.190441]: [Epoch: 1067(71.18078719146096%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:48:05.502429]: [Epoch: 1067(71.18078719146096%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:48:09.073926]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:48:09.190235]: ====================
[2018-04-17 17:48:09.194747]: Elapsed time since starting training: 1:52:54.590946
[2018-04-17 17:48:09.199259]: ====================
[2018-04-17 17:48:09.270448]: [Epoch: 1068(71.24749833222148%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:48:10.570405]: [Epoch: 1068(71.24749833222148%): Data: 25.333333333333336%]:Running loss: 4.350371181964874
[2018-04-17 17:48:11.837273]: [Epoch: 1068(71.24749833222148%): Data: 50.66666666666667%]:Running loss: 8.483223974704742
[2018-04-17 17:48:15.393229]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:48:15.520067]: ====================
[2018-04-17 17:48:15.524578]: Elapsed time since starting training: 1:53:00.920276
[2018-04-17 17:48:15.529090]: ====================
[2018-04-17 17:48:15.598274]: [Epoch: 1069(71.31420947298199%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:48:16.900766]: [Epoch: 1069(71.31420947298199%): Data: 25.333333333333336%]:Running loss: 4.35037162899971
[2018-04-17 17:48:18.173651]: [Epoch: 1069(71.31420947298199%): Data: 50.66666666666667%]:Running loss: 8.483225271105766
[2018-04-17 17:48:21.688999]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:48:21.797788]: ====================
[2018-04-17 17:48:21.802300]: Elapsed time since starting training: 1:53:07.198499
[2018-04-17 17:48:21.806310]: ====================
[2018-04-17 17:48:21.881511]: [Epoch: 1070(71.38092061374249%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:48:23.151387]: [Epoch: 1070(71.38092061374249%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:48:24.438811]: [Epoch: 1070(71.38092061374249%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 17:48:28.068963]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:48:28.178756]: ====================
[2018-04-17 17:48:28.183267]: Elapsed time since starting training: 1:53:13.579466
[2018-04-17 17:48:28.188280]: ====================
[2018-04-17 17:48:28.268506]: [Epoch: 1071(71.447631754503%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:48:29.579981]: [Epoch: 1071(71.447631754503%): Data: 25.333333333333336%]:Running loss: 4.350370526313782
[2018-04-17 17:48:30.922049]: [Epoch: 1071(71.447631754503%): Data: 50.66666666666667%]:Running loss: 8.483223035931587
[2018-04-17 17:48:34.544180]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:48:34.646452]: ====================
[2018-04-17 17:48:34.650964]: Elapsed time since starting training: 1:53:20.047163
[2018-04-17 17:48:34.656980]: ====================
[2018-04-17 17:48:34.726164]: [Epoch: 1072(71.51434289526351%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:48:36.066227]: [Epoch: 1072(71.51434289526351%): Data: 25.333333333333336%]:Running loss: 4.350371330976486
[2018-04-17 17:48:37.397276]: [Epoch: 1072(71.51434289526351%): Data: 50.66666666666667%]:Running loss: 8.483224123716354
[2018-04-17 17:48:40.980294]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:48:41.087579]: ====================
[2018-04-17 17:48:41.092091]: Elapsed time since starting training: 1:53:26.488290
[2018-04-17 17:48:41.096603]: ====================
[2018-04-17 17:48:41.171302]: [Epoch: 1073(71.58105403602401%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:48:42.491813]: [Epoch: 1073(71.58105403602401%): Data: 25.333333333333336%]:Running loss: 4.350371599197388
[2018-04-17 17:48:43.817337]: [Epoch: 1073(71.58105403602401%): Data: 50.66666666666667%]:Running loss: 8.483224958181381
[2018-04-17 17:48:47.394850]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:48:47.497624]: ====================
[2018-04-17 17:48:47.502135]: Elapsed time since starting training: 1:53:32.898334
[2018-04-17 17:48:47.507149]: ====================
[2018-04-17 17:48:47.576834]: [Epoch: 1074(71.64776517678453%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:48:48.904866]: [Epoch: 1074(71.64776517678453%): Data: 25.333333333333336%]:Running loss: 4.3503724336624146
[2018-04-17 17:48:50.234400]: [Epoch: 1074(71.64776517678453%): Data: 50.66666666666667%]:Running loss: 8.483226358890533
[2018-04-17 17:48:53.882605]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:48:53.989890]: ====================
[2018-04-17 17:48:53.994402]: Elapsed time since starting training: 1:53:39.390601
[2018-04-17 17:48:53.998914]: ====================
[2018-04-17 17:48:54.075619]: [Epoch: 1075(71.71447631754504%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:48:55.414678]: [Epoch: 1075(71.71447631754504%): Data: 25.333333333333336%]:Running loss: 4.350372686982155
[2018-04-17 17:48:56.762262]: [Epoch: 1075(71.71447631754504%): Data: 50.66666666666667%]:Running loss: 8.483226895332336
[2018-04-17 17:49:00.431017]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:49:00.539305]: ====================
[2018-04-17 17:49:00.545822]: Elapsed time since starting training: 1:53:45.942021
[2018-04-17 17:49:00.550335]: ====================
[2018-04-17 17:49:00.616510]: [Epoch: 1076(71.78118745830554%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:49:01.955571]: [Epoch: 1076(71.78118745830554%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:49:03.286610]: [Epoch: 1076(71.78118745830554%): Data: 50.66666666666667%]:Running loss: 8.483227699995041
[2018-04-17 17:49:06.855098]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:49:06.962885]: ====================
[2018-04-17 17:49:06.967397]: Elapsed time since starting training: 1:53:52.363596
[2018-04-17 17:49:06.971408]: ====================
[2018-04-17 17:49:07.042597]: [Epoch: 1077(71.84789859906604%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:49:08.358596]: [Epoch: 1077(71.84789859906604%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:49:09.670084]: [Epoch: 1077(71.84789859906604%): Data: 50.66666666666667%]:Running loss: 8.48322905600071
[2018-04-17 17:49:13.237068]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:49:13.345356]: ====================
[2018-04-17 17:49:13.349868]: Elapsed time since starting training: 1:53:58.746067
[2018-04-17 17:49:13.353879]: ====================
[2018-04-17 17:49:13.420556]: [Epoch: 1078(71.91460973982655%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:49:14.756609]: [Epoch: 1078(71.91460973982655%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:49:16.096673]: [Epoch: 1078(71.91460973982655%): Data: 50.66666666666667%]:Running loss: 8.483229637145996
[2018-04-17 17:49:19.638590]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:49:19.744872]: ====================
[2018-04-17 17:49:19.749885]: Elapsed time since starting training: 1:54:05.145584
[2018-04-17 17:49:19.754398]: ====================
[2018-04-17 17:49:19.831102]: [Epoch: 1079(71.98132088058706%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:49:21.145596]: [Epoch: 1079(71.98132088058706%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:49:22.472124]: [Epoch: 1079(71.98132088058706%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 17:49:26.091248]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:49:26.194522]: ====================
[2018-04-17 17:49:26.199535]: Elapsed time since starting training: 1:54:11.595233
[2018-04-17 17:49:26.200538]: ====================
[2018-04-17 17:49:26.268218]: [Epoch: 1080(72.04803202134757%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:49:27.606778]: [Epoch: 1080(72.04803202134757%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:49:28.940323]: [Epoch: 1080(72.04803202134757%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:49:32.543905]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:49:32.657708]: ====================
[2018-04-17 17:49:32.662220]: Elapsed time since starting training: 1:54:18.057918
[2018-04-17 17:49:32.666230]: ====================
[2018-04-17 17:49:32.741430]: [Epoch: 1081(72.11474316210807%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:49:34.062443]: [Epoch: 1081(72.11474316210807%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:49:35.407519]: [Epoch: 1081(72.11474316210807%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 17:49:39.015112]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:49:39.122898]: ====================
[2018-04-17 17:49:39.127411]: Elapsed time since starting training: 1:54:24.523108
[2018-04-17 17:49:39.131421]: ====================
[2018-04-17 17:49:39.198600]: [Epoch: 1082(72.18145430286857%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:49:40.540668]: [Epoch: 1082(72.18145430286857%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:49:41.876224]: [Epoch: 1082(72.18145430286857%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:49:45.468777]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 17:49:45.575059]: ====================
[2018-04-17 17:49:45.579070]: Elapsed time since starting training: 1:54:30.975269
[2018-04-17 17:49:45.583081]: ====================
[2018-04-17 17:49:45.657278]: [Epoch: 1083(72.24816544362909%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 17:49:46.997843]: [Epoch: 1083(72.24816544362909%): Data: 25.333333333333336%]:Running loss: 4.350376725196838
[2018-04-17 17:49:48.327378]: [Epoch: 1083(72.24816544362909%): Data: 50.66666666666667%]:Running loss: 8.483228892087936
[2018-04-17 17:49:51.902885]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:49:52.006661]: ====================
[2018-04-17 17:49:52.011173]: Elapsed time since starting training: 1:54:37.407372
[2018-04-17 17:49:52.015183]: ====================
[2018-04-17 17:49:52.084869]: [Epoch: 1084(72.3148765843896%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:49:53.430447]: [Epoch: 1084(72.3148765843896%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:49:54.768504]: [Epoch: 1084(72.3148765843896%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:49:58.390636]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:49:58.499426]: ====================
[2018-04-17 17:49:58.504438]: Elapsed time since starting training: 1:54:43.900637
[2018-04-17 17:49:58.508951]: ====================
[2018-04-17 17:49:58.589164]: [Epoch: 1085(72.3815877251501%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:49:59.917696]: [Epoch: 1085(72.3815877251501%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:50:01.256255]: [Epoch: 1085(72.3815877251501%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:50:04.855827]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:50:04.960104]: ====================
[2018-04-17 17:50:04.964616]: Elapsed time since starting training: 1:54:50.360314
[2018-04-17 17:50:04.969128]: ====================
[2018-04-17 17:50:05.038813]: [Epoch: 1086(72.44829886591062%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:50:06.379879]: [Epoch: 1086(72.44829886591062%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:50:07.710919]: [Epoch: 1086(72.44829886591062%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:50:11.329540]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:50:11.434820]: ====================
[2018-04-17 17:50:11.439332]: Elapsed time since starting training: 1:54:56.835531
[2018-04-17 17:50:11.443343]: ====================
[2018-04-17 17:50:11.516036]: [Epoch: 1087(72.5150100066711%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:50:12.866628]: [Epoch: 1087(72.5150100066711%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:50:14.208696]: [Epoch: 1087(72.5150100066711%): Data: 50.66666666666667%]:Running loss: 8.483219012618065
[2018-04-17 17:50:17.848875]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:50:17.951648]: ====================
[2018-04-17 17:50:17.955659]: Elapsed time since starting training: 1:55:03.351858
[2018-04-17 17:50:17.959670]: ====================
[2018-04-17 17:50:18.025345]: [Epoch: 1088(72.58172114743162%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:50:19.368415]: [Epoch: 1088(72.58172114743162%): Data: 25.333333333333336%]:Running loss: 4.350368648767471
[2018-04-17 17:50:20.705972]: [Epoch: 1088(72.58172114743162%): Data: 50.66666666666667%]:Running loss: 8.483218893408775
[2018-04-17 17:50:24.329607]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:50:24.437895]: ====================
[2018-04-17 17:50:24.442407]: Elapsed time since starting training: 1:55:09.838606
[2018-04-17 17:50:24.447421]: ====================
[2018-04-17 17:50:24.518609]: [Epoch: 1089(72.64843228819214%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:50:25.858673]: [Epoch: 1089(72.64843228819214%): Data: 25.333333333333336%]:Running loss: 4.350368931889534
[2018-04-17 17:50:27.200742]: [Epoch: 1089(72.64843228819214%): Data: 50.66666666666667%]:Running loss: 8.4832194596529
[2018-04-17 17:50:30.854456]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:50:30.956729]: ====================
[2018-04-17 17:50:30.960739]: Elapsed time since starting training: 1:55:16.356938
[2018-04-17 17:50:30.965252]: ====================
[2018-04-17 17:50:31.031428]: [Epoch: 1090(72.71514342895263%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:50:32.388536]: [Epoch: 1090(72.71514342895263%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:50:33.743639]: [Epoch: 1090(72.71514342895263%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:50:37.374292]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:50:37.485088]: ====================
[2018-04-17 17:50:37.490101]: Elapsed time since starting training: 1:55:22.886300
[2018-04-17 17:50:37.494112]: ====================
[2018-04-17 17:50:37.565301]: [Epoch: 1091(72.78185456971315%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:50:38.895839]: [Epoch: 1091(72.78185456971315%): Data: 25.333333333333336%]:Running loss: 4.35037037730217
[2018-04-17 17:50:40.236403]: [Epoch: 1091(72.78185456971315%): Data: 50.66666666666667%]:Running loss: 8.48322232067585
[2018-04-17 17:50:43.821947]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:50:43.927718]: ====================
[2018-04-17 17:50:43.932230]: Elapsed time since starting training: 1:55:29.328429
[2018-04-17 17:50:43.936743]: ====================
[2018-04-17 17:50:44.010438]: [Epoch: 1092(72.84856571047365%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:50:45.339973]: [Epoch: 1092(72.84856571047365%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:50:46.685551]: [Epoch: 1092(72.84856571047365%): Data: 50.66666666666667%]:Running loss: 8.483222588896751
[2018-04-17 17:50:50.279107]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:50:50.384888]: ====================
[2018-04-17 17:50:50.389401]: Elapsed time since starting training: 1:55:35.785600
[2018-04-17 17:50:50.390404]: ====================
[2018-04-17 17:50:50.464600]: [Epoch: 1093(72.91527685123415%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:50:51.772076]: [Epoch: 1093(72.91527685123415%): Data: 25.333333333333336%]:Running loss: 4.3503709733486176
[2018-04-17 17:50:53.075041]: [Epoch: 1093(72.91527685123415%): Data: 50.66666666666667%]:Running loss: 8.483223482966423
[2018-04-17 17:50:56.654559]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:50:56.759338]: ====================
[2018-04-17 17:50:56.764351]: Elapsed time since starting training: 1:55:42.160550
[2018-04-17 17:50:56.768863]: ====================
[2018-04-17 17:50:56.837545]: [Epoch: 1094(72.98198799199467%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:50:58.176105]: [Epoch: 1094(72.98198799199467%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:50:59.498120]: [Epoch: 1094(72.98198799199467%): Data: 50.66666666666667%]:Running loss: 8.483224123716354
[2018-04-17 17:51:03.105211]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:51:03.214001]: ====================
[2018-04-17 17:51:03.218514]: Elapsed time since starting training: 1:55:48.614211
[2018-04-17 17:51:03.223024]: ====================
[2018-04-17 17:51:03.293712]: [Epoch: 1095(73.04869913275517%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:51:04.620240]: [Epoch: 1095(73.04869913275517%): Data: 25.333333333333336%]:Running loss: 4.3503721952438354
[2018-04-17 17:51:05.966319]: [Epoch: 1095(73.04869913275517%): Data: 50.66666666666667%]:Running loss: 8.483225792646408
[2018-04-17 17:51:09.583939]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:51:09.795000]: ====================
[2018-04-17 17:51:09.799512]: Elapsed time since starting training: 1:55:55.195209
[2018-04-17 17:51:09.804024]: ====================
[2018-04-17 17:51:09.876717]: [Epoch: 1096(73.11541027351568%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:51:11.221793]: [Epoch: 1096(73.11541027351568%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:51:12.539797]: [Epoch: 1096(73.11541027351568%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:51:16.101268]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:51:16.207551]: ====================
[2018-04-17 17:51:16.212563]: Elapsed time since starting training: 1:56:01.608762
[2018-04-17 17:51:16.217076]: ====================
[2018-04-17 17:51:16.292777]: [Epoch: 1097(73.18212141427618%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:51:17.594739]: [Epoch: 1097(73.18212141427618%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:51:18.903721]: [Epoch: 1097(73.18212141427618%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:51:22.461680]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:51:22.564454]: ====================
[2018-04-17 17:51:22.569467]: Elapsed time since starting training: 1:56:07.965164
[2018-04-17 17:51:22.573978]: ====================
[2018-04-17 17:51:22.645669]: [Epoch: 1098(73.24883255503669%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:51:23.973199]: [Epoch: 1098(73.24883255503669%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:51:25.288196]: [Epoch: 1098(73.24883255503669%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:51:28.889270]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:51:28.998562]: ====================
[2018-04-17 17:51:29.002572]: Elapsed time since starting training: 1:56:14.398771
[2018-04-17 17:51:29.007084]: ====================
[2018-04-17 17:51:29.077271]: [Epoch: 1099(73.3155436957972%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:51:30.402795]: [Epoch: 1099(73.3155436957972%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:51:31.722805]: [Epoch: 1099(73.3155436957972%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:51:35.368499]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:51:35.485310]: ====================
[2018-04-17 17:51:35.489822]: Elapsed time since starting training: 1:56:20.885520
[2018-04-17 17:51:35.494834]: ====================
[2018-04-17 17:51:35.569534]: [Epoch: 1100(73.3822548365577%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:51:36.958226]: [Epoch: 1100(73.3822548365577%): Data: 25.333333333333336%]:Running loss: 4.35037387907505
[2018-04-17 17:51:38.305308]: [Epoch: 1100(73.3822548365577%): Data: 50.66666666666667%]:Running loss: 8.48322893679142
[2018-04-17 17:51:41.940975]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:51:42.047759]: ====================
[2018-04-17 17:51:42.052772]: Elapsed time since starting training: 1:56:27.448470
[2018-04-17 17:51:42.056783]: ====================
[2018-04-17 17:51:42.130980]: [Epoch: 1101(73.44896597731821%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:51:43.475555]: [Epoch: 1101(73.44896597731821%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:51:44.823142]: [Epoch: 1101(73.44896597731821%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:51:48.479862]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:51:48.596171]: ====================
[2018-04-17 17:51:48.600684]: Elapsed time since starting training: 1:56:33.996381
[2018-04-17 17:51:48.604694]: ====================
[2018-04-17 17:51:48.673878]: [Epoch: 1102(73.51567711807871%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:51:50.018955]: [Epoch: 1102(73.51567711807871%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:51:51.360020]: [Epoch: 1102(73.51567711807871%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:51:54.961096]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 17:51:55.068381]: ====================
[2018-04-17 17:51:55.073394]: Elapsed time since starting training: 1:56:40.469092
[2018-04-17 17:51:55.077906]: ====================
[2018-04-17 17:51:55.151602]: [Epoch: 1103(73.58238825883923%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 17:51:56.490161]: [Epoch: 1103(73.58238825883923%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 17:51:57.815686]: [Epoch: 1103(73.58238825883923%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 17:52:01.411246]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 17:52:01.514521]: ====================
[2018-04-17 17:52:01.519033]: Elapsed time since starting training: 1:56:46.914731
[2018-04-17 17:52:01.523546]: ====================
[2018-04-17 17:52:01.596740]: [Epoch: 1104(73.64909939959973%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 17:52:02.928781]: [Epoch: 1104(73.64909939959973%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 17:52:04.242786]: [Epoch: 1104(73.64909939959973%): Data: 50.66666666666667%]:Running loss: 8.48322831094265
[2018-04-17 17:52:07.753611]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:52:07.857888]: ====================
[2018-04-17 17:52:07.862401]: Elapsed time since starting training: 1:56:53.258098
[2018-04-17 17:52:07.865909]: ====================
[2018-04-17 17:52:07.935093]: [Epoch: 1105(73.71581054036024%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:52:09.236553]: [Epoch: 1105(73.71581054036024%): Data: 25.333333333333336%]:Running loss: 4.350373297929764
[2018-04-17 17:52:10.528990]: [Epoch: 1105(73.71581054036024%): Data: 50.66666666666667%]:Running loss: 8.483220994472504
[2018-04-17 17:52:14.034311]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 17:52:14.136082]: ====================
[2018-04-17 17:52:14.140594]: Elapsed time since starting training: 1:56:59.536793
[2018-04-17 17:52:14.145106]: ====================
[2018-04-17 17:52:14.216796]: [Epoch: 1106(73.78252168112076%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 17:52:15.530289]: [Epoch: 1106(73.78252168112076%): Data: 25.333333333333336%]:Running loss: 4.35036689043045
[2018-04-17 17:52:16.863333]: [Epoch: 1106(73.78252168112076%): Data: 50.66666666666667%]:Running loss: 8.483220338821411
[2018-04-17 17:52:20.471427]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 17:52:20.575705]: ====================
[2018-04-17 17:52:20.580217]: Elapsed time since starting training: 1:57:05.976416
[2018-04-17 17:52:20.585232]: ====================
[2018-04-17 17:52:20.658926]: [Epoch: 1107(73.84923282188124%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 17:52:22.002999]: [Epoch: 1107(73.84923282188124%): Data: 25.333333333333336%]:Running loss: 4.350370436906815
[2018-04-17 17:52:23.341559]: [Epoch: 1107(73.84923282188124%): Data: 50.66666666666667%]:Running loss: 8.483228892087936
[2018-04-17 17:52:26.920576]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:52:27.020843]: ====================
[2018-04-17 17:52:27.024853]: Elapsed time since starting training: 1:57:12.421052
[2018-04-17 17:52:27.029365]: ====================
[2018-04-17 17:52:27.104064]: [Epoch: 1108(73.91594396264176%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:52:28.423074]: [Epoch: 1108(73.91594396264176%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:52:29.741577]: [Epoch: 1108(73.91594396264176%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:52:33.267959]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:52:33.373740]: ====================
[2018-04-17 17:52:33.378252]: Elapsed time since starting training: 1:57:18.774451
[2018-04-17 17:52:33.383265]: ====================
[2018-04-17 17:52:33.459969]: [Epoch: 1109(73.98265510340227%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:52:34.782486]: [Epoch: 1109(73.98265510340227%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:52:36.076426]: [Epoch: 1109(73.98265510340227%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:52:39.589773]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:52:39.688034]: ====================
[2018-04-17 17:52:39.693047]: Elapsed time since starting training: 1:57:25.089246
[2018-04-17 17:52:39.697058]: ====================
[2018-04-17 17:52:39.768749]: [Epoch: 1110(74.04936624416277%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:52:41.080745]: [Epoch: 1110(74.04936624416277%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:52:42.391221]: [Epoch: 1110(74.04936624416277%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:52:45.907572]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:52:46.008841]: ====================
[2018-04-17 17:52:46.013353]: Elapsed time since starting training: 1:57:31.409552
[2018-04-17 17:52:46.017364]: ====================
[2018-04-17 17:52:46.088553]: [Epoch: 1111(74.11607738492329%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:52:47.393523]: [Epoch: 1111(74.11607738492329%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:52:48.705511]: [Epoch: 1111(74.11607738492329%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:52:52.253445]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 17:52:52.354715]: ====================
[2018-04-17 17:52:52.358725]: Elapsed time since starting training: 1:57:37.754924
[2018-04-17 17:52:52.363237]: ====================
[2018-04-17 17:52:52.434426]: [Epoch: 1112(74.18278852568379%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 17:52:53.733882]: [Epoch: 1112(74.18278852568379%): Data: 25.333333333333336%]:Running loss: 4.350369617342949
[2018-04-17 17:52:55.045369]: [Epoch: 1112(74.18278852568379%): Data: 50.66666666666667%]:Running loss: 8.483220979571342
[2018-04-17 17:52:58.602327]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:52:58.709110]: ====================
[2018-04-17 17:52:58.713122]: Elapsed time since starting training: 1:57:44.109321
[2018-04-17 17:52:58.717132]: ====================
[2018-04-17 17:52:58.787319]: [Epoch: 1113(74.2494996664443%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:53:00.107829]: [Epoch: 1113(74.2494996664443%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:53:01.434357]: [Epoch: 1113(74.2494996664443%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:53:05.065512]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:53:05.177811]: ====================
[2018-04-17 17:53:05.183827]: Elapsed time since starting training: 1:57:50.580026
[2018-04-17 17:53:05.187837]: ====================
[2018-04-17 17:53:05.253512]: [Epoch: 1114(74.31621080720481%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:53:06.620648]: [Epoch: 1114(74.31621080720481%): Data: 25.333333333333336%]:Running loss: 4.350370794534683
[2018-04-17 17:53:08.171772]: [Epoch: 1114(74.31621080720481%): Data: 50.66666666666667%]:Running loss: 8.483223304152489
[2018-04-17 17:53:11.863087]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:53:11.983407]: ====================
[2018-04-17 17:53:11.988420]: Elapsed time since starting training: 1:57:57.384118
[2018-04-17 17:53:11.992932]: ====================
[2018-04-17 17:53:12.060111]: [Epoch: 1115(74.38292194796531%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:53:13.350041]: [Epoch: 1115(74.38292194796531%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:53:14.655010]: [Epoch: 1115(74.38292194796531%): Data: 50.66666666666667%]:Running loss: 8.483224719762802
[2018-04-17 17:53:18.179382]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:53:18.316246]: ====================
[2018-04-17 17:53:18.321259]: Elapsed time since starting training: 1:58:03.716957
[2018-04-17 17:53:18.326273]: ====================
[2018-04-17 17:53:18.400972]: [Epoch: 1116(74.44963308872582%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:53:19.686389]: [Epoch: 1116(74.44963308872582%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:53:20.962281]: [Epoch: 1116(74.44963308872582%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:53:24.542301]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:53:24.669640]: ====================
[2018-04-17 17:53:24.674152]: Elapsed time since starting training: 1:58:10.070351
[2018-04-17 17:53:24.679165]: ====================
[2018-04-17 17:53:24.751363]: [Epoch: 1117(74.51634422948632%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:53:26.031260]: [Epoch: 1117(74.51634422948632%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:53:27.297126]: [Epoch: 1117(74.51634422948632%): Data: 50.66666666666667%]:Running loss: 8.483225986361504
[2018-04-17 17:53:30.881657]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:53:30.999471]: ====================
[2018-04-17 17:53:31.003983]: Elapsed time since starting training: 1:58:16.399681
[2018-04-17 17:53:31.008495]: ====================
[2018-04-17 17:53:31.075171]: [Epoch: 1118(74.58305537024683%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:53:32.371619]: [Epoch: 1118(74.58305537024683%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:53:33.670573]: [Epoch: 1118(74.58305537024683%): Data: 50.66666666666667%]:Running loss: 8.483226507902145
[2018-04-17 17:53:37.264128]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:53:37.383948]: ====================
[2018-04-17 17:53:37.388458]: Elapsed time since starting training: 1:58:22.784657
[2018-04-17 17:53:37.392971]: ====================
[2018-04-17 17:53:37.461654]: [Epoch: 1119(74.64976651100734%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:53:38.716490]: [Epoch: 1119(74.64976651100734%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:53:39.980852]: [Epoch: 1119(74.64976651100734%): Data: 50.66666666666667%]:Running loss: 8.48322831094265
[2018-04-17 17:53:43.496199]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:53:43.615015]: ====================
[2018-04-17 17:53:43.619527]: Elapsed time since starting training: 1:58:29.015726
[2018-04-17 17:53:43.624541]: ====================
[2018-04-17 17:53:43.693725]: [Epoch: 1120(74.71647765176785%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:53:44.948060]: [Epoch: 1120(74.71647765176785%): Data: 25.333333333333336%]:Running loss: 4.350372701883316
[2018-04-17 17:53:46.200390]: [Epoch: 1120(74.71647765176785%): Data: 50.66666666666667%]:Running loss: 8.483225494623184
[2018-04-17 17:53:49.774901]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:53:49.894721]: ====================
[2018-04-17 17:53:49.899232]: Elapsed time since starting training: 1:58:35.295431
[2018-04-17 17:53:49.903744]: ====================
[2018-04-17 17:53:49.973931]: [Epoch: 1121(74.78318879252835%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:53:51.250325]: [Epoch: 1121(74.78318879252835%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:53:52.514687]: [Epoch: 1121(74.78318879252835%): Data: 50.66666666666667%]:Running loss: 8.48322631418705
[2018-04-17 17:53:56.087191]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:53:56.217539]: ====================
[2018-04-17 17:53:56.222050]: Elapsed time since starting training: 1:58:41.617748
[2018-04-17 17:53:56.226061]: ====================
[2018-04-17 17:53:56.297256]: [Epoch: 1122(74.84989993328885%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:53:57.568631]: [Epoch: 1122(74.84989993328885%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:53:58.862069]: [Epoch: 1122(74.84989993328885%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 17:54:02.399476]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:54:02.523806]: ====================
[2018-04-17 17:54:02.528318]: Elapsed time since starting training: 1:58:47.924517
[2018-04-17 17:54:02.532830]: ====================
[2018-04-17 17:54:02.601513]: [Epoch: 1123(74.91661107404937%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:54:03.867379]: [Epoch: 1123(74.91661107404937%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:54:05.210951]: [Epoch: 1123(74.91661107404937%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:54:08.826565]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:54:08.948891]: ====================
[2018-04-17 17:54:08.954405]: Elapsed time since starting training: 1:58:54.350103
[2018-04-17 17:54:08.958415]: ====================
[2018-04-17 17:54:09.036625]: [Epoch: 1124(74.98332221480987%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:54:10.308004]: [Epoch: 1124(74.98332221480987%): Data: 25.333333333333336%]:Running loss: 4.350373387336731
[2018-04-17 17:54:11.582894]: [Epoch: 1124(74.98332221480987%): Data: 50.66666666666667%]:Running loss: 8.483227595686913
[2018-04-17 17:54:15.126317]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:54:15.245634]: ====================
[2018-04-17 17:54:15.250146]: Elapsed time since starting training: 1:59:00.646345
[2018-04-17 17:54:15.254156]: ====================
[2018-04-17 17:54:15.324343]: [Epoch: 1125(75.05003335557038%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:54:16.612267]: [Epoch: 1125(75.05003335557038%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 17:54:17.881643]: [Epoch: 1125(75.05003335557038%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 17:54:21.417043]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:54:21.529843]: ====================
[2018-04-17 17:54:21.534355]: Elapsed time since starting training: 1:59:06.930053
[2018-04-17 17:54:21.538366]: ====================
[2018-04-17 17:54:21.612062]: [Epoch: 1126(75.1167444963309%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:54:22.881437]: [Epoch: 1126(75.1167444963309%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:54:24.158332]: [Epoch: 1126(75.1167444963309%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:54:27.735348]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:54:27.868703]: ====================
[2018-04-17 17:54:27.873215]: Elapsed time since starting training: 1:59:13.268912
[2018-04-17 17:54:27.877225]: ====================
[2018-04-17 17:54:27.945406]: [Epoch: 1127(75.18345563709138%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:54:29.230324]: [Epoch: 1127(75.18345563709138%): Data: 25.333333333333336%]:Running loss: 4.350374311208725
[2018-04-17 17:54:30.498696]: [Epoch: 1127(75.18345563709138%): Data: 50.66666666666667%]:Running loss: 8.483230218291283
[2018-04-17 17:54:33.983462]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:54:34.101776]: ====================
[2018-04-17 17:54:34.106288]: Elapsed time since starting training: 1:59:19.501986
[2018-04-17 17:54:34.110299]: ====================
[2018-04-17 17:54:34.179984]: [Epoch: 1128(75.2501667778519%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:54:35.459386]: [Epoch: 1128(75.2501667778519%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:54:36.735279]: [Epoch: 1128(75.2501667778519%): Data: 50.66666666666667%]:Running loss: 8.483230754733086
[2018-04-17 17:54:40.271181]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:54:40.392002]: ====================
[2018-04-17 17:54:40.397517]: Elapsed time since starting training: 1:59:25.793716
[2018-04-17 17:54:40.402530]: ====================
[2018-04-17 17:54:40.470210]: [Epoch: 1129(75.31687791861242%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:54:41.844364]: [Epoch: 1129(75.31687791861242%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:54:43.208992]: [Epoch: 1129(75.31687791861242%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 17:54:46.843657]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:54:46.985033]: ====================
[2018-04-17 17:54:46.989545]: Elapsed time since starting training: 1:59:32.385243
[2018-04-17 17:54:46.993556]: ====================
[2018-04-17 17:54:47.062740]: [Epoch: 1130(75.38358905937291%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:54:48.350163]: [Epoch: 1130(75.38358905937291%): Data: 25.333333333333336%]:Running loss: 4.350367575883865
[2018-04-17 17:54:49.637084]: [Epoch: 1130(75.38358905937291%): Data: 50.66666666666667%]:Running loss: 8.483216971158981
[2018-04-17 17:54:53.227631]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:54:53.354971]: ====================
[2018-04-17 17:54:53.359482]: Elapsed time since starting training: 1:59:38.755681
[2018-04-17 17:54:53.363994]: ====================
[2018-04-17 17:54:53.436186]: [Epoch: 1131(75.45030020013343%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:54:54.720101]: [Epoch: 1131(75.45030020013343%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:54:56.022564]: [Epoch: 1131(75.45030020013343%): Data: 50.66666666666667%]:Running loss: 8.483217313885689
[2018-04-17 17:54:59.668759]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:54:59.791084]: ====================
[2018-04-17 17:54:59.796097]: Elapsed time since starting training: 1:59:45.191795
[2018-04-17 17:54:59.802114]: ====================
[2018-04-17 17:54:59.871297]: [Epoch: 1132(75.51701134089393%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:55:01.166742]: [Epoch: 1132(75.51701134089393%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:55:02.468704]: [Epoch: 1132(75.51701134089393%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:55:06.094846]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:55:06.223187]: ====================
[2018-04-17 17:55:06.228703]: Elapsed time since starting training: 1:59:51.624902
[2018-04-17 17:55:06.233715]: ====================
[2018-04-17 17:55:06.309918]: [Epoch: 1133(75.58372248165443%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:55:07.601351]: [Epoch: 1133(75.58372248165443%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:55:08.878747]: [Epoch: 1133(75.58372248165443%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:55:12.541988]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:55:12.668324]: ====================
[2018-04-17 17:55:12.672335]: Elapsed time since starting training: 1:59:58.068534
[2018-04-17 17:55:12.676847]: ====================
[2018-04-17 17:55:12.748037]: [Epoch: 1134(75.65043362241495%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:55:14.070052]: [Epoch: 1134(75.65043362241495%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:55:15.422648]: [Epoch: 1134(75.65043362241495%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:55:19.093408]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:55:19.235787]: ====================
[2018-04-17 17:55:19.241803]: Elapsed time since starting training: 2:00:04.637501
[2018-04-17 17:55:19.246817]: ====================
[2018-04-17 17:55:19.321515]: [Epoch: 1135(75.71714476317545%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:55:20.607434]: [Epoch: 1135(75.71714476317545%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:55:21.892351]: [Epoch: 1135(75.71714476317545%): Data: 50.66666666666667%]:Running loss: 8.48322020471096
[2018-04-17 17:55:25.564114]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:55:25.687443]: ====================
[2018-04-17 17:55:25.692456]: Elapsed time since starting training: 2:00:11.088153
[2018-04-17 17:55:25.696967]: ====================
[2018-04-17 17:55:25.769161]: [Epoch: 1136(75.78385590393596%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:55:27.048060]: [Epoch: 1136(75.78385590393596%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 17:55:28.388129]: [Epoch: 1136(75.78385590393596%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 17:55:32.013763]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:55:32.144111]: ====================
[2018-04-17 17:55:32.149625]: Elapsed time since starting training: 2:00:17.545824
[2018-04-17 17:55:32.155140]: ====================
[2018-04-17 17:55:32.226830]: [Epoch: 1137(75.85056704469646%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:55:33.518766]: [Epoch: 1137(75.85056704469646%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:55:34.826242]: [Epoch: 1137(75.85056704469646%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:55:38.438848]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:55:38.547136]: ====================
[2018-04-17 17:55:38.551648]: Elapsed time since starting training: 2:00:23.947847
[2018-04-17 17:55:38.555659]: ====================
[2018-04-17 17:55:38.626848]: [Epoch: 1138(75.91727818545696%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:55:39.898229]: [Epoch: 1138(75.91727818545696%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:55:41.153075]: [Epoch: 1138(75.91727818545696%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:55:44.657884]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:55:44.778205]: ====================
[2018-04-17 17:55:44.783217]: Elapsed time since starting training: 2:00:30.179416
[2018-04-17 17:55:44.788232]: ====================
[2018-04-17 17:55:44.859420]: [Epoch: 1139(75.98398932621748%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:55:46.112753]: [Epoch: 1139(75.98398932621748%): Data: 25.333333333333336%]:Running loss: 4.350371181964874
[2018-04-17 17:55:47.420229]: [Epoch: 1139(75.98398932621748%): Data: 50.66666666666667%]:Running loss: 8.483223974704742
[2018-04-17 17:55:50.946105]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:55:51.069934]: ====================
[2018-04-17 17:55:51.074948]: Elapsed time since starting training: 2:00:36.470647
[2018-04-17 17:55:51.079961]: ====================
[2018-04-17 17:55:51.151150]: [Epoch: 1140(76.05070046697799%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:55:52.409997]: [Epoch: 1140(76.05070046697799%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:55:53.671351]: [Epoch: 1140(76.05070046697799%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:55:57.191711]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:55:57.427839]: ====================
[2018-04-17 17:55:57.433354]: Elapsed time since starting training: 2:00:42.829553
[2018-04-17 17:55:57.438368]: ====================
[2018-04-17 17:55:57.509557]: [Epoch: 1141(76.11741160773849%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:55:58.765897]: [Epoch: 1141(76.11741160773849%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 17:56:00.025247]: [Epoch: 1141(76.11741160773849%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 17:56:03.522545]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:56:03.634844]: ====================
[2018-04-17 17:56:03.638855]: Elapsed time since starting training: 2:00:49.035054
[2018-04-17 17:56:03.643367]: ====================
[2018-04-17 17:56:03.708540]: [Epoch: 1142(76.184122748499%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:56:04.955355]: [Epoch: 1142(76.184122748499%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:56:06.202171]: [Epoch: 1142(76.184122748499%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 17:56:09.716515]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:56:09.833326]: ====================
[2018-04-17 17:56:09.837838]: Elapsed time since starting training: 2:00:55.233535
[2018-04-17 17:56:09.842350]: ====================
[2018-04-17 17:56:09.910030]: [Epoch: 1143(76.25083388925951%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:56:11.175394]: [Epoch: 1143(76.25083388925951%): Data: 25.333333333333336%]:Running loss: 4.350371986627579
[2018-04-17 17:56:12.423212]: [Epoch: 1143(76.25083388925951%): Data: 50.66666666666667%]:Running loss: 8.483225628733635
[2018-04-17 17:56:15.921514]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:56:16.042336]: ====================
[2018-04-17 17:56:16.046847]: Elapsed time since starting training: 2:01:01.443046
[2018-04-17 17:56:16.051359]: ====================
[2018-04-17 17:56:16.123551]: [Epoch: 1144(76.31754503002001%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:56:17.373876]: [Epoch: 1144(76.31754503002001%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:56:18.643752]: [Epoch: 1144(76.31754503002001%): Data: 50.66666666666667%]:Running loss: 8.483226343989372
[2018-04-17 17:56:22.153084]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:56:22.272902]: ====================
[2018-04-17 17:56:22.277916]: Elapsed time since starting training: 2:01:07.673614
[2018-04-17 17:56:22.282428]: ====================
[2018-04-17 17:56:22.350609]: [Epoch: 1145(76.38425617078052%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:56:23.606950]: [Epoch: 1145(76.38425617078052%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:56:24.863291]: [Epoch: 1145(76.38425617078052%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:56:28.402200]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:56:28.523523]: ====================
[2018-04-17 17:56:28.528536]: Elapsed time since starting training: 2:01:13.924234
[2018-04-17 17:56:28.533048]: ====================
[2018-04-17 17:56:28.603235]: [Epoch: 1146(76.45096731154104%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:56:29.870103]: [Epoch: 1146(76.45096731154104%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 17:56:31.122433]: [Epoch: 1146(76.45096731154104%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 17:56:34.619231]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:56:34.741556]: ====================
[2018-04-17 17:56:34.746570]: Elapsed time since starting training: 2:01:20.142769
[2018-04-17 17:56:34.751584]: ====================
[2018-04-17 17:56:34.823274]: [Epoch: 1147(76.51767845230152%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:56:36.096158]: [Epoch: 1147(76.51767845230152%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:56:37.344477]: [Epoch: 1147(76.51767845230152%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:56:40.933019]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:56:41.049830]: ====================
[2018-04-17 17:56:41.053841]: Elapsed time since starting training: 2:01:26.450040
[2018-04-17 17:56:41.059857]: ====================
[2018-04-17 17:56:41.131548]: [Epoch: 1148(76.58438959306204%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:56:42.417466]: [Epoch: 1148(76.58438959306204%): Data: 25.333333333333336%]:Running loss: 4.350372076034546
[2018-04-17 17:56:43.668794]: [Epoch: 1148(76.58438959306204%): Data: 50.66666666666667%]:Running loss: 8.483225718140602
[2018-04-17 17:56:47.199682]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 17:56:47.323525]: ====================
[2018-04-17 17:56:47.328525]: Elapsed time since starting training: 2:01:32.724223
[2018-04-17 17:56:47.329026]: ====================
[2018-04-17 17:56:47.399715]: [Epoch: 1149(76.65110073382255%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 17:56:48.660567]: [Epoch: 1149(76.65110073382255%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 17:56:49.910390]: [Epoch: 1149(76.65110073382255%): Data: 50.66666666666667%]:Running loss: 8.483225971460342
[2018-04-17 17:56:53.445289]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:56:53.568617]: ====================
[2018-04-17 17:56:53.573129]: Elapsed time since starting training: 2:01:38.969328
[2018-04-17 17:56:53.578644]: ====================
[2018-04-17 17:56:53.648831]: [Epoch: 1150(76.71781187458305%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:56:54.912696]: [Epoch: 1150(76.71781187458305%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:56:56.162013]: [Epoch: 1150(76.71781187458305%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 17:56:59.702928]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 17:56:59.824753]: ====================
[2018-04-17 17:56:59.829264]: Elapsed time since starting training: 2:01:45.225463
[2018-04-17 17:56:59.833776]: ====================
[2018-04-17 17:56:59.904966]: [Epoch: 1151(76.78452301534357%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 17:57:01.180362]: [Epoch: 1151(76.78452301534357%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 17:57:02.465780]: [Epoch: 1151(76.78452301534357%): Data: 50.66666666666667%]:Running loss: 8.483227327466011
[2018-04-17 17:57:06.026748]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 17:57:06.141556]: ====================
[2018-04-17 17:57:06.145564]: Elapsed time since starting training: 2:01:51.541763
[2018-04-17 17:57:06.150077]: ====================
[2018-04-17 17:57:06.220764]: [Epoch: 1152(76.85123415610407%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 17:57:07.502672]: [Epoch: 1152(76.85123415610407%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 17:57:08.778064]: [Epoch: 1152(76.85123415610407%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 17:57:12.291406]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 17:57:12.414233]: ====================
[2018-04-17 17:57:12.419749]: Elapsed time since starting training: 2:01:57.815445
[2018-04-17 17:57:12.424761]: ====================
[2018-04-17 17:57:12.494947]: [Epoch: 1153(76.91794529686457%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 17:57:13.775859]: [Epoch: 1153(76.91794529686457%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 17:57:15.059767]: [Epoch: 1153(76.91794529686457%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 17:57:18.693429]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:57:18.808234]: ====================
[2018-04-17 17:57:18.813248]: Elapsed time since starting training: 2:02:04.208945
[2018-04-17 17:57:18.818261]: ====================
[2018-04-17 17:57:18.888447]: [Epoch: 1154(76.98465643762509%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:57:20.158324]: [Epoch: 1154(76.98465643762509%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 17:57:21.425694]: [Epoch: 1154(76.98465643762509%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 17:57:24.968614]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 17:57:25.097958]: ====================
[2018-04-17 17:57:25.102471]: Elapsed time since starting training: 2:02:10.498670
[2018-04-17 17:57:25.106982]: ====================
[2018-04-17 17:57:25.177169]: [Epoch: 1155(77.0513675783856%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 17:57:26.449051]: [Epoch: 1155(77.0513675783856%): Data: 25.333333333333336%]:Running loss: 4.3503745049238205
[2018-04-17 17:57:27.707397]: [Epoch: 1155(77.0513675783856%): Data: 50.66666666666667%]:Running loss: 8.483230412006378
[2018-04-17 17:57:31.246307]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 17:57:31.368131]: ====================
[2018-04-17 17:57:31.373646]: Elapsed time since starting training: 2:02:16.769845
[2018-04-17 17:57:31.378658]: ====================
[2018-04-17 17:57:31.447843]: [Epoch: 1156(77.1180787191461%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 17:57:32.788407]: [Epoch: 1156(77.1180787191461%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 17:57:34.056278]: [Epoch: 1156(77.1180787191461%): Data: 50.66666666666667%]:Running loss: 8.483230948448181
[2018-04-17 17:57:37.578143]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 17:57:37.699967]: ====================
[2018-04-17 17:57:37.704980]: Elapsed time since starting training: 2:02:23.100678
[2018-04-17 17:57:37.708992]: ====================
[2018-04-17 17:57:37.780180]: [Epoch: 1157(77.1847898599066%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 17:57:39.042035]: [Epoch: 1157(77.1847898599066%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 17:57:40.312923]: [Epoch: 1157(77.1847898599066%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 17:57:43.819238]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 17:57:43.935046]: ====================
[2018-04-17 17:57:43.940059]: Elapsed time since starting training: 2:02:29.335757
[2018-04-17 17:57:43.944572]: ====================
[2018-04-17 17:57:44.013254]: [Epoch: 1158(77.2515010006671%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 17:57:45.289147]: [Epoch: 1158(77.2515010006671%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 17:57:46.559023]: [Epoch: 1158(77.2515010006671%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 17:57:50.105453]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 17:57:50.230286]: ====================
[2018-04-17 17:57:50.234797]: Elapsed time since starting training: 2:02:35.630996
[2018-04-17 17:57:50.240312]: ====================
[2018-04-17 17:57:50.306989]: [Epoch: 1159(77.31821214142762%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 17:57:51.576866]: [Epoch: 1159(77.31821214142762%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 17:57:52.854764]: [Epoch: 1159(77.31821214142762%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 17:57:56.395177]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 17:57:56.512489]: ====================
[2018-04-17 17:57:56.517503]: Elapsed time since starting training: 2:02:41.913201
[2018-04-17 17:57:56.522516]: ====================
[2018-04-17 17:57:56.592202]: [Epoch: 1160(77.38492328218813%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 17:57:57.862579]: [Epoch: 1160(77.38492328218813%): Data: 25.333333333333336%]:Running loss: 4.350366428494453
[2018-04-17 17:57:59.117416]: [Epoch: 1160(77.38492328218813%): Data: 50.66666666666667%]:Running loss: 8.483215257525444
[2018-04-17 17:58:02.704453]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 17:58:02.831793]: ====================
[2018-04-17 17:58:02.838310]: Elapsed time since starting training: 2:02:48.234509
[2018-04-17 17:58:02.842822]: ====================
[2018-04-17 17:58:02.911003]: [Epoch: 1161(77.45163442294863%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 17:58:04.164336]: [Epoch: 1161(77.45163442294863%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 17:58:05.466298]: [Epoch: 1161(77.45163442294863%): Data: 50.66666666666667%]:Running loss: 8.483216106891632
[2018-04-17 17:58:09.099967]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:58:09.235327]: ====================
[2018-04-17 17:58:09.239338]: Elapsed time since starting training: 2:02:54.635537
[2018-04-17 17:58:09.243849]: ====================
[2018-04-17 17:58:09.313033]: [Epoch: 1162(77.51834556370913%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:58:10.688189]: [Epoch: 1162(77.51834556370913%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:58:12.274408]: [Epoch: 1162(77.51834556370913%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:58:16.342224]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 17:58:16.483600]: ====================
[2018-04-17 17:58:16.488112]: Elapsed time since starting training: 2:03:01.884311
[2018-04-17 17:58:16.493125]: ====================
[2018-04-17 17:58:16.571835]: [Epoch: 1163(77.58505670446965%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 17:58:18.098895]: [Epoch: 1163(77.58505670446965%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 17:58:19.681102]: [Epoch: 1163(77.58505670446965%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 17:58:23.937419]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 17:58:24.060749]: ====================
[2018-04-17 17:58:24.064758]: Elapsed time since starting training: 2:03:09.460957
[2018-04-17 17:58:24.070774]: ====================
[2018-04-17 17:58:24.140460]: [Epoch: 1164(77.65176784523015%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 17:58:25.789344]: [Epoch: 1164(77.65176784523015%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 17:58:27.204105]: [Epoch: 1164(77.65176784523015%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 17:58:31.177671]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:58:31.317042]: ====================
[2018-04-17 17:58:31.321554]: Elapsed time since starting training: 2:03:16.717753
[2018-04-17 17:58:31.326066]: ====================
[2018-04-17 17:58:31.396253]: [Epoch: 1165(77.71847898599066%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:58:32.745841]: [Epoch: 1165(77.71847898599066%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:58:34.098939]: [Epoch: 1165(77.71847898599066%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:58:37.808303]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 17:58:37.931630]: ====================
[2018-04-17 17:58:37.937144]: Elapsed time since starting training: 2:03:23.333343
[2018-04-17 17:58:37.941657]: ====================
[2018-04-17 17:58:38.014851]: [Epoch: 1166(77.78519012675117%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 17:58:39.486263]: [Epoch: 1166(77.78519012675117%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 17:58:40.840364]: [Epoch: 1166(77.78519012675117%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 17:58:45.060586]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 17:58:45.202463]: ====================
[2018-04-17 17:58:45.207978]: Elapsed time since starting training: 2:03:30.603675
[2018-04-17 17:58:45.212991]: ====================
[2018-04-17 17:58:45.291199]: [Epoch: 1167(77.85190126751166%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 17:58:46.665854]: [Epoch: 1167(77.85190126751166%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 17:58:48.200936]: [Epoch: 1167(77.85190126751166%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 17:58:52.627707]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:58:52.760060]: ====================
[2018-04-17 17:58:52.765072]: Elapsed time since starting training: 2:03:38.161271
[2018-04-17 17:58:52.771088]: ====================
[2018-04-17 17:58:52.843781]: [Epoch: 1168(77.91861240827218%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:58:54.202895]: [Epoch: 1168(77.91861240827218%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 17:58:55.544963]: [Epoch: 1168(77.91861240827218%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 17:58:59.223746]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 17:58:59.359106]: ====================
[2018-04-17 17:58:59.363116]: Elapsed time since starting training: 2:03:44.759315
[2018-04-17 17:58:59.368130]: ====================
[2018-04-17 17:58:59.449345]: [Epoch: 1169(77.9853235490327%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 17:59:00.759832]: [Epoch: 1169(77.9853235490327%): Data: 25.333333333333336%]:Running loss: 4.350369483232498
[2018-04-17 17:59:02.098892]: [Epoch: 1169(77.9853235490327%): Data: 50.66666666666667%]:Running loss: 8.48322057723999
[2018-04-17 17:59:05.814771]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 17:59:05.935593]: ====================
[2018-04-17 17:59:05.941608]: Elapsed time since starting training: 2:03:51.337807
[2018-04-17 17:59:05.948126]: ====================
[2018-04-17 17:59:06.017818]: [Epoch: 1170(78.05203468979319%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 17:59:07.354365]: [Epoch: 1170(78.05203468979319%): Data: 25.333333333333336%]:Running loss: 4.3503696620464325
[2018-04-17 17:59:08.656327]: [Epoch: 1170(78.05203468979319%): Data: 50.66666666666667%]:Running loss: 8.483221516013145
[2018-04-17 17:59:12.354666]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 17:59:12.479498]: ====================
[2018-04-17 17:59:12.484512]: Elapsed time since starting training: 2:03:57.880210
[2018-04-17 17:59:12.489025]: ====================
[2018-04-17 17:59:12.564224]: [Epoch: 1171(78.1187458305537%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 17:59:13.880724]: [Epoch: 1171(78.1187458305537%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 17:59:15.263902]: [Epoch: 1171(78.1187458305537%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 17:59:18.926141]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 17:59:19.068519]: ====================
[2018-04-17 17:59:19.073031]: Elapsed time since starting training: 2:04:04.469230
[2018-04-17 17:59:19.078044]: ====================
[2018-04-17 17:59:19.152744]: [Epoch: 1172(78.18545697131421%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 17:59:20.512859]: [Epoch: 1172(78.18545697131421%): Data: 25.333333333333336%]:Running loss: 4.350371018052101
[2018-04-17 17:59:21.810309]: [Epoch: 1172(78.18545697131421%): Data: 50.66666666666667%]:Running loss: 8.483223527669907
[2018-04-17 17:59:25.518168]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 17:59:25.642500]: ====================
[2018-04-17 17:59:25.647512]: Elapsed time since starting training: 2:04:11.043711
[2018-04-17 17:59:25.652024]: ====================
[2018-04-17 17:59:25.729230]: [Epoch: 1173(78.25216811207471%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 17:59:27.043725]: [Epoch: 1173(78.25216811207471%): Data: 25.333333333333336%]:Running loss: 4.350371107459068
[2018-04-17 17:59:28.325132]: [Epoch: 1173(78.25216811207471%): Data: 50.66666666666667%]:Running loss: 8.483223900198936
[2018-04-17 17:59:32.073599]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 17:59:32.212468]: ====================
[2018-04-17 17:59:32.217482]: Elapsed time since starting training: 2:04:17.613180
[2018-04-17 17:59:32.221994]: ====================
[2018-04-17 17:59:32.297194]: [Epoch: 1174(78.31887925283523%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 17:59:33.609182]: [Epoch: 1174(78.31887925283523%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 17:59:34.913651]: [Epoch: 1174(78.31887925283523%): Data: 50.66666666666667%]:Running loss: 8.483224600553513
[2018-04-17 17:59:38.605467]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:59:38.727793]: ====================
[2018-04-17 17:59:38.732304]: Elapsed time since starting training: 2:04:24.128503
[2018-04-17 17:59:38.737318]: ====================
[2018-04-17 17:59:38.806503]: [Epoch: 1175(78.38559039359573%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:59:40.103450]: [Epoch: 1175(78.38559039359573%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 17:59:41.437999]: [Epoch: 1175(78.38559039359573%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 17:59:45.204013]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 17:59:45.345390]: ====================
[2018-04-17 17:59:45.352909]: Elapsed time since starting training: 2:04:30.749108
[2018-04-17 17:59:45.357922]: ====================
[2018-04-17 17:59:45.445655]: [Epoch: 1176(78.45230153435624%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 17:59:46.748620]: [Epoch: 1176(78.45230153435624%): Data: 25.333333333333336%]:Running loss: 4.350372165441513
[2018-04-17 17:59:48.073142]: [Epoch: 1176(78.45230153435624%): Data: 50.66666666666667%]:Running loss: 8.483226090669632
[2018-04-17 17:59:51.844169]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 17:59:51.994569]: ====================
[2018-04-17 17:59:51.999082]: Elapsed time since starting training: 2:04:37.395281
[2018-04-17 17:59:52.003593]: ====================
[2018-04-17 17:59:52.078291]: [Epoch: 1177(78.51901267511674%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 17:59:53.398803]: [Epoch: 1177(78.51901267511674%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 17:59:54.735356]: [Epoch: 1177(78.51901267511674%): Data: 50.66666666666667%]:Running loss: 8.483226835727692
[2018-04-17 17:59:58.448731]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 17:59:58.574565]: ====================
[2018-04-17 17:59:58.579578]: Elapsed time since starting training: 2:04:43.975276
[2018-04-17 17:59:58.584090]: ====================
[2018-04-17 17:59:58.651269]: [Epoch: 1178(78.58572381587724%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 17:59:59.986820]: [Epoch: 1178(78.58572381587724%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:00:01.307833]: [Epoch: 1178(78.58572381587724%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:00:05.054797]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:00:05.171105]: ====================
[2018-04-17 18:00:05.176119]: Elapsed time since starting training: 2:04:50.572318
[2018-04-17 18:00:05.181132]: ====================
[2018-04-17 18:00:05.249313]: [Epoch: 1179(78.65243495663776%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:00:06.586368]: [Epoch: 1179(78.65243495663776%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:00:07.892341]: [Epoch: 1179(78.65243495663776%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:00:11.613736]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:00:11.730547]: ====================
[2018-04-17 18:00:11.735059]: Elapsed time since starting training: 2:04:57.131258
[2018-04-17 18:00:11.740072]: ====================
[2018-04-17 18:00:11.813769]: [Epoch: 1180(78.71914609739827%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:00:13.118743]: [Epoch: 1180(78.71914609739827%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:00:14.479857]: [Epoch: 1180(78.71914609739827%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:00:18.248378]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:00:18.391759]: ====================
[2018-04-17 18:00:18.396772]: Elapsed time since starting training: 2:05:03.792971
[2018-04-17 18:00:18.401786]: ====================
[2018-04-17 18:00:18.488015]: [Epoch: 1181(78.78585723815877%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:00:19.815549]: [Epoch: 1181(78.78585723815877%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:00:21.158616]: [Epoch: 1181(78.78585723815877%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:00:24.951200]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:00:25.076534]: ====================
[2018-04-17 18:00:25.081046]: Elapsed time since starting training: 2:05:10.477245
[2018-04-17 18:00:25.085558]: ====================
[2018-04-17 18:00:25.154241]: [Epoch: 1182(78.85256837891927%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:00:26.527391]: [Epoch: 1182(78.85256837891927%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:00:27.951177]: [Epoch: 1182(78.85256837891927%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:00:31.713682]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:00:31.950312]: ====================
[2018-04-17 18:00:31.955324]: Elapsed time since starting training: 2:05:17.351021
[2018-04-17 18:00:31.959837]: ====================
[2018-04-17 18:00:32.031527]: [Epoch: 1183(78.91927951967979%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:00:33.362065]: [Epoch: 1183(78.91927951967979%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:00:34.678566]: [Epoch: 1183(78.91927951967979%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:00:38.444579]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:00:38.573923]: ====================
[2018-04-17 18:00:38.577933]: Elapsed time since starting training: 2:05:23.974132
[2018-04-17 18:00:38.582947]: ====================
[2018-04-17 18:00:38.652132]: [Epoch: 1184(78.9859906604403%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:00:39.938050]: [Epoch: 1184(78.9859906604403%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:00:41.270594]: [Epoch: 1184(78.9859906604403%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:00:44.976949]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:00:45.096768]: ====================
[2018-04-17 18:00:45.101279]: Elapsed time since starting training: 2:05:30.497478
[2018-04-17 18:00:45.105290]: ====================
[2018-04-17 18:00:45.173471]: [Epoch: 1185(79.0527018012008%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:00:46.520553]: [Epoch: 1185(79.0527018012008%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:00:47.864627]: [Epoch: 1185(79.0527018012008%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:00:51.657211]: Test set accuracy: 94.33962264150944% ,loss = 5.437956750392914
[2018-04-17 18:00:51.776530]: ====================
[2018-04-17 18:00:51.781542]: Elapsed time since starting training: 2:05:37.177741
[2018-04-17 18:00:51.785552]: ====================
[2018-04-17 18:00:51.856742]: [Epoch: 1186(79.11941294196131%): Data: 0.0%]:Running loss: 0.21751827001571655
[2018-04-17 18:00:53.203323]: [Epoch: 1186(79.11941294196131%): Data: 25.333333333333336%]:Running loss: 4.350365489721298
[2018-04-17 18:00:54.521334]: [Epoch: 1186(79.11941294196131%): Data: 50.66666666666667%]:Running loss: 8.483213186264038
[2018-04-17 18:00:58.256766]: Test set accuracy: 94.33962264150944% ,loss = 5.4379574954509735
[2018-04-17 18:00:58.402655]: ====================
[2018-04-17 18:00:58.407166]: Elapsed time since starting training: 2:05:43.803365
[2018-04-17 18:00:58.411679]: ====================
[2018-04-17 18:00:58.486377]: [Epoch: 1187(79.1861240827218%): Data: 0.0%]:Running loss: 0.21751829981803894
[2018-04-17 18:00:59.835464]: [Epoch: 1187(79.1861240827218%): Data: 25.333333333333336%]:Running loss: 4.350365996360779
[2018-04-17 18:01:01.138429]: [Epoch: 1187(79.1861240827218%): Data: 50.66666666666667%]:Running loss: 8.48321382701397
[2018-04-17 18:01:04.826234]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 18:01:04.964102]: ====================
[2018-04-17 18:01:04.968613]: Elapsed time since starting training: 2:05:50.364812
[2018-04-17 18:01:04.972624]: ====================
[2018-04-17 18:01:05.052336]: [Epoch: 1188(79.25283522348232%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 18:01:06.399418]: [Epoch: 1188(79.25283522348232%): Data: 25.333333333333336%]:Running loss: 4.350366294384003
[2018-04-17 18:01:07.716420]: [Epoch: 1188(79.25283522348232%): Data: 50.66666666666667%]:Running loss: 8.483214274048805
[2018-04-17 18:01:11.347575]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 18:01:11.480930]: ====================
[2018-04-17 18:01:11.485443]: Elapsed time since starting training: 2:05:56.881642
[2018-04-17 18:01:11.489954]: ====================
[2018-04-17 18:01:11.559138]: [Epoch: 1189(79.31954636424283%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 18:01:12.846059]: [Epoch: 1189(79.31954636424283%): Data: 25.333333333333336%]:Running loss: 4.35036689043045
[2018-04-17 18:01:14.155541]: [Epoch: 1189(79.31954636424283%): Data: 50.66666666666667%]:Running loss: 8.483215436339378
[2018-04-17 18:01:17.845859]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:01:17.994755]: ====================
[2018-04-17 18:01:18.001774]: Elapsed time since starting training: 2:06:03.397471
[2018-04-17 18:01:18.006787]: ====================
[2018-04-17 18:01:18.076974]: [Epoch: 1190(79.38625750500333%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:01:19.386455]: [Epoch: 1190(79.38625750500333%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 18:01:20.775649]: [Epoch: 1190(79.38625750500333%): Data: 50.66666666666667%]:Running loss: 8.483216598629951
[2018-04-17 18:01:24.521108]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:01:24.640425]: ====================
[2018-04-17 18:01:24.644436]: Elapsed time since starting training: 2:06:10.040635
[2018-04-17 18:01:24.649449]: ====================
[2018-04-17 18:01:24.714623]: [Epoch: 1191(79.45296864576385%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:01:26.056190]: [Epoch: 1191(79.45296864576385%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 18:01:27.344116]: [Epoch: 1191(79.45296864576385%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 18:01:30.991313]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:01:31.113136]: ====================
[2018-04-17 18:01:31.118150]: Elapsed time since starting training: 2:06:16.514349
[2018-04-17 18:01:31.124166]: ====================
[2018-04-17 18:01:31.196358]: [Epoch: 1192(79.51967978652435%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:01:32.600591]: [Epoch: 1192(79.51967978652435%): Data: 25.333333333333336%]:Running loss: 4.350368231534958
[2018-04-17 18:01:33.891023]: [Epoch: 1192(79.51967978652435%): Data: 50.66666666666667%]:Running loss: 8.483218476176262
[2018-04-17 18:01:37.637986]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:01:37.755799]: ====================
[2018-04-17 18:01:37.764823]: Elapsed time since starting training: 2:06:23.161022
[2018-04-17 18:01:37.774850]: ====================
[2018-04-17 18:01:37.855565]: [Epoch: 1193(79.58639092728485%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:01:39.347031]: [Epoch: 1193(79.58639092728485%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:01:40.849526]: [Epoch: 1193(79.58639092728485%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:01:44.587966]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:01:44.700766]: ====================
[2018-04-17 18:01:44.705279]: Elapsed time since starting training: 2:06:30.100975
[2018-04-17 18:01:44.709289]: ====================
[2018-04-17 18:01:44.783486]: [Epoch: 1194(79.65310206804537%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:01:46.085949]: [Epoch: 1194(79.65310206804537%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:01:47.356828]: [Epoch: 1194(79.65310206804537%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 18:01:50.975450]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:01:51.108304]: ====================
[2018-04-17 18:01:51.113317]: Elapsed time since starting training: 2:06:36.509516
[2018-04-17 18:01:51.117829]: ====================
[2018-04-17 18:01:51.190021]: [Epoch: 1195(79.71981320880587%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:01:52.450873]: [Epoch: 1195(79.71981320880587%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:01:53.721251]: [Epoch: 1195(79.71981320880587%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:01:57.250636]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:01:57.368951]: ====================
[2018-04-17 18:01:57.373462]: Elapsed time since starting training: 2:06:42.769661
[2018-04-17 18:01:57.378476]: ====================
[2018-04-17 18:01:57.454679]: [Epoch: 1196(79.78652434956638%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:01:58.721547]: [Epoch: 1196(79.78652434956638%): Data: 25.333333333333336%]:Running loss: 4.350370272994041
[2018-04-17 18:01:59.987413]: [Epoch: 1196(79.78652434956638%): Data: 50.66666666666667%]:Running loss: 8.483221650123596
[2018-04-17 18:02:03.560413]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:02:03.680733]: ====================
[2018-04-17 18:02:03.686248]: Elapsed time since starting training: 2:06:49.082447
[2018-04-17 18:02:03.690760]: ====================
[2018-04-17 18:02:03.754931]: [Epoch: 1197(79.85323549032688%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:02:05.053383]: [Epoch: 1197(79.85323549032688%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:02:06.322759]: [Epoch: 1197(79.85323549032688%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:02:09.866682]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:02:09.980986]: ====================
[2018-04-17 18:02:09.985999]: Elapsed time since starting training: 2:06:55.381697
[2018-04-17 18:02:09.990511]: ====================
[2018-04-17 18:02:10.058191]: [Epoch: 1198(79.91994663108738%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:02:11.354638]: [Epoch: 1198(79.91994663108738%): Data: 25.333333333333336%]:Running loss: 4.3503707349300385
[2018-04-17 18:02:12.669635]: [Epoch: 1198(79.91994663108738%): Data: 50.66666666666667%]:Running loss: 8.483222961425781
[2018-04-17 18:02:16.265696]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:02:16.385014]: ====================
[2018-04-17 18:02:16.390028]: Elapsed time since starting training: 2:07:01.786227
[2018-04-17 18:02:16.394539]: ====================
[2018-04-17 18:02:16.460715]: [Epoch: 1199(79.9866577718479%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:02:17.759168]: [Epoch: 1199(79.9866577718479%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:02:19.057620]: [Epoch: 1199(79.9866577718479%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:02:22.652178]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:02:22.773010]: ====================
[2018-04-17 18:02:22.778013]: Elapsed time since starting training: 2:07:08.173711
[2018-04-17 18:02:22.783027]: ====================
[2018-04-17 18:02:22.854216]: [Epoch: 1200(80.0533689126084%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:02:24.150663]: [Epoch: 1200(80.0533689126084%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:02:25.416027]: [Epoch: 1200(80.0533689126084%): Data: 50.66666666666667%]:Running loss: 8.483224391937256
[2018-04-17 18:02:28.931375]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:02:29.054715]: ====================
[2018-04-17 18:02:29.059215]: Elapsed time since starting training: 2:07:14.454913
[2018-04-17 18:02:29.063225]: ====================
[2018-04-17 18:02:29.133913]: [Epoch: 1201(80.12008005336891%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:02:30.456931]: [Epoch: 1201(80.12008005336891%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:02:31.739843]: [Epoch: 1201(80.12008005336891%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:02:35.303317]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:02:35.419627]: ====================
[2018-04-17 18:02:35.423638]: Elapsed time since starting training: 2:07:20.819837
[2018-04-17 18:02:35.427648]: ====================
[2018-04-17 18:02:35.498336]: [Epoch: 1202(80.18679119412941%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:02:36.751180]: [Epoch: 1202(80.18679119412941%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:02:38.028564]: [Epoch: 1202(80.18679119412941%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:02:41.519346]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:02:41.653202]: ====================
[2018-04-17 18:02:41.658216]: Elapsed time since starting training: 2:07:27.053913
[2018-04-17 18:02:41.662727]: ====================
[2018-04-17 18:02:41.731410]: [Epoch: 1203(80.25350233488993%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:02:42.986748]: [Epoch: 1203(80.25350233488993%): Data: 25.333333333333336%]:Running loss: 4.350372612476349
[2018-04-17 18:02:44.241084]: [Epoch: 1203(80.25350233488993%): Data: 50.66666666666667%]:Running loss: 8.48322682082653
[2018-04-17 18:02:47.787512]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:02:47.925380]: ====================
[2018-04-17 18:02:47.930393]: Elapsed time since starting training: 2:07:33.326592
[2018-04-17 18:02:47.934905]: ====================
[2018-04-17 18:02:48.002084]: [Epoch: 1204(80.32021347565043%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:02:49.293517]: [Epoch: 1204(80.32021347565043%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:02:50.588461]: [Epoch: 1204(80.32021347565043%): Data: 50.66666666666667%]:Running loss: 8.483227148652077
[2018-04-17 18:02:54.131381]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:02:54.251702]: ====================
[2018-04-17 18:02:54.256213]: Elapsed time since starting training: 2:07:39.651911
[2018-04-17 18:02:54.260223]: ====================
[2018-04-17 18:02:54.332416]: [Epoch: 1205(80.38692461641094%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:02:55.586250]: [Epoch: 1205(80.38692461641094%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:02:56.853118]: [Epoch: 1205(80.38692461641094%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:03:00.528391]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:03:00.649714]: ====================
[2018-04-17 18:03:00.654727]: Elapsed time since starting training: 2:07:46.050926
[2018-04-17 18:03:00.659239]: ====================
[2018-04-17 18:03:00.729426]: [Epoch: 1206(80.45363575717145%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:03:02.004817]: [Epoch: 1206(80.45363575717145%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:03:03.297754]: [Epoch: 1206(80.45363575717145%): Data: 50.66666666666667%]:Running loss: 8.483228042721748
[2018-04-17 18:03:06.910361]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:03:07.035193]: ====================
[2018-04-17 18:03:07.040707]: Elapsed time since starting training: 2:07:52.436405
[2018-04-17 18:03:07.045219]: ====================
[2018-04-17 18:03:07.123427]: [Epoch: 1207(80.52034689793194%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:03:08.482039]: [Epoch: 1207(80.52034689793194%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:03:10.003084]: [Epoch: 1207(80.52034689793194%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:03:13.909973]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:03:14.032298]: ====================
[2018-04-17 18:03:14.036810]: Elapsed time since starting training: 2:07:59.433009
[2018-04-17 18:03:14.041322]: ====================
[2018-04-17 18:03:14.113513]: [Epoch: 1208(80.58705803869246%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:03:15.429513]: [Epoch: 1208(80.58705803869246%): Data: 25.333333333333336%]:Running loss: 4.350372672080994
[2018-04-17 18:03:16.703400]: [Epoch: 1208(80.58705803869246%): Data: 50.66666666666667%]:Running loss: 8.483226880431175
[2018-04-17 18:03:20.229777]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:03:20.346086]: ====================
[2018-04-17 18:03:20.350598]: Elapsed time since starting training: 2:08:05.746797
[2018-04-17 18:03:20.355110]: ====================
[2018-04-17 18:03:20.423291]: [Epoch: 1209(80.65376917945298%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:03:21.715226]: [Epoch: 1209(80.65376917945298%): Data: 25.333333333333336%]:Running loss: 4.350372940301895
[2018-04-17 18:03:23.004655]: [Epoch: 1209(80.65376917945298%): Data: 50.66666666666667%]:Running loss: 8.483227998018265
[2018-04-17 18:03:26.540056]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:03:26.659373]: ====================
[2018-04-17 18:03:26.664386]: Elapsed time since starting training: 2:08:12.060084
[2018-04-17 18:03:26.671405]: ====================
[2018-04-17 18:03:26.738082]: [Epoch: 1210(80.72048032021347%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:03:28.005953]: [Epoch: 1210(80.72048032021347%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:03:29.309921]: [Epoch: 1210(80.72048032021347%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:03:32.823764]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:03:32.938068]: ====================
[2018-04-17 18:03:32.943081]: Elapsed time since starting training: 2:08:18.338779
[2018-04-17 18:03:32.947594]: ====================
[2018-04-17 18:03:33.016777]: [Epoch: 1211(80.78719146097399%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:03:34.272115]: [Epoch: 1211(80.78719146097399%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:03:35.542493]: [Epoch: 1211(80.78719146097399%): Data: 50.66666666666667%]:Running loss: 8.48322942852974
[2018-04-17 18:03:39.106971]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:03:39.226288]: ====================
[2018-04-17 18:03:39.232806]: Elapsed time since starting training: 2:08:24.628504
[2018-04-17 18:03:39.237827]: ====================
[2018-04-17 18:03:39.313019]: [Epoch: 1212(80.85390260173449%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:03:40.564346]: [Epoch: 1212(80.85390260173449%): Data: 25.333333333333336%]:Running loss: 4.350373476743698
[2018-04-17 18:03:41.843748]: [Epoch: 1212(80.85390260173449%): Data: 50.66666666666667%]:Running loss: 8.483228534460068
[2018-04-17 18:03:45.430284]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:03:45.549602]: ====================
[2018-04-17 18:03:45.554119]: Elapsed time since starting training: 2:08:30.950318
[2018-04-17 18:03:45.559128]: ====================
[2018-04-17 18:03:45.627308]: [Epoch: 1213(80.920613742495%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:03:46.944311]: [Epoch: 1213(80.920613742495%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:03:48.243264]: [Epoch: 1213(80.920613742495%): Data: 50.66666666666667%]:Running loss: 8.483228951692581
[2018-04-17 18:03:51.871412]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:03:51.991732]: ====================
[2018-04-17 18:03:51.995742]: Elapsed time since starting training: 2:08:37.391941
[2018-04-17 18:03:52.000756]: ====================
[2018-04-17 18:03:52.073950]: [Epoch: 1214(80.98732488325551%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:03:53.439582]: [Epoch: 1214(80.98732488325551%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:03:54.757586]: [Epoch: 1214(80.98732488325551%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:03:58.400271]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:03:58.516080]: ====================
[2018-04-17 18:03:58.520090]: Elapsed time since starting training: 2:08:43.916289
[2018-04-17 18:03:58.525605]: ====================
[2018-04-17 18:03:58.606320]: [Epoch: 1215(81.05403602401601%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:03:59.878202]: [Epoch: 1215(81.05403602401601%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:04:01.175150]: [Epoch: 1215(81.05403602401601%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:04:04.728097]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:04:04.851927]: ====================
[2018-04-17 18:04:04.856940]: Elapsed time since starting training: 2:08:50.253139
[2018-04-17 18:04:04.861452]: ====================
[2018-04-17 18:04:04.933143]: [Epoch: 1216(81.12074716477652%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:04:06.242123]: [Epoch: 1216(81.12074716477652%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:04:07.511498]: [Epoch: 1216(81.12074716477652%): Data: 50.66666666666667%]:Running loss: 8.483231842517853
[2018-04-17 18:04:11.142152]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:04:11.260467]: ====================
[2018-04-17 18:04:11.264979]: Elapsed time since starting training: 2:08:56.661178
[2018-04-17 18:04:11.269992]: ====================
[2018-04-17 18:04:11.345694]: [Epoch: 1217(81.18745830553702%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:04:12.615571]: [Epoch: 1217(81.18745830553702%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:04:13.892967]: [Epoch: 1217(81.18745830553702%): Data: 50.66666666666667%]:Running loss: 8.483231216669083
[2018-04-17 18:04:17.428868]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:04:17.546682]: ====================
[2018-04-17 18:04:17.551695]: Elapsed time since starting training: 2:09:02.947393
[2018-04-17 18:04:17.556709]: ====================
[2018-04-17 18:04:17.627396]: [Epoch: 1218(81.25416944629752%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:04:18.873209]: [Epoch: 1218(81.25416944629752%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:04:20.142584]: [Epoch: 1218(81.25416944629752%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 18:04:23.652923]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:04:23.768732]: ====================
[2018-04-17 18:04:23.773745]: Elapsed time since starting training: 2:09:09.169944
[2018-04-17 18:04:23.777755]: ====================
[2018-04-17 18:04:23.847453]: [Epoch: 1219(81.32088058705804%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:04:25.109797]: [Epoch: 1219(81.32088058705804%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:04:26.377167]: [Epoch: 1219(81.32088058705804%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 18:04:29.966210]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 18:04:30.087533]: ====================
[2018-04-17 18:04:30.092546]: Elapsed time since starting training: 2:09:15.488745
[2018-04-17 18:04:30.097058]: ====================
[2018-04-17 18:04:30.174263]: [Epoch: 1220(81.38759172781855%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 18:04:31.477228]: [Epoch: 1220(81.38759172781855%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 18:04:32.764657]: [Epoch: 1220(81.38759172781855%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 18:04:36.342665]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 18:04:36.458975]: ====================
[2018-04-17 18:04:36.463486]: Elapsed time since starting training: 2:09:21.859184
[2018-04-17 18:04:36.467998]: ====================
[2018-04-17 18:04:36.536681]: [Epoch: 1221(81.45430286857905%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 18:04:37.815582]: [Epoch: 1221(81.45430286857905%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:04:39.074930]: [Epoch: 1221(81.45430286857905%): Data: 50.66666666666667%]:Running loss: 8.48322308063507
[2018-04-17 18:04:42.632390]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:04:42.873030]: ====================
[2018-04-17 18:04:42.879547]: Elapsed time since starting training: 2:09:28.275245
[2018-04-17 18:04:42.884059]: ====================
[2018-04-17 18:04:42.953242]: [Epoch: 1222(81.52101400933957%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:04:44.244175]: [Epoch: 1222(81.52101400933957%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:04:45.545134]: [Epoch: 1222(81.52101400933957%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:04:49.101591]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:04:49.230935]: ====================
[2018-04-17 18:04:49.235448]: Elapsed time since starting training: 2:09:34.631647
[2018-04-17 18:04:49.239960]: ====================
[2018-04-17 18:04:49.315159]: [Epoch: 1223(81.58772515010007%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:04:50.593558]: [Epoch: 1223(81.58772515010007%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 18:04:51.923094]: [Epoch: 1223(81.58772515010007%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 18:04:55.440947]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:04:55.558761]: ====================
[2018-04-17 18:04:55.563272]: Elapsed time since starting training: 2:09:40.959471
[2018-04-17 18:04:55.568287]: ====================
[2018-04-17 18:04:55.641481]: [Epoch: 1224(81.65443629086057%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:04:56.907848]: [Epoch: 1224(81.65443629086057%): Data: 25.333333333333336%]:Running loss: 4.35037025809288
[2018-04-17 18:04:58.151154]: [Epoch: 1224(81.65443629086057%): Data: 50.66666666666667%]:Running loss: 8.48322220146656
[2018-04-17 18:05:01.753232]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:05:01.896113]: ====================
[2018-04-17 18:05:01.901125]: Elapsed time since starting training: 2:09:47.297324
[2018-04-17 18:05:01.905136]: ====================
[2018-04-17 18:05:01.977830]: [Epoch: 1225(81.72114743162108%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:05:03.242692]: [Epoch: 1225(81.72114743162108%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:05:04.545657]: [Epoch: 1225(81.72114743162108%): Data: 50.66666666666667%]:Running loss: 8.483222886919975
[2018-04-17 18:05:08.171798]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:05:08.289612]: ====================
[2018-04-17 18:05:08.294625]: Elapsed time since starting training: 2:09:53.690323
[2018-04-17 18:05:08.299137]: ====================
[2018-04-17 18:05:08.375841]: [Epoch: 1226(81.7878585723816%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:05:09.644213]: [Epoch: 1226(81.7878585723816%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:05:10.908074]: [Epoch: 1226(81.7878585723816%): Data: 50.66666666666667%]:Running loss: 8.483223617076874
[2018-04-17 18:05:14.446984]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:05:14.559283]: ====================
[2018-04-17 18:05:14.563795]: Elapsed time since starting training: 2:09:59.959994
[2018-04-17 18:05:14.569811]: ====================
[2018-04-17 18:05:14.636989]: [Epoch: 1227(81.8545697131421%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:05:15.946973]: [Epoch: 1227(81.8545697131421%): Data: 25.333333333333336%]:Running loss: 4.350371181964874
[2018-04-17 18:05:17.206327]: [Epoch: 1227(81.8545697131421%): Data: 50.66666666666667%]:Running loss: 8.483223408460617
[2018-04-17 18:05:20.741221]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:05:20.874576]: ====================
[2018-04-17 18:05:20.879087]: Elapsed time since starting training: 2:10:06.275286
[2018-04-17 18:05:20.883098]: ====================
[2018-04-17 18:05:20.949775]: [Epoch: 1228(81.9212808539026%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:05:22.208622]: [Epoch: 1228(81.9212808539026%): Data: 25.333333333333336%]:Running loss: 4.350371181964874
[2018-04-17 18:05:23.477998]: [Epoch: 1228(81.9212808539026%): Data: 50.66666666666667%]:Running loss: 8.483223974704742
[2018-04-17 18:05:27.340268]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:05:27.503702]: ====================
[2018-04-17 18:05:27.511222]: Elapsed time since starting training: 2:10:12.907421
[2018-04-17 18:05:27.516236]: ====================
[2018-04-17 18:05:27.595446]: [Epoch: 1229(81.9879919946631%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:05:29.032767]: [Epoch: 1229(81.9879919946631%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:05:30.440511]: [Epoch: 1229(81.9879919946631%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 18:05:34.100247]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:05:34.219565]: ====================
[2018-04-17 18:05:34.223575]: Elapsed time since starting training: 2:10:19.619774
[2018-04-17 18:05:34.228087]: ====================
[2018-04-17 18:05:34.298775]: [Epoch: 1230(82.05470313542361%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:05:35.588203]: [Epoch: 1230(82.05470313542361%): Data: 25.333333333333336%]:Running loss: 4.350371897220612
[2018-04-17 18:05:36.933280]: [Epoch: 1230(82.05470313542361%): Data: 50.66666666666667%]:Running loss: 8.483225539326668
[2018-04-17 18:05:40.688765]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:05:40.833150]: ====================
[2018-04-17 18:05:40.837662]: Elapsed time since starting training: 2:10:26.233359
[2018-04-17 18:05:40.842675]: ====================
[2018-04-17 18:05:40.908851]: [Epoch: 1231(82.12141427618413%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:05:42.266461]: [Epoch: 1231(82.12141427618413%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:05:43.547868]: [Epoch: 1231(82.12141427618413%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:05:47.248207]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:05:47.381060]: ====================
[2018-04-17 18:05:47.385573]: Elapsed time since starting training: 2:10:32.781270
[2018-04-17 18:05:47.390084]: ====================
[2018-04-17 18:05:47.466287]: [Epoch: 1232(82.18812541694463%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:05:48.790307]: [Epoch: 1232(82.18812541694463%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:05:50.110317]: [Epoch: 1232(82.18812541694463%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:05:53.785590]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:05:53.905409]: ====================
[2018-04-17 18:05:53.910923]: Elapsed time since starting training: 2:10:39.306621
[2018-04-17 18:05:53.915435]: ====================
[2018-04-17 18:05:53.987126]: [Epoch: 1233(82.25483655770513%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:05:55.302623]: [Epoch: 1233(82.25483655770513%): Data: 25.333333333333336%]:Running loss: 4.350370958447456
[2018-04-17 18:05:56.655721]: [Epoch: 1233(82.25483655770513%): Data: 50.66666666666667%]:Running loss: 8.483223468065262
[2018-04-17 18:06:00.323474]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:06:00.477885]: ====================
[2018-04-17 18:06:00.483400]: Elapsed time since starting training: 2:10:45.879097
[2018-04-17 18:06:00.487912]: ====================
[2018-04-17 18:06:00.563112]: [Epoch: 1234(82.32154769846565%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:06:01.876102]: [Epoch: 1234(82.32154769846565%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:06:03.370075]: [Epoch: 1234(82.32154769846565%): Data: 50.66666666666667%]:Running loss: 8.483224332332611
[2018-04-17 18:06:07.115534]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:06:07.240367]: ====================
[2018-04-17 18:06:07.245380]: Elapsed time since starting training: 2:10:52.641579
[2018-04-17 18:06:07.249892]: ====================
[2018-04-17 18:06:07.317571]: [Epoch: 1235(82.38825883922615%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:06:08.743363]: [Epoch: 1235(82.38825883922615%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:06:10.032792]: [Epoch: 1235(82.38825883922615%): Data: 50.66666666666667%]:Running loss: 8.483225375413895
[2018-04-17 18:06:13.656430]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:06:13.784270]: ====================
[2018-04-17 18:06:13.789284]: Elapsed time since starting training: 2:10:59.184982
[2018-04-17 18:06:13.794297]: ====================
[2018-04-17 18:06:13.868996]: [Epoch: 1236(82.45496997998666%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:06:15.156920]: [Epoch: 1236(82.45496997998666%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:06:16.433314]: [Epoch: 1236(82.45496997998666%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:06:20.060458]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:06:20.191808]: ====================
[2018-04-17 18:06:20.197824]: Elapsed time since starting training: 2:11:05.594023
[2018-04-17 18:06:20.203339]: ====================
[2018-04-17 18:06:20.286059]: [Epoch: 1237(82.52168112074717%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:06:21.586015]: [Epoch: 1237(82.52168112074717%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:06:22.855891]: [Epoch: 1237(82.52168112074717%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:06:26.616391]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:06:26.750248]: ====================
[2018-04-17 18:06:26.754759]: Elapsed time since starting training: 2:11:12.150958
[2018-04-17 18:06:26.758770]: ====================
[2018-04-17 18:06:26.828455]: [Epoch: 1238(82.58839226150766%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:06:28.144454]: [Epoch: 1238(82.58839226150766%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:06:29.451429]: [Epoch: 1238(82.58839226150766%): Data: 50.66666666666667%]:Running loss: 8.483227327466011
[2018-04-17 18:06:33.067044]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:06:33.184857]: ====================
[2018-04-17 18:06:33.188867]: Elapsed time since starting training: 2:11:18.585066
[2018-04-17 18:06:33.192877]: ====================
[2018-04-17 18:06:33.261560]: [Epoch: 1239(82.65510340226818%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:06:34.551490]: [Epoch: 1239(82.65510340226818%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:06:35.844428]: [Epoch: 1239(82.65510340226818%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:06:39.400383]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:06:39.534240]: ====================
[2018-04-17 18:06:39.538752]: Elapsed time since starting training: 2:11:24.934951
[2018-04-17 18:06:39.543263]: ====================
[2018-04-17 18:06:39.615957]: [Epoch: 1240(82.72181454302869%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:06:40.886836]: [Epoch: 1240(82.72181454302869%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:06:42.151699]: [Epoch: 1240(82.72181454302869%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:06:45.635462]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:06:45.762801]: ====================
[2018-04-17 18:06:45.767815]: Elapsed time since starting training: 2:11:31.163512
[2018-04-17 18:06:45.772327]: ====================
[2018-04-17 18:06:45.840006]: [Epoch: 1241(82.78852568378919%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:06:47.115899]: [Epoch: 1241(82.78852568378919%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:06:48.381263]: [Epoch: 1241(82.78852568378919%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:06:51.944237]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:06:52.059544]: ====================
[2018-04-17 18:06:52.064557]: Elapsed time since starting training: 2:11:37.460756
[2018-04-17 18:06:52.070072]: ====================
[2018-04-17 18:06:52.138754]: [Epoch: 1242(82.8552368245497%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:06:53.412642]: [Epoch: 1242(82.8552368245497%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:06:54.671489]: [Epoch: 1242(82.8552368245497%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:06:58.202879]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:06:58.323199]: ====================
[2018-04-17 18:06:58.327714]: Elapsed time since starting training: 2:11:43.723409
[2018-04-17 18:06:58.333226]: ====================
[2018-04-17 18:06:58.402911]: [Epoch: 1243(82.92194796531021%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:06:59.706377]: [Epoch: 1243(82.92194796531021%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:07:00.982269]: [Epoch: 1243(82.92194796531021%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:07:04.514160]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:07:04.632977]: ====================
[2018-04-17 18:07:04.636987]: Elapsed time since starting training: 2:11:50.033186
[2018-04-17 18:07:04.641499]: ====================
[2018-04-17 18:07:04.715195]: [Epoch: 1244(82.98865910607071%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:07:05.985072]: [Epoch: 1244(82.98865910607071%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:07:07.248431]: [Epoch: 1244(82.98865910607071%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 18:07:10.771800]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:07:10.886605]: ====================
[2018-04-17 18:07:10.891117]: Elapsed time since starting training: 2:11:56.287316
[2018-04-17 18:07:10.895629]: ====================
[2018-04-17 18:07:10.962808]: [Epoch: 1245(83.05537024683122%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:07:12.213132]: [Epoch: 1245(83.05537024683122%): Data: 25.333333333333336%]:Running loss: 4.3503757417202
[2018-04-17 18:07:13.486518]: [Epoch: 1245(83.05537024683122%): Data: 50.66666666666667%]:Running loss: 8.48323306441307
[2018-04-17 18:07:17.023422]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 18:07:17.146249]: ====================
[2018-04-17 18:07:17.152265]: Elapsed time since starting training: 2:12:02.548464
[2018-04-17 18:07:17.157780]: ====================
[2018-04-17 18:07:17.236489]: [Epoch: 1246(83.12208138759173%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 18:07:18.521405]: [Epoch: 1246(83.12208138759173%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 18:07:19.782258]: [Epoch: 1246(83.12208138759173%): Data: 50.66666666666667%]:Running loss: 8.483233779668808
[2018-04-17 18:07:23.294598]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 18:07:23.410407]: ====================
[2018-04-17 18:07:23.415920]: Elapsed time since starting training: 2:12:08.811618
[2018-04-17 18:07:23.420433]: ====================
[2018-04-17 18:07:23.489617]: [Epoch: 1247(83.18879252835224%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 18:07:24.805615]: [Epoch: 1247(83.18879252835224%): Data: 25.333333333333336%]:Running loss: 4.350376725196838
[2018-04-17 18:07:26.087023]: [Epoch: 1247(83.18879252835224%): Data: 50.66666666666667%]:Running loss: 8.483225226402283
[2018-04-17 18:07:29.817442]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 18:07:29.932749]: ====================
[2018-04-17 18:07:29.937260]: Elapsed time since starting training: 2:12:15.333459
[2018-04-17 18:07:29.941773]: ====================
[2018-04-17 18:07:30.014466]: [Epoch: 1248(83.25550366911274%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 18:07:31.323948]: [Epoch: 1248(83.25550366911274%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 18:07:32.623403]: [Epoch: 1248(83.25550366911274%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 18:07:36.231998]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:07:36.342292]: ====================
[2018-04-17 18:07:36.346804]: Elapsed time since starting training: 2:12:21.742501
[2018-04-17 18:07:36.350814]: ====================
[2018-04-17 18:07:36.430025]: [Epoch: 1249(83.32221480987326%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:07:37.753543]: [Epoch: 1249(83.32221480987326%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:07:39.107143]: [Epoch: 1249(83.32221480987326%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:07:42.755349]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:07:42.876672]: ====================
[2018-04-17 18:07:42.882188]: Elapsed time since starting training: 2:12:28.278387
[2018-04-17 18:07:42.887200]: ====================
[2018-04-17 18:07:42.965408]: [Epoch: 1250(83.38892595063375%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:07:44.288426]: [Epoch: 1250(83.38892595063375%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:07:45.612452]: [Epoch: 1250(83.38892595063375%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:07:49.222049]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:07:49.330839]: ====================
[2018-04-17 18:07:49.334849]: Elapsed time since starting training: 2:12:34.731048
[2018-04-17 18:07:49.339362]: ====================
[2018-04-17 18:07:49.414561]: [Epoch: 1251(83.45563709139427%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:07:50.741089]: [Epoch: 1251(83.45563709139427%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:07:52.064609]: [Epoch: 1251(83.45563709139427%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:07:55.723838]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:07:55.855187]: ====================
[2018-04-17 18:07:55.859700]: Elapsed time since starting training: 2:12:41.255899
[2018-04-17 18:07:55.863710]: ====================
[2018-04-17 18:07:55.938910]: [Epoch: 1252(83.52234823215477%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:07:57.287496]: [Epoch: 1252(83.52234823215477%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:07:58.633576]: [Epoch: 1252(83.52234823215477%): Data: 50.66666666666667%]:Running loss: 8.483218431472778
[2018-04-17 18:08:02.198053]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:08:02.322384]: ====================
[2018-04-17 18:08:02.326394]: Elapsed time since starting training: 2:12:47.722593
[2018-04-17 18:08:02.330405]: ====================
[2018-04-17 18:08:02.399088]: [Epoch: 1253(83.58905937291527%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:08:03.812345]: [Epoch: 1253(83.58905937291527%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 18:08:05.336899]: [Epoch: 1253(83.58905937291527%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 18:08:09.186636]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:08:09.330017]: ====================
[2018-04-17 18:08:09.337537]: Elapsed time since starting training: 2:12:54.733736
[2018-04-17 18:08:09.343051]: ====================
[2018-04-17 18:08:09.416246]: [Epoch: 1254(83.65577051367579%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:08:10.752800]: [Epoch: 1254(83.65577051367579%): Data: 25.333333333333336%]:Running loss: 4.350368306040764
[2018-04-17 18:08:12.300415]: [Epoch: 1254(83.65577051367579%): Data: 50.66666666666667%]:Running loss: 8.48321883380413
[2018-04-17 18:08:16.139624]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:08:16.260445]: ====================
[2018-04-17 18:08:16.264957]: Elapsed time since starting training: 2:13:01.660654
[2018-04-17 18:08:16.269970]: ====================
[2018-04-17 18:08:16.346172]: [Epoch: 1255(83.7224816544363%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:08:17.650140]: [Epoch: 1255(83.7224816544363%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:08:18.928038]: [Epoch: 1255(83.7224816544363%): Data: 50.66666666666667%]:Running loss: 8.483219742774963
[2018-04-17 18:08:22.700067]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:08:22.825902]: ====================
[2018-04-17 18:08:22.830414]: Elapsed time since starting training: 2:13:08.226613
[2018-04-17 18:08:22.837433]: ====================
[2018-04-17 18:08:22.912132]: [Epoch: 1256(83.7891927951968%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:08:24.193538]: [Epoch: 1256(83.7891927951968%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:08:25.492994]: [Epoch: 1256(83.7891927951968%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:08:29.274047]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:08:29.440992]: ====================
[2018-04-17 18:08:29.446005]: Elapsed time since starting training: 2:13:14.841703
[2018-04-17 18:08:29.452522]: ====================
[2018-04-17 18:08:29.534741]: [Epoch: 1257(83.85590393595731%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:08:30.924937]: [Epoch: 1257(83.85590393595731%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 18:08:32.236424]: [Epoch: 1257(83.85590393595731%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 18:08:35.771825]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:08:35.893148]: ====================
[2018-04-17 18:08:35.897660]: Elapsed time since starting training: 2:13:21.293358
[2018-04-17 18:08:35.903175]: ====================
[2018-04-17 18:08:35.970855]: [Epoch: 1258(83.9226150767178%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:08:37.238224]: [Epoch: 1258(83.9226150767178%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:08:38.521637]: [Epoch: 1258(83.9226150767178%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:08:42.063563]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:08:42.301194]: ====================
[2018-04-17 18:08:42.306709]: Elapsed time since starting training: 2:13:27.702407
[2018-04-17 18:08:42.311221]: ====================
[2018-04-17 18:08:42.380405]: [Epoch: 1259(83.98932621747832%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:08:43.640756]: [Epoch: 1259(83.98932621747832%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:08:44.918654]: [Epoch: 1259(83.98932621747832%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:08:48.526246]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:08:48.662108]: ====================
[2018-04-17 18:08:48.667622]: Elapsed time since starting training: 2:13:34.063320
[2018-04-17 18:08:48.671633]: ====================
[2018-04-17 18:08:48.736305]: [Epoch: 1260(84.05603735823883%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:08:50.070352]: [Epoch: 1260(84.05603735823883%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:08:51.373818]: [Epoch: 1260(84.05603735823883%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:08:55.021517]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:08:55.135320]: ====================
[2018-04-17 18:08:55.140333]: Elapsed time since starting training: 2:13:40.536031
[2018-04-17 18:08:55.144344]: ====================
[2018-04-17 18:08:55.215033]: [Epoch: 1261(84.12274849899933%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:08:56.491927]: [Epoch: 1261(84.12274849899933%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:08:57.772833]: [Epoch: 1261(84.12274849899933%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:09:01.300213]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:09:01.419531]: ====================
[2018-04-17 18:09:01.424042]: Elapsed time since starting training: 2:13:46.819739
[2018-04-17 18:09:01.429055]: ====================
[2018-04-17 18:09:01.497737]: [Epoch: 1262(84.18945963975985%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:09:02.790675]: [Epoch: 1262(84.18945963975985%): Data: 25.333333333333336%]:Running loss: 4.350372210144997
[2018-04-17 18:09:04.069576]: [Epoch: 1262(84.18945963975985%): Data: 50.66666666666667%]:Running loss: 8.483225852251053
[2018-04-17 18:09:07.649595]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:09:07.763899]: ====================
[2018-04-17 18:09:07.768412]: Elapsed time since starting training: 2:13:53.164110
[2018-04-17 18:09:07.772422]: ====================
[2018-04-17 18:09:07.838107]: [Epoch: 1263(84.25617078052035%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:09:09.114992]: [Epoch: 1263(84.25617078052035%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:09:10.369828]: [Epoch: 1263(84.25617078052035%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:09:13.971411]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:09:14.097741]: ====================
[2018-04-17 18:09:14.102754]: Elapsed time since starting training: 2:13:59.498953
[2018-04-17 18:09:14.108271]: ====================
[2018-04-17 18:09:14.180969]: [Epoch: 1264(84.32288192128085%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:09:15.471895]: [Epoch: 1264(84.32288192128085%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:09:16.746785]: [Epoch: 1264(84.32288192128085%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:09:20.295721]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:09:20.425065]: ====================
[2018-04-17 18:09:20.431081]: Elapsed time since starting training: 2:14:05.827280
[2018-04-17 18:09:20.437097]: ====================
[2018-04-17 18:09:20.505278]: [Epoch: 1265(84.38959306204136%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:09:21.857374]: [Epoch: 1265(84.38959306204136%): Data: 25.333333333333336%]:Running loss: 4.35037299990654
[2018-04-17 18:09:23.323774]: [Epoch: 1265(84.38959306204136%): Data: 50.66666666666667%]:Running loss: 8.483227491378784
[2018-04-17 18:09:27.761072]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:09:27.948068]: ====================
[2018-04-17 18:09:27.956592]: Elapsed time since starting training: 2:14:13.352791
[2018-04-17 18:09:27.967621]: ====================
[2018-04-17 18:09:28.048336]: [Epoch: 1266(84.45630420280187%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:09:29.381881]: [Epoch: 1266(84.45630420280187%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:09:30.745005]: [Epoch: 1266(84.45630420280187%): Data: 50.66666666666667%]:Running loss: 8.483228489756584
[2018-04-17 18:09:34.417772]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:09:34.535586]: ====================
[2018-04-17 18:09:34.540097]: Elapsed time since starting training: 2:14:19.936296
[2018-04-17 18:09:34.545612]: ====================
[2018-04-17 18:09:34.618806]: [Epoch: 1267(84.52301534356238%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:09:35.908235]: [Epoch: 1267(84.52301534356238%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:09:37.170090]: [Epoch: 1267(84.52301534356238%): Data: 50.66666666666667%]:Running loss: 8.4832294434309
[2018-04-17 18:09:40.711506]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:09:40.827315]: ====================
[2018-04-17 18:09:40.832328]: Elapsed time since starting training: 2:14:26.228025
[2018-04-17 18:09:40.836840]: ====================
[2018-04-17 18:09:40.907026]: [Epoch: 1268(84.58972648432288%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:09:42.241575]: [Epoch: 1268(84.58972648432288%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:09:43.512454]: [Epoch: 1268(84.58972648432288%): Data: 50.66666666666667%]:Running loss: 8.483229905366898
[2018-04-17 18:09:47.114031]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:09:47.232346]: ====================
[2018-04-17 18:09:47.237359]: Elapsed time since starting training: 2:14:32.633558
[2018-04-17 18:09:47.241369]: ====================
[2018-04-17 18:09:47.309551]: [Epoch: 1269(84.65643762508338%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:09:48.614521]: [Epoch: 1269(84.65643762508338%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:09:49.890914]: [Epoch: 1269(84.65643762508338%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:09:53.497504]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:09:53.619329]: ====================
[2018-04-17 18:09:53.625846]: Elapsed time since starting training: 2:14:39.022045
[2018-04-17 18:09:53.630859]: ====================
[2018-04-17 18:09:53.697538]: [Epoch: 1270(84.72314876584389%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:09:54.958389]: [Epoch: 1270(84.72314876584389%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:09:56.222751]: [Epoch: 1270(84.72314876584389%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:09:59.778707]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:09:59.912562]: ====================
[2018-04-17 18:09:59.917074]: Elapsed time since starting training: 2:14:45.312772
[2018-04-17 18:09:59.921587]: ====================
[2018-04-17 18:09:59.988766]: [Epoch: 1271(84.7898599066044%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:10:01.280700]: [Epoch: 1271(84.7898599066044%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:10:02.538544]: [Epoch: 1271(84.7898599066044%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:10:06.156168]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:10:06.296542]: ====================
[2018-04-17 18:10:06.304061]: Elapsed time since starting training: 2:14:51.699759
[2018-04-17 18:10:06.308573]: ====================
[2018-04-17 18:10:06.381768]: [Epoch: 1272(84.85657104736491%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:10:07.707793]: [Epoch: 1272(84.85657104736491%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:10:09.000230]: [Epoch: 1272(84.85657104736491%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:10:12.642414]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:10:12.763235]: ====================
[2018-04-17 18:10:12.770255]: Elapsed time since starting training: 2:14:58.166454
[2018-04-17 18:10:12.774767]: ====================
[2018-04-17 18:10:12.842446]: [Epoch: 1273(84.92328218812541%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:10:14.203065]: [Epoch: 1273(84.92328218812541%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:10:15.518061]: [Epoch: 1273(84.92328218812541%): Data: 50.66666666666667%]:Running loss: 8.483231827616692
[2018-04-17 18:10:19.170272]: Test set accuracy: 94.33962264150944% ,loss = 5.437956750392914
[2018-04-17 18:10:19.299617]: ====================
[2018-04-17 18:10:19.304128]: Elapsed time since starting training: 2:15:04.699826
[2018-04-17 18:10:19.309141]: ====================
[2018-04-17 18:10:19.378325]: [Epoch: 1274(84.98999332888593%): Data: 0.0%]:Running loss: 0.21751827001571655
[2018-04-17 18:10:20.676778]: [Epoch: 1274(84.98999332888593%): Data: 25.333333333333336%]:Running loss: 4.350365787744522
[2018-04-17 18:10:21.948158]: [Epoch: 1274(84.98999332888593%): Data: 50.66666666666667%]:Running loss: 8.483213484287262
[2018-04-17 18:10:25.478546]: Test set accuracy: 94.33962264150944% ,loss = 5.4379574954509735
[2018-04-17 18:10:25.607890]: ====================
[2018-04-17 18:10:25.612903]: Elapsed time since starting training: 2:15:11.009102
[2018-04-17 18:10:25.617415]: ====================
[2018-04-17 18:10:25.691112]: [Epoch: 1275(85.05670446964643%): Data: 0.0%]:Running loss: 0.21751829981803894
[2018-04-17 18:10:26.993073]: [Epoch: 1275(85.05670446964643%): Data: 25.333333333333336%]:Running loss: 4.350365996360779
[2018-04-17 18:10:28.262950]: [Epoch: 1275(85.05670446964643%): Data: 50.66666666666667%]:Running loss: 8.48321445286274
[2018-04-17 18:10:31.935715]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 18:10:32.071076]: ====================
[2018-04-17 18:10:32.075587]: Elapsed time since starting training: 2:15:17.471786
[2018-04-17 18:10:32.080099]: ====================
[2018-04-17 18:10:32.162820]: [Epoch: 1276(85.12341561040694%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 18:10:33.468792]: [Epoch: 1276(85.12341561040694%): Data: 25.333333333333336%]:Running loss: 4.35036689043045
[2018-04-17 18:10:34.779778]: [Epoch: 1276(85.12341561040694%): Data: 50.66666666666667%]:Running loss: 8.4832154661417
[2018-04-17 18:10:38.297631]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 18:10:38.410933]: ====================
[2018-04-17 18:10:38.414944]: Elapsed time since starting training: 2:15:23.811143
[2018-04-17 18:10:38.419455]: ====================
[2018-04-17 18:10:38.493152]: [Epoch: 1277(85.19012675116745%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 18:10:39.771050]: [Epoch: 1277(85.19012675116745%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 18:10:41.037417]: [Epoch: 1277(85.19012675116745%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 18:10:44.627462]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:10:44.752796]: ====================
[2018-04-17 18:10:44.758310]: Elapsed time since starting training: 2:15:30.154509
[2018-04-17 18:10:44.762321]: ====================
[2018-04-17 18:10:44.838525]: [Epoch: 1278(85.25683789192794%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:10:46.142491]: [Epoch: 1278(85.25683789192794%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 18:10:47.471525]: [Epoch: 1278(85.25683789192794%): Data: 50.66666666666667%]:Running loss: 8.483216598629951
[2018-04-17 18:10:51.236034]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:10:51.352345]: ====================
[2018-04-17 18:10:51.357358]: Elapsed time since starting training: 2:15:36.753055
[2018-04-17 18:10:51.361869]: ====================
[2018-04-17 18:10:51.436067]: [Epoch: 1279(85.32354903268846%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:10:52.735020]: [Epoch: 1279(85.32354903268846%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 18:10:54.057036]: [Epoch: 1279(85.32354903268846%): Data: 50.66666666666667%]:Running loss: 8.483216881752014
[2018-04-17 18:10:57.649087]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:10:57.768404]: ====================
[2018-04-17 18:10:57.774420]: Elapsed time since starting training: 2:15:43.170619
[2018-04-17 18:10:57.779433]: ====================
[2018-04-17 18:10:57.850623]: [Epoch: 1280(85.39026017344897%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:10:59.132030]: [Epoch: 1280(85.39026017344897%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 18:11:00.424466]: [Epoch: 1280(85.39026017344897%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 18:11:04.013509]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:11:04.129319]: ====================
[2018-04-17 18:11:04.133829]: Elapsed time since starting training: 2:15:49.530028
[2018-04-17 18:11:04.138843]: ====================
[2018-04-17 18:11:04.206022]: [Epoch: 1281(85.45697131420947%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:11:05.494949]: [Epoch: 1281(85.45697131420947%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:11:06.760313]: [Epoch: 1281(85.45697131420947%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 18:11:10.330808]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:11:10.456643]: ====================
[2018-04-17 18:11:10.461656]: Elapsed time since starting training: 2:15:55.857855
[2018-04-17 18:11:10.466167]: ====================
[2018-04-17 18:11:10.543373]: [Epoch: 1282(85.52368245496999%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:11:11.807734]: [Epoch: 1282(85.52368245496999%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:11:13.076118]: [Epoch: 1282(85.52368245496999%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 18:11:16.647604]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:11:16.770932]: ====================
[2018-04-17 18:11:16.775945]: Elapsed time since starting training: 2:16:02.171643
[2018-04-17 18:11:16.780959]: ====================
[2018-04-17 18:11:16.850142]: [Epoch: 1283(85.59039359573049%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:11:18.114003]: [Epoch: 1283(85.59039359573049%): Data: 25.333333333333336%]:Running loss: 4.350369438529015
[2018-04-17 18:11:19.388391]: [Epoch: 1283(85.59039359573049%): Data: 50.66666666666667%]:Running loss: 8.483220532536507
[2018-04-17 18:11:22.972421]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:11:23.092743]: ====================
[2018-04-17 18:11:23.097756]: Elapsed time since starting training: 2:16:08.493955
[2018-04-17 18:11:23.102267]: ====================
[2018-04-17 18:11:23.174960]: [Epoch: 1284(85.657104736491%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:11:24.444837]: [Epoch: 1284(85.657104736491%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:11:25.711706]: [Epoch: 1284(85.657104736491%): Data: 50.66666666666667%]:Running loss: 8.483221232891083
[2018-04-17 18:11:29.250615]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:11:29.363916]: ====================
[2018-04-17 18:11:29.368428]: Elapsed time since starting training: 2:16:14.764126
[2018-04-17 18:11:29.372940]: ====================
[2018-04-17 18:11:29.443629]: [Epoch: 1285(85.7238158772515%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:11:30.732054]: [Epoch: 1285(85.7238158772515%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:11:31.994912]: [Epoch: 1285(85.7238158772515%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:11:35.537331]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:11:35.659657]: ====================
[2018-04-17 18:11:35.663668]: Elapsed time since starting training: 2:16:21.059867
[2018-04-17 18:11:35.668179]: ====================
[2018-04-17 18:11:35.736869]: [Epoch: 1286(85.79052701801201%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:11:36.999720]: [Epoch: 1286(85.79052701801201%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:11:38.291154]: [Epoch: 1286(85.79052701801201%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:11:41.836080]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:11:41.963418]: ====================
[2018-04-17 18:11:41.968433]: Elapsed time since starting training: 2:16:27.364130
[2018-04-17 18:11:41.972944]: ====================
[2018-04-17 18:11:42.042629]: [Epoch: 1287(85.85723815877252%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:11:43.329551]: [Epoch: 1287(85.85723815877252%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:11:44.578371]: [Epoch: 1287(85.85723815877252%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 18:11:48.140844]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:11:48.259662]: ====================
[2018-04-17 18:11:48.264673]: Elapsed time since starting training: 2:16:33.660872
[2018-04-17 18:11:48.269185]: ====================
[2018-04-17 18:11:48.347894]: [Epoch: 1288(85.92394929953302%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:11:49.642838]: [Epoch: 1288(85.92394929953302%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:11:50.927754]: [Epoch: 1288(85.92394929953302%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:11:54.480702]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:11:54.597512]: ====================
[2018-04-17 18:11:54.602024]: Elapsed time since starting training: 2:16:39.998223
[2018-04-17 18:11:54.607038]: ====================
[2018-04-17 18:11:54.679229]: [Epoch: 1289(85.99066044029354%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:11:55.946098]: [Epoch: 1289(85.99066044029354%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:11:57.211462]: [Epoch: 1289(85.99066044029354%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:12:00.750874]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:12:00.868186]: ====================
[2018-04-17 18:12:00.872698]: Elapsed time since starting training: 2:16:46.268897
[2018-04-17 18:12:00.878714]: ====================
[2018-04-17 18:12:00.948901]: [Epoch: 1290(86.05737158105403%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:12:02.213764]: [Epoch: 1290(86.05737158105403%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:12:03.496181]: [Epoch: 1290(86.05737158105403%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:12:07.038593]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:12:07.153398]: ====================
[2018-04-17 18:12:07.158412]: Elapsed time since starting training: 2:16:52.554611
[2018-04-17 18:12:07.163926]: ====================
[2018-04-17 18:12:07.235617]: [Epoch: 1291(86.12408272181455%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:12:08.498475]: [Epoch: 1291(86.12408272181455%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:12:09.761834]: [Epoch: 1291(86.12408272181455%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:12:13.307763]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:12:13.428083]: ====================
[2018-04-17 18:12:13.432595]: Elapsed time since starting training: 2:16:58.828292
[2018-04-17 18:12:13.436605]: ====================
[2018-04-17 18:12:13.503784]: [Epoch: 1292(86.19079386257505%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:12:14.793213]: [Epoch: 1292(86.19079386257505%): Data: 25.333333333333336%]:Running loss: 4.350373446941376
[2018-04-17 18:12:16.063316]: [Epoch: 1292(86.19079386257505%): Data: 50.66666666666667%]:Running loss: 8.483228504657745
[2018-04-17 18:12:19.601725]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:12:19.717533]: ====================
[2018-04-17 18:12:19.722046]: Elapsed time since starting training: 2:17:05.117743
[2018-04-17 18:12:19.726557]: ====================
[2018-04-17 18:12:19.797746]: [Epoch: 1293(86.25750500333555%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:12:21.071634]: [Epoch: 1293(86.25750500333555%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:12:22.341510]: [Epoch: 1293(86.25750500333555%): Data: 50.66666666666667%]:Running loss: 8.483228981494904
[2018-04-17 18:12:25.901477]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:12:26.020293]: ====================
[2018-04-17 18:12:26.024804]: Elapsed time since starting training: 2:17:11.421003
[2018-04-17 18:12:26.030319]: ====================
[2018-04-17 18:12:26.105519]: [Epoch: 1294(86.32421614409607%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:12:27.383918]: [Epoch: 1294(86.32421614409607%): Data: 25.333333333333336%]:Running loss: 4.350372791290283
[2018-04-17 18:12:28.644771]: [Epoch: 1294(86.32421614409607%): Data: 50.66666666666667%]:Running loss: 8.48322643339634
[2018-04-17 18:12:32.159115]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:12:32.279937]: ====================
[2018-04-17 18:12:32.284949]: Elapsed time since starting training: 2:17:17.681148
[2018-04-17 18:12:32.289462]: ====================
[2018-04-17 18:12:32.359147]: [Epoch: 1295(86.39092728485657%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:12:33.648074]: [Epoch: 1295(86.39092728485657%): Data: 25.333333333333336%]:Running loss: 4.350372493267059
[2018-04-17 18:12:34.912937]: [Epoch: 1295(86.39092728485657%): Data: 50.66666666666667%]:Running loss: 8.483226701617241
[2018-04-17 18:12:38.469895]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:12:38.586706]: ====================
[2018-04-17 18:12:38.591218]: Elapsed time since starting training: 2:17:23.987417
[2018-04-17 18:12:38.596734]: ====================
[2018-04-17 18:12:38.665917]: [Epoch: 1296(86.45763842561708%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:12:39.921254]: [Epoch: 1296(86.45763842561708%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:12:41.196145]: [Epoch: 1296(86.45763842561708%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:12:44.752100]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:12:44.865401]: ====================
[2018-04-17 18:12:44.869914]: Elapsed time since starting training: 2:17:30.266113
[2018-04-17 18:12:44.874425]: ====================
[2018-04-17 18:12:44.944612]: [Epoch: 1297(86.5243495663776%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:12:46.195437]: [Epoch: 1297(86.5243495663776%): Data: 25.333333333333336%]:Running loss: 4.350373074412346
[2018-04-17 18:12:47.468322]: [Epoch: 1297(86.5243495663776%): Data: 50.66666666666667%]:Running loss: 8.483228132128716
[2018-04-17 18:12:51.016256]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:12:51.139084]: ====================
[2018-04-17 18:12:51.143596]: Elapsed time since starting training: 2:17:36.539795
[2018-04-17 18:12:51.147605]: ====================
[2018-04-17 18:12:51.222304]: [Epoch: 1298(86.59106070713808%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:12:52.497695]: [Epoch: 1298(86.59106070713808%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:12:53.781610]: [Epoch: 1298(86.59106070713808%): Data: 50.66666666666667%]:Running loss: 8.483228892087936
[2018-04-17 18:12:57.307485]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:12:57.423794]: ====================
[2018-04-17 18:12:57.428807]: Elapsed time since starting training: 2:17:42.824505
[2018-04-17 18:12:57.432818]: ====================
[2018-04-17 18:12:57.504007]: [Epoch: 1299(86.6577718478986%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:12:58.778396]: [Epoch: 1299(86.6577718478986%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:13:00.046768]: [Epoch: 1299(86.6577718478986%): Data: 50.66666666666667%]:Running loss: 8.483229249715805
[2018-04-17 18:13:03.571641]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:13:03.687950]: ====================
[2018-04-17 18:13:03.692462]: Elapsed time since starting training: 2:17:49.088661
[2018-04-17 18:13:03.697977]: ====================
[2018-04-17 18:13:03.771673]: [Epoch: 1300(86.7244829886591%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:13:05.053080]: [Epoch: 1300(86.7244829886591%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:13:06.322956]: [Epoch: 1300(86.7244829886591%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:13:09.829781]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:13:09.946592]: ====================
[2018-04-17 18:13:09.951605]: Elapsed time since starting training: 2:17:55.347304
[2018-04-17 18:13:09.956118]: ====================
[2018-04-17 18:13:10.021792]: [Epoch: 1301(86.79119412941961%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:13:11.285652]: [Epoch: 1301(86.79119412941961%): Data: 25.333333333333336%]:Running loss: 4.3503741174936295
[2018-04-17 18:13:12.559540]: [Epoch: 1301(86.79119412941961%): Data: 50.66666666666667%]:Running loss: 8.483229741454124
[2018-04-17 18:13:16.156103]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:13:16.280935]: ====================
[2018-04-17 18:13:16.287954]: Elapsed time since starting training: 2:18:01.684153
[2018-04-17 18:13:16.292465]: ====================
[2018-04-17 18:13:16.362151]: [Epoch: 1302(86.85790527018013%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:13:17.620998]: [Epoch: 1302(86.85790527018013%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:13:18.859792]: [Epoch: 1302(86.85790527018013%): Data: 50.66666666666667%]:Running loss: 8.483230084180832
[2018-04-17 18:13:22.433303]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:13:22.553622]: ====================
[2018-04-17 18:13:22.558636]: Elapsed time since starting training: 2:18:07.954333
[2018-04-17 18:13:22.563147]: ====================
[2018-04-17 18:13:22.636343]: [Epoch: 1303(86.92461641094063%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:13:23.903211]: [Epoch: 1303(86.92461641094063%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:13:25.167573]: [Epoch: 1303(86.92461641094063%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:13:28.723528]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:13:28.968179]: ====================
[2018-04-17 18:13:28.973694]: Elapsed time since starting training: 2:18:14.369893
[2018-04-17 18:13:28.981213]: ====================
[2018-04-17 18:13:29.053405]: [Epoch: 1304(86.99132755170113%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:13:30.347346]: [Epoch: 1304(86.99132755170113%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:13:31.616722]: [Epoch: 1304(86.99132755170113%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:13:35.169669]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:13:35.286479]: ====================
[2018-04-17 18:13:35.291493]: Elapsed time since starting training: 2:18:20.687190
[2018-04-17 18:13:35.296004]: ====================
[2018-04-17 18:13:35.365690]: [Epoch: 1305(87.05803869246164%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:13:36.649604]: [Epoch: 1305(87.05803869246164%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:13:37.917983]: [Epoch: 1305(87.05803869246164%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:13:41.454887]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:13:41.569193]: ====================
[2018-04-17 18:13:41.574706]: Elapsed time since starting training: 2:18:26.970404
[2018-04-17 18:13:41.581224]: ====================
[2018-04-17 18:13:41.650908]: [Epoch: 1306(87.12474983322215%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:13:42.914268]: [Epoch: 1306(87.12474983322215%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:13:44.184144]: [Epoch: 1306(87.12474983322215%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:13:47.709518]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:13:47.823822]: ====================
[2018-04-17 18:13:47.829840]: Elapsed time since starting training: 2:18:33.225536
[2018-04-17 18:13:47.833849]: ====================
[2018-04-17 18:13:47.900526]: [Epoch: 1307(87.19146097398266%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:13:49.168899]: [Epoch: 1307(87.19146097398266%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:13:50.430760]: [Epoch: 1307(87.19146097398266%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:13:53.966154]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:13:54.082966]: ====================
[2018-04-17 18:13:54.087478]: Elapsed time since starting training: 2:18:39.483175
[2018-04-17 18:13:54.092491]: ====================
[2018-04-17 18:13:54.160672]: [Epoch: 1308(87.25817211474316%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:13:55.431050]: [Epoch: 1308(87.25817211474316%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:13:56.696928]: [Epoch: 1308(87.25817211474316%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 18:14:00.226300]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:14:00.342108]: ====================
[2018-04-17 18:14:00.346621]: Elapsed time since starting training: 2:18:45.742820
[2018-04-17 18:14:00.351634]: ====================
[2018-04-17 18:14:00.423324]: [Epoch: 1309(87.32488325550366%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:14:01.706236]: [Epoch: 1309(87.32488325550366%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:14:02.970099]: [Epoch: 1309(87.32488325550366%): Data: 50.66666666666667%]:Running loss: 8.483219996094704
[2018-04-17 18:14:06.525049]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:14:06.642862]: ====================
[2018-04-17 18:14:06.647374]: Elapsed time since starting training: 2:18:52.043573
[2018-04-17 18:14:06.651886]: ====================
[2018-04-17 18:14:06.721571]: [Epoch: 1310(87.39159439626417%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:14:08.017016]: [Epoch: 1310(87.39159439626417%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:14:09.277868]: [Epoch: 1310(87.39159439626417%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:14:12.858389]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:14:12.976704]: ====================
[2018-04-17 18:14:12.981717]: Elapsed time since starting training: 2:18:58.377415
[2018-04-17 18:14:12.985728]: ====================
[2018-04-17 18:14:13.055914]: [Epoch: 1311(87.45830553702469%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:14:14.320276]: [Epoch: 1311(87.45830553702469%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:14:15.582633]: [Epoch: 1311(87.45830553702469%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:14:19.363192]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:14:19.478500]: ====================
[2018-04-17 18:14:19.483512]: Elapsed time since starting training: 2:19:04.879711
[2018-04-17 18:14:19.488025]: ====================
[2018-04-17 18:14:19.556707]: [Epoch: 1312(87.52501667778519%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:14:20.915821]: [Epoch: 1312(87.52501667778519%): Data: 25.333333333333336%]:Running loss: 4.3503707498312
[2018-04-17 18:14:22.183692]: [Epoch: 1312(87.52501667778519%): Data: 50.66666666666667%]:Running loss: 8.483222976326942
[2018-04-17 18:14:25.726112]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:14:25.842422]: ====================
[2018-04-17 18:14:25.846431]: Elapsed time since starting training: 2:19:11.242630
[2018-04-17 18:14:25.850943]: ====================
[2018-04-17 18:14:25.922634]: [Epoch: 1313(87.59172781854569%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:14:27.185492]: [Epoch: 1313(87.59172781854569%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:14:28.487454]: [Epoch: 1313(87.59172781854569%): Data: 50.66666666666667%]:Running loss: 8.483223259449005
[2018-04-17 18:14:32.067473]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:14:32.192306]: ====================
[2018-04-17 18:14:32.197319]: Elapsed time since starting training: 2:19:17.593016
[2018-04-17 18:14:32.202332]: ====================
[2018-04-17 18:14:32.274023]: [Epoch: 1314(87.65843895930621%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:14:33.554427]: [Epoch: 1314(87.65843895930621%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:14:34.821295]: [Epoch: 1314(87.65843895930621%): Data: 50.66666666666667%]:Running loss: 8.483223155140877
[2018-04-17 18:14:38.407331]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:14:38.523640]: ====================
[2018-04-17 18:14:38.528153]: Elapsed time since starting training: 2:19:23.923850
[2018-04-17 18:14:38.533167]: ====================
[2018-04-17 18:14:38.602851]: [Epoch: 1315(87.72515010006671%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:14:39.905815]: [Epoch: 1315(87.72515010006671%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:14:41.167169]: [Epoch: 1315(87.72515010006671%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:14:44.680010]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:14:44.801834]: ====================
[2018-04-17 18:14:44.805845]: Elapsed time since starting training: 2:19:30.202044
[2018-04-17 18:14:44.810356]: ====================
[2018-04-17 18:14:44.879541]: [Epoch: 1316(87.79186124082722%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:14:46.134377]: [Epoch: 1316(87.79186124082722%): Data: 25.333333333333336%]:Running loss: 4.35037088394165
[2018-04-17 18:14:47.407763]: [Epoch: 1316(87.79186124082722%): Data: 50.66666666666667%]:Running loss: 8.483223676681519
[2018-04-17 18:14:50.973243]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:14:51.092060]: ====================
[2018-04-17 18:14:51.096571]: Elapsed time since starting training: 2:19:36.492270
[2018-04-17 18:14:51.101585]: ====================
[2018-04-17 18:14:51.170268]: [Epoch: 1317(87.85857238158773%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:14:52.440144]: [Epoch: 1317(87.85857238158773%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:14:53.701999]: [Epoch: 1317(87.85857238158773%): Data: 50.66666666666667%]:Running loss: 8.483224466443062
[2018-04-17 18:14:57.235896]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:14:57.354210]: ====================
[2018-04-17 18:14:57.358722]: Elapsed time since starting training: 2:19:42.754921
[2018-04-17 18:14:57.363736]: ====================
[2018-04-17 18:14:57.433422]: [Epoch: 1318(87.92528352234822%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:14:58.722849]: [Epoch: 1318(87.92528352234822%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:14:59.983201]: [Epoch: 1318(87.92528352234822%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:15:03.555714]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:15:03.675533]: ====================
[2018-04-17 18:15:03.681048]: Elapsed time since starting training: 2:19:49.077247
[2018-04-17 18:15:03.685559]: ====================
[2018-04-17 18:15:03.756247]: [Epoch: 1319(87.99199466310874%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:15:05.021612]: [Epoch: 1319(87.99199466310874%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:15:06.288982]: [Epoch: 1319(87.99199466310874%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:15:09.855967]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:15:09.977289]: ====================
[2018-04-17 18:15:09.983306]: Elapsed time since starting training: 2:19:55.379003
[2018-04-17 18:15:09.987817]: ====================
[2018-04-17 18:15:10.058004]: [Epoch: 1320(88.05870580386924%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:15:11.341416]: [Epoch: 1320(88.05870580386924%): Data: 25.333333333333336%]:Running loss: 4.350372672080994
[2018-04-17 18:15:12.636861]: [Epoch: 1320(88.05870580386924%): Data: 50.66666666666667%]:Running loss: 8.4832251816988
[2018-04-17 18:15:16.223899]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:15:16.337701]: ====================
[2018-04-17 18:15:16.342213]: Elapsed time since starting training: 2:20:01.738412
[2018-04-17 18:15:16.347728]: ====================
[2018-04-17 18:15:16.422928]: [Epoch: 1321(88.12541694462975%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:15:17.716868]: [Epoch: 1321(88.12541694462975%): Data: 25.333333333333336%]:Running loss: 4.350371301174164
[2018-04-17 18:15:19.003790]: [Epoch: 1321(88.12541694462975%): Data: 50.66666666666667%]:Running loss: 8.483224093914032
[2018-04-17 18:15:22.569772]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:15:22.693100]: ====================
[2018-04-17 18:15:22.698113]: Elapsed time since starting training: 2:20:08.094312
[2018-04-17 18:15:22.703127]: ====================
[2018-04-17 18:15:22.776322]: [Epoch: 1322(88.19212808539027%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:15:24.042187]: [Epoch: 1322(88.19212808539027%): Data: 25.333333333333336%]:Running loss: 4.350371390581131
[2018-04-17 18:15:25.302539]: [Epoch: 1322(88.19212808539027%): Data: 50.66666666666667%]:Running loss: 8.483224749565125
[2018-04-17 18:15:28.855989]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:15:28.974302]: ====================
[2018-04-17 18:15:28.979817]: Elapsed time since starting training: 2:20:14.376016
[2018-04-17 18:15:28.985331]: ====================
[2018-04-17 18:15:29.054014]: [Epoch: 1323(88.25883922615077%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:15:30.333917]: [Epoch: 1323(88.25883922615077%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:15:31.583740]: [Epoch: 1323(88.25883922615077%): Data: 50.66666666666667%]:Running loss: 8.483225405216217
[2018-04-17 18:15:35.150725]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:15:35.273051]: ====================
[2018-04-17 18:15:35.279567]: Elapsed time since starting training: 2:20:20.675766
[2018-04-17 18:15:35.284581]: ====================
[2018-04-17 18:15:35.353766]: [Epoch: 1324(88.32555036691127%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:15:36.618127]: [Epoch: 1324(88.32555036691127%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:15:37.897529]: [Epoch: 1324(88.32555036691127%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:15:41.405356]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:15:41.527180]: ====================
[2018-04-17 18:15:41.531692]: Elapsed time since starting training: 2:20:26.927390
[2018-04-17 18:15:41.536212]: ====================
[2018-04-17 18:15:41.609399]: [Epoch: 1325(88.39226150767178%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:15:42.890806]: [Epoch: 1325(88.39226150767178%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:15:44.191264]: [Epoch: 1325(88.39226150767178%): Data: 50.66666666666667%]:Running loss: 8.483227550983429
[2018-04-17 18:15:47.723656]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:15:47.839466]: ====================
[2018-04-17 18:15:47.843976]: Elapsed time since starting training: 2:20:33.239674
[2018-04-17 18:15:47.847987]: ====================
[2018-04-17 18:15:47.918174]: [Epoch: 1326(88.4589726484323%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:15:49.197074]: [Epoch: 1326(88.4589726484323%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:15:50.470460]: [Epoch: 1326(88.4589726484323%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:15:53.981796]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:15:54.102117]: ====================
[2018-04-17 18:15:54.106128]: Elapsed time since starting training: 2:20:39.502327
[2018-04-17 18:15:54.110640]: ====================
[2018-04-17 18:15:54.180324]: [Epoch: 1327(88.5256837891928%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:15:55.469252]: [Epoch: 1327(88.5256837891928%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:15:56.748152]: [Epoch: 1327(88.5256837891928%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:16:00.301601]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:16:00.419917]: ====================
[2018-04-17 18:16:00.424428]: Elapsed time since starting training: 2:20:45.820627
[2018-04-17 18:16:00.429441]: ====================
[2018-04-17 18:16:00.504641]: [Epoch: 1328(88.5923949299533%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:16:01.773514]: [Epoch: 1328(88.5923949299533%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:16:03.059935]: [Epoch: 1328(88.5923949299533%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:16:06.702629]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:16:06.823450]: ====================
[2018-04-17 18:16:06.827962]: Elapsed time since starting training: 2:20:52.223659
[2018-04-17 18:16:06.832473]: ====================
[2018-04-17 18:16:06.902660]: [Epoch: 1329(88.65910607071382%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:16:08.190584]: [Epoch: 1329(88.65910607071382%): Data: 25.333333333333336%]:Running loss: 4.350374415516853
[2018-04-17 18:16:09.454947]: [Epoch: 1329(88.65910607071382%): Data: 50.66666666666667%]:Running loss: 8.483230322599411
[2018-04-17 18:16:13.003382]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:16:13.125206]: ====================
[2018-04-17 18:16:13.129728]: Elapsed time since starting training: 2:20:58.525927
[2018-04-17 18:16:13.134231]: ====================
[2018-04-17 18:16:13.207926]: [Epoch: 1330(88.72581721147431%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:16:14.489333]: [Epoch: 1330(88.72581721147431%): Data: 25.333333333333336%]:Running loss: 4.350374788045883
[2018-04-17 18:16:15.760714]: [Epoch: 1330(88.72581721147431%): Data: 50.66666666666667%]:Running loss: 8.483230888843536
[2018-04-17 18:16:19.322685]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:16:19.458044]: ====================
[2018-04-17 18:16:19.463058]: Elapsed time since starting training: 2:21:04.858756
[2018-04-17 18:16:19.467570]: ====================
[2018-04-17 18:16:19.537256]: [Epoch: 1331(88.79252835223483%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:16:20.804124]: [Epoch: 1331(88.79252835223483%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:16:22.052945]: [Epoch: 1331(88.79252835223483%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 18:16:25.612911]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:16:25.732729]: ====================
[2018-04-17 18:16:25.737241]: Elapsed time since starting training: 2:21:11.133440
[2018-04-17 18:16:25.741753]: ====================
[2018-04-17 18:16:25.812944]: [Epoch: 1332(88.85923949299533%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:16:27.068280]: [Epoch: 1332(88.85923949299533%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:16:28.349687]: [Epoch: 1332(88.85923949299533%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 18:16:31.860523]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:16:31.994380]: ====================
[2018-04-17 18:16:32.001397]: Elapsed time since starting training: 2:21:17.397596
[2018-04-17 18:16:32.007915]: ====================
[2018-04-17 18:16:32.077099]: [Epoch: 1333(88.92595063375583%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:16:33.341962]: [Epoch: 1333(88.92595063375583%): Data: 25.333333333333336%]:Running loss: 4.350376009941101
[2018-04-17 18:16:34.609833]: [Epoch: 1333(88.92595063375583%): Data: 50.66666666666667%]:Running loss: 8.483233332633972
[2018-04-17 18:16:38.195868]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 18:16:38.344765]: ====================
[2018-04-17 18:16:38.349778]: Elapsed time since starting training: 2:21:23.745977
[2018-04-17 18:16:38.354791]: ====================
[2018-04-17 18:16:38.425980]: [Epoch: 1334(88.99266177451635%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 18:16:39.699366]: [Epoch: 1334(88.99266177451635%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 18:16:40.959216]: [Epoch: 1334(88.99266177451635%): Data: 50.66666666666667%]:Running loss: 8.483233898878098
[2018-04-17 18:16:44.495118]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 18:16:44.631983]: ====================
[2018-04-17 18:16:44.636996]: Elapsed time since starting training: 2:21:30.033195
[2018-04-17 18:16:44.641510]: ====================
[2018-04-17 18:16:44.711193]: [Epoch: 1335(89.05937291527685%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 18:16:45.967533]: [Epoch: 1335(89.05937291527685%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 18:16:47.257463]: [Epoch: 1335(89.05937291527685%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 18:16:50.784843]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 18:16:50.910176]: ====================
[2018-04-17 18:16:50.914688]: Elapsed time since starting training: 2:21:36.310887
[2018-04-17 18:16:50.919200]: ====================
[2018-04-17 18:16:50.993397]: [Epoch: 1336(89.12608405603736%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 18:16:52.264277]: [Epoch: 1336(89.12608405603736%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 18:16:53.523124]: [Epoch: 1336(89.12608405603736%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 18:16:57.054012]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:16:57.179345]: ====================
[2018-04-17 18:16:57.184359]: Elapsed time since starting training: 2:21:42.580056
[2018-04-17 18:16:57.188871]: ====================
[2018-04-17 18:16:57.259559]: [Epoch: 1337(89.19279519679787%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:16:58.520411]: [Epoch: 1337(89.19279519679787%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:16:59.777253]: [Epoch: 1337(89.19279519679787%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:17:03.298115]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:17:03.422446]: ====================
[2018-04-17 18:17:03.426958]: Elapsed time since starting training: 2:21:48.823157
[2018-04-17 18:17:03.431971]: ====================
[2018-04-17 18:17:03.505668]: [Epoch: 1338(89.25950633755836%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:17:04.772535]: [Epoch: 1338(89.25950633755836%): Data: 25.333333333333336%]:Running loss: 4.3503682762384415
[2018-04-17 18:17:06.042914]: [Epoch: 1338(89.25950633755836%): Data: 50.66666666666667%]:Running loss: 8.483218520879745
[2018-04-17 18:17:09.569792]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:17:09.692618]: ====================
[2018-04-17 18:17:09.696628]: Elapsed time since starting training: 2:21:55.092827
[2018-04-17 18:17:09.701642]: ====================
[2018-04-17 18:17:09.774335]: [Epoch: 1339(89.32621747831888%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:17:11.083316]: [Epoch: 1339(89.32621747831888%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:17:12.356201]: [Epoch: 1339(89.32621747831888%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:17:15.916166]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:17:16.043004]: ====================
[2018-04-17 18:17:16.047516]: Elapsed time since starting training: 2:22:01.443715
[2018-04-17 18:17:16.052028]: ====================
[2018-04-17 18:17:16.122214]: [Epoch: 1340(89.39292861907938%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:17:17.391088]: [Epoch: 1340(89.39292861907938%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:17:18.659461]: [Epoch: 1340(89.39292861907938%): Data: 50.66666666666667%]:Running loss: 8.483219251036644
[2018-04-17 18:17:22.199874]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:17:22.322702]: ====================
[2018-04-17 18:17:22.327214]: Elapsed time since starting training: 2:22:07.722911
[2018-04-17 18:17:22.331726]: ====================
[2018-04-17 18:17:22.399906]: [Epoch: 1341(89.45963975983989%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:17:23.662764]: [Epoch: 1341(89.45963975983989%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:17:24.926625]: [Epoch: 1341(89.45963975983989%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:17:28.467039]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:17:28.597386]: ====================
[2018-04-17 18:17:28.601898]: Elapsed time since starting training: 2:22:13.998097
[2018-04-17 18:17:28.606911]: ====================
[2018-04-17 18:17:28.676596]: [Epoch: 1342(89.5263509006004%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:17:29.930430]: [Epoch: 1342(89.5263509006004%): Data: 25.333333333333336%]:Running loss: 4.3503688126802444
[2018-04-17 18:17:31.212840]: [Epoch: 1342(89.5263509006004%): Data: 50.66666666666667%]:Running loss: 8.483219340443611
[2018-04-17 18:17:34.750747]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:17:34.874577]: ====================
[2018-04-17 18:17:34.879591]: Elapsed time since starting training: 2:22:20.275790
[2018-04-17 18:17:34.884102]: ====================
[2018-04-17 18:17:34.953788]: [Epoch: 1343(89.59306204136091%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:17:36.243717]: [Epoch: 1343(89.59306204136091%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:17:37.508079]: [Epoch: 1343(89.59306204136091%): Data: 50.66666666666667%]:Running loss: 8.483219891786575
[2018-04-17 18:17:41.236994]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:17:41.373858]: ====================
[2018-04-17 18:17:41.379874]: Elapsed time since starting training: 2:22:26.776073
[2018-04-17 18:17:41.385389]: ====================
[2018-04-17 18:17:41.464600]: [Epoch: 1344(89.65977318212141%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:17:42.779095]: [Epoch: 1344(89.65977318212141%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:17:44.041451]: [Epoch: 1344(89.65977318212141%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:17:47.675615]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:17:47.804959]: ====================
[2018-04-17 18:17:47.811476]: Elapsed time since starting training: 2:22:33.207675
[2018-04-17 18:17:47.815987]: ====================
[2018-04-17 18:17:47.888180]: [Epoch: 1345(89.72648432288192%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:17:49.176606]: [Epoch: 1345(89.72648432288192%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:17:50.410386]: [Epoch: 1345(89.72648432288192%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:17:53.916709]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:17:54.169884]: ====================
[2018-04-17 18:17:54.175899]: Elapsed time since starting training: 2:22:39.571597
[2018-04-17 18:17:54.180411]: ====================
[2018-04-17 18:17:54.249602]: [Epoch: 1346(89.79319546364243%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:17:55.500922]: [Epoch: 1346(89.79319546364243%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:17:56.752750]: [Epoch: 1346(89.79319546364243%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:18:00.193901]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:18:00.314721]: ====================
[2018-04-17 18:18:00.319234]: Elapsed time since starting training: 2:22:45.714931
[2018-04-17 18:18:00.323746]: ====================
[2018-04-17 18:18:00.391425]: [Epoch: 1347(89.85990660440294%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:18:01.660813]: [Epoch: 1347(89.85990660440294%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:18:02.926165]: [Epoch: 1347(89.85990660440294%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:18:06.481118]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:18:06.616478]: ====================
[2018-04-17 18:18:06.620990]: Elapsed time since starting training: 2:22:52.017189
[2018-04-17 18:18:06.625502]: ====================
[2018-04-17 18:18:06.700708]: [Epoch: 1348(89.92661774516344%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:18:07.983112]: [Epoch: 1348(89.92661774516344%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:18:09.246434]: [Epoch: 1348(89.92661774516344%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:18:12.800885]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:18:12.929226]: ====================
[2018-04-17 18:18:12.934240]: Elapsed time since starting training: 2:22:58.330439
[2018-04-17 18:18:12.938752]: ====================
[2018-04-17 18:18:13.011946]: [Epoch: 1349(89.99332888592394%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:18:14.272298]: [Epoch: 1349(89.99332888592394%): Data: 25.333333333333336%]:Running loss: 4.3503716588020325
[2018-04-17 18:18:15.545190]: [Epoch: 1349(89.99332888592394%): Data: 50.66666666666667%]:Running loss: 8.483225017786026
[2018-04-17 18:18:19.080582]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:18:19.221458]: ====================
[2018-04-17 18:18:19.225468]: Elapsed time since starting training: 2:23:04.621667
[2018-04-17 18:18:19.229980]: ====================
[2018-04-17 18:18:19.297660]: [Epoch: 1350(90.06004002668445%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:18:20.581073]: [Epoch: 1350(90.06004002668445%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:18:21.844432]: [Epoch: 1350(90.06004002668445%): Data: 50.66666666666667%]:Running loss: 8.48322607576847
[2018-04-17 18:18:25.352259]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:18:25.481604]: ====================
[2018-04-17 18:18:25.486115]: Elapsed time since starting training: 2:23:10.882314
[2018-04-17 18:18:25.491630]: ====================
[2018-04-17 18:18:25.566830]: [Epoch: 1351(90.12675116744497%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:18:26.814146]: [Epoch: 1351(90.12675116744497%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:18:28.092048]: [Epoch: 1351(90.12675116744497%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:18:31.625941]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:18:31.754783]: ====================
[2018-04-17 18:18:31.759797]: Elapsed time since starting training: 2:23:17.155996
[2018-04-17 18:18:31.763808]: ====================
[2018-04-17 18:18:31.830986]: [Epoch: 1352(90.19346230820547%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:18:33.104372]: [Epoch: 1352(90.19346230820547%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:18:34.382270]: [Epoch: 1352(90.19346230820547%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:18:37.915163]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:18:38.032979]: ====================
[2018-04-17 18:18:38.037990]: Elapsed time since starting training: 2:23:23.434189
[2018-04-17 18:18:38.044508]: ====================
[2018-04-17 18:18:38.113691]: [Epoch: 1353(90.26017344896597%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:18:39.396603]: [Epoch: 1353(90.26017344896597%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:18:40.656954]: [Epoch: 1353(90.26017344896597%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:18:44.187849]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:18:44.311679]: ====================
[2018-04-17 18:18:44.315690]: Elapsed time since starting training: 2:23:29.711889
[2018-04-17 18:18:44.320202]: ====================
[2018-04-17 18:18:44.390890]: [Epoch: 1354(90.32688458972649%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:18:45.663774]: [Epoch: 1354(90.32688458972649%): Data: 25.333333333333336%]:Running loss: 4.35037337243557
[2018-04-17 18:18:46.934152]: [Epoch: 1354(90.32688458972649%): Data: 50.66666666666667%]:Running loss: 8.483228713274002
[2018-04-17 18:18:50.440475]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:18:50.564305]: ====================
[2018-04-17 18:18:50.569318]: Elapsed time since starting training: 2:23:35.965517
[2018-04-17 18:18:50.573830]: ====================
[2018-04-17 18:18:50.647526]: [Epoch: 1355(90.393595730487%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:18:51.944975]: [Epoch: 1355(90.393595730487%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:18:53.217860]: [Epoch: 1355(90.393595730487%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:18:56.740227]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:18:56.866562]: ====================
[2018-04-17 18:18:56.871576]: Elapsed time since starting training: 2:23:42.267273
[2018-04-17 18:18:56.876589]: ====================
[2018-04-17 18:18:56.947779]: [Epoch: 1356(90.4603068712475%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:18:58.204620]: [Epoch: 1356(90.4603068712475%): Data: 25.333333333333336%]:Running loss: 4.350374013185501
[2018-04-17 18:18:59.483020]: [Epoch: 1356(90.4603068712475%): Data: 50.66666666666667%]:Running loss: 8.48322907090187
[2018-04-17 18:19:03.234495]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:19:03.415476]: ====================
[2018-04-17 18:19:03.423999]: Elapsed time since starting training: 2:23:48.819696
[2018-04-17 18:19:03.431518]: ====================
[2018-04-17 18:19:03.520756]: [Epoch: 1357(90.52701801200801%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:19:05.053832]: [Epoch: 1357(90.52701801200801%): Data: 25.333333333333336%]:Running loss: 4.350373953580856
[2018-04-17 18:19:06.467091]: [Epoch: 1357(90.52701801200801%): Data: 50.66666666666667%]:Running loss: 8.483229577541351
[2018-04-17 18:19:10.196506]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:19:10.316827]: ====================
[2018-04-17 18:19:10.321338]: Elapsed time since starting training: 2:23:55.717537
[2018-04-17 18:19:10.325850]: ====================
[2018-04-17 18:19:10.403056]: [Epoch: 1358(90.5937291527685%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:19:11.729583]: [Epoch: 1358(90.5937291527685%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:19:13.064132]: [Epoch: 1358(90.5937291527685%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:19:16.699298]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:19:16.820620]: ====================
[2018-04-17 18:19:16.825633]: Elapsed time since starting training: 2:24:02.221331
[2018-04-17 18:19:16.829644]: ====================
[2018-04-17 18:19:16.898828]: [Epoch: 1359(90.66044029352902%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:19:18.168203]: [Epoch: 1359(90.66044029352902%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:19:19.487216]: [Epoch: 1359(90.66044029352902%): Data: 50.66666666666667%]:Running loss: 8.483230322599411
[2018-04-17 18:19:23.162989]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:19:23.292333]: ====================
[2018-04-17 18:19:23.297848]: Elapsed time since starting training: 2:24:08.693546
[2018-04-17 18:19:23.302360]: ====================
[2018-04-17 18:19:23.371042]: [Epoch: 1360(90.72715143428952%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:19:24.801345]: [Epoch: 1360(90.72715143428952%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:19:26.170987]: [Epoch: 1360(90.72715143428952%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:19:29.950036]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:19:30.084898]: ====================
[2018-04-17 18:19:30.090410]: Elapsed time since starting training: 2:24:15.486107
[2018-04-17 18:19:30.095924]: ====================
[2018-04-17 18:19:30.166612]: [Epoch: 1361(90.79386257505003%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:19:31.533747]: [Epoch: 1361(90.79386257505003%): Data: 25.333333333333336%]:Running loss: 4.350371778011322
[2018-04-17 18:19:32.810642]: [Epoch: 1361(90.79386257505003%): Data: 50.66666666666667%]:Running loss: 8.483219191432
[2018-04-17 18:19:36.338022]: Test set accuracy: 94.33962264150944% ,loss = 5.4379574954509735
[2018-04-17 18:19:36.456336]: ====================
[2018-04-17 18:19:36.461350]: Elapsed time since starting training: 2:24:21.857048
[2018-04-17 18:19:36.466864]: ====================
[2018-04-17 18:19:36.534543]: [Epoch: 1362(90.86057371581055%): Data: 0.0%]:Running loss: 0.21751829981803894
[2018-04-17 18:19:37.811439]: [Epoch: 1362(90.86057371581055%): Data: 25.333333333333336%]:Running loss: 4.350365996360779
[2018-04-17 18:19:39.077806]: [Epoch: 1362(90.86057371581055%): Data: 50.66666666666667%]:Running loss: 8.483213692903519
[2018-04-17 18:19:42.590647]: Test set accuracy: 94.33962264150944% ,loss = 5.4379574954509735
[2018-04-17 18:19:42.712471]: ====================
[2018-04-17 18:19:42.716983]: Elapsed time since starting training: 2:24:28.112681
[2018-04-17 18:19:42.720994]: ====================
[2018-04-17 18:19:42.788173]: [Epoch: 1363(90.92728485657105%): Data: 0.0%]:Running loss: 0.21751829981803894
[2018-04-17 18:19:44.046519]: [Epoch: 1363(90.92728485657105%): Data: 25.333333333333336%]:Running loss: 4.350366219878197
[2018-04-17 18:19:45.310378]: [Epoch: 1363(90.92728485657105%): Data: 50.66666666666667%]:Running loss: 8.483214765787125
[2018-04-17 18:19:48.873353]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 18:19:48.999188]: ====================
[2018-04-17 18:19:49.003198]: Elapsed time since starting training: 2:24:34.399397
[2018-04-17 18:19:49.007209]: ====================
[2018-04-17 18:19:49.080905]: [Epoch: 1364(90.99399599733155%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 18:19:50.351784]: [Epoch: 1364(90.99399599733155%): Data: 25.333333333333336%]:Running loss: 4.35036689043045
[2018-04-17 18:19:51.650236]: [Epoch: 1364(90.99399599733155%): Data: 50.66666666666667%]:Running loss: 8.483215495944023
[2018-04-17 18:19:55.429787]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:19:55.570160]: ====================
[2018-04-17 18:19:55.574671]: Elapsed time since starting training: 2:24:40.970369
[2018-04-17 18:19:55.579685]: ====================
[2018-04-17 18:19:55.653882]: [Epoch: 1365(91.06070713809206%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:19:56.946319]: [Epoch: 1365(91.06070713809206%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 18:19:58.263822]: [Epoch: 1365(91.06070713809206%): Data: 50.66666666666667%]:Running loss: 8.483216598629951
[2018-04-17 18:20:01.906006]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:20:02.030339]: ====================
[2018-04-17 18:20:02.035852]: Elapsed time since starting training: 2:24:47.431549
[2018-04-17 18:20:02.039863]: ====================
[2018-04-17 18:20:02.113558]: [Epoch: 1366(91.12741827885257%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:20:03.386257]: [Epoch: 1366(91.12741827885257%): Data: 25.333333333333336%]:Running loss: 4.350367769598961
[2018-04-17 18:20:04.689722]: [Epoch: 1366(91.12741827885257%): Data: 50.66666666666667%]:Running loss: 8.483217105269432
[2018-04-17 18:20:08.241668]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:20:08.373016]: ====================
[2018-04-17 18:20:08.377027]: Elapsed time since starting training: 2:24:53.773226
[2018-04-17 18:20:08.382041]: ====================
[2018-04-17 18:20:08.450222]: [Epoch: 1367(91.19412941961308%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:20:09.721602]: [Epoch: 1367(91.19412941961308%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:20:11.002508]: [Epoch: 1367(91.19412941961308%): Data: 50.66666666666667%]:Running loss: 8.483217254281044
[2018-04-17 18:20:14.574005]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:20:14.696831]: ====================
[2018-04-17 18:20:14.700842]: Elapsed time since starting training: 2:25:00.097041
[2018-04-17 18:20:14.705354]: ====================
[2018-04-17 18:20:14.775542]: [Epoch: 1368(91.26084056037358%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:20:16.037395]: [Epoch: 1368(91.26084056037358%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 18:20:17.301757]: [Epoch: 1368(91.26084056037358%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 18:20:20.831643]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:20:20.948455]: ====================
[2018-04-17 18:20:20.953469]: Elapsed time since starting training: 2:25:06.349166
[2018-04-17 18:20:20.957478]: ====================
[2018-04-17 18:20:21.030172]: [Epoch: 1369(91.3275517011341%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:20:22.301050]: [Epoch: 1369(91.3275517011341%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:20:23.568922]: [Epoch: 1369(91.3275517011341%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 18:20:27.094296]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:20:27.221634]: ====================
[2018-04-17 18:20:27.226147]: Elapsed time since starting training: 2:25:12.621844
[2018-04-17 18:20:27.231661]: ====================
[2018-04-17 18:20:27.304360]: [Epoch: 1370(91.39426284189459%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:20:28.572727]: [Epoch: 1370(91.39426284189459%): Data: 25.333333333333336%]:Running loss: 4.350369393825531
[2018-04-17 18:20:29.865163]: [Epoch: 1370(91.39426284189459%): Data: 50.66666666666667%]:Running loss: 8.483220487833023
[2018-04-17 18:20:33.383017]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:20:33.506346]: ====================
[2018-04-17 18:20:33.511359]: Elapsed time since starting training: 2:25:18.907558
[2018-04-17 18:20:33.516373]: ====================
[2018-04-17 18:20:33.584052]: [Epoch: 1371(91.4609739826551%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:20:34.867966]: [Epoch: 1371(91.4609739826551%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:20:36.136839]: [Epoch: 1371(91.4609739826551%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:20:39.666224]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:20:39.791056]: ====================
[2018-04-17 18:20:39.795067]: Elapsed time since starting training: 2:25:25.191266
[2018-04-17 18:20:39.800582]: ====================
[2018-04-17 18:20:39.868763]: [Epoch: 1372(91.52768512341561%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:20:41.153679]: [Epoch: 1372(91.52768512341561%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 18:20:42.433583]: [Epoch: 1372(91.52768512341561%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 18:20:45.976002]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:20:46.101336]: ====================
[2018-04-17 18:20:46.105346]: Elapsed time since starting training: 2:25:31.501545
[2018-04-17 18:20:46.109858]: ====================
[2018-04-17 18:20:46.179042]: [Epoch: 1373(91.59439626417611%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:20:47.553196]: [Epoch: 1373(91.59439626417611%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:20:48.852651]: [Epoch: 1373(91.59439626417611%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:20:52.826217]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:20:52.963081]: ====================
[2018-04-17 18:20:52.968094]: Elapsed time since starting training: 2:25:38.364293
[2018-04-17 18:20:52.973108]: ====================
[2018-04-17 18:20:53.045299]: [Epoch: 1374(91.66110740493663%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:20:54.385362]: [Epoch: 1374(91.66110740493663%): Data: 25.333333333333336%]:Running loss: 4.350370943546295
[2018-04-17 18:20:55.729436]: [Epoch: 1374(91.66110740493663%): Data: 50.66666666666667%]:Running loss: 8.4832234531641
[2018-04-17 18:20:59.509989]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:20:59.657382]: ====================
[2018-04-17 18:20:59.663397]: Elapsed time since starting training: 2:25:45.059596
[2018-04-17 18:20:59.668410]: ====================
[2018-04-17 18:20:59.738597]: [Epoch: 1375(91.72781854569713%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:21:00.994937]: [Epoch: 1375(91.72781854569713%): Data: 25.333333333333336%]:Running loss: 4.350371107459068
[2018-04-17 18:21:02.272334]: [Epoch: 1375(91.72781854569713%): Data: 50.66666666666667%]:Running loss: 8.483224466443062
[2018-04-17 18:21:05.813751]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:21:05.950114]: ====================
[2018-04-17 18:21:05.954123]: Elapsed time since starting training: 2:25:51.350322
[2018-04-17 18:21:05.958134]: ====================
[2018-04-17 18:21:06.028823]: [Epoch: 1376(91.79452968645764%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:21:07.290176]: [Epoch: 1376(91.79452968645764%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:21:08.536490]: [Epoch: 1376(91.79452968645764%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:21:12.041309]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:21:12.180682]: ====================
[2018-04-17 18:21:12.185694]: Elapsed time since starting training: 2:25:57.581391
[2018-04-17 18:21:12.190205]: ====================
[2018-04-17 18:21:12.260392]: [Epoch: 1377(91.86124082721815%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:21:13.508210]: [Epoch: 1377(91.86124082721815%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:21:14.747004]: [Epoch: 1377(91.86124082721815%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:21:18.207706]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:21:18.335546]: ====================
[2018-04-17 18:21:18.340560]: Elapsed time since starting training: 2:26:03.736257
[2018-04-17 18:21:18.344570]: ====================
[2018-04-17 18:21:18.418266]: [Epoch: 1378(91.92795196797864%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:21:19.667588]: [Epoch: 1378(91.92795196797864%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:21:20.963033]: [Epoch: 1378(91.92795196797864%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:21:24.710998]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:21:24.844353]: ====================
[2018-04-17 18:21:24.850871]: Elapsed time since starting training: 2:26:10.246568
[2018-04-17 18:21:24.854880]: ====================
[2018-04-17 18:21:24.929580]: [Epoch: 1379(91.99466310873916%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:21:26.375925]: [Epoch: 1379(91.99466310873916%): Data: 25.333333333333336%]:Running loss: 4.35037288069725
[2018-04-17 18:21:27.811241]: [Epoch: 1379(91.99466310873916%): Data: 50.66666666666667%]:Running loss: 8.483227372169495
[2018-04-17 18:21:31.899112]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:21:32.035976]: ====================
[2018-04-17 18:21:32.040487]: Elapsed time since starting training: 2:26:17.436686
[2018-04-17 18:21:32.044498]: ====================
[2018-04-17 18:21:32.121704]: [Epoch: 1380(92.06137424949966%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:21:33.661798]: [Epoch: 1380(92.06137424949966%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:21:35.002864]: [Epoch: 1380(92.06137424949966%): Data: 50.66666666666667%]:Running loss: 8.483228176832199
[2018-04-17 18:21:38.682649]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:21:38.803973]: ====================
[2018-04-17 18:21:38.809486]: Elapsed time since starting training: 2:26:24.205685
[2018-04-17 18:21:38.813497]: ====================
[2018-04-17 18:21:38.884686]: [Epoch: 1381(92.12808539026017%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:21:40.216728]: [Epoch: 1381(92.12808539026017%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:21:41.566818]: [Epoch: 1381(92.12808539026017%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:21:45.222037]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:21:45.354890]: ====================
[2018-04-17 18:21:45.359402]: Elapsed time since starting training: 2:26:30.755601
[2018-04-17 18:21:45.363914]: ====================
[2018-04-17 18:21:45.436106]: [Epoch: 1382(92.19479653102069%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:21:46.890975]: [Epoch: 1382(92.19479653102069%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:21:48.280670]: [Epoch: 1382(92.19479653102069%): Data: 50.66666666666667%]:Running loss: 8.483229026198387
[2018-04-17 18:21:52.021115]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:21:52.137926]: ====================
[2018-04-17 18:21:52.142438]: Elapsed time since starting training: 2:26:37.538637
[2018-04-17 18:21:52.146950]: ====================
[2018-04-17 18:21:52.212123]: [Epoch: 1383(92.26150767178119%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:21:53.557200]: [Epoch: 1383(92.26150767178119%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:21:54.968954]: [Epoch: 1383(92.26150767178119%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:21:59.002179]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:21:59.155084]: ====================
[2018-04-17 18:21:59.159597]: Elapsed time since starting training: 2:26:44.555796
[2018-04-17 18:21:59.164109]: ====================
[2018-04-17 18:21:59.237303]: [Epoch: 1384(92.32821881254169%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:22:00.588898]: [Epoch: 1384(92.32821881254169%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:22:01.896875]: [Epoch: 1384(92.32821881254169%): Data: 50.66666666666667%]:Running loss: 8.483227729797363
[2018-04-17 18:22:05.483412]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:22:05.724052]: ====================
[2018-04-17 18:22:05.729065]: Elapsed time since starting training: 2:26:51.125264
[2018-04-17 18:22:05.733076]: ====================
[2018-04-17 18:22:05.806270]: [Epoch: 1385(92.3949299533022%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:22:07.069633]: [Epoch: 1385(92.3949299533022%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:22:08.339506]: [Epoch: 1385(92.3949299533022%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:22:11.926043]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:22:12.049872]: ====================
[2018-04-17 18:22:12.055888]: Elapsed time since starting training: 2:26:57.452087
[2018-04-17 18:22:12.060400]: ====================
[2018-04-17 18:22:12.140613]: [Epoch: 1386(92.46164109406271%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:22:13.472655]: [Epoch: 1386(92.46164109406271%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:22:14.764088]: [Epoch: 1386(92.46164109406271%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:22:18.356140]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:22:18.490999]: ====================
[2018-04-17 18:22:18.495511]: Elapsed time since starting training: 2:27:03.891710
[2018-04-17 18:22:18.499522]: ====================
[2018-04-17 18:22:18.570711]: [Epoch: 1387(92.52835223482322%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:22:19.842593]: [Epoch: 1387(92.52835223482322%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:22:21.130017]: [Epoch: 1387(92.52835223482322%): Data: 50.66666666666667%]:Running loss: 8.483228951692581
[2018-04-17 18:22:24.638846]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:22:24.765182]: ====================
[2018-04-17 18:22:24.769694]: Elapsed time since starting training: 2:27:10.165893
[2018-04-17 18:22:24.774206]: ====================
[2018-04-17 18:22:24.839881]: [Epoch: 1388(92.59506337558372%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:22:26.101235]: [Epoch: 1388(92.59506337558372%): Data: 25.333333333333336%]:Running loss: 4.350373908877373
[2018-04-17 18:22:27.369106]: [Epoch: 1388(92.59506337558372%): Data: 50.66666666666667%]:Running loss: 8.483229249715805
[2018-04-17 18:22:30.900495]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:22:31.029339]: ====================
[2018-04-17 18:22:31.033350]: Elapsed time since starting training: 2:27:16.429549
[2018-04-17 18:22:31.038864]: ====================
[2018-04-17 18:22:31.105040]: [Epoch: 1389(92.66177451634422%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:22:32.378426]: [Epoch: 1389(92.66177451634422%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:22:33.639278]: [Epoch: 1389(92.66177451634422%): Data: 50.66666666666667%]:Running loss: 8.483229741454124
[2018-04-17 18:22:37.198241]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:22:37.321569]: ====================
[2018-04-17 18:22:37.326081]: Elapsed time since starting training: 2:27:22.722280
[2018-04-17 18:22:37.330092]: ====================
[2018-04-17 18:22:37.397771]: [Epoch: 1390(92.72848565710473%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:22:38.655123]: [Epoch: 1390(92.72848565710473%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:22:39.922485]: [Epoch: 1390(92.72848565710473%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:22:43.411763]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:22:43.544617]: ====================
[2018-04-17 18:22:43.549128]: Elapsed time since starting training: 2:27:28.945327
[2018-04-17 18:22:43.554643]: ====================
[2018-04-17 18:22:43.623827]: [Epoch: 1391(92.79519679786524%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:22:44.875154]: [Epoch: 1391(92.79519679786524%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:22:46.143025]: [Epoch: 1391(92.79519679786524%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:22:49.674916]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:22:49.797743]: ====================
[2018-04-17 18:22:49.802256]: Elapsed time since starting training: 2:27:35.198455
[2018-04-17 18:22:49.806767]: ====================
[2018-04-17 18:22:49.875951]: [Epoch: 1392(92.86190793862575%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:22:51.128782]: [Epoch: 1392(92.86190793862575%): Data: 25.333333333333336%]:Running loss: 4.350375235080719
[2018-04-17 18:22:52.387128]: [Epoch: 1392(92.86190793862575%): Data: 50.66666666666667%]:Running loss: 8.48323142528534
[2018-04-17 18:22:55.906995]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:22:56.031828]: ====================
[2018-04-17 18:22:56.036339]: Elapsed time since starting training: 2:27:41.432538
[2018-04-17 18:22:56.041353]: ====================
[2018-04-17 18:22:56.109537]: [Epoch: 1393(92.92861907938625%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:22:57.427037]: [Epoch: 1393(92.92861907938625%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:22:58.713458]: [Epoch: 1393(92.92861907938625%): Data: 50.66666666666667%]:Running loss: 8.483231708407402
[2018-04-17 18:23:02.746181]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:23:02.880538]: ====================
[2018-04-17 18:23:02.885050]: Elapsed time since starting training: 2:27:48.280748
[2018-04-17 18:23:02.890565]: ====================
[2018-04-17 18:23:02.962255]: [Epoch: 1394(92.99533022014677%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:23:04.351449]: [Epoch: 1394(92.99533022014677%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:23:05.787268]: [Epoch: 1394(92.99533022014677%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 18:23:09.478081]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 18:23:09.612940]: ====================
[2018-04-17 18:23:09.617454]: Elapsed time since starting training: 2:27:55.013653
[2018-04-17 18:23:09.622967]: ====================
[2018-04-17 18:23:09.692150]: [Epoch: 1395(93.06204136090727%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 18:23:10.971552]: [Epoch: 1395(93.06204136090727%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 18:23:12.276020]: [Epoch: 1395(93.06204136090727%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 18:23:15.859047]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 18:23:15.998920]: ====================
[2018-04-17 18:23:16.003432]: Elapsed time since starting training: 2:28:01.399129
[2018-04-17 18:23:16.007442]: ====================
[2018-04-17 18:23:16.079634]: [Epoch: 1396(93.12875250166778%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 18:23:17.353523]: [Epoch: 1396(93.12875250166778%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 18:23:18.626406]: [Epoch: 1396(93.12875250166778%): Data: 50.66666666666667%]:Running loss: 8.483234524726868
[2018-04-17 18:23:22.122702]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 18:23:22.243023]: ====================
[2018-04-17 18:23:22.247534]: Elapsed time since starting training: 2:28:07.643733
[2018-04-17 18:23:22.251545]: ====================
[2018-04-17 18:23:22.328751]: [Epoch: 1397(93.1954636424283%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 18:23:23.604643]: [Epoch: 1397(93.1954636424283%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 18:23:24.881539]: [Epoch: 1397(93.1954636424283%): Data: 50.66666666666667%]:Running loss: 8.483235776424408
[2018-04-17 18:23:28.507680]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:23:28.656577]: ====================
[2018-04-17 18:23:28.661088]: Elapsed time since starting training: 2:28:14.057287
[2018-04-17 18:23:28.665600]: ====================
[2018-04-17 18:23:28.741302]: [Epoch: 1398(93.26217478318878%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:23:30.036245]: [Epoch: 1398(93.26217478318878%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:23:31.324170]: [Epoch: 1398(93.26217478318878%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:23:34.845533]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:23:34.962343]: ====================
[2018-04-17 18:23:34.967357]: Elapsed time since starting training: 2:28:20.363556
[2018-04-17 18:23:34.972370]: ====================
[2018-04-17 18:23:35.043057]: [Epoch: 1399(93.3288859239493%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:23:36.301905]: [Epoch: 1399(93.3288859239493%): Data: 25.333333333333336%]:Running loss: 4.350370287895203
[2018-04-17 18:23:37.589830]: [Epoch: 1399(93.3288859239493%): Data: 50.66666666666667%]:Running loss: 8.483222231268883
[2018-04-17 18:23:41.126233]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:23:41.256579]: ====================
[2018-04-17 18:23:41.261091]: Elapsed time since starting training: 2:28:26.657290
[2018-04-17 18:23:41.266606]: ====================
[2018-04-17 18:23:41.338297]: [Epoch: 1400(93.3955970647098%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:23:42.602157]: [Epoch: 1400(93.3955970647098%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:23:43.884066]: [Epoch: 1400(93.3955970647098%): Data: 50.66666666666667%]:Running loss: 8.48322294652462
[2018-04-17 18:23:47.376853]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:23:47.497174]: ====================
[2018-04-17 18:23:47.501685]: Elapsed time since starting training: 2:28:32.897884
[2018-04-17 18:23:47.506698]: ====================
[2018-04-17 18:23:47.577387]: [Epoch: 1401(93.46230820547031%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:23:48.822197]: [Epoch: 1401(93.46230820547031%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:23:50.082549]: [Epoch: 1401(93.46230820547031%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:23:53.586364]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:23:53.705682]: ====================
[2018-04-17 18:23:53.710194]: Elapsed time since starting training: 2:28:39.106393
[2018-04-17 18:23:53.714706]: ====================
[2018-04-17 18:23:53.782385]: [Epoch: 1402(93.52901934623083%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:23:55.059782]: [Epoch: 1402(93.52901934623083%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:23:56.344699]: [Epoch: 1402(93.52901934623083%): Data: 50.66666666666667%]:Running loss: 8.483223855495453
[2018-04-17 18:23:59.879598]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:23:59.999918]: ====================
[2018-04-17 18:24:00.004430]: Elapsed time since starting training: 2:28:45.400629
[2018-04-17 18:24:00.009945]: ====================
[2018-04-17 18:24:00.081635]: [Epoch: 1403(93.59573048699133%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:24:01.386609]: [Epoch: 1403(93.59573048699133%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:24:02.658994]: [Epoch: 1403(93.59573048699133%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:24:06.189382]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:24:06.315716]: ====================
[2018-04-17 18:24:06.320228]: Elapsed time since starting training: 2:28:51.716427
[2018-04-17 18:24:06.324740]: ====================
[2018-04-17 18:24:06.402447]: [Epoch: 1404(93.66244162775183%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:24:07.668814]: [Epoch: 1404(93.66244162775183%): Data: 25.333333333333336%]:Running loss: 4.350371092557907
[2018-04-17 18:24:08.955736]: [Epoch: 1404(93.66244162775183%): Data: 50.66666666666667%]:Running loss: 8.483223885297775
[2018-04-17 18:24:12.456544]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:24:12.575360]: ====================
[2018-04-17 18:24:12.579873]: Elapsed time since starting training: 2:28:57.976072
[2018-04-17 18:24:12.583883]: ====================
[2018-04-17 18:24:12.651061]: [Epoch: 1405(93.72915276851234%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:24:13.961546]: [Epoch: 1405(93.72915276851234%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:24:15.252479]: [Epoch: 1405(93.72915276851234%): Data: 50.66666666666667%]:Running loss: 8.483224421739578
[2018-04-17 18:24:18.802920]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:24:18.930258]: ====================
[2018-04-17 18:24:18.934770]: Elapsed time since starting training: 2:29:04.330467
[2018-04-17 18:24:18.939282]: ====================
[2018-04-17 18:24:19.015986]: [Epoch: 1406(93.79586390927285%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:24:20.297393]: [Epoch: 1406(93.79586390927285%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:24:21.567270]: [Epoch: 1406(93.79586390927285%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:24:25.057550]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:24:25.179876]: ====================
[2018-04-17 18:24:25.184889]: Elapsed time since starting training: 2:29:10.581088
[2018-04-17 18:24:25.189902]: ====================
[2018-04-17 18:24:25.260089]: [Epoch: 1407(93.86257505003336%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:24:26.536984]: [Epoch: 1407(93.86257505003336%): Data: 25.333333333333336%]:Running loss: 4.350372612476349
[2018-04-17 18:24:27.820898]: [Epoch: 1407(93.86257505003336%): Data: 50.66666666666667%]:Running loss: 8.483224555850029
[2018-04-17 18:24:31.324214]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:24:31.454560]: ====================
[2018-04-17 18:24:31.460075]: Elapsed time since starting training: 2:29:16.856274
[2018-04-17 18:24:31.464587]: ====================
[2018-04-17 18:24:31.535776]: [Epoch: 1408(93.92928619079386%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:24:32.801141]: [Epoch: 1408(93.92928619079386%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:24:34.058985]: [Epoch: 1408(93.92928619079386%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:24:37.604914]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:24:37.727239]: ====================
[2018-04-17 18:24:37.731249]: Elapsed time since starting training: 2:29:23.127448
[2018-04-17 18:24:37.735260]: ====================
[2018-04-17 18:24:37.805948]: [Epoch: 1409(93.99599733155438%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:24:39.088860]: [Epoch: 1409(93.99599733155438%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:24:40.365754]: [Epoch: 1409(93.99599733155438%): Data: 50.66666666666667%]:Running loss: 8.483224377036095
[2018-04-17 18:24:43.925219]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:24:44.047545]: ====================
[2018-04-17 18:24:44.052558]: Elapsed time since starting training: 2:29:29.448255
[2018-04-17 18:24:44.057070]: ====================
[2018-04-17 18:24:44.136281]: [Epoch: 1410(94.06270847231488%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:24:45.407661]: [Epoch: 1410(94.06270847231488%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:24:46.700098]: [Epoch: 1410(94.06270847231488%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:24:50.224970]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:24:50.344289]: ====================
[2018-04-17 18:24:50.348800]: Elapsed time since starting training: 2:29:35.744497
[2018-04-17 18:24:50.352810]: ====================
[2018-04-17 18:24:50.425002]: [Epoch: 1411(94.12941961307538%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:24:51.700393]: [Epoch: 1411(94.12941961307538%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:24:52.964756]: [Epoch: 1411(94.12941961307538%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:24:56.465063]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:24:56.586888]: ====================
[2018-04-17 18:24:56.592903]: Elapsed time since starting training: 2:29:41.988600
[2018-04-17 18:24:56.597415]: ====================
[2018-04-17 18:24:56.667100]: [Epoch: 1412(94.19613075383589%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:24:57.929958]: [Epoch: 1412(94.19613075383589%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:24:59.209359]: [Epoch: 1412(94.19613075383589%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:25:02.771832]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:25:02.890649]: ====================
[2018-04-17 18:25:02.896163]: Elapsed time since starting training: 2:29:48.292362
[2018-04-17 18:25:02.900675]: ====================
[2018-04-17 18:25:02.972365]: [Epoch: 1413(94.26284189459639%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:25:04.262295]: [Epoch: 1413(94.26284189459639%): Data: 25.333333333333336%]:Running loss: 4.350372835993767
[2018-04-17 18:25:05.549719]: [Epoch: 1413(94.26284189459639%): Data: 50.66666666666667%]:Running loss: 8.483227044343948
[2018-04-17 18:25:09.125226]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:25:09.247050]: ====================
[2018-04-17 18:25:09.251562]: Elapsed time since starting training: 2:29:54.647259
[2018-04-17 18:25:09.256074]: ====================
[2018-04-17 18:25:09.326261]: [Epoch: 1414(94.32955303535691%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:25:10.608169]: [Epoch: 1414(94.32955303535691%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:25:11.875038]: [Epoch: 1414(94.32955303535691%): Data: 50.66666666666667%]:Running loss: 8.483227849006653
[2018-04-17 18:25:15.480625]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:25:15.604455]: ====================
[2018-04-17 18:25:15.609969]: Elapsed time since starting training: 2:30:01.006168
[2018-04-17 18:25:15.614982]: ====================
[2018-04-17 18:25:15.687174]: [Epoch: 1415(94.39626417611741%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:25:16.978106]: [Epoch: 1415(94.39626417611741%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:25:18.260015]: [Epoch: 1415(94.39626417611741%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:25:21.834032]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:25:21.954338]: ====================
[2018-04-17 18:25:21.959854]: Elapsed time since starting training: 2:30:07.356053
[2018-04-17 18:25:21.963864]: ====================
[2018-04-17 18:25:22.035554]: [Epoch: 1416(94.46297531687792%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:25:23.317463]: [Epoch: 1416(94.46297531687792%): Data: 25.333333333333336%]:Running loss: 4.350374102592468
[2018-04-17 18:25:24.616417]: [Epoch: 1416(94.46297531687792%): Data: 50.66666666666667%]:Running loss: 8.483229726552963
[2018-04-17 18:25:28.152820]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:25:28.271637]: ====================
[2018-04-17 18:25:28.276650]: Elapsed time since starting training: 2:30:13.672849
[2018-04-17 18:25:28.281161]: ====================
[2018-04-17 18:25:28.349846]: [Epoch: 1417(94.52968645763843%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:25:29.633758]: [Epoch: 1417(94.52968645763843%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:25:30.902631]: [Epoch: 1417(94.52968645763843%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:25:34.523761]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:25:34.652603]: ====================
[2018-04-17 18:25:34.657115]: Elapsed time since starting training: 2:30:20.052813
[2018-04-17 18:25:34.662129]: ====================
[2018-04-17 18:25:34.736840]: [Epoch: 1418(94.59639759839892%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:25:36.033776]: [Epoch: 1418(94.59639759839892%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:25:37.324207]: [Epoch: 1418(94.59639759839892%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 18:25:40.951852]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:25:41.064152]: ====================
[2018-04-17 18:25:41.068663]: Elapsed time since starting training: 2:30:26.464862
[2018-04-17 18:25:41.073175]: ====================
[2018-04-17 18:25:41.144866]: [Epoch: 1419(94.66310873915944%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:25:42.453846]: [Epoch: 1419(94.66310873915944%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:25:43.766336]: [Epoch: 1419(94.66310873915944%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 18:25:47.385961]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:25:47.506281]: ====================
[2018-04-17 18:25:47.511295]: Elapsed time since starting training: 2:30:32.906992
[2018-04-17 18:25:47.515806]: ====================
[2018-04-17 18:25:47.589001]: [Epoch: 1420(94.72981987991996%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:25:48.895981]: [Epoch: 1420(94.72981987991996%): Data: 25.333333333333336%]:Running loss: 4.350375950336456
[2018-04-17 18:25:50.184908]: [Epoch: 1420(94.72981987991996%): Data: 50.66666666666667%]:Running loss: 8.483233273029327
[2018-04-17 18:25:53.790495]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 18:25:53.949419]: ====================
[2018-04-17 18:25:53.954431]: Elapsed time since starting training: 2:30:39.350630
[2018-04-17 18:25:53.960447]: ====================
[2018-04-17 18:25:54.036149]: [Epoch: 1421(94.79653102068045%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 18:25:55.417822]: [Epoch: 1421(94.79653102068045%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 18:25:56.747858]: [Epoch: 1421(94.79653102068045%): Data: 50.66666666666667%]:Running loss: 8.483233630657196
[2018-04-17 18:26:00.509360]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 18:26:00.829211]: ====================
[2018-04-17 18:26:00.836731]: Elapsed time since starting training: 2:30:46.232429
[2018-04-17 18:26:00.846257]: ====================
[2018-04-17 18:26:00.922960]: [Epoch: 1422(94.86324216144097%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 18:26:02.484612]: [Epoch: 1422(94.86324216144097%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 18:26:03.968057]: [Epoch: 1422(94.86324216144097%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 18:26:07.708503]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 18:26:07.828322]: ====================
[2018-04-17 18:26:07.832833]: Elapsed time since starting training: 2:30:53.229032
[2018-04-17 18:26:07.837847]: ====================
[2018-04-17 18:26:07.907532]: [Epoch: 1423(94.92995330220147%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 18:26:09.197964]: [Epoch: 1423(94.92995330220147%): Data: 25.333333333333336%]:Running loss: 4.350376725196838
[2018-04-17 18:26:10.461824]: [Epoch: 1423(94.92995330220147%): Data: 50.66666666666667%]:Running loss: 8.483227461576462
[2018-04-17 18:26:14.021288]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 18:26:14.148126]: ====================
[2018-04-17 18:26:14.152639]: Elapsed time since starting training: 2:30:59.548336
[2018-04-17 18:26:14.157151]: ====================
[2018-04-17 18:26:14.227839]: [Epoch: 1424(94.99666444296197%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 18:26:15.539826]: [Epoch: 1424(94.99666444296197%): Data: 25.333333333333336%]:Running loss: 4.350367605686188
[2018-04-17 18:26:16.813212]: [Epoch: 1424(94.99666444296197%): Data: 50.66666666666667%]:Running loss: 8.483217000961304
[2018-04-17 18:26:20.355631]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:26:20.475451]: ====================
[2018-04-17 18:26:20.480463]: Elapsed time since starting training: 2:31:05.876662
[2018-04-17 18:26:20.484474]: ====================
[2018-04-17 18:26:20.552154]: [Epoch: 1425(95.06337558372249%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:26:21.839577]: [Epoch: 1425(95.06337558372249%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:26:23.121486]: [Epoch: 1425(95.06337558372249%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:26:26.697494]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:26:26.841878]: ====================
[2018-04-17 18:26:26.846390]: Elapsed time since starting training: 2:31:12.242589
[2018-04-17 18:26:26.851404]: ====================
[2018-04-17 18:26:26.920588]: [Epoch: 1426(95.130086724483%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:26:28.197490]: [Epoch: 1426(95.130086724483%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:26:29.451317]: [Epoch: 1426(95.130086724483%): Data: 50.66666666666667%]:Running loss: 8.48321744799614
[2018-04-17 18:26:32.997746]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:26:33.126590]: ====================
[2018-04-17 18:26:33.130600]: Elapsed time since starting training: 2:31:18.526799
[2018-04-17 18:26:33.135112]: ====================
[2018-04-17 18:26:33.201789]: [Epoch: 1427(95.1967978652435%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:26:34.469160]: [Epoch: 1427(95.1967978652435%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:26:35.723996]: [Epoch: 1427(95.1967978652435%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:26:39.257893]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:26:39.381722]: ====================
[2018-04-17 18:26:39.386234]: Elapsed time since starting training: 2:31:24.782433
[2018-04-17 18:26:39.392250]: ====================
[2018-04-17 18:26:39.465445]: [Epoch: 1428(95.263509006004%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:26:40.719287]: [Epoch: 1428(95.263509006004%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:26:42.013228]: [Epoch: 1428(95.263509006004%): Data: 50.66666666666667%]:Running loss: 8.483219906687737
[2018-04-17 18:26:45.513034]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:26:45.632853]: ====================
[2018-04-17 18:26:45.638367]: Elapsed time since starting training: 2:31:31.034065
[2018-04-17 18:26:45.642378]: ====================
[2018-04-17 18:26:45.711061]: [Epoch: 1429(95.3302201467645%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:26:46.973417]: [Epoch: 1429(95.3302201467645%): Data: 25.333333333333336%]:Running loss: 4.350368842482567
[2018-04-17 18:26:48.248809]: [Epoch: 1429(95.3302201467645%): Data: 50.66666666666667%]:Running loss: 8.483219370245934
[2018-04-17 18:26:52.090523]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:26:52.231899]: ====================
[2018-04-17 18:26:52.236913]: Elapsed time since starting training: 2:31:37.632610
[2018-04-17 18:26:52.241424]: ====================
[2018-04-17 18:26:52.314118]: [Epoch: 1430(95.39693128752502%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:26:53.698800]: [Epoch: 1430(95.39693128752502%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:26:55.096517]: [Epoch: 1430(95.39693128752502%): Data: 50.66666666666667%]:Running loss: 8.483219772577286
[2018-04-17 18:26:58.766274]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:26:58.891608]: ====================
[2018-04-17 18:26:58.896120]: Elapsed time since starting training: 2:31:44.291817
[2018-04-17 18:26:58.901634]: ====================
[2018-04-17 18:26:58.977838]: [Epoch: 1431(95.46364242828552%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:27:00.260246]: [Epoch: 1431(95.46364242828552%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:27:01.730657]: [Epoch: 1431(95.46364242828552%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 18:27:05.954888]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:27:06.082228]: ====================
[2018-04-17 18:27:06.088244]: Elapsed time since starting training: 2:31:51.483941
[2018-04-17 18:27:06.092254]: ====================
[2018-04-17 18:27:06.167453]: [Epoch: 1432(95.53035356904603%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:27:07.483453]: [Epoch: 1432(95.53035356904603%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:27:08.789426]: [Epoch: 1432(95.53035356904603%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:27:13.138991]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:27:13.267834]: ====================
[2018-04-17 18:27:13.272345]: Elapsed time since starting training: 2:31:58.668544
[2018-04-17 18:27:13.276857]: ====================
[2018-04-17 18:27:13.351056]: [Epoch: 1433(95.59706470980653%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:27:14.641987]: [Epoch: 1433(95.59706470980653%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:27:15.898830]: [Epoch: 1433(95.59706470980653%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:27:19.603681]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:27:19.731520]: ====================
[2018-04-17 18:27:19.736535]: Elapsed time since starting training: 2:32:05.132734
[2018-04-17 18:27:19.740545]: ====================
[2018-04-17 18:27:19.812235]: [Epoch: 1434(95.66377585056705%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:27:21.082613]: [Epoch: 1434(95.66377585056705%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:27:22.614186]: [Epoch: 1434(95.66377585056705%): Data: 50.66666666666667%]:Running loss: 8.483222529292107
[2018-04-17 18:27:26.304498]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:27:26.433341]: ====================
[2018-04-17 18:27:26.438354]: Elapsed time since starting training: 2:32:11.834553
[2018-04-17 18:27:26.442866]: ====================
[2018-04-17 18:27:26.517064]: [Epoch: 1435(95.73048699132755%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:27:27.820541]: [Epoch: 1435(95.73048699132755%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:27:29.102939]: [Epoch: 1435(95.73048699132755%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:27:32.703012]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:27:32.834361]: ====================
[2018-04-17 18:27:32.839375]: Elapsed time since starting training: 2:32:18.235072
[2018-04-17 18:27:32.843886]: ====================
[2018-04-17 18:27:32.912569]: [Epoch: 1436(95.79719813208806%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:27:34.203501]: [Epoch: 1436(95.79719813208806%): Data: 25.333333333333336%]:Running loss: 4.350371181964874
[2018-04-17 18:27:35.469379]: [Epoch: 1436(95.79719813208806%): Data: 50.66666666666667%]:Running loss: 8.483223974704742
[2018-04-17 18:27:39.078965]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:27:39.194773]: ====================
[2018-04-17 18:27:39.199786]: Elapsed time since starting training: 2:32:24.595985
[2018-04-17 18:27:39.209312]: ====================
[2018-04-17 18:27:39.281505]: [Epoch: 1437(95.86390927284857%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:27:40.892789]: [Epoch: 1437(95.86390927284857%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:27:42.186227]: [Epoch: 1437(95.86390927284857%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:27:45.714108]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:27:45.836434]: ====================
[2018-04-17 18:27:45.841447]: Elapsed time since starting training: 2:32:31.237144
[2018-04-17 18:27:45.845458]: ====================
[2018-04-17 18:27:45.917650]: [Epoch: 1438(95.93062041360906%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:27:47.166470]: [Epoch: 1438(95.93062041360906%): Data: 25.333333333333336%]:Running loss: 4.350372165441513
[2018-04-17 18:27:48.460410]: [Epoch: 1438(95.93062041360906%): Data: 50.66666666666667%]:Running loss: 8.48322580754757
[2018-04-17 18:27:52.286584]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:27:52.410916]: ====================
[2018-04-17 18:27:52.414926]: Elapsed time since starting training: 2:32:37.811125
[2018-04-17 18:27:52.419939]: ====================
[2018-04-17 18:27:52.488621]: [Epoch: 1439(95.99733155436958%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:27:53.708866]: [Epoch: 1439(95.99733155436958%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:27:54.943659]: [Epoch: 1439(95.99733155436958%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 18:27:58.395327]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:27:58.516149]: ====================
[2018-04-17 18:27:58.520159]: Elapsed time since starting training: 2:32:43.916358
[2018-04-17 18:27:58.524671]: ====================
[2018-04-17 18:27:58.591349]: [Epoch: 1440(96.0640426951301%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:27:59.832649]: [Epoch: 1440(96.0640426951301%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:28:01.090995]: [Epoch: 1440(96.0640426951301%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:28:04.697096]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:28:04.817905]: ====================
[2018-04-17 18:28:04.822417]: Elapsed time since starting training: 2:32:50.218115
[2018-04-17 18:28:04.826428]: ====================
[2018-04-17 18:28:04.900123]: [Epoch: 1441(96.13075383589059%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:28:06.182032]: [Epoch: 1441(96.13075383589059%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:28:07.457423]: [Epoch: 1441(96.13075383589059%): Data: 50.66666666666667%]:Running loss: 8.483228147029877
[2018-04-17 18:28:11.497165]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:28:11.627512]: ====================
[2018-04-17 18:28:11.632024]: Elapsed time since starting training: 2:32:57.027721
[2018-04-17 18:28:11.637037]: ====================
[2018-04-17 18:28:11.709229]: [Epoch: 1442(96.1974649766511%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:28:12.995650]: [Epoch: 1442(96.1974649766511%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:28:14.271542]: [Epoch: 1442(96.1974649766511%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:28:18.287721]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:28:18.408041]: ====================
[2018-04-17 18:28:18.412554]: Elapsed time since starting training: 2:33:03.808753
[2018-04-17 18:28:18.417066]: ====================
[2018-04-17 18:28:18.480734]: [Epoch: 1443(96.26417611741161%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:28:19.744595]: [Epoch: 1443(96.26417611741161%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:28:20.994920]: [Epoch: 1443(96.26417611741161%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:28:24.590480]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:28:24.712304]: ====================
[2018-04-17 18:28:24.716816]: Elapsed time since starting training: 2:33:10.112513
[2018-04-17 18:28:24.722331]: ====================
[2018-04-17 18:28:24.795024]: [Epoch: 1444(96.33088725817211%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:28:26.052868]: [Epoch: 1444(96.33088725817211%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:28:27.308708]: [Epoch: 1444(96.33088725817211%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:28:30.866167]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:28:30.995511]: ====================
[2018-04-17 18:28:31.000525]: Elapsed time since starting training: 2:33:16.396724
[2018-04-17 18:28:31.005037]: ====================
[2018-04-17 18:28:31.077730]: [Epoch: 1445(96.39759839893263%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:28:32.366155]: [Epoch: 1445(96.39759839893263%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:28:33.640544]: [Epoch: 1445(96.39759839893263%): Data: 50.66666666666667%]:Running loss: 8.483228921890259
[2018-04-17 18:28:37.238110]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:28:37.359433]: ====================
[2018-04-17 18:28:37.363944]: Elapsed time since starting training: 2:33:22.760143
[2018-04-17 18:28:37.368456]: ====================
[2018-04-17 18:28:37.438643]: [Epoch: 1446(96.46430953969313%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:28:38.705512]: [Epoch: 1446(96.46430953969313%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:28:40.198983]: [Epoch: 1446(96.46430953969313%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:28:44.451791]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:28:44.576122]: ====================
[2018-04-17 18:28:44.580633]: Elapsed time since starting training: 2:33:29.976832
[2018-04-17 18:28:44.585647]: ====================
[2018-04-17 18:28:44.655834]: [Epoch: 1447(96.53102068045364%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:28:45.954287]: [Epoch: 1447(96.53102068045364%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:28:47.239203]: [Epoch: 1447(96.53102068045364%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:28:50.939040]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 18:28:51.070892]: ====================
[2018-04-17 18:28:51.075904]: Elapsed time since starting training: 2:33:36.471602
[2018-04-17 18:28:51.080417]: ====================
[2018-04-17 18:28:51.155617]: [Epoch: 1448(96.59773182121414%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 18:28:52.440032]: [Epoch: 1448(96.59773182121414%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 18:28:53.725449]: [Epoch: 1448(96.59773182121414%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 18:28:57.338056]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 18:28:57.457874]: ====================
[2018-04-17 18:28:57.462386]: Elapsed time since starting training: 2:33:42.858585
[2018-04-17 18:28:57.466899]: ====================
[2018-04-17 18:28:57.538589]: [Epoch: 1449(96.66444296197466%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 18:28:58.821500]: [Epoch: 1449(96.66444296197466%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 18:29:00.094384]: [Epoch: 1449(96.66444296197466%): Data: 50.66666666666667%]:Running loss: 8.483231395483017
[2018-04-17 18:29:03.688441]: Test set accuracy: 94.33962264150944% ,loss = 5.4379574954509735
[2018-04-17 18:29:03.813274]: ====================
[2018-04-17 18:29:03.818287]: Elapsed time since starting training: 2:33:49.213985
[2018-04-17 18:29:03.822798]: ====================
[2018-04-17 18:29:03.897497]: [Epoch: 1450(96.73115410273516%): Data: 0.0%]:Running loss: 0.21751829981803894
[2018-04-17 18:29:05.177901]: [Epoch: 1450(96.73115410273516%): Data: 25.333333333333336%]:Running loss: 4.350365996360779
[2018-04-17 18:29:06.445272]: [Epoch: 1450(96.73115410273516%): Data: 50.66666666666667%]:Running loss: 8.483213856816292
[2018-04-17 18:29:10.033312]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 18:29:10.161653]: ====================
[2018-04-17 18:29:10.166667]: Elapsed time since starting training: 2:33:55.562364
[2018-04-17 18:29:10.171179]: ====================
[2018-04-17 18:29:10.242368]: [Epoch: 1451(96.79786524349566%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 18:29:11.528789]: [Epoch: 1451(96.79786524349566%): Data: 25.333333333333336%]:Running loss: 4.350366294384003
[2018-04-17 18:29:12.820222]: [Epoch: 1451(96.79786524349566%): Data: 50.66666666666667%]:Running loss: 8.483214274048805
[2018-04-17 18:29:16.396732]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 18:29:16.526578]: ====================
[2018-04-17 18:29:16.533597]: Elapsed time since starting training: 2:34:01.929796
[2018-04-17 18:29:16.539613]: ====================
[2018-04-17 18:29:16.615815]: [Epoch: 1452(96.86457638425617%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 18:29:17.883686]: [Epoch: 1452(96.86457638425617%): Data: 25.333333333333336%]:Running loss: 4.35036689043045
[2018-04-17 18:29:19.124987]: [Epoch: 1452(96.86457638425617%): Data: 50.66666666666667%]:Running loss: 8.483215436339378
[2018-04-17 18:29:22.753635]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:29:22.881476]: ====================
[2018-04-17 18:29:22.886990]: Elapsed time since starting training: 2:34:08.283189
[2018-04-17 18:29:22.892003]: ====================
[2018-04-17 18:29:22.961187]: [Epoch: 1453(96.93128752501667%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:29:24.242093]: [Epoch: 1453(96.93128752501667%): Data: 25.333333333333336%]:Running loss: 4.350367486476898
[2018-04-17 18:29:25.510466]: [Epoch: 1453(96.93128752501667%): Data: 50.66666666666667%]:Running loss: 8.483216598629951
[2018-04-17 18:29:29.360202]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 18:29:29.492054]: ====================
[2018-04-17 18:29:29.497568]: Elapsed time since starting training: 2:34:14.893265
[2018-04-17 18:29:29.502582]: ====================
[2018-04-17 18:29:29.575776]: [Epoch: 1454(96.99799866577719%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 18:29:30.913833]: [Epoch: 1454(96.99799866577719%): Data: 25.333333333333336%]:Running loss: 4.350367873907089
[2018-04-17 18:29:32.165160]: [Epoch: 1454(96.99799866577719%): Data: 50.66666666666667%]:Running loss: 8.483217552304268
[2018-04-17 18:29:36.500689]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 18:29:36.648081]: ====================
[2018-04-17 18:29:36.652091]: Elapsed time since starting training: 2:34:22.048290
[2018-04-17 18:29:36.662620]: ====================
[2018-04-17 18:29:36.746341]: [Epoch: 1455(97.06470980653769%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 18:29:38.018224]: [Epoch: 1455(97.06470980653769%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 18:29:39.275066]: [Epoch: 1455(97.06470980653769%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 18:29:42.955853]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:29:43.093719]: ====================
[2018-04-17 18:29:43.098733]: Elapsed time since starting training: 2:34:28.494431
[2018-04-17 18:29:43.103746]: ====================
[2018-04-17 18:29:43.172443]: [Epoch: 1456(97.1314209472982%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:29:44.433782]: [Epoch: 1456(97.1314209472982%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:29:45.653024]: [Epoch: 1456(97.1314209472982%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:29:49.229033]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:29:49.360383]: ====================
[2018-04-17 18:29:49.364393]: Elapsed time since starting training: 2:34:34.760592
[2018-04-17 18:29:49.368905]: ====================
[2018-04-17 18:29:49.439094]: [Epoch: 1457(97.19813208805871%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:29:50.653826]: [Epoch: 1457(97.19813208805871%): Data: 25.333333333333336%]:Running loss: 4.3503688126802444
[2018-04-17 18:29:51.881085]: [Epoch: 1457(97.19813208805871%): Data: 50.66666666666667%]:Running loss: 8.483219340443611
[2018-04-17 18:29:55.300681]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 18:29:55.538314]: ====================
[2018-04-17 18:29:55.542826]: Elapsed time since starting training: 2:34:40.939025
[2018-04-17 18:29:55.547338]: ====================
[2018-04-17 18:29:55.616521]: [Epoch: 1458(97.2648432288192%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 18:29:56.855816]: [Epoch: 1458(97.2648432288192%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 18:29:58.080072]: [Epoch: 1458(97.2648432288192%): Data: 50.66666666666667%]:Running loss: 8.48321969807148
[2018-04-17 18:30:01.492646]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:30:01.619483]: ====================
[2018-04-17 18:30:01.624496]: Elapsed time since starting training: 2:34:47.020695
[2018-04-17 18:30:01.629009]: ====================
[2018-04-17 18:30:01.696187]: [Epoch: 1459(97.33155436957972%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:30:02.960550]: [Epoch: 1459(97.33155436957972%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 18:30:04.196335]: [Epoch: 1459(97.33155436957972%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 18:30:08.343864]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 18:30:08.552419]: ====================
[2018-04-17 18:30:08.558936]: Elapsed time since starting training: 2:34:53.955135
[2018-04-17 18:30:08.563949]: ====================
[2018-04-17 18:30:08.644162]: [Epoch: 1460(97.39826551034024%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 18:30:10.049398]: [Epoch: 1460(97.39826551034024%): Data: 25.333333333333336%]:Running loss: 4.3503697514534
[2018-04-17 18:30:11.433077]: [Epoch: 1460(97.39826551034024%): Data: 50.66666666666667%]:Running loss: 8.48322169482708
[2018-04-17 18:30:15.377566]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:30:15.512424]: ====================
[2018-04-17 18:30:15.517438]: Elapsed time since starting training: 2:35:00.913135
[2018-04-17 18:30:15.521949]: ====================
[2018-04-17 18:30:15.592638]: [Epoch: 1461(97.46497665110073%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:30:16.860007]: [Epoch: 1461(97.46497665110073%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:30:18.112839]: [Epoch: 1461(97.46497665110073%): Data: 50.66666666666667%]:Running loss: 8.483222514390945
[2018-04-17 18:30:21.711410]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:30:21.862813]: ====================
[2018-04-17 18:30:21.867826]: Elapsed time since starting training: 2:35:07.264025
[2018-04-17 18:30:21.873342]: ====================
[2018-04-17 18:30:21.944029]: [Epoch: 1462(97.53168779186124%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:30:23.241980]: [Epoch: 1462(97.53168779186124%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:30:24.475760]: [Epoch: 1462(97.53168779186124%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:30:27.986596]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:30:28.127972]: ====================
[2018-04-17 18:30:28.132985]: Elapsed time since starting training: 2:35:13.528683
[2018-04-17 18:30:28.137999]: ====================
[2018-04-17 18:30:28.209187]: [Epoch: 1463(97.59839893262175%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:30:29.470041]: [Epoch: 1463(97.59839893262175%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:30:30.725378]: [Epoch: 1463(97.59839893262175%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:30:34.239728]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:30:34.395141]: ====================
[2018-04-17 18:30:34.400656]: Elapsed time since starting training: 2:35:19.796855
[2018-04-17 18:30:34.405167]: ====================
[2018-04-17 18:30:34.475354]: [Epoch: 1464(97.66511007338225%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:30:35.737209]: [Epoch: 1464(97.66511007338225%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:30:36.999064]: [Epoch: 1464(97.66511007338225%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 18:30:40.507393]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:30:40.633729]: ====================
[2018-04-17 18:30:40.639745]: Elapsed time since starting training: 2:35:26.035944
[2018-04-17 18:30:40.644257]: ====================
[2018-04-17 18:30:40.712445]: [Epoch: 1465(97.73182121414277%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:30:41.998859]: [Epoch: 1465(97.73182121414277%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:30:43.278762]: [Epoch: 1465(97.73182121414277%): Data: 50.66666666666667%]:Running loss: 8.4832261800766
[2018-04-17 18:30:47.060819]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:30:47.202195]: ====================
[2018-04-17 18:30:47.208211]: Elapsed time since starting training: 2:35:32.604410
[2018-04-17 18:30:47.213224]: ====================
[2018-04-17 18:30:47.285917]: [Epoch: 1466(97.79853235490327%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 18:30:48.559805]: [Epoch: 1466(97.79853235490327%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 18:30:49.800103]: [Epoch: 1466(97.79853235490327%): Data: 50.66666666666667%]:Running loss: 8.483226656913757
[2018-04-17 18:30:53.295898]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:30:53.440282]: ====================
[2018-04-17 18:30:53.445295]: Elapsed time since starting training: 2:35:38.841494
[2018-04-17 18:30:53.450308]: ====================
[2018-04-17 18:30:53.519993]: [Epoch: 1467(97.86524349566378%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:30:54.773828]: [Epoch: 1467(97.86524349566378%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:30:56.031672]: [Epoch: 1467(97.86524349566378%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:30:59.561558]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 18:30:59.699926]: ====================
[2018-04-17 18:30:59.704438]: Elapsed time since starting training: 2:35:45.100135
[2018-04-17 18:30:59.708950]: ====================
[2018-04-17 18:30:59.776129]: [Epoch: 1468(97.93195463642428%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 18:31:01.006901]: [Epoch: 1468(97.93195463642428%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 18:31:02.248704]: [Epoch: 1468(97.93195463642428%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 18:31:05.742493]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:31:05.877352]: ====================
[2018-04-17 18:31:05.882365]: Elapsed time since starting training: 2:35:51.278063
[2018-04-17 18:31:05.886877]: ====================
[2018-04-17 18:31:05.958568]: [Epoch: 1469(97.99866577718478%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:31:07.207388]: [Epoch: 1469(97.99866577718478%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:31:08.450694]: [Epoch: 1469(97.99866577718478%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:31:12.121956]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:31:12.263834]: ====================
[2018-04-17 18:31:12.268847]: Elapsed time since starting training: 2:35:57.665046
[2018-04-17 18:31:12.273860]: ====================
[2018-04-17 18:31:12.350063]: [Epoch: 1470(98.0653769179453%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:31:13.646510]: [Epoch: 1470(98.0653769179453%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:31:14.960503]: [Epoch: 1470(98.0653769179453%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:31:18.530998]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:31:18.657835]: ====================
[2018-04-17 18:31:18.662347]: Elapsed time since starting training: 2:36:04.058546
[2018-04-17 18:31:18.666859]: ====================
[2018-04-17 18:31:18.737046]: [Epoch: 1471(98.1320880587058%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:31:19.998400]: [Epoch: 1471(98.1320880587058%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:31:21.265769]: [Epoch: 1471(98.1320880587058%): Data: 50.66666666666667%]:Running loss: 8.48322643339634
[2018-04-17 18:31:24.825234]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:31:24.958589]: ====================
[2018-04-17 18:31:24.963602]: Elapsed time since starting training: 2:36:10.359300
[2018-04-17 18:31:24.968615]: ====================
[2018-04-17 18:31:25.039303]: [Epoch: 1472(98.19879919946631%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:31:26.302662]: [Epoch: 1472(98.19879919946631%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:31:27.547472]: [Epoch: 1472(98.19879919946631%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 18:31:31.159577]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:31:31.312985]: ====================
[2018-04-17 18:31:31.317497]: Elapsed time since starting training: 2:36:16.713696
[2018-04-17 18:31:31.321508]: ====================
[2018-04-17 18:31:31.386180]: [Epoch: 1473(98.26551034022681%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:31:32.654552]: [Epoch: 1473(98.26551034022681%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:31:33.922423]: [Epoch: 1473(98.26551034022681%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:31:37.415712]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:31:37.547563]: ====================
[2018-04-17 18:31:37.552577]: Elapsed time since starting training: 2:36:22.948274
[2018-04-17 18:31:37.558592]: ====================
[2018-04-17 18:31:37.629781]: [Epoch: 1474(98.33222148098733%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:31:38.867572]: [Epoch: 1474(98.33222148098733%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:31:40.103358]: [Epoch: 1474(98.33222148098733%): Data: 50.66666666666667%]:Running loss: 8.483229130506516
[2018-04-17 18:31:43.655805]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 18:31:43.800188]: ====================
[2018-04-17 18:31:43.808210]: Elapsed time since starting training: 2:36:29.204409
[2018-04-17 18:31:43.813724]: ====================
[2018-04-17 18:31:43.887420]: [Epoch: 1475(98.39893262174783%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 18:31:45.147270]: [Epoch: 1475(98.39893262174783%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 18:31:46.405114]: [Epoch: 1475(98.39893262174783%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 18:31:49.945537]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 18:31:50.081399]: ====================
[2018-04-17 18:31:50.087415]: Elapsed time since starting training: 2:36:35.483614
[2018-04-17 18:31:50.092429]: ====================
[2018-04-17 18:31:50.162113]: [Epoch: 1476(98.46564376250834%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 18:31:51.404918]: [Epoch: 1476(98.46564376250834%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 18:31:52.657248]: [Epoch: 1476(98.46564376250834%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 18:31:56.157054]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:31:56.280382]: ====================
[2018-04-17 18:31:56.284894]: Elapsed time since starting training: 2:36:41.681093
[2018-04-17 18:31:56.289406]: ====================
[2018-04-17 18:31:56.358088]: [Epoch: 1477(98.53235490326885%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:31:57.595378]: [Epoch: 1477(98.53235490326885%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 18:31:58.829159]: [Epoch: 1477(98.53235490326885%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 18:32:02.370074]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 18:32:02.510448]: ====================
[2018-04-17 18:32:02.514960]: Elapsed time since starting training: 2:36:47.910657
[2018-04-17 18:32:02.519472]: ====================
[2018-04-17 18:32:02.588655]: [Epoch: 1478(98.59906604402934%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 18:32:03.823439]: [Epoch: 1478(98.59906604402934%): Data: 25.333333333333336%]:Running loss: 4.350374549627304
[2018-04-17 18:32:05.057219]: [Epoch: 1478(98.59906604402934%): Data: 50.66666666666667%]:Running loss: 8.483230456709862
[2018-04-17 18:32:08.613676]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 18:32:08.748033]: ====================
[2018-04-17 18:32:08.752545]: Elapsed time since starting training: 2:36:54.148744
[2018-04-17 18:32:08.757058]: ====================
[2018-04-17 18:32:08.825740]: [Epoch: 1479(98.66577718478986%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 18:32:10.068043]: [Epoch: 1479(98.66577718478986%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 18:32:11.342432]: [Epoch: 1479(98.66577718478986%): Data: 50.66666666666667%]:Running loss: 8.48323130607605
[2018-04-17 18:32:14.859286]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 18:32:15.001665]: ====================
[2018-04-17 18:32:15.005675]: Elapsed time since starting training: 2:37:00.401874
[2018-04-17 18:32:15.010689]: ====================
[2018-04-17 18:32:15.078369]: [Epoch: 1480(98.73248832555038%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 18:32:16.329695]: [Epoch: 1480(98.73248832555038%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 18:32:17.595561]: [Epoch: 1480(98.73248832555038%): Data: 50.66666666666667%]:Running loss: 8.483232319355011
[2018-04-17 18:32:21.191623]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:32:21.325479]: ====================
[2018-04-17 18:32:21.329991]: Elapsed time since starting training: 2:37:06.726190
[2018-04-17 18:32:21.334002]: ====================
[2018-04-17 18:32:21.401682]: [Epoch: 1481(98.79919946631087%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:32:22.644487]: [Epoch: 1481(98.79919946631087%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 18:32:23.875760]: [Epoch: 1481(98.79919946631087%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 18:32:27.370553]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 18:32:27.503908]: ====================
[2018-04-17 18:32:27.509422]: Elapsed time since starting training: 2:37:12.905621
[2018-04-17 18:32:27.515438]: ====================
[2018-04-17 18:32:27.584624]: [Epoch: 1482(98.86591060707138%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 18:32:28.823917]: [Epoch: 1482(98.86591060707138%): Data: 25.333333333333336%]:Running loss: 4.350367873907089
[2018-04-17 18:32:30.072237]: [Epoch: 1482(98.86591060707138%): Data: 50.66666666666667%]:Running loss: 8.483218118548393
[2018-04-17 18:32:33.585579]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 18:32:33.714421]: ====================
[2018-04-17 18:32:33.719937]: Elapsed time since starting training: 2:37:19.115634
[2018-04-17 18:32:33.724449]: ====================
[2018-04-17 18:32:33.794637]: [Epoch: 1483(98.93262174783189%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 18:32:35.054986]: [Epoch: 1483(98.93262174783189%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 18:32:36.288767]: [Epoch: 1483(98.93262174783189%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 18:32:39.783559]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 18:32:39.921928]: ====================
[2018-04-17 18:32:39.927943]: Elapsed time since starting training: 2:37:25.324142
[2018-04-17 18:32:39.932957]: ====================
[2018-04-17 18:32:40.002641]: [Epoch: 1484(98.99933288859239%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 18:32:41.224394]: [Epoch: 1484(98.99933288859239%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 18:32:42.456671]: [Epoch: 1484(98.99933288859239%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 18:32:45.977031]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:32:46.119911]: ====================
[2018-04-17 18:32:46.124926]: Elapsed time since starting training: 2:37:31.520622
[2018-04-17 18:32:46.131451]: ====================
[2018-04-17 18:32:46.200124]: [Epoch: 1485(99.06604402935291%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:32:47.441926]: [Epoch: 1485(99.06604402935291%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 18:32:48.682726]: [Epoch: 1485(99.06604402935291%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 18:32:52.201583]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:32:52.340953]: ====================
[2018-04-17 18:32:52.346467]: Elapsed time since starting training: 2:37:37.742666
[2018-04-17 18:32:52.351481]: ====================
[2018-04-17 18:32:52.421166]: [Epoch: 1486(99.13275517011341%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:32:53.672493]: [Epoch: 1486(99.13275517011341%): Data: 25.333333333333336%]:Running loss: 4.3503695875406265
[2018-04-17 18:32:54.908780]: [Epoch: 1486(99.13275517011341%): Data: 50.66666666666667%]:Running loss: 8.483220681548119
[2018-04-17 18:32:58.430645]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 18:32:58.560492]: ====================
[2018-04-17 18:32:58.565002]: Elapsed time since starting training: 2:37:43.961201
[2018-04-17 18:32:58.569515]: ====================
[2018-04-17 18:32:58.640704]: [Epoch: 1487(99.19946631087392%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 18:32:59.877492]: [Epoch: 1487(99.19946631087392%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 18:33:01.123305]: [Epoch: 1487(99.19946631087392%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 18:33:04.612082]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:33:04.743431]: ====================
[2018-04-17 18:33:04.747943]: Elapsed time since starting training: 2:37:50.143640
[2018-04-17 18:33:04.752455]: ====================
[2018-04-17 18:33:04.822140]: [Epoch: 1488(99.26617745163442%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:33:06.067962]: [Epoch: 1488(99.26617745163442%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 18:33:07.305243]: [Epoch: 1488(99.26617745163442%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 18:33:10.817582]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 18:33:10.943416]: ====================
[2018-04-17 18:33:10.948430]: Elapsed time since starting training: 2:37:56.344629
[2018-04-17 18:33:10.953444]: ====================
[2018-04-17 18:33:11.023630]: [Epoch: 1489(99.33288859239494%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 18:33:12.265431]: [Epoch: 1489(99.33288859239494%): Data: 25.333333333333336%]:Running loss: 4.350370824337006
[2018-04-17 18:33:13.512247]: [Epoch: 1489(99.33288859239494%): Data: 50.66666666666667%]:Running loss: 8.483223333954811
[2018-04-17 18:33:17.021077]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:33:17.165970]: ====================
[2018-04-17 18:33:17.170989]: Elapsed time since starting training: 2:38:02.567188
[2018-04-17 18:33:17.175989]: ====================
[2018-04-17 18:33:17.244170]: [Epoch: 1490(99.39959973315544%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:33:18.474942]: [Epoch: 1490(99.39959973315544%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:33:19.713737]: [Epoch: 1490(99.39959973315544%): Data: 50.66666666666667%]:Running loss: 8.48322419822216
[2018-04-17 18:33:23.202012]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 18:33:23.329351]: ====================
[2018-04-17 18:33:23.334364]: Elapsed time since starting training: 2:38:08.730563
[2018-04-17 18:33:23.339381]: ====================
[2018-04-17 18:33:23.408060]: [Epoch: 1491(99.46631087391594%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 18:33:24.649361]: [Epoch: 1491(99.46631087391594%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 18:33:25.871611]: [Epoch: 1491(99.46631087391594%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 18:33:29.351864]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:33:29.480206]: ====================
[2018-04-17 18:33:29.484718]: Elapsed time since starting training: 2:38:14.880917
[2018-04-17 18:33:29.489731]: ====================
[2018-04-17 18:33:29.559918]: [Epoch: 1492(99.53302201467645%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:33:30.787682]: [Epoch: 1492(99.53302201467645%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:33:32.023468]: [Epoch: 1492(99.53302201467645%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 18:33:35.490687]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:33:35.622038]: ====================
[2018-04-17 18:33:35.626549]: Elapsed time since starting training: 2:38:21.022748
[2018-04-17 18:33:35.631562]: ====================
[2018-04-17 18:33:35.701248]: [Epoch: 1493(99.59973315543695%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:33:36.955583]: [Epoch: 1493(99.59973315543695%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 18:33:38.199891]: [Epoch: 1493(99.59973315543695%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 18:33:41.673126]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 18:33:41.916273]: ====================
[2018-04-17 18:33:41.922791]: Elapsed time since starting training: 2:38:27.318990
[2018-04-17 18:33:41.927303]: ====================
[2018-04-17 18:33:41.994983]: [Epoch: 1494(99.66644429619747%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 18:33:43.231270]: [Epoch: 1494(99.66644429619747%): Data: 25.333333333333336%]:Running loss: 4.350372076034546
[2018-04-17 18:33:44.468058]: [Epoch: 1494(99.66644429619747%): Data: 50.66666666666667%]:Running loss: 8.483225718140602
[2018-04-17 18:33:47.946808]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 18:33:48.070637]: ====================
[2018-04-17 18:33:48.074648]: Elapsed time since starting training: 2:38:33.470847
[2018-04-17 18:33:48.079661]: ====================
[2018-04-17 18:33:48.145336]: [Epoch: 1495(99.73315543695797%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 18:33:49.382125]: [Epoch: 1495(99.73315543695797%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 18:33:50.616908]: [Epoch: 1495(99.73315543695797%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 18:33:54.100170]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 18:33:54.234026]: ====================
[2018-04-17 18:33:54.238037]: Elapsed time since starting training: 2:38:39.634236
[2018-04-17 18:33:54.242548]: ====================
[2018-04-17 18:33:54.315744]: [Epoch: 1496(99.79986657771848%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 18:33:55.546014]: [Epoch: 1496(99.79986657771848%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 18:33:56.777289]: [Epoch: 1496(99.79986657771848%): Data: 50.66666666666667%]:Running loss: 8.4832251816988
[2018-04-17 18:34:00.282609]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:34:00.410449]: ====================
[2018-04-17 18:34:00.414961]: Elapsed time since starting training: 2:38:45.811160
[2018-04-17 18:34:00.419974]: ====================
[2018-04-17 18:34:00.489159]: [Epoch: 1497(99.866577718479%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:34:01.731967]: [Epoch: 1497(99.866577718479%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 18:34:02.949199]: [Epoch: 1497(99.866577718479%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 18:34:06.434968]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 18:34:06.563810]: ====================
[2018-04-17 18:34:06.569326]: Elapsed time since starting training: 2:38:51.965024
[2018-04-17 18:34:06.573336]: ====================
[2018-04-17 18:34:06.643021]: [Epoch: 1498(99.93328885923948%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 18:34:07.877303]: [Epoch: 1498(99.93328885923948%): Data: 25.333333333333336%]:Running loss: 4.350371420383453
[2018-04-17 18:34:09.108577]: [Epoch: 1498(99.93328885923948%): Data: 50.66666666666667%]:Running loss: 8.483224779367447
[2018-04-17 18:34:12.602367]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 18:34:12.735722]: ====================
[2018-04-17 18:34:12.740234]: Elapsed time since starting training: 2:38:58.136433
[2018-04-17 18:34:12.744244]: ====================
[2018-04-17 18:34:12.815434]: [Epoch: 1499(100.0%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 18:34:14.047209]: [Epoch: 1499(100.0%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 18:34:15.280990]: [Epoch: 1499(100.0%): Data: 50.66666666666667%]:Running loss: 8.483225584030151
[2018-04-17 18:34:18.801852]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:34:18.929191]: ====================
[2018-04-17 18:34:18.934204]: Elapsed time since starting training: 2:39:04.329902
[2018-04-17 18:34:18.938716]: ====================
[2018-04-17 18:34:18.942726]: Elapsed time on training: 2:39:04.338925
[2018-04-17 18:34:20.139408]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 18:37:30.288530]: Starting
[2018-04-17 18:37:30.293544]: OS detected: Windows
[2018-04-17 18:37:30.300562]: Using G:\Data\map_data\ as file path
[2018-04-17 18:37:30.306077]: Using CUDA: True
[2018-04-17 18:37:31.298717]: Raw Data loaded. Turning to batches
[2018-04-17 18:37:31.316765]: Batches generated
[2018-04-17 18:37:31.321778]: Generating 25 string maps per stringless one.
[2018-04-17 18:37:31.326290]: Estimated time till completion of map generation: 0:37:30
[2018-04-17 18:37:31.330802]: Estimated time of completion of map generation: 2018-04-17 19:15:01.330802
[2018-04-17 18:37:31.334813]: Values for string maps: (G_mu,v,A):(1e-07,1,1e-07)
[2018-04-17 19:08:24.031433]: Training Batches generated. 75 Elements in train_arr.
[2018-04-17 19:08:24.035945]: 106 elements per train batch.
[2018-04-17 19:20:33.816318]: Testing Batches generated. 25 Elements in test_arr.
[2018-04-17 19:20:33.821331]: 106 elements per test batch.
[2018-04-17 19:20:33.829854]: Network and optimizers created
[2018-04-17 19:20:33.835369]: Projected finishing time = 2018-04-17 20:35:33.835369
[2018-04-17 19:20:33.842389]: Projected time to completion = 1:15:00
[2018-04-17 19:20:34.051443]: [Epoch: 0(0.0%): Data: 0.0%]:Running loss: 0.7616611123085022
[2018-04-17 19:20:35.564968]: [Epoch: 0(0.0%): Data: 25.333333333333336%]:Running loss: 15.136441946029663
[2018-04-17 19:20:37.132637]: [Epoch: 0(0.0%): Data: 50.66666666666667%]:Running loss: 29.329971313476562
[2018-04-17 19:20:41.458137]: Test set accuracy: 5.660377358490566% ,loss = 18.118467926979065
[2018-04-17 19:20:49.100458]: ====================
[2018-04-17 19:20:49.105472]: Elapsed time since starting training: 0:00:15.270103
[2018-04-17 19:20:49.109984]: Estimated time left: 1:14:44.725886
[2018-04-17 19:20:49.114496]: ====================
[2018-04-17 19:20:49.187189]: [Epoch: 1(0.10010010010010009%): Data: 0.0%]:Running loss: 0.7247387170791626
[2018-04-17 19:20:50.703220]: [Epoch: 1(0.10010010010010009%): Data: 25.333333333333336%]:Running loss: 14.405722498893738
[2018-04-17 19:20:52.190676]: [Epoch: 1(0.10010010010010009%): Data: 50.66666666666667%]:Running loss: 27.91992074251175
[2018-04-17 19:20:56.523195]: Test set accuracy: 94.33962264150944% ,loss = 17.269141972064972
[2018-04-17 19:20:58.695973]: ====================
[2018-04-17 19:20:58.701989]: Elapsed time since starting training: 0:00:24.866620
[2018-04-17 19:20:58.708005]: Estimated time left: 1:14:35.127865
[2018-04-17 19:20:58.715524]: ====================
[2018-04-17 19:20:58.788719]: [Epoch: 2(0.20020020020020018%): Data: 0.0%]:Running loss: 0.6907656788825989
[2018-04-17 19:21:00.278181]: [Epoch: 2(0.20020020020020018%): Data: 25.333333333333336%]:Running loss: 13.733377814292908
[2018-04-17 19:21:01.788697]: [Epoch: 2(0.20020020020020018%): Data: 50.66666666666667%]:Running loss: 26.622537851333618
[2018-04-17 19:21:06.133749]: Test set accuracy: 94.33962264150944% ,loss = 16.487714648246765
[2018-04-17 19:21:06.784981]: ====================
[2018-04-17 19:21:06.792502]: Elapsed time since starting training: 0:00:32.957133
[2018-04-17 19:21:06.799520]: Estimated time left: 1:14:27.035849
[2018-04-17 19:21:06.804533]: ====================
[2018-04-17 19:21:06.875221]: [Epoch: 3(0.3003003003003003%): Data: 0.0%]:Running loss: 0.6595085859298706
[2018-04-17 19:21:08.355156]: [Epoch: 3(0.3003003003003003%): Data: 25.333333333333336%]:Running loss: 13.114788234233856
[2018-04-17 19:21:09.830579]: [Epoch: 3(0.3003003003003003%): Data: 50.66666666666667%]:Running loss: 25.428877472877502
[2018-04-17 19:21:14.220754]: Test set accuracy: 94.33962264150944% ,loss = 15.768690407276154
[2018-04-17 19:21:14.340572]: ====================
[2018-04-17 19:21:14.345585]: Elapsed time since starting training: 0:00:40.509714
[2018-04-17 19:21:14.350098]: Estimated time left: 1:14:19.485271
[2018-04-17 19:21:14.356114]: ====================
[2018-04-17 19:21:14.478939]: [Epoch: 4(0.40040040040040037%): Data: 0.0%]:Running loss: 0.6307476162910461
[2018-04-17 19:21:15.935813]: [Epoch: 4(0.40040040040040037%): Data: 25.333333333333336%]:Running loss: 12.545575201511383
[2018-04-17 19:21:17.371631]: [Epoch: 4(0.40040040040040037%): Data: 50.66666666666667%]:Running loss: 24.330459117889404
[2018-04-17 19:21:21.563778]: Test set accuracy: 94.33962264150944% ,loss = 15.106867253780365
[2018-04-17 19:21:21.726210]: ====================
[2018-04-17 19:21:21.731223]: Elapsed time since starting training: 0:00:47.895854
[2018-04-17 19:21:21.736738]: Estimated time left: 1:14:12.099132
[2018-04-17 19:21:21.742253]: ====================
[2018-04-17 19:21:21.818455]: [Epoch: 5(0.5005005005005005%): Data: 0.0%]:Running loss: 0.6042746901512146
[2018-04-17 19:21:23.307916]: [Epoch: 5(0.5005005005005005%): Data: 25.333333333333336%]:Running loss: 12.02162092924118
[2018-04-17 19:21:24.768801]: [Epoch: 5(0.5005005005005005%): Data: 50.66666666666667%]:Running loss: 23.31931871175766
[2018-04-17 19:21:28.872211]: Test set accuracy: 94.33962264150944% ,loss = 14.497396349906921
[2018-04-17 19:21:29.014088]: ====================
[2018-04-17 19:21:29.019603]: Elapsed time since starting training: 0:00:55.183733
[2018-04-17 19:21:29.024617]: Estimated time left: 1:14:04.810752
[2018-04-17 19:21:29.032637]: ====================
[2018-04-17 19:21:29.103326]: [Epoch: 6(0.6006006006006006%): Data: 0.0%]:Running loss: 0.5798958539962769
[2018-04-17 19:21:30.645927]: [Epoch: 6(0.6006006006006006%): Data: 25.333333333333336%]:Running loss: 11.539076745510101
[2018-04-17 19:21:32.089766]: [Epoch: 6(0.6006006006006006%): Data: 50.66666666666667%]:Running loss: 22.38802045583725
[2018-04-17 19:21:36.434318]: Test set accuracy: 94.33962264150944% ,loss = 13.935783505439758
[2018-04-17 19:21:36.585721]: ====================
[2018-04-17 19:21:36.591737]: Elapsed time since starting training: 0:01:02.756368
[2018-04-17 19:21:36.601764]: Estimated time left: 1:13:57.233605
[2018-04-17 19:21:36.607780]: ====================
[2018-04-17 19:21:36.720079]: [Epoch: 7(0.7007007007007007%): Data: 0.0%]:Running loss: 0.5574313402175903
[2018-04-17 19:21:38.162916]: [Epoch: 7(0.7007007007007007%): Data: 25.333333333333336%]:Running loss: 11.094383001327515
[2018-04-17 19:21:39.587703]: [Epoch: 7(0.7007007007007007%): Data: 50.66666666666667%]:Running loss: 21.52969664335251
[2018-04-17 19:21:43.686101]: Test set accuracy: 94.33962264150944% ,loss = 13.417887687683105
[2018-04-17 19:21:43.847029]: ====================
[2018-04-17 19:21:43.851541]: Elapsed time since starting training: 0:01:10.016172
[2018-04-17 19:21:43.856554]: Estimated time left: 1:13:49.979316
[2018-04-17 19:21:43.860565]: ====================
[2018-04-17 19:21:43.935765]: [Epoch: 8(0.8008008008008007%): Data: 0.0%]:Running loss: 0.5367155075073242
[2018-04-17 19:21:45.408181]: [Epoch: 8(0.8008008008008007%): Data: 25.333333333333336%]:Running loss: 10.684253692626953
[2018-04-17 19:21:46.991390]: [Epoch: 8(0.8008008008008007%): Data: 50.66666666666667%]:Running loss: 20.738003134727478
[2018-04-17 19:21:51.201084]: Test set accuracy: 94.33962264150944% ,loss = 12.939861416816711
[2018-04-17 19:21:51.327419]: ====================
[2018-04-17 19:21:51.331931]: Elapsed time since starting training: 0:01:17.496562
[2018-04-17 19:21:51.336444]: Estimated time left: 1:13:42.499427
[2018-04-17 19:21:51.340956]: ====================
[2018-04-17 19:21:51.424176]: [Epoch: 9(0.9009009009009009%): Data: 0.0%]:Running loss: 0.5175944566726685
[2018-04-17 19:21:52.873530]: [Epoch: 9(0.9009009009009009%): Data: 25.333333333333336%]:Running loss: 10.305673599243164
[2018-04-17 19:21:54.391567]: [Epoch: 9(0.9009009009009009%): Data: 50.66666666666667%]:Running loss: 20.007126450538635
[2018-04-17 19:21:58.754167]: Test set accuracy: 94.33962264150944% ,loss = 12.49825581908226
[2018-04-17 19:21:58.899553]: ====================
[2018-04-17 19:21:58.905068]: Elapsed time since starting training: 0:01:25.069699
[2018-04-17 19:21:58.910082]: Estimated time left: 1:13:34.925789
[2018-04-17 19:21:58.914594]: ====================
[2018-04-17 19:21:58.987788]: [Epoch: 10(1.001001001001001%): Data: 0.0%]:Running loss: 0.4999302327632904
[2018-04-17 19:22:00.491286]: [Epoch: 10(1.001001001001001%): Data: 25.333333333333336%]:Running loss: 9.95588281750679
[2018-04-17 19:22:01.915573]: [Epoch: 10(1.001001001001001%): Data: 50.66666666666667%]:Running loss: 19.33174628019333
[2018-04-17 19:22:06.276669]: Test set accuracy: 94.33962264150944% ,loss = 12.089882791042328
[2018-04-17 19:22:06.462664]: ====================
[2018-04-17 19:22:06.467677]: Elapsed time since starting training: 0:01:32.632308
[2018-04-17 19:22:06.474195]: Estimated time left: 1:13:27.361174
[2018-04-17 19:22:06.481714]: ====================
[2018-04-17 19:22:06.550898]: [Epoch: 11(1.1011011011011012%): Data: 0.0%]:Running loss: 0.4835953116416931
[2018-04-17 19:22:08.055900]: [Epoch: 11(1.1011011011011012%): Data: 25.333333333333336%]:Running loss: 9.632367372512817
[2018-04-17 19:22:09.523804]: [Epoch: 11(1.1011011011011012%): Data: 50.66666666666667%]:Running loss: 18.70701503753662
[2018-04-17 19:22:13.726986]: Test set accuracy: 94.33962264150944% ,loss = 11.711817979812622
[2018-04-17 19:22:13.863348]: ====================
[2018-04-17 19:22:13.868862]: Elapsed time since starting training: 0:01:40.033493
[2018-04-17 19:22:13.877887]: Estimated time left: 1:13:19.957482
[2018-04-17 19:22:13.882399]: ====================
[2018-04-17 19:22:13.980158]: [Epoch: 12(1.2012012012012012%): Data: 0.0%]:Running loss: 0.4684727191925049
[2018-04-17 19:22:15.675667]: [Epoch: 12(1.2012012012012012%): Data: 25.333333333333336%]:Running loss: 9.33283132314682
[2018-04-17 19:22:17.125021]: [Epoch: 12(1.2012012012012012%): Data: 50.66666666666667%]:Running loss: 18.12851557135582
[2018-04-17 19:22:21.318170]: Test set accuracy: 94.33962264150944% ,loss = 11.36145144701004
[2018-04-17 19:22:21.480101]: ====================
[2018-04-17 19:22:21.485616]: Elapsed time since starting training: 0:01:47.650247
[2018-04-17 19:22:21.490629]: Estimated time left: 1:13:12.344740
[2018-04-17 19:22:21.495642]: ====================
[2018-04-17 19:22:21.568837]: [Epoch: 13(1.3013013013013013%): Data: 0.0%]:Running loss: 0.4544580578804016
[2018-04-17 19:22:23.060303]: [Epoch: 13(1.3013013013013013%): Data: 25.333333333333336%]:Running loss: 9.05519750714302
[2018-04-17 19:22:24.624963]: [Epoch: 13(1.3013013013013013%): Data: 50.66666666666667%]:Running loss: 17.59223636984825
[2018-04-17 19:22:29.157014]: Test set accuracy: 94.33962264150944% ,loss = 11.036383360624313
[2018-04-17 19:22:29.276833]: ====================
[2018-04-17 19:22:29.297387]: Elapsed time since starting training: 0:01:55.462018
[2018-04-17 19:22:29.310421]: Estimated time left: 1:13:04.525449
[2018-04-17 19:22:29.324960]: ====================
[2018-04-17 19:22:29.420213]: [Epoch: 14(1.4014014014014013%): Data: 0.0%]:Running loss: 0.44145533442497253
[2018-04-17 19:22:31.027988]: [Epoch: 14(1.4014014014014013%): Data: 25.333333333333336%]:Running loss: 8.797571957111359
[2018-04-17 19:22:32.558559]: [Epoch: 14(1.4014014014014013%): Data: 50.66666666666667%]:Running loss: 17.094537883996964
[2018-04-17 19:22:36.848471]: Test set accuracy: 94.33962264150944% ,loss = 10.73443815112114
[2018-04-17 19:22:37.015416]: ====================
[2018-04-17 19:22:37.020930]: Elapsed time since starting training: 0:02:03.185059
[2018-04-17 19:22:37.025442]: Estimated time left: 1:12:56.809927
[2018-04-17 19:22:37.031458]: ====================
[2018-04-17 19:22:37.106657]: [Epoch: 15(1.5015015015015014%): Data: 0.0%]:Running loss: 0.4293775260448456
[2018-04-17 19:22:38.667809]: [Epoch: 15(1.5015015015015014%): Data: 25.333333333333336%]:Running loss: 8.55824425816536
[2018-04-17 19:22:40.299147]: [Epoch: 15(1.5015015015015014%): Data: 50.66666666666667%]:Running loss: 16.632118731737137
[2018-04-17 19:22:44.575517]: Test set accuracy: 94.33962264150944% ,loss = 10.453668981790543
[2018-04-17 19:22:44.706365]: ====================
[2018-04-17 19:22:44.714387]: Elapsed time since starting training: 0:02:10.878517
[2018-04-17 19:22:44.718397]: Estimated time left: 1:12:49.116972
[2018-04-17 19:22:44.723411]: ====================
[2018-04-17 19:22:44.792595]: [Epoch: 16(1.6016016016016015%): Data: 0.0%]:Running loss: 0.4181467592716217
[2018-04-17 19:22:46.361266]: [Epoch: 16(1.6016016016016015%): Data: 25.333333333333336%]:Running loss: 8.335658997297287
[2018-04-17 19:22:47.887826]: [Epoch: 16(1.6016016016016015%): Data: 50.66666666666667%]:Running loss: 16.20199105143547
[2018-04-17 19:22:52.378265]: Test set accuracy: 94.33962264150944% ,loss = 10.19226461648941
[2018-04-17 19:22:52.568270]: ====================
[2018-04-17 19:22:52.573786]: Elapsed time since starting training: 0:02:18.737914
[2018-04-17 19:22:52.578798]: Estimated time left: 1:12:41.256571
[2018-04-17 19:22:52.583812]: ====================
[2018-04-17 19:22:52.658510]: [Epoch: 17(1.7017017017017018%): Data: 0.0%]:Running loss: 0.4076905846595764
[2018-04-17 19:22:54.291854]: [Epoch: 17(1.7017017017017018%): Data: 25.333333333333336%]:Running loss: 8.128406077623367
[2018-04-17 19:22:55.856513]: [Epoch: 17(1.7017017017017018%): Data: 50.66666666666667%]:Running loss: 15.801430583000183
[2018-04-17 19:23:00.164970]: Test set accuracy: 94.33962264150944% ,loss = 9.948630630970001
[2018-04-17 19:23:00.328905]: ====================
[2018-04-17 19:23:00.334421]: Elapsed time since starting training: 0:02:26.498549
[2018-04-17 19:23:00.338933]: Estimated time left: 1:12:33.496436
[2018-04-17 19:23:00.343444]: ====================
[2018-04-17 19:23:00.418644]: [Epoch: 18(1.8018018018018018%): Data: 0.0%]:Running loss: 0.39794522523880005
[2018-04-17 19:23:01.941694]: [Epoch: 18(1.8018018018018018%): Data: 25.333333333333336%]:Running loss: 7.935209721326828
[2018-04-17 19:23:03.545960]: [Epoch: 18(1.8018018018018018%): Data: 50.66666666666667%]:Running loss: 15.427985101938248
[2018-04-17 19:23:07.705037]: Test set accuracy: 94.33962264150944% ,loss = 9.721299260854721
[2018-04-17 19:23:07.853433]: ====================
[2018-04-17 19:23:07.858445]: Elapsed time since starting training: 0:02:34.022575
[2018-04-17 19:23:07.862957]: Estimated time left: 1:12:25.972412
[2018-04-17 19:23:07.870478]: ====================
[2018-04-17 19:23:07.939661]: [Epoch: 19(1.9019019019019021%): Data: 0.0%]:Running loss: 0.38885197043418884
[2018-04-17 19:23:09.439650]: [Epoch: 19(1.9019019019019021%): Data: 25.333333333333336%]:Running loss: 7.754911422729492
[2018-04-17 19:23:10.919084]: [Epoch: 19(1.9019019019019021%): Data: 50.66666666666667%]:Running loss: 15.07942196726799
[2018-04-17 19:23:15.161865]: Test set accuracy: 94.33962264150944% ,loss = 9.508927911520004
[2018-04-17 19:23:15.331816]: ====================
[2018-04-17 19:23:15.336830]: Elapsed time since starting training: 0:02:41.501461
[2018-04-17 19:23:15.341342]: Estimated time left: 1:12:18.494027
[2018-04-17 19:23:15.346355]: ====================
[2018-04-17 19:23:15.426569]: [Epoch: 20(2.002002002002002%): Data: 0.0%]:Running loss: 0.38035711646080017
[2018-04-17 19:23:16.965304]: [Epoch: 20(2.002002002002002%): Data: 25.333333333333336%]:Running loss: 7.586461275815964
[2018-04-17 19:23:18.511917]: [Epoch: 20(2.002002002002002%): Data: 50.66666666666667%]:Running loss: 14.753719687461853
[2018-04-17 19:23:22.806837]: Test set accuracy: 94.33962264150944% ,loss = 9.310326725244522
[2018-04-17 19:23:22.936181]: ====================
[2018-04-17 19:23:22.940693]: Elapsed time since starting training: 0:02:49.105324
[2018-04-17 19:23:22.945707]: Estimated time left: 1:12:10.889662
[2018-04-17 19:23:22.950218]: ====================
[2018-04-17 19:23:23.072043]: [Epoch: 21(2.1021021021021022%): Data: 0.0%]:Running loss: 0.3724130690097809
[2018-04-17 19:23:24.569023]: [Epoch: 21(2.1021021021021022%): Data: 25.333333333333336%]:Running loss: 7.428909540176392
[2018-04-17 19:23:26.087563]: [Epoch: 21(2.1021021021021022%): Data: 50.66666666666667%]:Running loss: 14.44904774427414
[2018-04-17 19:23:30.510321]: Test set accuracy: 94.33962264150944% ,loss = 9.124401211738586
[2018-04-17 19:23:30.620113]: ====================
[2018-04-17 19:23:30.624625]: Elapsed time since starting training: 0:02:56.789256
[2018-04-17 19:23:30.631644]: Estimated time left: 1:12:03.203725
[2018-04-17 19:23:30.637158]: ====================
[2018-04-17 19:23:30.710854]: [Epoch: 22(2.2022022022022023%): Data: 0.0%]:Running loss: 0.36497604846954346
[2018-04-17 19:23:32.415386]: [Epoch: 22(2.2022022022022023%): Data: 25.333333333333336%]:Running loss: 7.2813878655433655
[2018-04-17 19:23:33.994084]: [Epoch: 22(2.2022022022022023%): Data: 50.66666666666667%]:Running loss: 14.163733541965485
[2018-04-17 19:23:38.155148]: Test set accuracy: 94.33962264150944% ,loss = 8.950143307447433
[2018-04-17 19:23:38.299031]: ====================
[2018-04-17 19:23:38.303542]: Elapsed time since starting training: 0:03:04.468173
[2018-04-17 19:23:38.308055]: Estimated time left: 1:11:55.527314
[2018-04-17 19:23:38.313068]: ====================
[2018-04-17 19:23:38.384257]: [Epoch: 23(2.3023023023023024%): Data: 0.0%]:Running loss: 0.35800573229789734
[2018-04-17 19:23:39.855168]: [Epoch: 23(2.3023023023023024%): Data: 25.333333333333336%]:Running loss: 7.143111974000931
[2018-04-17 19:23:41.439882]: [Epoch: 23(2.3023023023023024%): Data: 50.66666666666667%]:Running loss: 13.896265864372253
[2018-04-17 19:23:45.891218]: Test set accuracy: 94.33962264150944% ,loss = 8.78666490316391
[2018-04-17 19:23:46.046130]: ====================
[2018-04-17 19:23:46.051143]: Elapsed time since starting training: 0:03:12.215774
[2018-04-17 19:23:46.055655]: Estimated time left: 1:11:47.779714
[2018-04-17 19:23:46.061170]: ====================
[2018-04-17 19:23:46.130855]: [Epoch: 24(2.4024024024024024%): Data: 0.0%]:Running loss: 0.3514665961265564
[2018-04-17 19:23:47.667943]: [Epoch: 24(2.4024024024024024%): Data: 25.333333333333336%]:Running loss: 7.013366937637329
[2018-04-17 19:23:49.133343]: [Epoch: 24(2.4024024024024024%): Data: 50.66666666666667%]:Running loss: 13.645265847444534
[2018-04-17 19:23:53.390161]: Test set accuracy: 94.33962264150944% ,loss = 8.633123338222504
[2018-04-17 19:23:53.550086]: ====================
[2018-04-17 19:23:53.555099]: Elapsed time since starting training: 0:03:19.719730
[2018-04-17 19:23:53.562620]: Estimated time left: 1:11:40.272749
[2018-04-17 19:23:53.568134]: ====================
[2018-04-17 19:23:53.641329]: [Epoch: 25(2.5025025025025025%): Data: 0.0%]:Running loss: 0.34532493352890015
[2018-04-17 19:23:55.126277]: [Epoch: 25(2.5025025025025025%): Data: 25.333333333333336%]:Running loss: 6.891501188278198
[2018-04-17 19:23:56.586660]: [Epoch: 25(2.5025025025025025%): Data: 50.66666666666667%]:Running loss: 13.409479528665543
[2018-04-17 19:24:00.786329]: Test set accuracy: 94.33962264150944% ,loss = 8.488793671131134
[2018-04-17 19:24:00.931212]: ====================
[2018-04-17 19:24:00.936226]: Elapsed time since starting training: 0:03:27.100857
[2018-04-17 19:24:00.940737]: Estimated time left: 1:11:32.894632
[2018-04-17 19:24:00.949261]: ====================
[2018-04-17 19:24:01.016439]: [Epoch: 26(2.6026026026026026%): Data: 0.0%]:Running loss: 0.33955174684524536
[2018-04-17 19:24:02.530966]: [Epoch: 26(2.6026026026026026%): Data: 25.333333333333336%]:Running loss: 6.77692186832428
[2018-04-17 19:24:04.024951]: [Epoch: 26(2.6026026026026026%): Data: 50.66666666666667%]:Running loss: 13.187764436006546
[2018-04-17 19:24:08.134867]: Test set accuracy: 94.33962264150944% ,loss = 8.352965861558914
[2018-04-17 19:24:08.407091]: ====================
[2018-04-17 19:24:08.413106]: Elapsed time since starting training: 0:03:34.577737
[2018-04-17 19:24:08.418121]: Estimated time left: 1:11:25.417248
[2018-04-17 19:24:08.423133]: ====================
[2018-04-17 19:24:08.496829]: [Epoch: 27(2.7027027027027026%): Data: 0.0%]:Running loss: 0.33411863446235657
[2018-04-17 19:24:10.034418]: [Epoch: 27(2.7027027027027026%): Data: 25.333333333333336%]:Running loss: 6.669087290763855
[2018-04-17 19:24:11.548945]: [Epoch: 27(2.7027027027027026%): Data: 50.66666666666667%]:Running loss: 12.979074954986572
[2018-04-17 19:24:15.849881]: Test set accuracy: 94.33962264150944% ,loss = 8.225032687187195
[2018-04-17 19:24:15.961678]: ====================
[2018-04-17 19:24:15.966190]: Elapsed time since starting training: 0:03:42.130821
[2018-04-17 19:24:15.970702]: Estimated time left: 1:11:17.864667
[2018-04-17 19:24:15.975214]: ====================
[2018-04-17 19:24:16.075983]: [Epoch: 28(2.8028028028028027%): Data: 0.0%]:Running loss: 0.3290013074874878
[2018-04-17 19:24:17.519821]: [Epoch: 28(2.8028028028028027%): Data: 25.333333333333336%]:Running loss: 6.5675066113471985
[2018-04-17 19:24:19.032343]: [Epoch: 28(2.8028028028028027%): Data: 50.66666666666667%]:Running loss: 12.782463937997818
[2018-04-17 19:24:23.228500]: Test set accuracy: 94.33962264150944% ,loss = 8.104418218135834
[2018-04-17 19:24:23.353332]: ====================
[2018-04-17 19:24:23.361354]: Elapsed time since starting training: 0:03:49.525483
[2018-04-17 19:24:23.367370]: Estimated time left: 1:11:10.467999
[2018-04-17 19:24:23.371882]: ====================
[2018-04-17 19:24:23.471147]: [Epoch: 29(2.902902902902903%): Data: 0.0%]:Running loss: 0.32417672872543335
[2018-04-17 19:24:24.950078]: [Epoch: 29(2.902902902902903%): Data: 25.333333333333336%]:Running loss: 6.471725583076477
[2018-04-17 19:24:26.406953]: [Epoch: 29(2.902902902902903%): Data: 50.66666666666667%]:Running loss: 12.597058087587357
[2018-04-17 19:24:30.770555]: Test set accuracy: 94.33962264150944% ,loss = 7.990606129169464
[2018-04-17 19:24:30.895387]: ====================
[2018-04-17 19:24:30.900400]: Elapsed time since starting training: 0:03:57.065031
[2018-04-17 19:24:30.905915]: Estimated time left: 1:11:02.929956
[2018-04-17 19:24:30.910427]: ====================
[2018-04-17 19:24:30.991643]: [Epoch: 30(3.003003003003003%): Data: 0.0%]:Running loss: 0.31962424516677856
[2018-04-17 19:24:32.497647]: [Epoch: 30(3.003003003003003%): Data: 25.333333333333336%]:Running loss: 6.381332635879517
[2018-04-17 19:24:33.967055]: [Epoch: 30(3.003003003003003%): Data: 50.66666666666667%]:Running loss: 12.422063052654266
[2018-04-17 19:24:38.204321]: Test set accuracy: 94.33962264150944% ,loss = 7.883103936910629
[2018-04-17 19:24:38.354221]: ====================
[2018-04-17 19:24:38.367254]: Elapsed time since starting training: 0:04:04.531384
[2018-04-17 19:24:38.371766]: Estimated time left: 1:10:55.463603
[2018-04-17 19:24:38.376278]: ====================
[2018-04-17 19:24:38.447969]: [Epoch: 31(3.1031031031031033%): Data: 0.0%]:Running loss: 0.31532415747642517
[2018-04-17 19:24:39.961997]: [Epoch: 31(3.1031031031031033%): Data: 25.333333333333336%]:Running loss: 6.295941382646561
[2018-04-17 19:24:41.417364]: [Epoch: 31(3.1031031031031033%): Data: 50.66666666666667%]:Running loss: 12.25673121213913
[2018-04-17 19:24:45.639090]: Test set accuracy: 94.33962264150944% ,loss = 7.781483232975006
[2018-04-17 19:24:45.804029]: ====================
[2018-04-17 19:24:45.809042]: Elapsed time since starting training: 0:04:11.973673
[2018-04-17 19:24:45.814056]: Estimated time left: 1:10:48.021313
[2018-04-17 19:24:45.818567]: ====================
[2018-04-17 19:24:45.890258]: [Epoch: 32(3.203203203203203%): Data: 0.0%]:Running loss: 0.31125932931900024
[2018-04-17 19:24:47.399271]: [Epoch: 32(3.203203203203203%): Data: 25.333333333333336%]:Running loss: 6.215219110250473
[2018-04-17 19:24:48.878705]: [Epoch: 32(3.203203203203203%): Data: 50.66666666666667%]:Running loss: 12.100425660610199
[2018-04-17 19:24:53.089902]: Test set accuracy: 94.33962264150944% ,loss = 7.685340940952301
[2018-04-17 19:24:53.206714]: ====================
[2018-04-17 19:24:53.211224]: Elapsed time since starting training: 0:04:19.375855
[2018-04-17 19:24:53.216237]: Estimated time left: 1:10:40.619633
[2018-04-17 19:24:53.220750]: ====================
[2018-04-17 19:24:53.304974]: [Epoch: 33(3.303303303303303%): Data: 0.0%]:Running loss: 0.30741363763809204
[2018-04-17 19:24:54.869133]: [Epoch: 33(3.303303303303303%): Data: 25.333333333333336%]:Running loss: 6.138843894004822
[2018-04-17 19:24:56.297430]: [Epoch: 33(3.303303303303303%): Data: 50.66666666666667%]:Running loss: 11.952521860599518
[2018-04-17 19:25:00.537705]: Test set accuracy: 94.33962264150944% ,loss = 7.594317942857742
[2018-04-17 19:25:00.687103]: ====================
[2018-04-17 19:25:00.691614]: Elapsed time since starting training: 0:04:26.856245
[2018-04-17 19:25:00.696628]: Estimated time left: 1:10:33.139242
[2018-04-17 19:25:00.701140]: ====================
[2018-04-17 19:25:00.770324]: [Epoch: 34(3.4034034034034035%): Data: 0.0%]:Running loss: 0.3037727177143097
[2018-04-17 19:25:02.343005]: [Epoch: 34(3.4034034034034035%): Data: 25.333333333333336%]:Running loss: 6.066521018743515
[2018-04-17 19:25:03.860039]: [Epoch: 34(3.4034034034034035%): Data: 50.66666666666667%]:Running loss: 11.812449634075165
[2018-04-17 19:25:08.070235]: Test set accuracy: 94.33962264150944% ,loss = 7.508069276809692
[2018-04-17 19:25:08.193061]: ====================
[2018-04-17 19:25:08.197573]: Elapsed time since starting training: 0:04:34.361703
[2018-04-17 19:25:08.202086]: Estimated time left: 1:10:25.633283
[2018-04-17 19:25:08.206597]: ====================
[2018-04-17 19:25:08.326416]: [Epoch: 35(3.5035035035035036%): Data: 0.0%]:Running loss: 0.3003227710723877
[2018-04-17 19:25:09.809860]: [Epoch: 35(3.5035035035035036%): Data: 25.333333333333336%]:Running loss: 5.997981399297714
[2018-04-17 19:25:11.358478]: [Epoch: 35(3.5035035035035036%): Data: 50.66666666666667%]:Running loss: 11.679693758487701
[2018-04-17 19:25:15.681473]: Test set accuracy: 94.33962264150944% ,loss = 7.426267117261887
[2018-04-17 19:25:15.802796]: ====================
[2018-04-17 19:25:15.807808]: Elapsed time since starting training: 0:04:41.972439
[2018-04-17 19:25:15.812320]: Estimated time left: 1:10:18.023049
[2018-04-17 19:25:15.817335]: ====================
[2018-04-17 19:25:15.918102]: [Epoch: 36(3.6036036036036037%): Data: 0.0%]:Running loss: 0.29705068469047546
[2018-04-17 19:25:17.491786]: [Epoch: 36(3.6036036036036037%): Data: 25.333333333333336%]:Running loss: 5.932977974414825
[2018-04-17 19:25:18.993279]: [Epoch: 36(3.6036036036036037%): Data: 50.66666666666667%]:Running loss: 11.553774267435074
[2018-04-17 19:25:23.159356]: Test set accuracy: 94.33962264150944% ,loss = 7.348643243312836
[2018-04-17 19:25:23.311260]: ====================
[2018-04-17 19:25:23.316273]: Elapsed time since starting training: 0:04:49.480403
[2018-04-17 19:25:23.323292]: Estimated time left: 1:10:10.512077
[2018-04-17 19:25:23.327805]: ====================
[2018-04-17 19:25:23.399494]: [Epoch: 37(3.7037037037037033%): Data: 0.0%]:Running loss: 0.2939457297325134
[2018-04-17 19:25:24.879933]: [Epoch: 37(3.7037037037037033%): Data: 25.333333333333336%]:Running loss: 5.871282547712326
[2018-04-17 19:25:26.377915]: [Epoch: 37(3.7037037037037033%): Data: 50.66666666666667%]:Running loss: 11.434250116348267
[2018-04-17 19:25:30.554018]: Test set accuracy: 94.33962264150944% ,loss = 7.274910062551498
[2018-04-17 19:25:30.673837]: ====================
[2018-04-17 19:25:30.680856]: Elapsed time since starting training: 0:04:56.845487
[2018-04-17 19:25:30.685368]: Estimated time left: 1:10:03.150001
[2018-04-17 19:25:30.689879]: ====================
[2018-04-17 19:25:30.772098]: [Epoch: 38(3.8038038038038042%): Data: 0.0%]:Running loss: 0.29099640250205994
[2018-04-17 19:25:32.326231]: [Epoch: 38(3.8038038038038042%): Data: 25.333333333333336%]:Running loss: 5.8126823008060455
[2018-04-17 19:25:33.786113]: [Epoch: 38(3.8038038038038042%): Data: 50.66666666666667%]:Running loss: 11.320714116096497
[2018-04-17 19:25:37.948680]: Test set accuracy: 94.33962264150944% ,loss = 7.204848527908325
[2018-04-17 19:25:38.123647]: ====================
[2018-04-17 19:25:38.128660]: Elapsed time since starting training: 0:05:04.292789
[2018-04-17 19:25:38.134675]: Estimated time left: 1:09:55.701194
[2018-04-17 19:25:38.139689]: ====================
[2018-04-17 19:25:38.208873]: [Epoch: 39(3.903903903903904%): Data: 0.0%]:Running loss: 0.288193941116333
[2018-04-17 19:25:39.703849]: [Epoch: 39(3.903903903903904%): Data: 25.333333333333336%]:Running loss: 5.756986290216446
[2018-04-17 19:25:41.226898]: [Epoch: 39(3.903903903903904%): Data: 50.66666666666667%]:Running loss: 11.212795317173004
[2018-04-17 19:25:45.486725]: Test set accuracy: 94.33962264150944% ,loss = 7.138212025165558
[2018-04-17 19:25:45.645146]: ====================
[2018-04-17 19:25:45.650159]: Elapsed time since starting training: 0:05:11.814790
[2018-04-17 19:25:45.654671]: Estimated time left: 1:09:48.181200
[2018-04-17 19:25:45.658682]: ====================
[2018-04-17 19:25:45.731876]: [Epoch: 40(4.004004004004004%): Data: 0.0%]:Running loss: 0.2855284810066223
[2018-04-17 19:25:47.269967]: [Epoch: 40(4.004004004004004%): Data: 25.333333333333336%]:Running loss: 5.704010456800461
[2018-04-17 19:25:48.758925]: [Epoch: 40(4.004004004004004%): Data: 50.66666666666667%]:Running loss: 11.110139638185501
[2018-04-17 19:25:53.089440]: Test set accuracy: 94.33962264150944% ,loss = 7.074790447950363
[2018-04-17 19:25:53.211264]: ====================
[2018-04-17 19:25:53.215776]: Elapsed time since starting training: 0:05:19.380407
[2018-04-17 19:25:53.220789]: Estimated time left: 1:09:40.614580
[2018-04-17 19:25:53.225803]: ====================
[2018-04-17 19:25:53.320554]: [Epoch: 41(4.1041041041041035%): Data: 0.0%]:Running loss: 0.2829916179180145
[2018-04-17 19:25:54.819541]: [Epoch: 41(4.1041041041041035%): Data: 25.333333333333336%]:Running loss: 5.653591990470886
[2018-04-17 19:25:56.362142]: [Epoch: 41(4.1041041041041035%): Data: 50.66666666666667%]:Running loss: 11.01242944598198
[2018-04-17 19:26:00.673105]: Test set accuracy: 94.33962264150944% ,loss = 7.014399021863937
[2018-04-17 19:26:00.788913]: ====================
[2018-04-17 19:26:00.793425]: Elapsed time since starting training: 0:05:26.958056
[2018-04-17 19:26:00.802449]: Estimated time left: 1:09:33.033420
[2018-04-17 19:26:00.808465]: ====================
[2018-04-17 19:26:00.918257]: [Epoch: 42(4.2042042042042045%): Data: 0.0%]:Running loss: 0.2805759608745575
[2018-04-17 19:26:02.470384]: [Epoch: 42(4.2042042042042045%): Data: 25.333333333333336%]:Running loss: 5.605573445558548
[2018-04-17 19:26:03.944804]: [Epoch: 42(4.2042042042042045%): Data: 50.66666666666667%]:Running loss: 10.919364124536514
[2018-04-17 19:26:08.442263]: Test set accuracy: 94.33962264150944% ,loss = 6.956857442855835
[2018-04-17 19:26:08.629260]: ====================
[2018-04-17 19:26:08.641292]: Elapsed time since starting training: 0:05:34.805923
[2018-04-17 19:26:08.646807]: Estimated time left: 1:09:25.188562
[2018-04-17 19:26:08.655329]: ====================
[2018-04-17 19:26:08.738551]: [Epoch: 43(4.3043043043043046%): Data: 0.0%]:Running loss: 0.2782742977142334
[2018-04-17 19:26:10.418016]: [Epoch: 43(4.3043043043043046%): Data: 25.333333333333336%]:Running loss: 5.559815913438797
[2018-04-17 19:26:12.077932]: [Epoch: 43(4.3043043043043046%): Data: 50.66666666666667%]:Running loss: 10.83067438006401
[2018-04-17 19:26:16.490162]: Test set accuracy: 94.33962264150944% ,loss = 6.901988387107849
[2018-04-17 19:26:16.634046]: ====================
[2018-04-17 19:26:16.640562]: Elapsed time since starting training: 0:05:42.805193
[2018-04-17 19:26:16.645575]: Estimated time left: 1:09:17.189794
[2018-04-17 19:26:16.651090]: ====================
[2018-04-17 19:26:16.721277]: [Epoch: 44(4.404404404404405%): Data: 0.0%]:Running loss: 0.27607953548431396
[2018-04-17 19:26:18.203720]: [Epoch: 44(4.404404404404405%): Data: 25.333333333333336%]:Running loss: 5.516182392835617
[2018-04-17 19:26:19.688166]: [Epoch: 44(4.404404404404405%): Data: 50.66666666666667%]:Running loss: 10.74609363079071
[2018-04-17 19:26:23.923433]: Test set accuracy: 94.33962264150944% ,loss = 6.849636137485504
[2018-04-17 19:26:24.041247]: ====================
[2018-04-17 19:26:24.045758]: Elapsed time since starting training: 0:05:50.210389
[2018-04-17 19:26:24.051274]: Estimated time left: 1:09:09.784597
[2018-04-17 19:26:24.055786]: ====================
[2018-04-17 19:26:24.157558]: [Epoch: 45(4.504504504504505%): Data: 0.0%]:Running loss: 0.27398544549942017
[2018-04-17 19:26:25.620947]: [Epoch: 45(4.504504504504505%): Data: 25.333333333333336%]:Running loss: 5.474550276994705
[2018-04-17 19:26:27.009138]: [Epoch: 45(4.504504504504505%): Data: 50.66666666666667%]:Running loss: 10.66538742184639
[2018-04-17 19:26:30.969167]: Test set accuracy: 94.33962264150944% ,loss = 6.799665838479996
[2018-04-17 19:26:31.090992]: ====================
[2018-04-17 19:26:31.095504]: Elapsed time since starting training: 0:05:57.260135
[2018-04-17 19:26:31.100016]: Estimated time left: 1:09:02.735353
[2018-04-17 19:26:31.107536]: ====================
[2018-04-17 19:26:31.180229]: [Epoch: 46(4.604604604604605%): Data: 0.0%]:Running loss: 0.27198663353919983
[2018-04-17 19:26:32.531824]: [Epoch: 46(4.604604604604605%): Data: 25.333333333333336%]:Running loss: 5.4348064959049225
[2018-04-17 19:26:33.856846]: [Epoch: 46(4.604604604604605%): Data: 50.66666666666667%]:Running loss: 10.58833709359169
[2018-04-17 19:26:37.674998]: Test set accuracy: 94.33962264150944% ,loss = 6.751936674118042
[2018-04-17 19:26:37.798828]: ====================
[2018-04-17 19:26:37.804844]: Elapsed time since starting training: 0:06:03.969475
[2018-04-17 19:26:37.810358]: Estimated time left: 1:08:56.025011
[2018-04-17 19:26:37.815372]: ====================
[2018-04-17 19:26:37.888065]: [Epoch: 47(4.704704704704705%): Data: 0.0%]:Running loss: 0.2700774669647217
[2018-04-17 19:26:39.225622]: [Epoch: 47(4.704704704704705%): Data: 25.333333333333336%]:Running loss: 5.396842807531357
[2018-04-17 19:26:40.561173]: [Epoch: 47(4.704704704704705%): Data: 50.66666666666667%]:Running loss: 10.514732450246811
[2018-04-17 19:26:44.472573]: Test set accuracy: 94.33962264150944% ,loss = 6.706327199935913
[2018-04-17 19:26:44.608434]: ====================
[2018-04-17 19:26:44.613448]: Elapsed time since starting training: 0:06:10.777578
[2018-04-17 19:26:44.618963]: Estimated time left: 1:08:49.216406
[2018-04-17 19:26:44.623976]: ====================
[2018-04-17 19:26:44.697673]: [Epoch: 48(4.804804804804805%): Data: 0.0%]:Running loss: 0.2682530879974365
[2018-04-17 19:26:46.185628]: [Epoch: 48(4.804804804804805%): Data: 25.333333333333336%]:Running loss: 5.360561519861221
[2018-04-17 19:26:47.691633]: [Epoch: 48(4.804804804804805%): Data: 50.66666666666667%]:Running loss: 10.444382697343826
[2018-04-17 19:26:52.005604]: Test set accuracy: 94.33962264150944% ,loss = 6.6627152264118195
[2018-04-17 19:26:52.171545]: ====================
[2018-04-17 19:26:52.176057]: Elapsed time since starting training: 0:06:18.340688
[2018-04-17 19:26:52.181572]: Estimated time left: 1:08:41.654299
[2018-04-17 19:26:52.186585]: ====================
[2018-04-17 19:26:52.258275]: [Epoch: 49(4.904904904904905%): Data: 0.0%]:Running loss: 0.2665086090564728
[2018-04-17 19:26:53.727182]: [Epoch: 49(4.904904904904905%): Data: 25.333333333333336%]:Running loss: 5.325867027044296
[2018-04-17 19:26:55.228675]: [Epoch: 49(4.904904904904905%): Data: 50.66666666666667%]:Running loss: 10.377107203006744
[2018-04-17 19:26:59.744181]: Test set accuracy: 94.33962264150944% ,loss = 6.620991230010986
[2018-04-17 19:26:59.915636]: ====================
[2018-04-17 19:26:59.923156]: Elapsed time since starting training: 0:06:26.087288
[2018-04-17 19:26:59.932682]: Estimated time left: 1:08:33.903189
[2018-04-17 19:26:59.938196]: ====================
[2018-04-17 19:27:00.011893]: [Epoch: 50(5.005005005005005%): Data: 0.0%]:Running loss: 0.26483964920043945
[2018-04-17 19:27:01.535944]: [Epoch: 50(5.005005005005005%): Data: 25.333333333333336%]:Running loss: 5.292674154043198
[2018-04-17 19:27:03.144221]: [Epoch: 50(5.005005005005005%): Data: 50.66666666666667%]:Running loss: 10.312738835811615
[2018-04-17 19:27:07.318821]: Test set accuracy: 94.33962264150944% ,loss = 6.581059098243713
[2018-04-17 19:27:07.437637]: ====================
[2018-04-17 19:27:07.444656]: Elapsed time since starting training: 0:06:33.608786
[2018-04-17 19:27:07.449168]: Estimated time left: 1:08:26.386201
[2018-04-17 19:27:07.454182]: ====================
[2018-04-17 19:27:07.555451]: [Epoch: 51(5.105105105105105%): Data: 0.0%]:Running loss: 0.26324236392974854
[2018-04-17 19:27:09.018341]: [Epoch: 51(5.105105105105105%): Data: 25.333333333333336%]:Running loss: 5.260902047157288
[2018-04-17 19:27:10.450649]: [Epoch: 51(5.105105105105105%): Data: 50.66666666666667%]:Running loss: 10.25112298130989
[2018-04-17 19:27:14.637782]: Test set accuracy: 94.33962264150944% ,loss = 6.542811542749405
[2018-04-17 19:27:14.755094]: ====================
[2018-04-17 19:27:14.762113]: Elapsed time since starting training: 0:06:40.926243
[2018-04-17 19:27:14.767627]: Estimated time left: 1:08:19.067742
[2018-04-17 19:27:14.772641]: ====================
[2018-04-17 19:27:14.881431]: [Epoch: 52(5.205205205205205%): Data: 0.0%]:Running loss: 0.2617124617099762
[2018-04-17 19:27:16.297703]: [Epoch: 52(5.205205205205205%): Data: 25.333333333333336%]:Running loss: 5.23047348856926
[2018-04-17 19:27:17.784656]: [Epoch: 52(5.205205205205205%): Data: 50.66666666666667%]:Running loss: 10.192108154296875
[2018-04-17 19:27:21.889571]: Test set accuracy: 94.33962264150944% ,loss = 6.5061792731285095
[2018-04-17 19:27:22.044984]: ====================
[2018-04-17 19:27:22.049496]: Elapsed time since starting training: 0:06:48.214127
[2018-04-17 19:27:22.054509]: Estimated time left: 1:08:11.780860
[2018-04-17 19:27:22.059021]: ====================
[2018-04-17 19:27:22.130212]: [Epoch: 53(5.305305305305305%): Data: 0.0%]:Running loss: 0.2602471709251404
[2018-04-17 19:27:23.608141]: [Epoch: 53(5.305305305305305%): Data: 25.333333333333336%]:Running loss: 5.201320052146912
[2018-04-17 19:27:25.148737]: [Epoch: 53(5.305305305305305%): Data: 50.66666666666667%]:Running loss: 10.135562479496002
[2018-04-17 19:27:29.344393]: Test set accuracy: 94.33962264150944% ,loss = 6.47105872631073
[2018-04-17 19:27:29.498805]: ====================
[2018-04-17 19:27:29.503817]: Elapsed time since starting training: 0:06:55.667947
[2018-04-17 19:27:29.508830]: Estimated time left: 1:08:04.326539
[2018-04-17 19:27:29.516351]: ====================
[2018-04-17 19:27:29.588542]: [Epoch: 54(5.405405405405405%): Data: 0.0%]:Running loss: 0.2588423490524292
[2018-04-17 19:27:31.088030]: [Epoch: 54(5.405405405405405%): Data: 25.333333333333336%]:Running loss: 5.173373579978943
[2018-04-17 19:27:32.619101]: [Epoch: 54(5.405405405405405%): Data: 50.66666666666667%]:Running loss: 10.081356585025787
[2018-04-17 19:27:36.805733]: Test set accuracy: 94.33962264150944% ,loss = 6.437380611896515
[2018-04-17 19:27:36.924047]: ====================
[2018-04-17 19:27:36.944603]: Elapsed time since starting training: 0:07:03.108732
[2018-04-17 19:27:36.969669]: Estimated time left: 1:07:56.865700
[2018-04-17 19:27:36.975685]: ====================
[2018-04-17 19:27:37.051387]: [Epoch: 55(5.505505505505505%): Data: 0.0%]:Running loss: 0.2574952244758606
[2018-04-17 19:27:38.528816]: [Epoch: 55(5.505505505505505%): Data: 25.333333333333336%]:Running loss: 5.146572440862656
[2018-04-17 19:27:40.024793]: [Epoch: 55(5.505505505505505%): Data: 50.66666666666667%]:Running loss: 10.029368698596954
[2018-04-17 19:27:44.204907]: Test set accuracy: 94.33962264150944% ,loss = 6.4050644636154175
[2018-04-17 19:27:44.348289]: ====================
[2018-04-17 19:27:44.353302]: Elapsed time since starting training: 0:07:10.517933
[2018-04-17 19:27:44.360321]: Estimated time left: 1:07:49.475048
[2018-04-17 19:27:44.366337]: ====================
[2018-04-17 19:27:44.438529]: [Epoch: 56(5.605605605605605%): Data: 0.0%]:Running loss: 0.2562025785446167
[2018-04-17 19:27:45.933003]: [Epoch: 56(5.605605605605605%): Data: 25.333333333333336%]:Running loss: 5.120859742164612
[2018-04-17 19:27:47.416948]: [Epoch: 56(5.605605605605605%): Data: 50.66666666666667%]:Running loss: 9.979487121105194
[2018-04-17 19:27:51.509330]: Test set accuracy: 94.33962264150944% ,loss = 6.37405663728714
[2018-04-17 19:27:51.662238]: ====================
[2018-04-17 19:27:51.667249]: Elapsed time since starting training: 0:07:17.831880
[2018-04-17 19:27:51.672263]: Estimated time left: 1:07:42.163106
[2018-04-17 19:27:51.679783]: ====================
[2018-04-17 19:27:51.755485]: [Epoch: 57(5.7057057057057055%): Data: 0.0%]:Running loss: 0.2549622654914856
[2018-04-17 19:27:53.238929]: [Epoch: 57(5.7057057057057055%): Data: 25.333333333333336%]:Running loss: 5.0961781442165375
[2018-04-17 19:27:54.722374]: [Epoch: 57(5.7057057057057055%): Data: 50.66666666666667%]:Running loss: 9.931605696678162
[2018-04-17 19:27:58.876419]: Test set accuracy: 94.33962264150944% ,loss = 6.344278156757355
[2018-04-17 19:27:59.115554]: ====================
[2018-04-17 19:27:59.120568]: Elapsed time since starting training: 0:07:25.285199
[2018-04-17 19:27:59.125582]: Estimated time left: 1:07:34.709787
[2018-04-17 19:27:59.130093]: ====================
[2018-04-17 19:27:59.239885]: [Epoch: 58(5.805805805805806%): Data: 0.0%]:Running loss: 0.2537711262702942
[2018-04-17 19:28:00.705282]: [Epoch: 58(5.805805805805806%): Data: 25.333333333333336%]:Running loss: 5.07247868180275
[2018-04-17 19:28:02.117036]: [Epoch: 58(5.805805805805806%): Data: 50.66666666666667%]:Running loss: 9.885626405477524
[2018-04-17 19:28:06.316703]: Test set accuracy: 94.33962264150944% ,loss = 6.315676122903824
[2018-04-17 19:28:06.436521]: ====================
[2018-04-17 19:28:06.441033]: Elapsed time since starting training: 0:07:32.605664
[2018-04-17 19:28:06.446046]: Estimated time left: 1:07:27.389323
[2018-04-17 19:28:06.450558]: ====================
[2018-04-17 19:28:06.549823]: [Epoch: 59(5.905905905905906%): Data: 0.0%]:Running loss: 0.25262704491615295
[2018-04-17 19:28:07.991656]: [Epoch: 59(5.905905905905906%): Data: 25.333333333333336%]:Running loss: 5.049712687730789
[2018-04-17 19:28:09.467580]: [Epoch: 59(5.905905905905906%): Data: 50.66666666666667%]:Running loss: 9.841455638408661
[2018-04-17 19:28:13.779545]: Test set accuracy: 94.33962264150944% ,loss = 6.288193911314011
[2018-04-17 19:28:13.935962]: ====================
[2018-04-17 19:28:13.940975]: Elapsed time since starting training: 0:07:40.105105
[2018-04-17 19:28:13.945487]: Estimated time left: 1:07:19.890383
[2018-04-17 19:28:13.949999]: ====================
[2018-04-17 19:28:14.023194]: [Epoch: 60(6.006006006006006%): Data: 0.0%]:Running loss: 0.2515277564525604
[2018-04-17 19:28:15.495609]: [Epoch: 60(6.006006006006006%): Data: 25.333333333333336%]:Running loss: 5.027832448482513
[2018-04-17 19:28:17.076813]: [Epoch: 60(6.006006006006006%): Data: 50.66666666666667%]:Running loss: 9.79900336265564
[2018-04-17 19:28:21.407829]: Test set accuracy: 94.33962264150944% ,loss = 6.26177191734314
[2018-04-17 19:28:21.528150]: ====================
[2018-04-17 19:28:21.532661]: Elapsed time since starting training: 0:07:47.697292
[2018-04-17 19:28:21.537674]: Estimated time left: 1:07:12.297695
[2018-04-17 19:28:21.542689]: ====================
[2018-04-17 19:28:21.653989]: [Epoch: 61(6.106106106106106%): Data: 0.0%]:Running loss: 0.2504708766937256
[2018-04-17 19:28:23.129908]: [Epoch: 61(6.106106106106106%): Data: 25.333333333333336%]:Running loss: 5.006798088550568
[2018-04-17 19:28:24.667498]: [Epoch: 61(6.106106106106106%): Data: 50.66666666666667%]:Running loss: 9.758187651634216
[2018-04-17 19:28:28.841095]: Test set accuracy: 94.33962264150944% ,loss = 6.236356124281883
[2018-04-17 19:28:28.960413]: ====================
[2018-04-17 19:28:28.977457]: Elapsed time since starting training: 0:07:55.142088
[2018-04-17 19:28:28.986982]: Estimated time left: 1:07:04.848387
[2018-04-17 19:28:29.005532]: ====================
[2018-04-17 19:28:29.076721]: [Epoch: 62(6.206206206206207%): Data: 0.0%]:Running loss: 0.24945424497127533
[2018-04-17 19:28:30.569697]: [Epoch: 62(6.206206206206207%): Data: 25.333333333333336%]:Running loss: 4.98656952381134
[2018-04-17 19:28:32.037601]: [Epoch: 62(6.206206206206207%): Data: 50.66666666666667%]:Running loss: 9.718934461474419
[2018-04-17 19:28:36.218216]: Test set accuracy: 94.33962264150944% ,loss = 6.211905553936958
[2018-04-17 19:28:36.372124]: ====================
[2018-04-17 19:28:36.377639]: Elapsed time since starting training: 0:08:02.542270
[2018-04-17 19:28:36.382653]: Estimated time left: 1:06:57.453218
[2018-04-17 19:28:36.387164]: ====================
[2018-04-17 19:28:36.460860]: [Epoch: 63(6.306306306306306%): Data: 0.0%]:Running loss: 0.24847622215747833
[2018-04-17 19:28:37.953831]: [Epoch: 63(6.306306306306306%): Data: 25.333333333333336%]:Running loss: 4.967105567455292
[2018-04-17 19:28:39.440283]: [Epoch: 63(6.306306306306306%): Data: 50.66666666666667%]:Running loss: 9.681163594126701
[2018-04-17 19:28:43.663512]: Test set accuracy: 94.33962264150944% ,loss = 6.188380345702171
[2018-04-17 19:28:43.785336]: ====================
[2018-04-17 19:28:43.790851]: Elapsed time since starting training: 0:08:09.955482
[2018-04-17 19:28:43.797870]: Estimated time left: 1:06:50.037499
[2018-04-17 19:28:43.802382]: ====================
[2018-04-17 19:28:43.905155]: [Epoch: 64(6.406406406406406%): Data: 0.0%]:Running loss: 0.24753521382808685
[2018-04-17 19:28:45.394624]: [Epoch: 64(6.406406406406406%): Data: 25.333333333333336%]:Running loss: 4.9483741372823715
[2018-04-17 19:28:46.835948]: [Epoch: 64(6.406406406406406%): Data: 50.66666666666667%]:Running loss: 9.64481121301651
[2018-04-17 19:28:51.056169]: Test set accuracy: 94.33962264150944% ,loss = 6.165731698274612
[2018-04-17 19:28:51.205567]: ====================
[2018-04-17 19:28:51.211081]: Elapsed time since starting training: 0:08:17.375712
[2018-04-17 19:28:51.215593]: Estimated time left: 1:06:42.619776
[2018-04-17 19:28:51.220606]: ====================
[2018-04-17 19:28:51.294302]: [Epoch: 65(6.506506506506507%): Data: 0.0%]:Running loss: 0.2466292679309845
[2018-04-17 19:28:52.809332]: [Epoch: 65(6.506506506506507%): Data: 25.333333333333336%]:Running loss: 4.93033629655838
[2018-04-17 19:28:54.345415]: [Epoch: 65(6.506506506506507%): Data: 50.66666666666667%]:Running loss: 9.60980612039566
[2018-04-17 19:28:58.537061]: Test set accuracy: 94.33962264150944% ,loss = 6.143908575177193
[2018-04-17 19:28:58.688965]: ====================
[2018-04-17 19:28:58.693477]: Elapsed time since starting training: 0:08:24.858108
[2018-04-17 19:28:58.697989]: Estimated time left: 1:06:35.137380
[2018-04-17 19:28:58.702501]: ====================
[2018-04-17 19:28:58.775195]: [Epoch: 66(6.606606606606606%): Data: 0.0%]:Running loss: 0.2457563430070877
[2018-04-17 19:29:00.352388]: [Epoch: 66(6.606606606606606%): Data: 25.333333333333336%]:Running loss: 4.912967413663864
[2018-04-17 19:29:01.878947]: [Epoch: 66(6.606606606606606%): Data: 50.66666666666667%]:Running loss: 9.576094180345535
[2018-04-17 19:29:06.151308]: Test set accuracy: 94.33962264150944% ,loss = 6.1228930950164795
[2018-04-17 19:29:06.275137]: ====================
[2018-04-17 19:29:06.280651]: Elapsed time since starting training: 0:08:32.445282
[2018-04-17 19:29:06.285163]: Estimated time left: 1:06:27.550206
[2018-04-17 19:29:06.290180]: ====================
[2018-04-17 19:29:06.400971]: [Epoch: 67(6.706706706706707%): Data: 0.0%]:Running loss: 0.24491572380065918
[2018-04-17 19:29:07.936554]: [Epoch: 67(6.706706706706707%): Data: 25.333333333333336%]:Running loss: 4.89623136818409
[2018-04-17 19:29:09.426516]: [Epoch: 67(6.706706706706707%): Data: 50.66666666666667%]:Running loss: 9.54361230134964
[2018-04-17 19:29:13.651750]: Test set accuracy: 94.33962264150944% ,loss = 6.1026375740766525
[2018-04-17 19:29:13.815186]: ====================
[2018-04-17 19:29:13.821703]: Elapsed time since starting training: 0:08:39.985832
[2018-04-17 19:29:13.826215]: Estimated time left: 1:06:20.009656
[2018-04-17 19:29:13.833235]: ====================
[2018-04-17 19:29:13.901416]: [Epoch: 68(6.806806806806807%): Data: 0.0%]:Running loss: 0.2441055029630661
[2018-04-17 19:29:15.480616]: [Epoch: 68(6.806806806806807%): Data: 25.333333333333336%]:Running loss: 4.880101442337036
[2018-04-17 19:29:16.970576]: [Epoch: 68(6.806806806806807%): Data: 50.66666666666667%]:Running loss: 9.512306168675423
[2018-04-17 19:29:21.108077]: Test set accuracy: 94.33962264150944% ,loss = 6.083114817738533
[2018-04-17 19:29:21.227394]: ====================
[2018-04-17 19:29:21.245442]: Elapsed time since starting training: 0:08:47.410073
[2018-04-17 19:29:21.265496]: Estimated time left: 1:06:12.569873
[2018-04-17 19:29:21.279533]: ====================
[2018-04-17 19:29:21.352227]: [Epoch: 69(6.906906906906906%): Data: 0.0%]:Running loss: 0.24332459270954132
[2018-04-17 19:29:22.811607]: [Epoch: 69(6.906906906906906%): Data: 25.333333333333336%]:Running loss: 4.86455200612545
[2018-04-17 19:29:24.342678]: [Epoch: 69(6.906906906906906%): Data: 50.66666666666667%]:Running loss: 9.482123523950577
[2018-04-17 19:29:28.614040]: Test set accuracy: 94.33962264150944% ,loss = 6.064276024699211
[2018-04-17 19:29:28.731853]: ====================
[2018-04-17 19:29:28.737368]: Elapsed time since starting training: 0:08:54.901999
[2018-04-17 19:29:28.741879]: Estimated time left: 1:06:05.093991
[2018-04-17 19:29:28.746391]: ====================
[2018-04-17 19:29:28.828109]: [Epoch: 70(7.007007007007007%): Data: 0.0%]:Running loss: 0.24257104098796844
[2018-04-17 19:29:30.304535]: [Epoch: 70(7.007007007007007%): Data: 25.333333333333336%]:Running loss: 4.849556386470795
[2018-04-17 19:29:31.820566]: [Epoch: 70(7.007007007007007%): Data: 50.66666666666667%]:Running loss: 9.453014984726906
[2018-04-17 19:29:36.116990]: Test set accuracy: 94.33962264150944% ,loss = 6.0461170971393585
[2018-04-17 19:29:36.270398]: ====================
[2018-04-17 19:29:36.275412]: Elapsed time since starting training: 0:09:02.439541
[2018-04-17 19:29:36.282931]: Estimated time left: 1:05:57.552939
[2018-04-17 19:29:36.287945]: ====================
[2018-04-17 19:29:36.360137]: [Epoch: 71(7.107107107107106%): Data: 0.0%]:Running loss: 0.24184468388557434
[2018-04-17 19:29:37.806987]: [Epoch: 71(7.107107107107106%): Data: 25.333333333333336%]:Running loss: 4.835091829299927
[2018-04-17 19:29:39.279901]: [Epoch: 71(7.107107107107106%): Data: 50.66666666666667%]:Running loss: 9.424936056137085
[2018-04-17 19:29:43.571316]: Test set accuracy: 94.33962264150944% ,loss = 6.028593331575394
[2018-04-17 19:29:43.729737]: ====================
[2018-04-17 19:29:43.734249]: Elapsed time since starting training: 0:09:09.898378
[2018-04-17 19:29:43.738259]: Estimated time left: 1:05:50.097110
[2018-04-17 19:29:43.742270]: ====================
[2018-04-17 19:29:43.814963]: [Epoch: 72(7.207207207207207%): Data: 0.0%]:Running loss: 0.24114373326301575
[2018-04-17 19:29:45.323476]: [Epoch: 72(7.207207207207207%): Data: 25.333333333333336%]:Running loss: 4.821134686470032
[2018-04-17 19:29:46.867079]: [Epoch: 72(7.207207207207207%): Data: 50.66666666666667%]:Running loss: 9.397840574383736
[2018-04-17 19:29:51.019620]: Test set accuracy: 94.33962264150944% ,loss = 6.011674553155899
[2018-04-17 19:29:51.173529]: ====================
[2018-04-17 19:29:51.179044]: Elapsed time since starting training: 0:09:17.343675
[2018-04-17 19:29:51.183556]: Estimated time left: 1:05:42.651813
[2018-04-17 19:29:51.188069]: ====================
[2018-04-17 19:29:51.259258]: [Epoch: 73(7.307307307307307%): Data: 0.0%]:Running loss: 0.24046698212623596
[2018-04-17 19:29:52.799855]: [Epoch: 73(7.307307307307307%): Data: 25.333333333333336%]:Running loss: 4.807660087943077
[2018-04-17 19:29:54.334434]: [Epoch: 73(7.307307307307307%): Data: 50.66666666666667%]:Running loss: 9.371681585907936
[2018-04-17 19:29:58.527584]: Test set accuracy: 94.33962264150944% ,loss = 5.995337292551994
[2018-04-17 19:29:58.651915]: ====================
[2018-04-17 19:29:58.656427]: Elapsed time since starting training: 0:09:24.821058
[2018-04-17 19:29:58.661941]: Estimated time left: 1:05:35.173428
[2018-04-17 19:29:58.666453]: ====================
[2018-04-17 19:29:58.777749]: [Epoch: 74(7.4074074074074066%): Data: 0.0%]:Running loss: 0.23981349170207977
[2018-04-17 19:30:00.267712]: [Epoch: 74(7.4074074074074066%): Data: 25.333333333333336%]:Running loss: 4.794651314616203
[2018-04-17 19:30:01.815827]: [Epoch: 74(7.4074074074074066%): Data: 50.66666666666667%]:Running loss: 9.346427723765373
[2018-04-17 19:30:06.035052]: Test set accuracy: 94.33962264150944% ,loss = 5.979568138718605
[2018-04-17 19:30:06.190966]: ====================
[2018-04-17 19:30:06.196482]: Elapsed time since starting training: 0:09:32.361113
[2018-04-17 19:30:06.203500]: Estimated time left: 1:05:27.631869
[2018-04-17 19:30:06.208012]: ====================
[2018-04-17 19:30:06.285719]: [Epoch: 75(7.5075075075075075%): Data: 0.0%]:Running loss: 0.2391827255487442
[2018-04-17 19:30:07.824310]: [Epoch: 75(7.5075075075075075%): Data: 25.333333333333336%]:Running loss: 4.782089546322823
[2018-04-17 19:30:09.430584]: [Epoch: 75(7.5075075075075075%): Data: 50.66666666666667%]:Running loss: 9.322037473320961
[2018-04-17 19:30:13.810227]: Test set accuracy: 94.33962264150944% ,loss = 5.964330956339836
[2018-04-17 19:30:13.971656]: ====================
[2018-04-17 19:30:13.976669]: Elapsed time since starting training: 0:09:40.140799
[2018-04-17 19:30:13.981181]: Estimated time left: 1:05:19.854188
[2018-04-17 19:30:13.985693]: ====================
[2018-04-17 19:30:14.061895]: [Epoch: 76(7.6076076076076085%): Data: 0.0%]:Running loss: 0.23857323825359344
[2018-04-17 19:30:15.549853]: [Epoch: 76(7.6076076076076085%): Data: 25.333333333333336%]:Running loss: 4.769952714443207
[2018-04-17 19:30:17.037809]: [Epoch: 76(7.6076076076076085%): Data: 50.66666666666667%]:Running loss: 9.29847440123558
[2018-04-17 19:30:21.331224]: Test set accuracy: 94.33962264150944% ,loss = 5.949611589312553
[2018-04-17 19:30:21.452547]: ====================
[2018-04-17 19:30:21.457059]: Elapsed time since starting training: 0:09:47.621690
[2018-04-17 19:30:21.461571]: Estimated time left: 1:05:12.373798
[2018-04-17 19:30:21.466083]: ====================
[2018-04-17 19:30:21.576877]: [Epoch: 77(7.707707707707708%): Data: 0.0%]:Running loss: 0.23798446357250214
[2018-04-17 19:30:23.075863]: [Epoch: 77(7.707707707707708%): Data: 25.333333333333336%]:Running loss: 4.758225694298744
[2018-04-17 19:30:24.523213]: [Epoch: 77(7.707707707707708%): Data: 50.66666666666667%]:Running loss: 9.275704935193062
[2018-04-17 19:30:28.819637]: Test set accuracy: 94.33962264150944% ,loss = 5.935375019907951
[2018-04-17 19:30:28.946475]: ====================
[2018-04-17 19:30:28.964522]: Elapsed time since starting training: 0:09:55.129153
[2018-04-17 19:30:28.980564]: Estimated time left: 1:05:04.854805
[2018-04-17 19:30:28.991594]: ====================
[2018-04-17 19:30:29.066292]: [Epoch: 78(7.807807807807808%): Data: 0.0%]:Running loss: 0.23741500079631805
[2018-04-17 19:30:30.581321]: [Epoch: 78(7.807807807807808%): Data: 25.333333333333336%]:Running loss: 4.746890425682068
[2018-04-17 19:30:32.066270]: [Epoch: 78(7.807807807807808%): Data: 50.66666666666667%]:Running loss: 9.253696665167809
[2018-04-17 19:30:36.308048]: Test set accuracy: 94.33962264150944% ,loss = 5.92162013053894
[2018-04-17 19:30:36.464965]: ====================
[2018-04-17 19:30:36.469979]: Elapsed time since starting training: 0:10:02.634610
[2018-04-17 19:30:36.475996]: Estimated time left: 1:04:57.359874
[2018-04-17 19:30:36.482512]: ====================
[2018-04-17 19:30:36.552698]: [Epoch: 79(7.907907907907907%): Data: 0.0%]:Running loss: 0.23686480522155762
[2018-04-17 19:30:38.045669]: [Epoch: 79(7.907907907907907%): Data: 25.333333333333336%]:Running loss: 4.735933393239975
[2018-04-17 19:30:39.513077]: [Epoch: 79(7.907907907907907%): Data: 50.66666666666667%]:Running loss: 9.232419773936272
[2018-04-17 19:30:43.718259]: Test set accuracy: 94.33962264150944% ,loss = 5.9083230793476105
[2018-04-17 19:30:43.850110]: ====================
[2018-04-17 19:30:43.855123]: Elapsed time since starting training: 0:10:10.019252
[2018-04-17 19:30:43.859133]: Estimated time left: 1:04:49.976236
[2018-04-17 19:30:43.865651]: ====================
[2018-04-17 19:30:43.978450]: [Epoch: 80(8.008008008008009%): Data: 0.0%]:Running loss: 0.23633292317390442
[2018-04-17 19:30:45.593745]: [Epoch: 80(8.008008008008009%): Data: 25.333333333333336%]:Running loss: 4.725336909294128
[2018-04-17 19:30:47.082204]: [Epoch: 80(8.008008008008009%): Data: 50.66666666666667%]:Running loss: 9.211843967437744
[2018-04-17 19:30:51.354563]: Test set accuracy: 94.33962264150944% ,loss = 5.895456671714783
[2018-04-17 19:30:51.519001]: ====================
[2018-04-17 19:30:51.523513]: Elapsed time since starting training: 0:10:17.688144
[2018-04-17 19:30:51.530532]: Estimated time left: 1:04:42.305339
[2018-04-17 19:30:51.535545]: ====================
[2018-04-17 19:30:51.612249]: [Epoch: 81(8.108108108108109%): Data: 0.0%]:Running loss: 0.2358182668685913
[2018-04-17 19:30:53.269154]: [Epoch: 81(8.108108108108109%): Data: 25.333333333333336%]:Running loss: 4.715087443590164
[2018-04-17 19:30:54.954135]: [Epoch: 81(8.108108108108109%): Data: 50.66666666666667%]:Running loss: 9.191940873861313
[2018-04-17 19:30:59.287658]: Test set accuracy: 94.33962264150944% ,loss = 5.883010849356651
[2018-04-17 19:30:59.451594]: ====================
[2018-04-17 19:30:59.456105]: Elapsed time since starting training: 0:10:25.620736
[2018-04-17 19:30:59.461120]: Estimated time left: 1:04:34.374752
[2018-04-17 19:30:59.465631]: ====================
[2018-04-17 19:30:59.538324]: [Epoch: 82(8.208208208208207%): Data: 0.0%]:Running loss: 0.23532043397426605
[2018-04-17 19:31:01.159636]: [Epoch: 82(8.208208208208207%): Data: 25.333333333333336%]:Running loss: 4.705170348286629
[2018-04-17 19:31:02.716776]: [Epoch: 82(8.208208208208207%): Data: 50.66666666666667%]:Running loss: 9.172683358192444
[2018-04-17 19:31:06.961061]: Test set accuracy: 94.33962264150944% ,loss = 5.870961770415306
[2018-04-17 19:31:07.126501]: ====================
[2018-04-17 19:31:07.132016]: Elapsed time since starting training: 0:10:33.296647
[2018-04-17 19:31:07.136528]: Estimated time left: 1:04:26.698841
[2018-04-17 19:31:07.141039]: ====================
[2018-04-17 19:31:07.215739]: [Epoch: 83(8.308308308308309%): Data: 0.0%]:Running loss: 0.23483847081661224
[2018-04-17 19:31:08.769871]: [Epoch: 83(8.308308308308309%): Data: 25.333333333333336%]:Running loss: 4.695575386285782
[2018-04-17 19:31:10.292419]: [Epoch: 83(8.308308308308309%): Data: 50.66666666666667%]:Running loss: 9.154048934578896
[2018-04-17 19:31:14.530689]: Test set accuracy: 94.33962264150944% ,loss = 5.859307572245598
[2018-04-17 19:31:14.672567]: ====================
[2018-04-17 19:31:14.680086]: Elapsed time since starting training: 0:10:40.844717
[2018-04-17 19:31:14.685099]: Estimated time left: 1:04:19.150771
[2018-04-17 19:31:14.689612]: ====================
[2018-04-17 19:31:14.760300]: [Epoch: 84(8.408408408408409%): Data: 0.0%]:Running loss: 0.2343723028898239
[2018-04-17 19:31:16.268309]: [Epoch: 84(8.408408408408409%): Data: 25.333333333333336%]:Running loss: 4.686286091804504
[2018-04-17 19:31:17.786847]: [Epoch: 84(8.408408408408409%): Data: 50.66666666666667%]:Running loss: 9.136009618639946
[2018-04-17 19:31:21.942897]: Test set accuracy: 94.33962264150944% ,loss = 5.84801509976387
[2018-04-17 19:31:22.056199]: ====================
[2018-04-17 19:31:22.061213]: Elapsed time since starting training: 0:10:48.225342
[2018-04-17 19:31:22.065725]: Estimated time left: 1:04:11.769644
[2018-04-17 19:31:22.070236]: ====================
[2018-04-17 19:31:22.171005]: [Epoch: 85(8.508508508508509%): Data: 0.0%]:Running loss: 0.2339206039905548
[2018-04-17 19:31:23.668987]: [Epoch: 85(8.508508508508509%): Data: 25.333333333333336%]:Running loss: 4.6772924810647964
[2018-04-17 19:31:25.125861]: [Epoch: 85(8.508508508508509%): Data: 50.66666666666667%]:Running loss: 9.118544593453407
[2018-04-17 19:31:29.524557]: Test set accuracy: 94.33962264150944% ,loss = 5.83709292113781
[2018-04-17 19:31:29.648386]: ====================
[2018-04-17 19:31:29.653901]: Elapsed time since starting training: 0:10:55.818532
[2018-04-17 19:31:29.659917]: Estimated time left: 1:04:04.175953
[2018-04-17 19:31:29.665933]: ====================
[2018-04-17 19:31:29.766200]: [Epoch: 86(8.608608608608609%): Data: 0.0%]:Running loss: 0.2334837168455124
[2018-04-17 19:31:31.221570]: [Epoch: 86(8.608608608608609%): Data: 25.333333333333336%]:Running loss: 4.6685832887887955
[2018-04-17 19:31:32.619286]: [Epoch: 86(8.608608608608609%): Data: 50.66666666666667%]:Running loss: 9.101631045341492
[2018-04-17 19:31:36.961833]: Test set accuracy: 94.33962264150944% ,loss = 5.826505646109581
[2018-04-17 19:31:37.173897]: ====================
[2018-04-17 19:31:37.179913]: Elapsed time since starting training: 0:11:03.344544
[2018-04-17 19:31:37.187432]: Estimated time left: 1:03:56.647937
[2018-04-17 19:31:37.194453]: ====================
[2018-04-17 19:31:37.318782]: [Epoch: 87(8.708708708708707%): Data: 0.0%]:Running loss: 0.23306022584438324
[2018-04-17 19:31:38.921570]: [Epoch: 87(8.708708708708707%): Data: 25.333333333333336%]:Running loss: 4.66014988720417
[2018-04-17 19:31:40.558924]: [Epoch: 87(8.708708708708707%): Data: 50.66666666666667%]:Running loss: 9.08525025844574
[2018-04-17 19:31:45.208787]: Test set accuracy: 94.33962264150944% ,loss = 5.8162543922662735
[2018-04-17 19:31:45.366708]: ====================
[2018-04-17 19:31:45.371220]: Elapsed time since starting training: 0:11:11.535851
[2018-04-17 19:31:45.376233]: Estimated time left: 1:03:48.459136
[2018-04-17 19:31:45.381748]: ====================
[2018-04-17 19:31:45.454942]: [Epoch: 88(8.80880880880881%): Data: 0.0%]:Running loss: 0.23265017569065094
[2018-04-17 19:31:47.034141]: [Epoch: 88(8.80880880880881%): Data: 25.333333333333336%]:Running loss: 4.651979357004166
[2018-04-17 19:31:48.455420]: [Epoch: 88(8.80880880880881%): Data: 50.66666666666667%]:Running loss: 9.06938174366951
[2018-04-17 19:31:52.663118]: Test set accuracy: 94.33962264150944% ,loss = 5.806315317749977
[2018-04-17 19:31:52.819033]: ====================
[2018-04-17 19:31:52.824047]: Elapsed time since starting training: 0:11:18.988176
[2018-04-17 19:31:52.828558]: Estimated time left: 1:03:41.006811
[2018-04-17 19:31:52.835076]: ====================
[2018-04-17 19:31:52.910277]: [Epoch: 89(8.90890890890891%): Data: 0.0%]:Running loss: 0.23225261270999908
[2018-04-17 19:31:54.445357]: [Epoch: 89(8.90890890890891%): Data: 25.333333333333336%]:Running loss: 4.644061788916588
[2018-04-17 19:31:55.933814]: [Epoch: 89(8.90890890890891%): Data: 50.66666666666667%]:Running loss: 9.054003193974495
[2018-04-17 19:32:00.178601]: Test set accuracy: 94.33962264150944% ,loss = 5.796688795089722
[2018-04-17 19:32:00.415733]: ====================
[2018-04-17 19:32:00.420745]: Elapsed time since starting training: 0:11:26.585376
[2018-04-17 19:32:00.425759]: Estimated time left: 1:03:33.409610
[2018-04-17 19:32:00.430772]: ====================
[2018-04-17 19:32:00.504468]: [Epoch: 90(9.00900900900901%): Data: 0.0%]:Running loss: 0.23186755180358887
[2018-04-17 19:32:01.981897]: [Epoch: 90(9.00900900900901%): Data: 25.333333333333336%]:Running loss: 4.636388495564461
[2018-04-17 19:32:03.469853]: [Epoch: 90(9.00900900900901%): Data: 50.66666666666667%]:Running loss: 9.039099276065826
[2018-04-17 19:32:07.727173]: Test set accuracy: 94.33962264150944% ,loss = 5.787350609898567
[2018-04-17 19:32:07.840976]: ====================
[2018-04-17 19:32:07.846490]: Elapsed time since starting training: 0:11:34.011121
[2018-04-17 19:32:07.852507]: Estimated time left: 1:03:25.982862
[2018-04-17 19:32:07.857520]: ====================
[2018-04-17 19:32:07.964806]: [Epoch: 91(9.10910910910911%): Data: 0.0%]:Running loss: 0.2314940243959427
[2018-04-17 19:32:09.451262]: [Epoch: 91(9.10910910910911%): Data: 25.333333333333336%]:Running loss: 4.628950163722038
[2018-04-17 19:32:10.944733]: [Epoch: 91(9.10910910910911%): Data: 50.66666666666667%]:Running loss: 9.024650990962982
[2018-04-17 19:32:15.281264]: Test set accuracy: 94.33962264150944% ,loss = 5.778299272060394
[2018-04-17 19:32:15.393563]: ====================
[2018-04-17 19:32:15.400080]: Elapsed time since starting training: 0:11:41.564210
[2018-04-17 19:32:15.411109]: Estimated time left: 1:03:18.424761
[2018-04-17 19:32:15.421637]: ====================
[2018-04-17 19:32:15.520400]: [Epoch: 92(9.20920920920921%): Data: 0.0%]:Running loss: 0.23113197088241577
[2018-04-17 19:32:16.981785]: [Epoch: 92(9.20920920920921%): Data: 25.333333333333336%]:Running loss: 4.621738463640213
[2018-04-17 19:32:18.471246]: [Epoch: 92(9.20920920920921%): Data: 50.66666666666667%]:Running loss: 9.010642021894455
[2018-04-17 19:32:23.034379]: Test set accuracy: 94.33962264150944% ,loss = 5.769523978233337
[2018-04-17 19:32:23.186785]: ====================
[2018-04-17 19:32:23.193804]: Elapsed time since starting training: 0:11:49.357933
[2018-04-17 19:32:23.199318]: Estimated time left: 1:03:10.636051
[2018-04-17 19:32:23.204833]: ====================
[2018-04-17 19:32:23.279030]: [Epoch: 93(9.30930930930931%): Data: 0.0%]:Running loss: 0.2307809591293335
[2018-04-17 19:32:24.775007]: [Epoch: 93(9.30930930930931%): Data: 25.333333333333336%]:Running loss: 4.614744856953621
[2018-04-17 19:32:26.225363]: [Epoch: 93(9.30930930930931%): Data: 50.66666666666667%]:Running loss: 8.997057899832726
[2018-04-17 19:32:30.528806]: Test set accuracy: 94.33962264150944% ,loss = 5.7610053569078445
[2018-04-17 19:32:30.637095]: ====================
[2018-04-17 19:32:30.650631]: Elapsed time since starting training: 0:11:56.810749
[2018-04-17 19:32:30.666172]: Estimated time left: 1:03:03.169197
[2018-04-17 19:32:30.691740]: ====================
[2018-04-17 19:32:30.764935]: [Epoch: 94(9.40940940940941%): Data: 0.0%]:Running loss: 0.23044021427631378
[2018-04-17 19:32:32.226321]: [Epoch: 94(9.40940940940941%): Data: 25.333333333333336%]:Running loss: 4.607961714267731
[2018-04-17 19:32:33.693722]: [Epoch: 94(9.40940940940941%): Data: 50.66666666666667%]:Running loss: 8.983882457017899
[2018-04-17 19:32:37.875341]: Test set accuracy: 94.33962264150944% ,loss = 5.752760171890259
[2018-04-17 19:32:37.985635]: ====================
[2018-04-17 19:32:37.990146]: Elapsed time since starting training: 0:12:04.154777
[2018-04-17 19:32:37.995160]: Estimated time left: 1:02:55.840209
[2018-04-17 19:32:38.002680]: ====================
[2018-04-17 19:32:38.106456]: [Epoch: 95(9.50950950950951%): Data: 0.0%]:Running loss: 0.23011040687561035
[2018-04-17 19:32:39.603437]: [Epoch: 95(9.50950950950951%): Data: 25.333333333333336%]:Running loss: 4.601382404565811
[2018-04-17 19:32:41.059307]: [Epoch: 95(9.50950950950951%): Data: 50.66666666666667%]:Running loss: 8.97109979391098
[2018-04-17 19:32:45.378291]: Test set accuracy: 94.33962264150944% ,loss = 5.744743719696999
[2018-04-17 19:32:45.516660]: ====================
[2018-04-17 19:32:45.522174]: Elapsed time since starting training: 0:12:11.686805
[2018-04-17 19:32:45.532702]: Estimated time left: 1:02:48.302667
[2018-04-17 19:32:45.537214]: ====================
[2018-04-17 19:32:45.608403]: [Epoch: 96(9.60960960960961%): Data: 0.0%]:Running loss: 0.22978974878787994
[2018-04-17 19:32:47.107890]: [Epoch: 96(9.60960960960961%): Data: 25.333333333333336%]:Running loss: 4.594997972249985
[2018-04-17 19:32:48.626428]: [Epoch: 96(9.60960960960961%): Data: 50.66666666666667%]:Running loss: 8.958697363734245
[2018-04-17 19:32:52.955439]: Test set accuracy: 94.33962264150944% ,loss = 5.736970901489258
[2018-04-17 19:32:53.154971]: ====================
[2018-04-17 19:32:53.163492]: Elapsed time since starting training: 0:12:19.328123
[2018-04-17 19:32:53.169508]: Estimated time left: 1:02:40.665861
[2018-04-17 19:32:53.174020]: ====================
[2018-04-17 19:32:53.248220]: [Epoch: 97(9.70970970970971%): Data: 0.0%]:Running loss: 0.2294788360595703
[2018-04-17 19:32:54.772771]: [Epoch: 97(9.70970970970971%): Data: 25.333333333333336%]:Running loss: 4.588800936937332
[2018-04-17 19:32:56.264237]: [Epoch: 97(9.70970970970971%): Data: 50.66666666666667%]:Running loss: 8.946660667657852
[2018-04-17 19:33:00.513536]: Test set accuracy: 94.33962264150944% ,loss = 5.729415640234947
[2018-04-17 19:33:00.681482]: ====================
[2018-04-17 19:33:00.686496]: Elapsed time since starting training: 0:12:26.850625
[2018-04-17 19:33:00.691008]: Estimated time left: 1:02:33.144361
[2018-04-17 19:33:00.697024]: ====================
[2018-04-17 19:33:00.765706]: [Epoch: 98(9.80980980980981%): Data: 0.0%]:Running loss: 0.2291766256093979
[2018-04-17 19:33:02.304799]: [Epoch: 98(9.80980980980981%): Data: 25.333333333333336%]:Running loss: 4.582787394523621
[2018-04-17 19:33:03.830355]: [Epoch: 98(9.80980980980981%): Data: 50.66666666666667%]:Running loss: 8.934978783130646
[2018-04-17 19:33:08.081158]: Test set accuracy: 94.33962264150944% ,loss = 5.722103640437126
[2018-04-17 19:33:08.212006]: ====================
[2018-04-17 19:33:08.232561]: Elapsed time since starting training: 0:12:34.397192
[2018-04-17 19:33:08.261136]: Estimated time left: 1:02:25.574233
[2018-04-17 19:33:08.267654]: ====================
[2018-04-17 19:33:08.342854]: [Epoch: 99(9.90990990990991%): Data: 0.0%]:Running loss: 0.22888414561748505
[2018-04-17 19:33:09.864400]: [Epoch: 99(9.90990990990991%): Data: 25.333333333333336%]:Running loss: 4.576950058341026
[2018-04-17 19:33:11.404496]: [Epoch: 99(9.90990990990991%): Data: 50.66666666666667%]:Running loss: 8.92363752424717
[2018-04-17 19:33:15.610679]: Test set accuracy: 94.33962264150944% ,loss = 5.714986100792885
[2018-04-17 19:33:15.763587]: ====================
[2018-04-17 19:33:15.768098]: Elapsed time since starting training: 0:12:41.932729
[2018-04-17 19:33:15.773111]: Estimated time left: 1:02:18.062759
[2018-04-17 19:33:15.777623]: ====================
[2018-04-17 19:33:15.850316]: [Epoch: 100(10.01001001001001%): Data: 0.0%]:Running loss: 0.2285994440317154
[2018-04-17 19:33:17.357825]: [Epoch: 100(10.01001001001001%): Data: 25.333333333333336%]:Running loss: 4.571281060576439
[2018-04-17 19:33:18.995180]: [Epoch: 100(10.01001001001001%): Data: 50.66666666666667%]:Running loss: 8.912625283002853
[2018-04-17 19:33:23.284584]: Test set accuracy: 94.33962264150944% ,loss = 5.708086118102074
[2018-04-17 19:33:23.404403]: ====================
[2018-04-17 19:33:23.409917]: Elapsed time since starting training: 0:12:49.574548
[2018-04-17 19:33:23.414931]: Estimated time left: 1:02:10.420940
[2018-04-17 19:33:23.419443]: ====================
[2018-04-17 19:33:23.525725]: [Epoch: 101(10.11011011011011%): Data: 0.0%]:Running loss: 0.22832344472408295
[2018-04-17 19:33:24.996637]: [Epoch: 101(10.11011011011011%): Data: 25.333333333333336%]:Running loss: 4.565777882933617
[2018-04-17 19:33:26.568817]: [Epoch: 101(10.11011011011011%): Data: 50.66666666666667%]:Running loss: 8.901932492852211
[2018-04-17 19:33:30.948963]: Test set accuracy: 94.33962264150944% ,loss = 5.701372027397156
[2018-04-17 19:33:31.064771]: ====================
[2018-04-17 19:33:31.069785]: Elapsed time since starting training: 0:12:57.234416
[2018-04-17 19:33:31.074798]: Estimated time left: 1:02:02.761072
[2018-04-17 19:33:31.094350]: ====================
[2018-04-17 19:33:31.185102]: [Epoch: 102(10.21021021021021%): Data: 0.0%]:Running loss: 0.22805488109588623
[2018-04-17 19:33:32.667533]: [Epoch: 102(10.21021021021021%): Data: 25.333333333333336%]:Running loss: 4.560432493686676
[2018-04-17 19:33:34.204119]: [Epoch: 102(10.21021021021021%): Data: 50.66666666666667%]:Running loss: 8.891546174883842
[2018-04-17 19:33:38.609332]: Test set accuracy: 94.33962264150944% ,loss = 5.694863572716713
[2018-04-17 19:33:38.725642]: ====================
[2018-04-17 19:33:38.731157]: Elapsed time since starting training: 0:13:04.895286
[2018-04-17 19:33:38.735669]: Estimated time left: 1:01:55.100202
[2018-04-17 19:33:38.740682]: ====================
[2018-04-17 19:33:38.849471]: [Epoch: 103(10.31031031031031%): Data: 0.0%]:Running loss: 0.22779454290866852
[2018-04-17 19:33:40.353971]: [Epoch: 103(10.31031031031031%): Data: 25.333333333333336%]:Running loss: 4.555239945650101
[2018-04-17 19:33:41.878024]: [Epoch: 103(10.31031031031031%): Data: 50.66666666666667%]:Running loss: 8.881458297371864
[2018-04-17 19:33:46.243632]: Test set accuracy: 94.33962264150944% ,loss = 5.688529461622238
[2018-04-17 19:33:46.391525]: ====================
[2018-04-17 19:33:46.396538]: Elapsed time since starting training: 0:13:12.560668
[2018-04-17 19:33:46.400549]: Estimated time left: 1:01:47.434820
[2018-04-17 19:33:46.405562]: ====================
[2018-04-17 19:33:46.478758]: [Epoch: 104(10.41041041041041%): Data: 0.0%]:Running loss: 0.22754117846488953
[2018-04-17 19:33:48.010330]: [Epoch: 104(10.41041041041041%): Data: 25.333333333333336%]:Running loss: 4.550194203853607
[2018-04-17 19:33:49.518340]: [Epoch: 104(10.41041041041041%): Data: 50.66666666666667%]:Running loss: 8.871654853224754
[2018-04-17 19:33:53.919542]: Test set accuracy: 94.33962264150944% ,loss = 5.682381242513657
[2018-04-17 19:33:54.075958]: ====================
[2018-04-17 19:33:54.081473]: Elapsed time since starting training: 0:13:20.246104
[2018-04-17 19:33:54.085984]: Estimated time left: 1:01:39.749385
[2018-04-17 19:33:54.090999]: ====================
[2018-04-17 19:33:54.161685]: [Epoch: 105(10.51051051051051%): Data: 0.0%]:Running loss: 0.22729524970054626
[2018-04-17 19:33:55.691254]: [Epoch: 105(10.51051051051051%): Data: 25.333333333333336%]:Running loss: 4.545291855931282
[2018-04-17 19:33:57.185225]: [Epoch: 105(10.51051051051051%): Data: 50.66666666666667%]:Running loss: 8.86213006079197
[2018-04-17 19:34:01.442044]: Test set accuracy: 94.33962264150944% ,loss = 5.676404386758804
[2018-04-17 19:34:01.593948]: ====================
[2018-04-17 19:34:01.601468]: Elapsed time since starting training: 0:13:27.766099
[2018-04-17 19:34:01.606482]: Estimated time left: 1:01:32.229389
[2018-04-17 19:34:01.610993]: ====================
[2018-04-17 19:34:01.684690]: [Epoch: 106(10.61061061061061%): Data: 0.0%]:Running loss: 0.22705617547035217
[2018-04-17 19:34:03.169136]: [Epoch: 106(10.61061061061061%): Data: 25.333333333333336%]:Running loss: 4.54052796959877
[2018-04-17 19:34:04.647066]: [Epoch: 106(10.61061061061061%): Data: 50.66666666666667%]:Running loss: 8.852873399853706
[2018-04-17 19:34:09.006659]: Test set accuracy: 94.33962264150944% ,loss = 5.670589953660965
[2018-04-17 19:34:09.153048]: ====================
[2018-04-17 19:34:09.158562]: Elapsed time since starting training: 0:13:35.322692
[2018-04-17 19:34:09.162072]: Estimated time left: 1:01:24.673297
[2018-04-17 19:34:09.166082]: ====================
[2018-04-17 19:34:09.238274]: [Epoch: 107(10.71071071071071%): Data: 0.0%]:Running loss: 0.2268235981464386
[2018-04-17 19:34:10.713196]: [Epoch: 107(10.71071071071071%): Data: 25.333333333333336%]:Running loss: 4.5358966588974
[2018-04-17 19:34:12.238253]: [Epoch: 107(10.71071071071071%): Data: 50.66666666666667%]:Running loss: 8.84387682378292
[2018-04-17 19:34:16.490056]: Test set accuracy: 94.33962264150944% ,loss = 5.664946883916855
[2018-04-17 19:34:16.627423]: ====================
[2018-04-17 19:34:16.632436]: Elapsed time since starting training: 0:13:42.797067
[2018-04-17 19:34:16.636947]: Estimated time left: 1:01:17.198422
[2018-04-17 19:34:16.644467]: ====================
[2018-04-17 19:34:16.715657]: [Epoch: 108(10.81081081081081%): Data: 0.0%]:Running loss: 0.2265978753566742
[2018-04-17 19:34:18.427208]: [Epoch: 108(10.81081081081081%): Data: 25.333333333333336%]:Running loss: 4.531395211815834
[2018-04-17 19:34:19.960793]: [Epoch: 108(10.81081081081081%): Data: 50.66666666666667%]:Running loss: 8.835129275918007
[2018-04-17 19:34:24.353472]: Test set accuracy: 94.33962264150944% ,loss = 5.6594595313072205
[2018-04-17 19:34:24.524427]: ====================
[2018-04-17 19:34:24.528939]: Elapsed time since starting training: 0:13:50.693570
[2018-04-17 19:34:24.533452]: Estimated time left: 1:01:09.301917
[2018-04-17 19:34:24.540971]: ====================
[2018-04-17 19:34:24.608651]: [Epoch: 109(10.91091091091091%): Data: 0.0%]:Running loss: 0.22637838125228882
[2018-04-17 19:34:26.206400]: [Epoch: 109(10.91091091091091%): Data: 25.333333333333336%]:Running loss: 4.527019664645195
[2018-04-17 19:34:27.830719]: [Epoch: 109(10.91091091091091%): Data: 50.66666666666667%]:Running loss: 8.826626047492027
[2018-04-17 19:34:32.287067]: Test set accuracy: 94.33962264150944% ,loss = 5.6541211903095245
[2018-04-17 19:34:32.402375]: ====================
[2018-04-17 19:34:32.406886]: Elapsed time since starting training: 0:13:58.571517
[2018-04-17 19:34:32.411398]: Estimated time left: 1:01:01.423971
[2018-04-17 19:34:32.415910]: ====================
[2018-04-17 19:34:32.525702]: [Epoch: 110(11.01101101101101%): Data: 0.0%]:Running loss: 0.22616484761238098
[2018-04-17 19:34:34.129968]: [Epoch: 110(11.01101101101101%): Data: 25.333333333333336%]:Running loss: 4.522763833403587
[2018-04-17 19:34:35.601882]: [Epoch: 110(11.01101101101101%): Data: 50.66666666666667%]:Running loss: 8.818356201052666
[2018-04-17 19:34:39.918359]: Test set accuracy: 94.33962264150944% ,loss = 5.648932233452797
[2018-04-17 19:34:40.062743]: ====================
[2018-04-17 19:34:40.070263]: Elapsed time since starting training: 0:14:06.234393
[2018-04-17 19:34:40.074274]: Estimated time left: 1:00:53.761095
[2018-04-17 19:34:40.079287]: ====================
[2018-04-17 19:34:40.147468]: [Epoch: 111(11.11111111111111%): Data: 0.0%]:Running loss: 0.22595728933811188
[2018-04-17 19:34:41.778806]: [Epoch: 111(11.11111111111111%): Data: 25.333333333333336%]:Running loss: 4.518625393509865
[2018-04-17 19:34:43.371541]: [Epoch: 111(11.11111111111111%): Data: 50.66666666666667%]:Running loss: 8.810315430164337
[2018-04-17 19:34:47.804829]: Test set accuracy: 94.33962264150944% ,loss = 5.643877014517784
[2018-04-17 19:34:47.934675]: ====================
[2018-04-17 19:34:47.961747]: Elapsed time since starting training: 0:14:14.126378
[2018-04-17 19:34:47.971773]: Estimated time left: 1:00:45.863596
[2018-04-17 19:34:47.978291]: ====================
[2018-04-17 19:34:48.047976]: [Epoch: 112(11.21121121121121%): Data: 0.0%]:Running loss: 0.22575508058071136
[2018-04-17 19:34:49.559496]: [Epoch: 112(11.21121121121121%): Data: 25.333333333333336%]:Running loss: 4.51459813117981
[2018-04-17 19:34:51.049958]: [Epoch: 112(11.21121121121121%): Data: 50.66666666666667%]:Running loss: 8.802491828799248
[2018-04-17 19:34:55.385486]: Test set accuracy: 94.33962264150944% ,loss = 5.638967826962471
[2018-04-17 19:34:55.538392]: ====================
[2018-04-17 19:34:55.542904]: Elapsed time since starting training: 0:14:21.707535
[2018-04-17 19:34:55.547918]: Estimated time left: 1:00:38.287952
[2018-04-17 19:34:55.551929]: ====================
[2018-04-17 19:34:55.627128]: [Epoch: 113(11.31131131131131%): Data: 0.0%]:Running loss: 0.22555871307849884
[2018-04-17 19:34:57.143159]: [Epoch: 113(11.31131131131131%): Data: 25.333333333333336%]:Running loss: 4.510684609413147
[2018-04-17 19:34:58.688268]: [Epoch: 113(11.31131131131131%): Data: 50.66666666666667%]:Running loss: 8.794884040951729
[2018-04-17 19:35:03.026308]: Test set accuracy: 94.33962264150944% ,loss = 5.634193494915962
[2018-04-17 19:35:03.194757]: ====================
[2018-04-17 19:35:03.202277]: Elapsed time since starting training: 0:14:29.366406
[2018-04-17 19:35:03.207290]: Estimated time left: 1:00:30.628079
[2018-04-17 19:35:03.213306]: ====================
[2018-04-17 19:35:03.291012]: [Epoch: 114(11.411411411411411%): Data: 0.0%]:Running loss: 0.2253677397966385
[2018-04-17 19:35:04.857677]: [Epoch: 114(11.411411411411411%): Data: 25.333333333333336%]:Running loss: 4.506875604391098
[2018-04-17 19:35:06.355662]: [Epoch: 114(11.411411411411411%): Data: 50.66666666666667%]:Running loss: 8.787481307983398
[2018-04-17 19:35:10.660106]: Test set accuracy: 94.33962264150944% ,loss = 5.629535019397736
[2018-04-17 19:35:10.778922]: ====================
[2018-04-17 19:35:10.783935]: Elapsed time since starting training: 0:14:36.948566
[2018-04-17 19:35:10.788448]: Estimated time left: 1:00:23.046921
[2018-04-17 19:35:10.795967]: ====================
[2018-04-17 19:35:10.903253]: [Epoch: 115(11.511511511511511%): Data: 0.0%]:Running loss: 0.22518140077590942
[2018-04-17 19:35:12.623828]: [Epoch: 115(11.511511511511511%): Data: 25.333333333333336%]:Running loss: 4.503166928887367
[2018-04-17 19:35:14.123816]: [Epoch: 115(11.511511511511511%): Data: 50.66666666666667%]:Running loss: 8.780276790261269
[2018-04-17 19:35:18.416731]: Test set accuracy: 94.33962264150944% ,loss = 5.625017359852791
[2018-04-17 19:35:18.577158]: ====================
[2018-04-17 19:35:18.582171]: Elapsed time since starting training: 0:14:44.746301
[2018-04-17 19:35:18.586684]: Estimated time left: 1:00:15.248685
[2018-04-17 19:35:18.591697]: ====================
[2018-04-17 19:35:18.664891]: [Epoch: 116(11.611611611611613%): Data: 0.0%]:Running loss: 0.22500069439411163
[2018-04-17 19:35:20.174906]: [Epoch: 116(11.611611611611613%): Data: 25.333333333333336%]:Running loss: 4.4995598793029785
[2018-04-17 19:35:21.757113]: [Epoch: 116(11.611611611611613%): Data: 50.66666666666667%]:Running loss: 8.77326637506485
[2018-04-17 19:35:26.000396]: Test set accuracy: 94.33962264150944% ,loss = 5.620605871081352
[2018-04-17 19:35:26.127233]: ====================
[2018-04-17 19:35:26.133751]: Elapsed time since starting training: 0:14:52.297881
[2018-04-17 19:35:26.166338]: Estimated time left: 1:00:07.669031
[2018-04-17 19:35:26.171853]: ====================
[2018-04-17 19:35:26.246552]: [Epoch: 117(11.711711711711711%): Data: 0.0%]:Running loss: 0.2248242348432541
[2018-04-17 19:35:27.685377]: [Epoch: 117(11.711711711711711%): Data: 25.333333333333336%]:Running loss: 4.496048778295517
[2018-04-17 19:35:29.215946]: [Epoch: 117(11.711711711711711%): Data: 50.66666666666667%]:Running loss: 8.766442686319351
[2018-04-17 19:35:33.676807]: Test set accuracy: 94.33962264150944% ,loss = 5.616327002644539
[2018-04-17 19:35:33.894887]: ====================
[2018-04-17 19:35:33.900402]: Elapsed time since starting training: 0:15:00.065033
[2018-04-17 19:35:33.904914]: Estimated time left: 0:59:59.930455
[2018-04-17 19:35:33.912935]: ====================
[2018-04-17 19:35:33.982119]: [Epoch: 118(11.811811811811811%): Data: 0.0%]:Running loss: 0.22465308010578156
[2018-04-17 19:35:35.686652]: [Epoch: 118(11.811811811811811%): Data: 25.333333333333336%]:Running loss: 4.492632821202278
[2018-04-17 19:35:37.394693]: [Epoch: 118(11.811811811811811%): Data: 50.66666666666667%]:Running loss: 8.759803727269173
[2018-04-17 19:35:42.077645]: Test set accuracy: 94.33962264150944% ,loss = 5.612146481871605
[2018-04-17 19:35:42.257624]: ====================
[2018-04-17 19:35:42.265144]: Elapsed time since starting training: 0:15:08.429273
[2018-04-17 19:35:42.270158]: Estimated time left: 0:59:51.565211
[2018-04-17 19:35:42.275172]: ====================
[2018-04-17 19:35:42.407523]: [Epoch: 119(11.911911911911911%): Data: 0.0%]:Running loss: 0.2244858592748642
[2018-04-17 19:35:43.997250]: [Epoch: 119(11.911911911911911%): Data: 25.333333333333336%]:Running loss: 4.489306196570396
[2018-04-17 19:35:45.743895]: [Epoch: 119(11.911911911911911%): Data: 50.66666666666667%]:Running loss: 8.753338038921356
[2018-04-17 19:35:50.565715]: Test set accuracy: 94.33962264150944% ,loss = 5.608093366026878
[2018-04-17 19:35:50.738174]: ====================
[2018-04-17 19:35:50.746697]: Elapsed time since starting training: 0:15:16.911328
[2018-04-17 19:35:50.754719]: Estimated time left: 0:59:43.081152
[2018-04-17 19:35:50.761736]: ====================
[2018-04-17 19:35:50.835432]: [Epoch: 120(12.012012012012011%): Data: 0.0%]:Running loss: 0.22432373464107513
[2018-04-17 19:35:52.517915]: [Epoch: 120(12.012012012012011%): Data: 25.333333333333336%]:Running loss: 4.486066788434982
[2018-04-17 19:35:54.145242]: [Epoch: 120(12.012012012012011%): Data: 50.66666666666667%]:Running loss: 8.747043162584305
[2018-04-17 19:35:58.486285]: Test set accuracy: 94.33962264150944% ,loss = 5.604137480258942
[2018-04-17 19:35:58.611618]: ====================
[2018-04-17 19:35:58.616131]: Elapsed time since starting training: 0:15:24.780259
[2018-04-17 19:35:58.620642]: Estimated time left: 0:59:35.214727
[2018-04-17 19:35:58.625154]: ====================
[2018-04-17 19:35:58.727930]: [Epoch: 121(12.112112112112113%): Data: 0.0%]:Running loss: 0.22416549921035767
[2018-04-17 19:36:00.222902]: [Epoch: 121(12.112112112112113%): Data: 25.333333333333336%]:Running loss: 4.482913166284561
[2018-04-17 19:36:01.768512]: [Epoch: 121(12.112112112112113%): Data: 50.66666666666667%]:Running loss: 8.740915134549141
[2018-04-17 19:36:06.118078]: Test set accuracy: 94.33962264150944% ,loss = 5.600282549858093
[2018-04-17 19:36:06.307582]: ====================
[2018-04-17 19:36:06.316105]: Elapsed time since starting training: 0:15:32.480736
[2018-04-17 19:36:06.322622]: Estimated time left: 0:59:27.513249
[2018-04-17 19:36:06.328136]: ====================
[2018-04-17 19:36:06.401832]: [Epoch: 122(12.212212212212211%): Data: 0.0%]:Running loss: 0.22401130199432373
[2018-04-17 19:36:07.961981]: [Epoch: 122(12.212212212212211%): Data: 25.333333333333336%]:Running loss: 4.479841515421867
[2018-04-17 19:36:09.562737]: [Epoch: 122(12.212212212212211%): Data: 50.66666666666667%]:Running loss: 8.734944969415665
[2018-04-17 19:36:13.984996]: Test set accuracy: 94.33962264150944% ,loss = 5.596531927585602
[2018-04-17 19:36:14.112334]: ====================
[2018-04-17 19:36:14.116846]: Elapsed time since starting training: 0:15:40.281477
[2018-04-17 19:36:14.136398]: Estimated time left: 0:59:19.698971
[2018-04-17 19:36:14.176506]: ====================
[2018-04-17 19:36:14.253711]: [Epoch: 123(12.312312312312311%): Data: 0.0%]:Running loss: 0.22386127710342407
[2018-04-17 19:36:15.834413]: [Epoch: 123(12.312312312312311%): Data: 25.333333333333336%]:Running loss: 4.476850911974907
[2018-04-17 19:36:17.382529]: [Epoch: 123(12.312312312312311%): Data: 50.66666666666667%]:Running loss: 8.729132190346718
[2018-04-17 19:36:21.909567]: Test set accuracy: 94.33962264150944% ,loss = 5.592883378267288
[2018-04-17 19:36:22.030389]: ====================
[2018-04-17 19:36:22.034399]: Elapsed time since starting training: 0:15:48.199030
[2018-04-17 19:36:22.041418]: Estimated time left: 0:59:11.794453
[2018-04-17 19:36:22.046431]: ====================
[2018-04-17 19:36:22.161237]: [Epoch: 124(12.412412412412413%): Data: 0.0%]:Running loss: 0.22371533513069153
[2018-04-17 19:36:23.715369]: [Epoch: 124(12.412412412412413%): Data: 25.333333333333336%]:Running loss: 4.473937094211578
[2018-04-17 19:36:25.216861]: [Epoch: 124(12.412412412412413%): Data: 50.66666666666667%]:Running loss: 8.72346916794777
[2018-04-17 19:36:29.590992]: Test set accuracy: 94.33962264150944% ,loss = 5.58931864798069
[2018-04-17 19:36:29.722341]: ====================
[2018-04-17 19:36:29.727355]: Elapsed time since starting training: 0:15:55.891484
[2018-04-17 19:36:29.731867]: Estimated time left: 0:59:04.103502
[2018-04-17 19:36:29.736879]: ====================
[2018-04-17 19:36:29.848176]: [Epoch: 125(12.512512512512513%): Data: 0.0%]:Running loss: 0.2235727459192276
[2018-04-17 19:36:31.305550]: [Epoch: 125(12.512512512512513%): Data: 25.333333333333336%]:Running loss: 4.471098408102989
[2018-04-17 19:36:32.797518]: [Epoch: 125(12.512512512512513%): Data: 50.66666666666667%]:Running loss: 8.717952266335487
[2018-04-17 19:36:37.070880]: Test set accuracy: 94.33962264150944% ,loss = 5.585844442248344
[2018-04-17 19:36:37.195713]: ====================
[2018-04-17 19:36:37.204236]: Elapsed time since starting training: 0:16:03.368365
[2018-04-17 19:36:37.208748]: Estimated time left: 0:58:56.626621
[2018-04-17 19:36:37.214763]: ====================
[2018-04-17 19:36:37.331072]: [Epoch: 126(12.612612612612612%): Data: 0.0%]:Running loss: 0.22343377768993378
[2018-04-17 19:36:38.883200]: [Epoch: 126(12.612612612612612%): Data: 25.333333333333336%]:Running loss: 4.468333512544632
[2018-04-17 19:36:40.374164]: [Epoch: 126(12.612612612612612%): Data: 50.66666666666667%]:Running loss: 8.71257834136486
[2018-04-17 19:36:44.610930]: Test set accuracy: 94.33962264150944% ,loss = 5.582466349005699
[2018-04-17 19:36:44.769351]: ====================
[2018-04-17 19:36:44.774364]: Elapsed time since starting training: 0:16:10.938494
[2018-04-17 19:36:44.778877]: Estimated time left: 0:58:49.056492
[2018-04-17 19:36:44.784391]: ====================
[2018-04-17 19:36:44.855580]: [Epoch: 127(12.712712712712712%): Data: 0.0%]:Running loss: 0.22329865396022797
[2018-04-17 19:36:46.364593]: [Epoch: 127(12.712712712712712%): Data: 25.333333333333336%]:Running loss: 4.465639173984528
[2018-04-17 19:36:47.906192]: [Epoch: 127(12.712712712712712%): Data: 50.66666666666667%]:Running loss: 8.707341074943542
[2018-04-17 19:36:52.406658]: Test set accuracy: 94.33962264150944% ,loss = 5.579177290201187
[2018-04-17 19:36:52.666354]: ====================
[2018-04-17 19:36:52.673369]: Elapsed time since starting training: 0:16:18.837498
[2018-04-17 19:36:52.679885]: Estimated time left: 0:58:41.155484
[2018-04-17 19:36:52.686402]: ====================
[2018-04-17 19:36:52.757592]: [Epoch: 128(12.812812812812812%): Data: 0.0%]:Running loss: 0.22316709160804749
[2018-04-17 19:36:54.309719]: [Epoch: 128(12.812812812812812%): Data: 25.333333333333336%]:Running loss: 4.463014617562294
[2018-04-17 19:36:55.963617]: [Epoch: 128(12.812812812812812%): Data: 50.66666666666667%]:Running loss: 8.70223993062973
[2018-04-17 19:37:00.378856]: Test set accuracy: 94.33962264150944% ,loss = 5.575963854789734
[2018-04-17 19:37:00.561843]: ====================
[2018-04-17 19:37:00.567859]: Elapsed time since starting training: 0:16:26.732490
[2018-04-17 19:37:00.573376]: Estimated time left: 0:58:33.262497
[2018-04-17 19:37:00.578888]: ====================
[2018-04-17 19:37:00.652585]: [Epoch: 129(12.912912912912914%): Data: 0.0%]:Running loss: 0.22303855419158936
[2018-04-17 19:37:02.268882]: [Epoch: 129(12.912912912912914%): Data: 25.333333333333336%]:Running loss: 4.460455223917961
[2018-04-17 19:37:03.838056]: [Epoch: 129(12.912912912912914%): Data: 50.66666666666667%]:Running loss: 8.69726549088955
[2018-04-17 19:37:08.367598]: Test set accuracy: 94.33962264150944% ,loss = 5.572839453816414
[2018-04-17 19:37:08.534041]: ====================
[2018-04-17 19:37:08.539054]: Elapsed time since starting training: 0:16:34.703184
[2018-04-17 19:37:08.543566]: Estimated time left: 0:58:25.291803
[2018-04-17 19:37:08.549583]: ====================
[2018-04-17 19:37:08.622777]: [Epoch: 130(13.013013013013014%): Data: 0.0%]:Running loss: 0.22291357815265656
[2018-04-17 19:37:10.198467]: [Epoch: 130(13.013013013013014%): Data: 25.333333333333336%]:Running loss: 4.457961916923523
[2018-04-17 19:37:11.789698]: [Epoch: 130(13.013013013013014%): Data: 50.66666666666667%]:Running loss: 8.692419052124023
[2018-04-17 19:37:16.349322]: Test set accuracy: 94.33962264150944% ,loss = 5.569792538881302
[2018-04-17 19:37:16.471647]: ====================
[2018-04-17 19:37:16.477163]: Elapsed time since starting training: 0:16:42.641292
[2018-04-17 19:37:16.484181]: Estimated time left: 0:58:17.351188
[2018-04-17 19:37:16.488692]: ====================
[2018-04-17 19:37:16.610015]: [Epoch: 131(13.113113113113112%): Data: 0.0%]:Running loss: 0.22279170155525208
[2018-04-17 19:37:18.180190]: [Epoch: 131(13.113113113113112%): Data: 25.333333333333336%]:Running loss: 4.4555303901433945
[2018-04-17 19:37:19.844115]: [Epoch: 131(13.113113113113112%): Data: 50.66666666666667%]:Running loss: 8.687694355845451
[2018-04-17 19:37:24.378672]: Test set accuracy: 94.33962264150944% ,loss = 5.566824972629547
[2018-04-17 19:37:24.567676]: ====================
[2018-04-17 19:37:24.574192]: Elapsed time since starting training: 0:16:50.738823
[2018-04-17 19:37:24.579205]: Estimated time left: 0:58:09.256164
[2018-04-17 19:37:24.583717]: ====================
[2018-04-17 19:37:24.655407]: [Epoch: 132(13.213213213213212%): Data: 0.0%]:Running loss: 0.22267299890518188
[2018-04-17 19:37:26.248646]: [Epoch: 132(13.213213213213212%): Data: 25.333333333333336%]:Running loss: 4.453161314129829
[2018-04-17 19:37:27.695993]: [Epoch: 132(13.213213213213212%): Data: 50.66666666666667%]:Running loss: 8.683088272809982
[2018-04-17 19:37:32.153846]: Test set accuracy: 94.33962264150944% ,loss = 5.563921853899956
[2018-04-17 19:37:32.282689]: ====================
[2018-04-17 19:37:32.287702]: Elapsed time since starting training: 0:16:58.451832
[2018-04-17 19:37:32.292214]: Estimated time left: 0:58:01.543657
[2018-04-17 19:37:32.296725]: ====================
[2018-04-17 19:37:32.377942]: [Epoch: 133(13.313313313313312%): Data: 0.0%]:Running loss: 0.22255687415599823
[2018-04-17 19:37:33.950122]: [Epoch: 133(13.313313313313312%): Data: 25.333333333333336%]:Running loss: 4.450850918889046
[2018-04-17 19:37:35.516788]: [Epoch: 133(13.313313313313312%): Data: 50.66666666666667%]:Running loss: 8.678597390651703
[2018-04-17 19:37:40.008732]: Test set accuracy: 94.33962264150944% ,loss = 5.561097711324692
[2018-04-17 19:37:40.179185]: ====================
[2018-04-17 19:37:40.184199]: Elapsed time since starting training: 0:17:06.348830
[2018-04-17 19:37:40.189213]: Estimated time left: 0:57:53.646659
[2018-04-17 19:37:40.194727]: ====================
[2018-04-17 19:37:40.269927]: [Epoch: 134(13.413413413413414%): Data: 0.0%]:Running loss: 0.22244390845298767
[2018-04-17 19:37:41.841613]: [Epoch: 134(13.413413413413414%): Data: 25.333333333333336%]:Running loss: 4.448598861694336
[2018-04-17 19:37:43.381708]: [Epoch: 134(13.413413413413414%): Data: 50.66666666666667%]:Running loss: 8.674220576882362
[2018-04-17 19:37:47.961386]: Test set accuracy: 94.33962264150944% ,loss = 5.55834099650383
[2018-04-17 19:37:48.134847]: ====================
[2018-04-17 19:37:48.139860]: Elapsed time since starting training: 0:17:14.304491
[2018-04-17 19:37:48.144372]: Estimated time left: 0:57:45.690997
[2018-04-17 19:37:48.155903]: ====================
[2018-04-17 19:37:48.226089]: [Epoch: 135(13.513513513513514%): Data: 0.0%]:Running loss: 0.2223336398601532
[2018-04-17 19:37:49.765182]: [Epoch: 135(13.513513513513514%): Data: 25.333333333333336%]:Running loss: 4.446402698755264
[2018-04-17 19:37:51.230577]: [Epoch: 135(13.513513513513514%): Data: 50.66666666666667%]:Running loss: 8.669951885938644
[2018-04-17 19:37:55.659855]: Test set accuracy: 94.33962264150944% ,loss = 5.555662885308266
[2018-04-17 19:37:55.846352]: ====================
[2018-04-17 19:37:55.854372]: Elapsed time since starting training: 0:17:22.018502
[2018-04-17 19:37:55.858884]: Estimated time left: 0:57:37.976485
[2018-04-17 19:37:55.863898]: ====================
[2018-04-17 19:37:55.939599]: [Epoch: 136(13.613613613613614%): Data: 0.0%]:Running loss: 0.22222651541233063
[2018-04-17 19:37:57.429059]: [Epoch: 136(13.613613613613614%): Data: 25.333333333333336%]:Running loss: 4.44426141679287
[2018-04-17 19:37:58.921027]: [Epoch: 136(13.613613613613614%): Data: 50.66666666666667%]:Running loss: 8.665789231657982
[2018-04-17 19:38:03.359334]: Test set accuracy: 94.33962264150944% ,loss = 5.553042516112328
[2018-04-17 19:38:03.540315]: ====================
[2018-04-17 19:38:03.558363]: Elapsed time since starting training: 0:17:29.722492
[2018-04-17 19:38:03.577413]: Estimated time left: 0:57:30.257956
[2018-04-17 19:38:03.603984]: ====================
[2018-04-17 19:38:03.675675]: [Epoch: 137(13.713713713713712%): Data: 0.0%]:Running loss: 0.2221217006444931
[2018-04-17 19:38:05.180677]: [Epoch: 137(13.713713713713712%): Data: 25.333333333333336%]:Running loss: 4.442172721028328
[2018-04-17 19:38:06.728792]: [Epoch: 137(13.713713713713712%): Data: 50.66666666666667%]:Running loss: 8.661728337407112
[2018-04-17 19:38:11.244299]: Test set accuracy: 94.33962264150944% ,loss = 5.550491064786911
[2018-04-17 19:38:11.423777]: ====================
[2018-04-17 19:38:11.434806]: Elapsed time since starting training: 0:17:37.599437
[2018-04-17 19:38:11.439820]: Estimated time left: 0:57:22.395549
[2018-04-17 19:38:11.446337]: ====================
[2018-04-17 19:38:11.594229]: [Epoch: 138(13.813813813813812%): Data: 0.0%]:Running loss: 0.22201964259147644
[2018-04-17 19:38:13.503807]: [Epoch: 138(13.813813813813812%): Data: 25.333333333333336%]:Running loss: 4.4401345402002335
[2018-04-17 19:38:15.368766]: [Epoch: 138(13.813813813813812%): Data: 50.66666666666667%]:Running loss: 8.657767921686172
[2018-04-17 19:38:20.549041]: Test set accuracy: 94.33962264150944% ,loss = 5.547994375228882
[2018-04-17 19:38:20.770128]: ====================
[2018-04-17 19:38:20.777147]: Elapsed time since starting training: 0:17:46.941778
[2018-04-17 19:38:20.781158]: Estimated time left: 0:57:13.054211
[2018-04-17 19:38:20.786672]: ====================
[2018-04-17 19:38:20.908497]: [Epoch: 139(13.913913913913914%): Data: 0.0%]:Running loss: 0.22191977500915527
[2018-04-17 19:38:22.552368]: [Epoch: 139(13.913913913913914%): Data: 25.333333333333336%]:Running loss: 4.438147589564323
[2018-04-17 19:38:24.230831]: [Epoch: 139(13.913913913913914%): Data: 50.66666666666667%]:Running loss: 8.653904840350151
[2018-04-17 19:38:28.845601]: Test set accuracy: 94.33962264150944% ,loss = 5.545566603541374
[2018-04-17 19:38:28.993997]: ====================
[2018-04-17 19:38:28.999009]: Elapsed time since starting training: 0:17:55.163640
[2018-04-17 19:38:29.008033]: Estimated time left: 0:57:04.827336
[2018-04-17 19:38:29.013047]: ====================
[2018-04-17 19:38:29.110806]: [Epoch: 140(14.014014014014014%): Data: 0.0%]:Running loss: 0.22182266414165497
[2018-04-17 19:38:30.676470]: [Epoch: 140(14.014014014014014%): Data: 25.333333333333336%]:Running loss: 4.436209082603455
[2018-04-17 19:38:32.220074]: [Epoch: 140(14.014014014014014%): Data: 50.66666666666667%]:Running loss: 8.650136411190033
[2018-04-17 19:38:36.658375]: Test set accuracy: 94.33962264150944% ,loss = 5.543197318911552
[2018-04-17 19:38:36.844871]: ====================
[2018-04-17 19:38:36.850887]: Elapsed time since starting training: 0:18:03.015518
[2018-04-17 19:38:36.857906]: Estimated time left: 0:56:56.977463
[2018-04-17 19:38:36.862417]: ====================
[2018-04-17 19:38:36.935111]: [Epoch: 141(14.114114114114114%): Data: 0.0%]:Running loss: 0.2217278927564621
[2018-04-17 19:38:38.710335]: [Epoch: 141(14.114114114114114%): Data: 25.333333333333336%]:Running loss: 4.434318035840988
[2018-04-17 19:38:40.284517]: [Epoch: 141(14.114114114114114%): Data: 50.66666666666667%]:Running loss: 8.646459981799126
[2018-04-17 19:38:44.598488]: Test set accuracy: 94.33962264150944% ,loss = 5.5408775806427
[2018-04-17 19:38:44.761421]: ====================
[2018-04-17 19:38:44.767437]: Elapsed time since starting training: 0:18:10.932068
[2018-04-17 19:38:44.772451]: Estimated time left: 0:56:49.063420
[2018-04-17 19:38:44.776963]: ====================
[2018-04-17 19:38:44.848654]: [Epoch: 142(14.214214214214213%): Data: 0.0%]:Running loss: 0.221635103225708
[2018-04-17 19:38:46.426348]: [Epoch: 142(14.214214214214213%): Data: 25.333333333333336%]:Running loss: 4.432472541928291
[2018-04-17 19:38:48.010060]: [Epoch: 142(14.214214214214213%): Data: 50.66666666666667%]:Running loss: 8.642871722579002
[2018-04-17 19:38:52.458387]: Test set accuracy: 94.33962264150944% ,loss = 5.538623407483101
[2018-04-17 19:38:52.660927]: ====================
[2018-04-17 19:38:52.667945]: Elapsed time since starting training: 0:18:18.832576
[2018-04-17 19:38:52.673459]: Estimated time left: 0:56:41.161910
[2018-04-17 19:38:52.681982]: ====================
[2018-04-17 19:38:52.754675]: [Epoch: 143(14.314314314314313%): Data: 0.0%]:Running loss: 0.22154493629932404
[2018-04-17 19:38:54.513352]: [Epoch: 143(14.314314314314313%): Data: 25.333333333333336%]:Running loss: 4.430671975016594
[2018-04-17 19:38:56.076006]: [Epoch: 143(14.314314314314313%): Data: 50.66666666666667%]:Running loss: 8.639372155070305
[2018-04-17 19:39:00.576474]: Test set accuracy: 94.33962264150944% ,loss = 5.536417290568352
[2018-04-17 19:39:00.769486]: ====================
[2018-04-17 19:39:00.777006]: Elapsed time since starting training: 0:18:26.941637
[2018-04-17 19:39:00.782521]: Estimated time left: 0:56:33.053349
[2018-04-17 19:39:00.790041]: ====================
[2018-04-17 19:39:00.866244]: [Epoch: 144(14.414414414414415%): Data: 0.0%]:Running loss: 0.22145669162273407
[2018-04-17 19:39:02.509113]: [Epoch: 144(14.414414414414415%): Data: 25.333333333333336%]:Running loss: 4.428914695978165
[2018-04-17 19:39:04.127415]: [Epoch: 144(14.414414414414415%): Data: 50.66666666666667%]:Running loss: 8.635956451296806
[2018-04-17 19:39:08.646932]: Test set accuracy: 94.33962264150944% ,loss = 5.534270405769348
[2018-04-17 19:39:08.863007]: ====================
[2018-04-17 19:39:08.868522]: Elapsed time since starting training: 0:18:35.033153
[2018-04-17 19:39:08.877045]: Estimated time left: 0:56:24.958826
[2018-04-17 19:39:08.881055]: ====================
[2018-04-17 19:39:08.954751]: [Epoch: 145(14.514514514514515%): Data: 0.0%]:Running loss: 0.22137081623077393
[2018-04-17 19:39:10.643742]: [Epoch: 145(14.514514514514515%): Data: 25.333333333333336%]:Running loss: 4.427200272679329
[2018-04-17 19:39:12.201384]: [Epoch: 145(14.514514514514515%): Data: 50.66666666666667%]:Running loss: 8.632623389363289
[2018-04-17 19:39:16.735440]: Test set accuracy: 94.33962264150944% ,loss = 5.532173812389374
[2018-04-17 19:39:16.862277]: ====================
[2018-04-17 19:39:16.867290]: Elapsed time since starting training: 0:18:43.031921
[2018-04-17 19:39:16.872304]: Estimated time left: 0:56:16.963065
[2018-04-17 19:39:16.885839]: ====================
[2018-04-17 19:39:16.990116]: [Epoch: 146(14.614614614614615%): Data: 0.0%]:Running loss: 0.22128695249557495
[2018-04-17 19:39:18.521693]: [Epoch: 146(14.614614614614615%): Data: 25.333333333333336%]:Running loss: 4.42552687227726
[2018-04-17 19:39:20.191132]: [Epoch: 146(14.614614614614615%): Data: 50.66666666666667%]:Running loss: 8.62936945259571
[2018-04-17 19:39:24.771321]: Test set accuracy: 94.33962264150944% ,loss = 5.53012490272522
[2018-04-17 19:39:24.897657]: ====================
[2018-04-17 19:39:24.902170]: Elapsed time since starting training: 0:18:51.066299
[2018-04-17 19:39:24.906681]: Estimated time left: 0:56:08.928688
[2018-04-17 19:39:24.911193]: ====================
[2018-04-17 19:39:25.023993]: [Epoch: 147(14.714714714714713%): Data: 0.0%]:Running loss: 0.2212049961090088
[2018-04-17 19:39:26.627757]: [Epoch: 147(14.714714714714713%): Data: 25.333333333333336%]:Running loss: 4.423892110586166
[2018-04-17 19:39:28.239544]: [Epoch: 147(14.714714714714713%): Data: 50.66666666666667%]:Running loss: 8.62619312107563
[2018-04-17 19:39:32.879882]: Test set accuracy: 94.33962264150944% ,loss = 5.528121441602707
[2018-04-17 19:39:33.067883]: ====================
[2018-04-17 19:39:33.077407]: Elapsed time since starting training: 0:18:59.242038
[2018-04-17 19:39:33.081919]: Estimated time left: 0:56:00.753450
[2018-04-17 19:39:33.087435]: ====================
[2018-04-17 19:39:33.159626]: [Epoch: 148(14.814814814814813%): Data: 0.0%]:Running loss: 0.22112485766410828
[2018-04-17 19:39:34.757375]: [Epoch: 148(14.814814814814813%): Data: 25.333333333333336%]:Running loss: 4.422297850251198
[2018-04-17 19:39:36.357629]: [Epoch: 148(14.814814814814813%): Data: 50.66666666666667%]:Running loss: 8.623093515634537
[2018-04-17 19:39:41.053393]: Test set accuracy: 94.33962264150944% ,loss = 5.526170134544373
[2018-04-17 19:39:41.197777]: ====================
[2018-04-17 19:39:41.233373]: Elapsed time since starting training: 0:19:07.397502
[2018-04-17 19:39:41.238385]: Estimated time left: 0:55:52.596984
[2018-04-17 19:39:41.247911]: ====================
[2018-04-17 19:39:41.321607]: [Epoch: 149(14.914914914914915%): Data: 0.0%]:Running loss: 0.2210468053817749
[2018-04-17 19:39:43.006086]: [Epoch: 149(14.914914914914915%): Data: 25.333333333333336%]:Running loss: 4.4207413494586945
[2018-04-17 19:39:44.586287]: [Epoch: 149(14.914914914914915%): Data: 50.66666666666667%]:Running loss: 8.62006664276123
[2018-04-17 19:39:49.208579]: Test set accuracy: 94.33962264150944% ,loss = 5.524268746376038
[2018-04-17 19:39:49.334914]: ====================
[2018-04-17 19:39:49.339927]: Elapsed time since starting training: 0:19:15.504057
[2018-04-17 19:39:49.344439]: Estimated time left: 0:55:44.491431
[2018-04-17 19:39:49.348450]: ====================
[2018-04-17 19:39:49.427161]: [Epoch: 150(15.015015015015015%): Data: 0.0%]:Running loss: 0.2209707498550415
[2018-04-17 19:39:51.001847]: [Epoch: 150(15.015015015015015%): Data: 25.333333333333336%]:Running loss: 4.419221639633179
[2018-04-17 19:39:52.630677]: [Epoch: 150(15.015015015015015%): Data: 50.66666666666667%]:Running loss: 8.617111772298813
[2018-04-17 19:39:57.016840]: Test set accuracy: 94.33962264150944% ,loss = 5.522403120994568
[2018-04-17 19:39:57.150196]: ====================
[2018-04-17 19:39:57.159220]: Elapsed time since starting training: 0:19:23.323349
[2018-04-17 19:39:57.177267]: Estimated time left: 0:55:36.658102
[2018-04-17 19:39:57.209853]: ====================
[2018-04-17 19:39:57.297085]: [Epoch: 151(15.115115115115115%): Data: 0.0%]:Running loss: 0.22089612483978271
[2018-04-17 19:39:59.019666]: [Epoch: 151(15.115115115115115%): Data: 25.333333333333336%]:Running loss: 4.417737618088722
[2018-04-17 19:40:00.560763]: [Epoch: 151(15.115115115115115%): Data: 50.66666666666667%]:Running loss: 8.614227011799812
[2018-04-17 19:40:04.943417]: Test set accuracy: 94.33962264150944% ,loss = 5.520587041974068
[2018-04-17 19:40:05.133924]: ====================
[2018-04-17 19:40:05.140943]: Elapsed time since starting training: 0:19:31.305574
[2018-04-17 19:40:05.145454]: Estimated time left: 0:55:28.689915
[2018-04-17 19:40:05.150469]: ====================
[2018-04-17 19:40:05.226671]: [Epoch: 152(15.215215215215217%): Data: 0.0%]:Running loss: 0.2208234816789627
[2018-04-17 19:40:06.926691]: [Epoch: 152(15.215215215215217%): Data: 25.333333333333336%]:Running loss: 4.416289210319519
[2018-04-17 19:40:08.474817]: [Epoch: 152(15.215215215215217%): Data: 50.66666666666667%]:Running loss: 8.611411288380623
[2018-04-17 19:40:12.893556]: Test set accuracy: 94.33962264150944% ,loss = 5.518811196088791
[2018-04-17 19:40:13.047967]: ====================
[2018-04-17 19:40:13.053481]: Elapsed time since starting training: 0:19:39.218112
[2018-04-17 19:40:13.058495]: Estimated time left: 0:55:20.777375
[2018-04-17 19:40:13.063007]: ====================
[2018-04-17 19:40:13.133193]: [Epoch: 153(15.315315315315313%): Data: 0.0%]:Running loss: 0.22075244784355164
[2018-04-17 19:40:14.822686]: [Epoch: 153(15.315315315315313%): Data: 25.333333333333336%]:Running loss: 4.414874657988548
[2018-04-17 19:40:16.396370]: [Epoch: 153(15.315315315315313%): Data: 50.66666666666667%]:Running loss: 8.608660206198692
[2018-04-17 19:40:20.835178]: Test set accuracy: 94.33962264150944% ,loss = 5.517084151506424
[2018-04-17 19:40:21.075818]: ====================
[2018-04-17 19:40:21.080831]: Elapsed time since starting training: 0:19:47.245462
[2018-04-17 19:40:21.087850]: Estimated time left: 0:55:12.747519
[2018-04-17 19:40:21.094367]: ====================
[2018-04-17 19:40:21.167562]: [Epoch: 154(15.415415415415415%): Data: 0.0%]:Running loss: 0.22068336606025696
[2018-04-17 19:40:22.872094]: [Epoch: 154(15.415415415415415%): Data: 25.333333333333336%]:Running loss: 4.413492023944855
[2018-04-17 19:40:24.460317]: [Epoch: 154(15.415415415415415%): Data: 50.66666666666667%]:Running loss: 8.605973854660988
[2018-04-17 19:40:28.913157]: Test set accuracy: 94.33962264150944% ,loss = 5.515386536717415
[2018-04-17 19:40:29.104165]: ====================
[2018-04-17 19:40:29.111184]: Elapsed time since starting training: 0:19:55.275815
[2018-04-17 19:40:29.118202]: Estimated time left: 0:55:04.717668
[2018-04-17 19:40:29.122714]: ====================
[2018-04-17 19:40:29.190895]: [Epoch: 155(15.515515515515515%): Data: 0.0%]:Running loss: 0.2206154614686966
[2018-04-17 19:40:30.906457]: [Epoch: 155(15.515515515515515%): Data: 25.333333333333336%]:Running loss: 4.412142992019653
[2018-04-17 19:40:32.590936]: [Epoch: 155(15.515515515515515%): Data: 50.66666666666667%]:Running loss: 8.603350475430489
[2018-04-17 19:40:37.001664]: Test set accuracy: 94.33962264150944% ,loss = 5.513739213347435
[2018-04-17 19:40:37.167104]: ====================
[2018-04-17 19:40:37.172117]: Elapsed time since starting training: 0:20:03.336247
[2018-04-17 19:40:37.176630]: Estimated time left: 0:54:56.659241
[2018-04-17 19:40:37.181141]: ====================
[2018-04-17 19:40:37.250826]: [Epoch: 156(15.615615615615615%): Data: 0.0%]:Running loss: 0.2205495685338974
[2018-04-17 19:40:38.857098]: [Epoch: 156(15.615615615615615%): Data: 25.333333333333336%]:Running loss: 4.410825505852699
[2018-04-17 19:40:40.495455]: [Epoch: 156(15.615615615615615%): Data: 50.66666666666667%]:Running loss: 8.60078738629818
[2018-04-17 19:40:44.982384]: Test set accuracy: 94.33962264150944% ,loss = 5.5121202021837234
[2018-04-17 19:40:45.111227]: ====================
[2018-04-17 19:40:45.116241]: Elapsed time since starting training: 0:20:11.280872
[2018-04-17 19:40:45.125265]: Estimated time left: 0:54:48.710104
[2018-04-17 19:40:45.129777]: ====================
[2018-04-17 19:40:45.246588]: [Epoch: 157(15.715715715715717%): Data: 0.0%]:Running loss: 0.22048480808734894
[2018-04-17 19:40:46.848346]: [Epoch: 157(15.715715715715717%): Data: 25.333333333333336%]:Running loss: 4.409537136554718
[2018-04-17 19:40:48.601007]: [Epoch: 157(15.715715715715717%): Data: 50.66666666666667%]:Running loss: 8.598284602165222
[2018-04-17 19:40:53.075905]: Test set accuracy: 94.33962264150944% ,loss = 5.510542914271355
[2018-04-17 19:40:53.256385]: ====================
[2018-04-17 19:40:53.261900]: Elapsed time since starting training: 0:20:19.426029
[2018-04-17 19:40:53.268919]: Estimated time left: 0:54:40.566952
[2018-04-17 19:40:53.274434]: ====================
[2018-04-17 19:40:53.343116]: [Epoch: 158(15.815815815815814%): Data: 0.0%]:Running loss: 0.2204217165708542
[2018-04-17 19:40:54.977963]: [Epoch: 158(15.815815815815814%): Data: 25.333333333333336%]:Running loss: 4.408280178904533
[2018-04-17 19:40:56.610304]: [Epoch: 158(15.815815815815814%): Data: 50.66666666666667%]:Running loss: 8.595840156078339
[2018-04-17 19:41:01.157394]: Test set accuracy: 94.33962264150944% ,loss = 5.509005859494209
[2018-04-17 19:41:01.294258]: ====================
[2018-04-17 19:41:01.298770]: Elapsed time since starting training: 0:20:27.463401
[2018-04-17 19:41:01.303282]: Estimated time left: 0:54:32.532588
[2018-04-17 19:41:01.308295]: ====================
[2018-04-17 19:41:01.441650]: [Epoch: 159(15.915915915915916%): Data: 0.0%]:Running loss: 0.22036023437976837
[2018-04-17 19:41:02.998289]: [Epoch: 159(15.915915915915916%): Data: 25.333333333333336%]:Running loss: 4.4070524126291275
[2018-04-17 19:41:04.578490]: [Epoch: 159(15.915915915915916%): Data: 50.66666666666667%]:Running loss: 8.59345331788063
[2018-04-17 19:41:09.093496]: Test set accuracy: 94.33962264150944% ,loss = 5.507496744394302
[2018-04-17 19:41:09.283000]: ====================
[2018-04-17 19:41:09.292024]: Elapsed time since starting training: 0:20:35.456655
[2018-04-17 19:41:09.296536]: Estimated time left: 0:54:24.539334
[2018-04-17 19:41:09.301048]: ====================
[2018-04-17 19:41:09.376750]: [Epoch: 160(16.016016016016017%): Data: 0.0%]:Running loss: 0.2202998697757721
[2018-04-17 19:41:10.933889]: [Epoch: 160(16.016016016016017%): Data: 25.333333333333336%]:Running loss: 4.405852720141411
[2018-04-17 19:41:12.462454]: [Epoch: 160(16.016016016016017%): Data: 50.66666666666667%]:Running loss: 8.591119274497032
[2018-04-17 19:41:16.908776]: Test set accuracy: 94.33962264150944% ,loss = 5.5060286074876785
[2018-04-17 19:41:17.088254]: ====================
[2018-04-17 19:41:17.093267]: Elapsed time since starting training: 0:20:43.257397
[2018-04-17 19:41:17.098281]: Estimated time left: 0:54:16.737589
[2018-04-17 19:41:17.103796]: ====================
[2018-04-17 19:41:17.175486]: [Epoch: 161(16.116116116116117%): Data: 0.0%]:Running loss: 0.22024114429950714
[2018-04-17 19:41:18.771230]: [Epoch: 161(16.116116116116117%): Data: 25.333333333333336%]:Running loss: 4.404678896069527
[2018-04-17 19:41:20.407079]: [Epoch: 161(16.116116116116117%): Data: 50.66666666666667%]:Running loss: 8.588838249444962
[2018-04-17 19:41:24.974223]: Test set accuracy: 94.33962264150944% ,loss = 5.5046021938323975
[2018-04-17 19:41:25.248955]: ====================
[2018-04-17 19:41:25.253967]: Elapsed time since starting training: 0:20:51.418598
[2018-04-17 19:41:25.259481]: Estimated time left: 0:54:08.575888
[2018-04-17 19:41:25.264495]: ====================
[2018-04-17 19:41:25.338191]: [Epoch: 162(16.216216216216218%): Data: 0.0%]:Running loss: 0.2201840877532959
[2018-04-17 19:41:26.886308]: [Epoch: 162(16.216216216216218%): Data: 25.333333333333336%]:Running loss: 4.403533652424812
[2018-04-17 19:41:28.509623]: [Epoch: 162(16.216216216216218%): Data: 50.66666666666667%]:Running loss: 8.586611852049828
[2018-04-17 19:41:32.909322]: Test set accuracy: 94.33962264150944% ,loss = 5.503194406628609
[2018-04-17 19:41:33.109855]: ====================
[2018-04-17 19:41:33.114868]: Elapsed time since starting training: 0:20:59.279499
[2018-04-17 19:41:33.122388]: Estimated time left: 0:54:00.713482
[2018-04-17 19:41:33.127402]: ====================
[2018-04-17 19:41:33.199093]: [Epoch: 163(16.316316316316314%): Data: 0.0%]:Running loss: 0.22012777626514435
[2018-04-17 19:41:34.787315]: [Epoch: 163(16.316316316316314%): Data: 25.333333333333336%]:Running loss: 4.402413532137871
[2018-04-17 19:41:36.385064]: [Epoch: 163(16.316316316316314%): Data: 50.66666666666667%]:Running loss: 8.584434628486633
[2018-04-17 19:41:40.853951]: Test set accuracy: 94.33962264150944% ,loss = 5.501818284392357
[2018-04-17 19:41:41.036938]: ====================
[2018-04-17 19:41:41.042453]: Elapsed time since starting training: 0:21:07.207084
[2018-04-17 19:41:41.047467]: Estimated time left: 0:53:52.788405
[2018-04-17 19:41:41.051477]: ====================
[2018-04-17 19:41:41.128181]: [Epoch: 164(16.416416416416414%): Data: 0.0%]:Running loss: 0.22007273137569427
[2018-04-17 19:41:42.740969]: [Epoch: 164(16.416416416416414%): Data: 25.333333333333336%]:Running loss: 4.401319548487663
[2018-04-17 19:41:44.359273]: [Epoch: 164(16.416416416416414%): Data: 50.66666666666667%]:Running loss: 8.582308620214462
[2018-04-17 19:41:48.715856]: Test set accuracy: 94.33962264150944% ,loss = 5.500481277704239
[2018-04-17 19:41:48.852218]: ====================
[2018-04-17 19:41:48.877285]: Elapsed time since starting training: 0:21:15.041415
[2018-04-17 19:41:48.881797]: Estimated time left: 0:53:44.954074
[2018-04-17 19:41:48.885808]: ====================
[2018-04-17 19:41:48.958502]: [Epoch: 165(16.516516516516518%): Data: 0.0%]:Running loss: 0.22001925110816956
[2018-04-17 19:41:50.522159]: [Epoch: 165(16.516516516516518%): Data: 25.333333333333336%]:Running loss: 4.400252133607864
[2018-04-17 19:41:52.021144]: [Epoch: 165(16.516516516516518%): Data: 50.66666666666667%]:Running loss: 8.580230548977852
[2018-04-17 19:41:56.381238]: Test set accuracy: 94.33962264150944% ,loss = 5.499175935983658
[2018-04-17 19:41:56.523116]: ====================
[2018-04-17 19:41:56.539660]: Elapsed time since starting training: 0:21:22.704291
[2018-04-17 19:41:56.545174]: Estimated time left: 0:53:37.290195
[2018-04-17 19:41:56.552695]: ====================
[2018-04-17 19:41:56.621878]: [Epoch: 166(16.616616616616618%): Data: 0.0%]:Running loss: 0.2199670374393463
[2018-04-17 19:41:58.136906]: [Epoch: 166(16.616616616616618%): Data: 25.333333333333336%]:Running loss: 4.3992060869932175
[2018-04-17 19:41:59.661460]: [Epoch: 166(16.616616616616618%): Data: 50.66666666666667%]:Running loss: 8.578198030591011
[2018-04-17 19:42:04.032583]: Test set accuracy: 94.33962264150944% ,loss = 5.497893318533897
[2018-04-17 19:42:04.210056]: ====================
[2018-04-17 19:42:04.215068]: Elapsed time since starting training: 0:21:30.379198
[2018-04-17 19:42:04.219580]: Estimated time left: 0:53:29.616290
[2018-04-17 19:42:04.223591]: ====================
[2018-04-17 19:42:04.297789]: [Epoch: 167(16.716716716716718%): Data: 0.0%]:Running loss: 0.2199157327413559
[2018-04-17 19:42:05.868465]: [Epoch: 167(16.716716716716718%): Data: 25.333333333333336%]:Running loss: 4.398186132311821
[2018-04-17 19:42:07.352912]: [Epoch: 167(16.716716716716718%): Data: 50.66666666666667%]:Running loss: 8.576213121414185
[2018-04-17 19:42:11.733560]: Test set accuracy: 94.33962264150944% ,loss = 5.496641248464584
[2018-04-17 19:42:11.901005]: ====================
[2018-04-17 19:42:11.906520]: Elapsed time since starting training: 0:21:38.071151
[2018-04-17 19:42:11.911032]: Estimated time left: 0:53:21.924337
[2018-04-17 19:42:11.917048]: ====================
[2018-04-17 19:42:11.989239]: [Epoch: 168(16.816816816816818%): Data: 0.0%]:Running loss: 0.21986564993858337
[2018-04-17 19:42:13.647149]: [Epoch: 168(16.816816816816818%): Data: 25.333333333333336%]:Running loss: 4.397187143564224
[2018-04-17 19:42:15.171702]: [Epoch: 168(16.816816816816818%): Data: 50.66666666666667%]:Running loss: 8.574272736907005
[2018-04-17 19:42:19.425513]: Test set accuracy: 94.33962264150944% ,loss = 5.495420470833778
[2018-04-17 19:42:19.564382]: ====================
[2018-04-17 19:42:19.569395]: Elapsed time since starting training: 0:21:45.733525
[2018-04-17 19:42:19.574408]: Estimated time left: 0:53:14.260961
[2018-04-17 19:42:19.579422]: ====================
[2018-04-17 19:42:19.689214]: [Epoch: 169(16.916916916916914%): Data: 0.0%]:Running loss: 0.21981681883335114
[2018-04-17 19:42:21.203740]: [Epoch: 169(16.916916916916914%): Data: 25.333333333333336%]:Running loss: 4.396212354302406
[2018-04-17 19:42:22.695211]: [Epoch: 169(16.916916916916914%): Data: 50.66666666666667%]:Running loss: 8.57237608730793
[2018-04-17 19:42:26.876330]: Test set accuracy: 94.33962264150944% ,loss = 5.494219064712524
[2018-04-17 19:42:27.004169]: ====================
[2018-04-17 19:42:27.009684]: Elapsed time since starting training: 0:21:53.174315
[2018-04-17 19:42:27.014196]: Estimated time left: 0:53:06.821173
[2018-04-17 19:42:27.018708]: ====================
[2018-04-17 19:42:27.118473]: [Epoch: 170(17.017017017017018%): Data: 0.0%]:Running loss: 0.21976876258850098
[2018-04-17 19:42:28.650046]: [Epoch: 170(17.017017017017018%): Data: 25.333333333333336%]:Running loss: 4.3952585607767105
[2018-04-17 19:42:30.153042]: [Epoch: 170(17.017017017017018%): Data: 50.66666666666667%]:Running loss: 8.570521861314774
[2018-04-17 19:42:34.327642]: Test set accuracy: 94.33962264150944% ,loss = 5.493051931262016
[2018-04-17 19:42:34.501605]: ====================
[2018-04-17 19:42:34.505616]: Elapsed time since starting training: 0:22:00.670247
[2018-04-17 19:42:34.511131]: Estimated time left: 0:52:59.324238
[2018-04-17 19:42:34.519653]: ====================
[2018-04-17 19:42:34.589338]: [Epoch: 171(17.117117117117118%): Data: 0.0%]:Running loss: 0.21972207725048065
[2018-04-17 19:42:36.061252]: [Epoch: 171(17.117117117117118%): Data: 25.333333333333336%]:Running loss: 4.394325420260429
[2018-04-17 19:42:37.600344]: [Epoch: 171(17.117117117117118%): Data: 50.66666666666667%]:Running loss: 8.568708315491676
[2018-04-17 19:42:42.007563]: Test set accuracy: 94.33962264150944% ,loss = 5.491913482546806
[2018-04-17 19:42:42.164982]: ====================
[2018-04-17 19:42:42.169995]: Elapsed time since starting training: 0:22:08.334125
[2018-04-17 19:42:42.174507]: Estimated time left: 0:52:51.661363
[2018-04-17 19:42:42.179019]: ====================
[2018-04-17 19:42:42.254219]: [Epoch: 172(17.217217217217218%): Data: 0.0%]:Running loss: 0.21967653930187225
[2018-04-17 19:42:43.785791]: [Epoch: 172(17.217217217217218%): Data: 25.333333333333336%]:Running loss: 4.393415182828903
[2018-04-17 19:42:45.293802]: [Epoch: 172(17.217217217217218%): Data: 50.66666666666667%]:Running loss: 8.566937029361725
[2018-04-17 19:42:49.477426]: Test set accuracy: 94.33962264150944% ,loss = 5.490788817405701
[2018-04-17 19:42:49.640861]: ====================
[2018-04-17 19:42:49.645373]: Elapsed time since starting training: 0:22:15.810004
[2018-04-17 19:42:49.649884]: Estimated time left: 0:52:44.185485
[2018-04-17 19:42:49.654396]: ====================
[2018-04-17 19:42:49.727090]: [Epoch: 173(17.31731731731732%): Data: 0.0%]:Running loss: 0.21963155269622803
[2018-04-17 19:42:51.200007]: [Epoch: 173(17.31731731731732%): Data: 25.333333333333336%]:Running loss: 4.392523214221001
[2018-04-17 19:42:52.755643]: [Epoch: 173(17.31731731731732%): Data: 50.66666666666667%]:Running loss: 8.56520365178585
[2018-04-17 19:42:56.984386]: Test set accuracy: 94.33962264150944% ,loss = 5.489706993103027
[2018-04-17 19:42:57.135789]: ====================
[2018-04-17 19:42:57.140803]: Elapsed time since starting training: 0:22:23.304933
[2018-04-17 19:42:57.146317]: Estimated time left: 0:52:36.689552
[2018-04-17 19:42:57.151330]: ====================
[2018-04-17 19:42:57.232045]: [Epoch: 174(17.417417417417415%): Data: 0.0%]:Running loss: 0.2195882797241211
[2018-04-17 19:42:58.721506]: [Epoch: 174(17.417417417417415%): Data: 25.333333333333336%]:Running loss: 4.391652539372444
[2018-04-17 19:43:00.226006]: [Epoch: 174(17.417417417417415%): Data: 50.66666666666667%]:Running loss: 8.563510820269585
[2018-04-17 19:43:04.495358]: Test set accuracy: 94.33962264150944% ,loss = 5.488636717200279
[2018-04-17 19:43:04.657790]: ====================
[2018-04-17 19:43:04.662302]: Elapsed time since starting training: 0:22:30.826933
[2018-04-17 19:43:04.667817]: Estimated time left: 0:52:29.167552
[2018-04-17 19:43:04.674835]: ====================
[2018-04-17 19:43:04.746526]: [Epoch: 175(17.51751751751752%): Data: 0.0%]:Running loss: 0.21954546868801117
[2018-04-17 19:43:06.390397]: [Epoch: 175(17.51751751751752%): Data: 25.333333333333336%]:Running loss: 4.390800639986992
[2018-04-17 19:43:07.898908]: [Epoch: 175(17.51751751751752%): Data: 50.66666666666667%]:Running loss: 8.561852842569351
[2018-04-17 19:43:12.134170]: Test set accuracy: 94.33962264150944% ,loss = 5.487588793039322
[2018-04-17 19:43:12.311642]: ====================
[2018-04-17 19:43:12.317658]: Elapsed time since starting training: 0:22:38.481787
[2018-04-17 19:43:12.327684]: Estimated time left: 0:52:21.508186
[2018-04-17 19:43:12.332196]: ====================
[2018-04-17 19:43:12.404890]: [Epoch: 176(17.61761761761762%): Data: 0.0%]:Running loss: 0.21950355172157288
[2018-04-17 19:43:13.907385]: [Epoch: 176(17.61761761761762%): Data: 25.333333333333336%]:Running loss: 4.389967396855354
[2018-04-17 19:43:15.392834]: [Epoch: 176(17.61761761761762%): Data: 50.66666666666667%]:Running loss: 8.560234114527702
[2018-04-17 19:43:19.565429]: Test set accuracy: 94.33962264150944% ,loss = 5.486571416258812
[2018-04-17 19:43:19.719338]: ====================
[2018-04-17 19:43:19.724352]: Elapsed time since starting training: 0:22:45.888983
[2018-04-17 19:43:19.729365]: Estimated time left: 0:52:14.106004
[2018-04-17 19:43:19.733877]: ====================
[2018-04-17 19:43:19.805569]: [Epoch: 177(17.71771771771772%): Data: 0.0%]:Running loss: 0.21946285665035248
[2018-04-17 19:43:21.293023]: [Epoch: 177(17.71771771771772%): Data: 25.333333333333336%]:Running loss: 4.389153331518173
[2018-04-17 19:43:22.830611]: [Epoch: 177(17.71771771771772%): Data: 50.66666666666667%]:Running loss: 8.55865141749382
[2018-04-17 19:43:27.029778]: Test set accuracy: 94.33962264150944% ,loss = 5.4855674505233765
[2018-04-17 19:43:27.188700]: ====================
[2018-04-17 19:43:27.193211]: Elapsed time since starting training: 0:22:53.357842
[2018-04-17 19:43:27.198727]: Estimated time left: 0:52:06.637144
[2018-04-17 19:43:27.205745]: ====================
[2018-04-17 19:43:27.279942]: [Epoch: 178(17.81781781781782%): Data: 0.0%]:Running loss: 0.21942269802093506
[2018-04-17 19:43:28.750853]: [Epoch: 178(17.81781781781782%): Data: 25.333333333333336%]:Running loss: 4.388357266783714
[2018-04-17 19:43:30.275407]: [Epoch: 178(17.81781781781782%): Data: 50.66666666666667%]:Running loss: 8.557102367281914
[2018-04-17 19:43:34.630988]: Test set accuracy: 94.33962264150944% ,loss = 5.484598875045776
[2018-04-17 19:43:34.796930]: ====================
[2018-04-17 19:43:34.801943]: Elapsed time since starting training: 0:23:00.966073
[2018-04-17 19:43:34.806455]: Estimated time left: 0:51:59.028914
[2018-04-17 19:43:34.810967]: ====================
[2018-04-17 19:43:34.887671]: [Epoch: 179(17.917917917917915%): Data: 0.0%]:Running loss: 0.21938395500183105
[2018-04-17 19:43:36.348555]: [Epoch: 179(17.917917917917915%): Data: 25.333333333333336%]:Running loss: 4.387578576803207
[2018-04-17 19:43:37.853056]: [Epoch: 179(17.917917917917915%): Data: 50.66666666666667%]:Running loss: 8.555587857961655
[2018-04-17 19:43:42.342995]: Test set accuracy: 94.33962264150944% ,loss = 5.483640730381012
[2018-04-17 19:43:42.503421]: ====================
[2018-04-17 19:43:42.509940]: Elapsed time since starting training: 0:23:08.674571
[2018-04-17 19:43:42.515453]: Estimated time left: 0:51:51.319916
[2018-04-17 19:43:42.520467]: ====================
[2018-04-17 19:43:42.595165]: [Epoch: 180(18.01801801801802%): Data: 0.0%]:Running loss: 0.21934562921524048
[2018-04-17 19:43:44.271122]: [Epoch: 180(18.01801801801802%): Data: 25.333333333333336%]:Running loss: 4.386816814541817
[2018-04-17 19:43:45.855835]: [Epoch: 180(18.01801801801802%): Data: 50.66666666666667%]:Running loss: 8.554106131196022
[2018-04-17 19:43:50.429497]: Test set accuracy: 94.33962264150944% ,loss = 5.482703819870949
[2018-04-17 19:43:50.597945]: ====================
[2018-04-17 19:43:50.603460]: Elapsed time since starting training: 0:23:16.768091
[2018-04-17 19:43:50.607971]: Estimated time left: 0:51:43.227398
[2018-04-17 19:43:50.613486]: ====================
[2018-04-17 19:43:50.693699]: [Epoch: 181(18.11811811811812%): Data: 0.0%]:Running loss: 0.21930815279483795
[2018-04-17 19:43:52.287939]: [Epoch: 181(18.11811811811812%): Data: 25.333333333333336%]:Running loss: 4.386070787906647
[2018-04-17 19:43:53.886689]: [Epoch: 181(18.11811811811812%): Data: 50.66666666666667%]:Running loss: 8.552656546235085
[2018-04-17 19:43:58.663892]: Test set accuracy: 94.33962264150944% ,loss = 5.481794476509094
[2018-04-17 19:43:58.831341]: ====================
[2018-04-17 19:43:58.839359]: Elapsed time since starting training: 0:23:25.003990
[2018-04-17 19:43:58.843871]: Estimated time left: 0:51:34.991498
[2018-04-17 19:43:58.849385]: ====================
[2018-04-17 19:43:58.928094]: [Epoch: 182(18.21821821821822%): Data: 0.0%]:Running loss: 0.21927177906036377
[2018-04-17 19:44:00.578984]: [Epoch: 182(18.21821821821822%): Data: 25.333333333333336%]:Running loss: 4.385342687368393
[2018-04-17 19:44:02.260956]: [Epoch: 182(18.21821821821822%): Data: 50.66666666666667%]:Running loss: 8.551240146160126
[2018-04-17 19:44:06.902298]: Test set accuracy: 94.33962264150944% ,loss = 5.480895563960075
[2018-04-17 19:44:07.080272]: ====================
[2018-04-17 19:44:07.085786]: Elapsed time since starting training: 0:23:33.250417
[2018-04-17 19:44:07.091300]: Estimated time left: 0:51:26.744069
[2018-04-17 19:44:07.095813]: ====================
[2018-04-17 19:44:07.173518]: [Epoch: 183(18.31831831831832%): Data: 0.0%]:Running loss: 0.21923582255840302
[2018-04-17 19:44:08.714616]: [Epoch: 183(18.31831831831832%): Data: 25.333333333333336%]:Running loss: 4.384628891944885
[2018-04-17 19:44:10.218616]: [Epoch: 183(18.31831831831832%): Data: 50.66666666666667%]:Running loss: 8.549852952361107
[2018-04-17 19:44:14.659424]: Test set accuracy: 94.33962264150944% ,loss = 5.480020120739937
[2018-04-17 19:44:14.819850]: ====================
[2018-04-17 19:44:14.824362]: Elapsed time since starting training: 0:23:40.988993
[2018-04-17 19:44:14.828874]: Estimated time left: 0:51:19.006495
[2018-04-17 19:44:14.834390]: ====================
[2018-04-17 19:44:14.914603]: [Epoch: 184(18.41841841841842%): Data: 0.0%]:Running loss: 0.21920080482959747
[2018-04-17 19:44:16.456202]: [Epoch: 184(18.41841841841842%): Data: 25.333333333333336%]:Running loss: 4.3839320838451385
[2018-04-17 19:44:18.026376]: [Epoch: 184(18.41841841841842%): Data: 50.66666666666667%]:Running loss: 8.54849711060524
[2018-04-17 19:44:22.642651]: Test set accuracy: 94.33962264150944% ,loss = 5.4791707545518875
[2018-04-17 19:44:22.804581]: ====================
[2018-04-17 19:44:22.809094]: Elapsed time since starting training: 0:23:48.973725
[2018-04-17 19:44:22.814108]: Estimated time left: 0:51:11.021764
[2018-04-17 19:44:22.818619]: ====================
[2018-04-17 19:44:22.935430]: [Epoch: 185(18.51851851851852%): Data: 0.0%]:Running loss: 0.2191668301820755
[2018-04-17 19:44:24.612890]: [Epoch: 185(18.51851851851852%): Data: 25.333333333333336%]:Running loss: 4.383249744772911
[2018-04-17 19:44:26.150980]: [Epoch: 185(18.51851851851852%): Data: 50.66666666666667%]:Running loss: 8.547170370817184
[2018-04-17 19:44:30.801847]: Test set accuracy: 94.33962264150944% ,loss = 5.4783303290605545
[2018-04-17 19:44:30.931692]: ====================
[2018-04-17 19:44:30.936705]: Elapsed time since starting training: 0:23:57.101336
[2018-04-17 19:44:30.941217]: Estimated time left: 0:51:02.894152
[2018-04-17 19:44:30.945729]: ====================
[2018-04-17 19:44:31.069559]: [Epoch: 186(18.61861861861862%): Data: 0.0%]:Running loss: 0.21913321316242218
[2018-04-17 19:44:32.643745]: [Epoch: 186(18.61861861861862%): Data: 25.333333333333336%]:Running loss: 4.382582023739815
[2018-04-17 19:44:34.166794]: [Epoch: 186(18.61861861861862%): Data: 50.66666666666667%]:Running loss: 8.545871764421463
[2018-04-17 19:44:38.550951]: Test set accuracy: 94.33962264150944% ,loss = 5.47751858830452
[2018-04-17 19:44:38.716893]: ====================
[2018-04-17 19:44:38.722407]: Elapsed time since starting training: 0:24:04.887038
[2018-04-17 19:44:38.726919]: Estimated time left: 0:50:55.108450
[2018-04-17 19:44:38.731932]: ====================
[2018-04-17 19:44:38.803122]: [Epoch: 187(18.71871871871872%): Data: 0.0%]:Running loss: 0.2191007435321808
[2018-04-17 19:44:40.361265]: [Epoch: 187(18.71871871871872%): Data: 25.333333333333336%]:Running loss: 4.381928667426109
[2018-04-17 19:44:41.918907]: [Epoch: 187(18.71871871871872%): Data: 50.66666666666667%]:Running loss: 8.544601812958717
[2018-04-17 19:44:46.320611]: Test set accuracy: 94.33962264150944% ,loss = 5.476709082722664
[2018-04-17 19:44:46.491064]: ====================
[2018-04-17 19:44:46.495576]: Elapsed time since starting training: 0:24:12.660207
[2018-04-17 19:44:46.500088]: Estimated time left: 0:50:47.335281
[2018-04-17 19:44:46.504600]: ====================
[2018-04-17 19:44:46.577294]: [Epoch: 188(18.81881881881882%): Data: 0.0%]:Running loss: 0.21906836330890656
[2018-04-17 19:44:48.118391]: [Epoch: 188(18.81881881881882%): Data: 25.333333333333336%]:Running loss: 4.381290316581726
[2018-04-17 19:44:49.675531]: [Epoch: 188(18.81881881881882%): Data: 50.66666666666667%]:Running loss: 8.543360695242882
[2018-04-17 19:44:54.013566]: Test set accuracy: 94.33962264150944% ,loss = 5.475934222340584
[2018-04-17 19:44:54.182515]: ====================
[2018-04-17 19:44:54.187529]: Elapsed time since starting training: 0:24:20.352160
[2018-04-17 19:44:54.193545]: Estimated time left: 0:50:39.642325
[2018-04-17 19:44:54.202569]: ====================
[2018-04-17 19:44:54.275763]: [Epoch: 189(18.91891891891892%): Data: 0.0%]:Running loss: 0.21903736889362335
[2018-04-17 19:44:55.842429]: [Epoch: 189(18.91891891891892%): Data: 25.333333333333336%]:Running loss: 4.380664482712746
[2018-04-17 19:44:57.516381]: [Epoch: 189(18.91891891891892%): Data: 50.66666666666667%]:Running loss: 8.542142853140831
[2018-04-17 19:45:01.859929]: Test set accuracy: 94.33962264150944% ,loss = 5.475159734487534
[2018-04-17 19:45:02.021860]: ====================
[2018-04-17 19:45:02.026874]: Elapsed time since starting training: 0:24:28.191505
[2018-04-17 19:45:02.031386]: Estimated time left: 0:50:31.804485
[2018-04-17 19:45:02.039407]: ====================
[2018-04-17 19:45:02.111599]: [Epoch: 190(19.01901901901902%): Data: 0.0%]:Running loss: 0.21900638937950134
[2018-04-17 19:45:03.663725]: [Epoch: 190(19.01901901901902%): Data: 25.333333333333336%]:Running loss: 4.380053475499153
[2018-04-17 19:45:05.131630]: [Epoch: 190(19.01901901901902%): Data: 50.66666666666667%]:Running loss: 8.540955618023872
[2018-04-17 19:45:09.394465]: Test set accuracy: 94.33962264150944% ,loss = 5.4744139313697815
[2018-04-17 19:45:09.540352]: ====================
[2018-04-17 19:45:09.544363]: Elapsed time since starting training: 0:24:35.708994
[2018-04-17 19:45:09.552885]: Estimated time left: 0:50:24.282985
[2018-04-17 19:45:09.557397]: ====================
[2018-04-17 19:45:09.639616]: [Epoch: 191(19.11911911911912%): Data: 0.0%]:Running loss: 0.21897655725479126
[2018-04-17 19:45:11.179711]: [Epoch: 191(19.11911911911912%): Data: 25.333333333333336%]:Running loss: 4.379455074667931
[2018-04-17 19:45:12.716297]: [Epoch: 191(19.11911911911912%): Data: 50.66666666666667%]:Running loss: 8.539791375398636
[2018-04-17 19:45:16.946545]: Test set accuracy: 94.33962264150944% ,loss = 5.473682656884193
[2018-04-17 19:45:17.107473]: ====================
[2018-04-17 19:45:17.115995]: Elapsed time since starting training: 0:24:43.280125
[2018-04-17 19:45:17.121009]: Estimated time left: 0:50:16.714862
[2018-04-17 19:45:17.125521]: ====================
[2018-04-17 19:45:17.195707]: [Epoch: 192(19.21921921921922%): Data: 0.0%]:Running loss: 0.21894730627536774
[2018-04-17 19:45:18.780421]: [Epoch: 192(19.21921921921922%): Data: 25.333333333333336%]:Running loss: 4.378869563341141
[2018-04-17 19:45:20.285423]: [Epoch: 192(19.21921921921922%): Data: 50.66666666666667%]:Running loss: 8.538652643561363
[2018-04-17 19:45:24.534220]: Test set accuracy: 94.33962264150944% ,loss = 5.47296516597271
[2018-04-17 19:45:24.675096]: ====================
[2018-04-17 19:45:24.680108]: Elapsed time since starting training: 0:24:50.844739
[2018-04-17 19:45:24.685121]: Estimated time left: 0:50:09.150248
[2018-04-17 19:45:24.690135]: ====================
[2018-04-17 19:45:24.799928]: [Epoch: 193(19.31931931931932%): Data: 0.0%]:Running loss: 0.2189186066389084
[2018-04-17 19:45:26.254293]: [Epoch: 193(19.31931931931932%): Data: 25.333333333333336%]:Running loss: 4.378296419978142
[2018-04-17 19:45:27.765817]: [Epoch: 193(19.31931931931932%): Data: 50.66666666666667%]:Running loss: 8.537538185715675
[2018-04-17 19:45:32.057729]: Test set accuracy: 94.33962264150944% ,loss = 5.4722607135772705
[2018-04-17 19:45:32.311404]: ====================
[2018-04-17 19:45:32.316918]: Elapsed time since starting training: 0:24:58.481048
[2018-04-17 19:45:32.323937]: Estimated time left: 0:50:01.511432
[2018-04-17 19:45:32.328449]: ====================
[2018-04-17 19:45:32.422700]: [Epoch: 194(19.41941941941942%): Data: 0.0%]:Running loss: 0.21889042854309082
[2018-04-17 19:45:33.951264]: [Epoch: 194(19.41941941941942%): Data: 25.333333333333336%]:Running loss: 4.377736315131187
[2018-04-17 19:45:35.482838]: [Epoch: 194(19.41941941941942%): Data: 50.66666666666667%]:Running loss: 8.536447867751122
[2018-04-17 19:45:39.717597]: Test set accuracy: 94.33962264150944% ,loss = 5.471571534872055
[2018-04-17 19:45:39.848445]: ====================
[2018-04-17 19:45:39.855464]: Elapsed time since starting training: 0:25:06.019593
[2018-04-17 19:45:39.876520]: Estimated time left: 0:49:53.959350
[2018-04-17 19:45:39.902088]: ====================
[2018-04-17 19:45:39.975783]: [Epoch: 195(19.51951951951952%): Data: 0.0%]:Running loss: 0.2188628613948822
[2018-04-17 19:45:41.478781]: [Epoch: 195(19.51951951951952%): Data: 25.333333333333336%]:Running loss: 4.3771862387657166
[2018-04-17 19:45:42.993307]: [Epoch: 195(19.51951951951952%): Data: 50.66666666666667%]:Running loss: 8.535379350185394
[2018-04-17 19:45:47.247118]: Test set accuracy: 94.33962264150944% ,loss = 5.470898747444153
[2018-04-17 19:45:47.412057]: ====================
[2018-04-17 19:45:47.417070]: Elapsed time since starting training: 0:25:13.581199
[2018-04-17 19:45:47.421582]: Estimated time left: 0:49:46.414289
[2018-04-17 19:45:47.427599]: ====================
[2018-04-17 19:45:47.504301]: [Epoch: 196(19.61961961961962%): Data: 0.0%]:Running loss: 0.2188359498977661
[2018-04-17 19:45:49.052920]: [Epoch: 196(19.61961961961962%): Data: 25.333333333333336%]:Running loss: 4.376649335026741
[2018-04-17 19:45:50.538369]: [Epoch: 196(19.61961961961962%): Data: 50.66666666666667%]:Running loss: 8.53433509171009
[2018-04-17 19:45:54.757086]: Test set accuracy: 94.33962264150944% ,loss = 5.470241233706474
[2018-04-17 19:45:54.936063]: ====================
[2018-04-17 19:45:54.940574]: Elapsed time since starting training: 0:25:21.105205
[2018-04-17 19:45:54.946590]: Estimated time left: 0:49:38.888779
[2018-04-17 19:45:54.951604]: ====================
[2018-04-17 19:45:55.023796]: [Epoch: 197(19.71971971971972%): Data: 0.0%]:Running loss: 0.21880964934825897
[2018-04-17 19:45:56.518771]: [Epoch: 197(19.71971971971972%): Data: 25.333333333333336%]:Running loss: 4.376123368740082
[2018-04-17 19:45:58.021768]: [Epoch: 197(19.71971971971972%): Data: 50.66666666666667%]:Running loss: 8.533311784267426
[2018-04-17 19:46:02.382362]: Test set accuracy: 94.33962264150944% ,loss = 5.46959824860096
[2018-04-17 19:46:02.547300]: ====================
[2018-04-17 19:46:02.553318]: Elapsed time since starting training: 0:25:28.717949
[2018-04-17 19:46:02.559834]: Estimated time left: 0:49:31.275535
[2018-04-17 19:46:02.563845]: ====================
[2018-04-17 19:46:02.636037]: [Epoch: 198(19.81981981981982%): Data: 0.0%]:Running loss: 0.2187839299440384
[2018-04-17 19:46:04.102436]: [Epoch: 198(19.81981981981982%): Data: 25.333333333333336%]:Running loss: 4.3756101578474045
[2018-04-17 19:46:05.607939]: [Epoch: 198(19.81981981981982%): Data: 50.66666666666667%]:Running loss: 8.53231255710125
[2018-04-17 19:46:09.877792]: Test set accuracy: 94.33962264150944% ,loss = 5.468958616256714
[2018-04-17 19:46:10.050251]: ====================
[2018-04-17 19:46:10.055264]: Elapsed time since starting training: 0:25:36.219895
[2018-04-17 19:46:10.059776]: Estimated time left: 0:49:23.775593
[2018-04-17 19:46:10.064288]: ====================
[2018-04-17 19:46:10.138987]: [Epoch: 199(19.91991991991992%): Data: 0.0%]:Running loss: 0.21875834465026855
[2018-04-17 19:46:11.818954]: [Epoch: 199(19.91991991991992%): Data: 25.333333333333336%]:Running loss: 4.375103756785393
[2018-04-17 19:46:13.357052]: [Epoch: 199(19.91991991991992%): Data: 50.66666666666667%]:Running loss: 8.5313301384449
[2018-04-17 19:46:17.633923]: Test set accuracy: 94.33962264150944% ,loss = 5.46833872795105
[2018-04-17 19:46:17.809390]: ====================
[2018-04-17 19:46:17.815908]: Elapsed time since starting training: 0:25:43.980539
[2018-04-17 19:46:17.820920]: Estimated time left: 0:49:16.014449
[2018-04-17 19:46:17.826937]: ====================
[2018-04-17 19:46:17.895118]: [Epoch: 200(20.02002002002002%): Data: 0.0%]:Running loss: 0.218733549118042
[2018-04-17 19:46:19.541495]: [Epoch: 200(20.02002002002002%): Data: 25.333333333333336%]:Running loss: 4.374611988663673
[2018-04-17 19:46:20.989357]: [Epoch: 200(20.02002002002002%): Data: 50.66666666666667%]:Running loss: 8.530373111367226
[2018-04-17 19:46:25.210570]: Test set accuracy: 94.33962264150944% ,loss = 5.4677315056324005
[2018-04-17 19:46:25.356959]: ====================
[2018-04-17 19:46:25.361471]: Elapsed time since starting training: 0:25:51.526102
[2018-04-17 19:46:25.367487]: Estimated time left: 0:49:08.467882
[2018-04-17 19:46:25.373503]: ====================
[2018-04-17 19:46:25.488811]: [Epoch: 201(20.12012012012012%): Data: 0.0%]:Running loss: 0.21870926022529602
[2018-04-17 19:46:27.037929]: [Epoch: 201(20.12012012012012%): Data: 25.333333333333336%]:Running loss: 4.374128624796867
[2018-04-17 19:46:28.554461]: [Epoch: 201(20.12012012012012%): Data: 50.66666666666667%]:Running loss: 8.529433995485306
[2018-04-17 19:46:32.775685]: Test set accuracy: 94.33962264150944% ,loss = 5.467141792178154
[2018-04-17 19:46:32.944133]: ====================
[2018-04-17 19:46:32.949146]: Elapsed time since starting training: 0:25:59.113777
[2018-04-17 19:46:32.953658]: Estimated time left: 0:49:00.881711
[2018-04-17 19:46:32.958171]: ====================
[2018-04-17 19:46:33.034373]: [Epoch: 202(20.22022022022022%): Data: 0.0%]:Running loss: 0.21868567168712616
[2018-04-17 19:46:34.581988]: [Epoch: 202(20.22022022022022%): Data: 25.333333333333336%]:Running loss: 4.373655587434769
[2018-04-17 19:46:36.146649]: [Epoch: 202(20.22022022022022%): Data: 50.66666666666667%]:Running loss: 8.52851451933384
[2018-04-17 19:46:40.316239]: Test set accuracy: 94.33962264150944% ,loss = 5.466567352414131
[2018-04-17 19:46:40.484186]: ====================
[2018-04-17 19:46:40.490201]: Elapsed time since starting training: 0:26:06.654832
[2018-04-17 19:46:40.494211]: Estimated time left: 0:48:53.341158
[2018-04-17 19:46:40.499225]: ====================
[2018-04-17 19:46:40.570414]: [Epoch: 203(20.32032032032032%): Data: 0.0%]:Running loss: 0.21866269409656525
[2018-04-17 19:46:42.086948]: [Epoch: 203(20.32032032032032%): Data: 25.333333333333336%]:Running loss: 4.373193666338921
[2018-04-17 19:46:43.606487]: [Epoch: 203(20.32032032032032%): Data: 50.66666666666667%]:Running loss: 8.527615576982498
[2018-04-17 19:46:47.983125]: Test set accuracy: 94.33962264150944% ,loss = 5.465997755527496
[2018-04-17 19:46:48.136032]: ====================
[2018-04-17 19:46:48.140543]: Elapsed time since starting training: 0:26:14.305174
[2018-04-17 19:46:48.145055]: Estimated time left: 0:48:45.690314
[2018-04-17 19:46:48.152576]: ====================
[2018-04-17 19:46:48.226271]: [Epoch: 204(20.42042042042042%): Data: 0.0%]:Running loss: 0.21863991022109985
[2018-04-17 19:46:49.808980]: [Epoch: 204(20.42042042042042%): Data: 25.333333333333336%]:Running loss: 4.372741207480431
[2018-04-17 19:46:51.411239]: [Epoch: 204(20.42042042042042%): Data: 50.66666666666667%]:Running loss: 8.526735052466393
[2018-04-17 19:46:55.859568]: Test set accuracy: 94.33962264150944% ,loss = 5.465434119105339
[2018-04-17 19:46:56.034032]: ====================
[2018-04-17 19:46:56.043557]: Elapsed time since starting training: 0:26:22.208188
[2018-04-17 19:46:56.048070]: Estimated time left: 0:48:37.787299
[2018-04-17 19:46:56.053083]: ====================
[2018-04-17 19:46:56.126277]: [Epoch: 205(20.52052052052052%): Data: 0.0%]:Running loss: 0.21861736476421356
[2018-04-17 19:46:57.654341]: [Epoch: 205(20.52052052052052%): Data: 25.333333333333336%]:Running loss: 4.372297689318657
[2018-04-17 19:46:59.307737]: [Epoch: 205(20.52052052052052%): Data: 50.66666666666667%]:Running loss: 8.525872990489006
[2018-04-17 19:47:03.746541]: Test set accuracy: 94.33962264150944% ,loss = 5.464900657534599
[2018-04-17 19:47:03.865355]: ====================
[2018-04-17 19:47:03.870369]: Elapsed time since starting training: 0:26:30.034499
[2018-04-17 19:47:03.874881]: Estimated time left: 0:48:29.960488
[2018-04-17 19:47:03.882401]: ====================
[2018-04-17 19:47:03.971638]: [Epoch: 206(20.62062062062062%): Data: 0.0%]:Running loss: 0.21859602630138397
[2018-04-17 19:47:05.602475]: [Epoch: 206(20.62062062062062%): Data: 25.333333333333336%]:Running loss: 4.371863529086113
[2018-04-17 19:47:07.202730]: [Epoch: 206(20.62062062062062%): Data: 50.66666666666667%]:Running loss: 8.525028392672539
[2018-04-17 19:47:11.725255]: Test set accuracy: 94.33962264150944% ,loss = 5.464371293783188
[2018-04-17 19:47:11.845575]: ====================
[2018-04-17 19:47:11.850088]: Elapsed time since starting training: 0:26:38.014719
[2018-04-17 19:47:11.854600]: Estimated time left: 0:48:21.980769
[2018-04-17 19:47:11.859612]: ====================
[2018-04-17 19:47:11.973416]: [Epoch: 207(20.72072072072072%): Data: 0.0%]:Running loss: 0.21857485175132751
[2018-04-17 19:47:13.545598]: [Epoch: 207(20.72072072072072%): Data: 25.333333333333336%]:Running loss: 4.3714393973350525
[2018-04-17 19:47:15.076166]: [Epoch: 207(20.72072072072072%): Data: 50.66666666666667%]:Running loss: 8.524203181266785
[2018-04-17 19:47:19.427234]: Test set accuracy: 94.33962264150944% ,loss = 5.463846400380135
[2018-04-17 19:47:19.539032]: ====================
[2018-04-17 19:47:19.544045]: Elapsed time since starting training: 0:26:45.708676
[2018-04-17 19:47:19.548557]: Estimated time left: 0:48:14.287314
[2018-04-17 19:47:19.554573]: ====================
[2018-04-17 19:47:19.657848]: [Epoch: 208(20.82082082082082%): Data: 0.0%]:Running loss: 0.21855385601520538
[2018-04-17 19:47:21.131265]: [Epoch: 208(20.82082082082082%): Data: 25.333333333333336%]:Running loss: 4.371023073792458
[2018-04-17 19:47:22.705451]: [Epoch: 208(20.82082082082082%): Data: 50.66666666666667%]:Running loss: 8.523392170667648
[2018-04-17 19:47:27.124702]: Test set accuracy: 94.33962264150944% ,loss = 5.463328957557678
[2018-04-17 19:47:27.240510]: ====================
[2018-04-17 19:47:27.280616]: Elapsed time since starting training: 0:26:53.445247
[2018-04-17 19:47:27.292649]: Estimated time left: 0:48:06.543222
[2018-04-17 19:47:27.296659]: ====================
[2018-04-17 19:47:27.370356]: [Epoch: 209(20.92092092092092%): Data: 0.0%]:Running loss: 0.21853315830230713
[2018-04-17 19:47:28.877864]: [Epoch: 209(20.92092092092092%): Data: 25.333333333333336%]:Running loss: 4.370615482330322
[2018-04-17 19:47:30.378353]: [Epoch: 209(20.92092092092092%): Data: 50.66666666666667%]:Running loss: 8.522601157426834
[2018-04-17 19:47:34.749476]: Test set accuracy: 94.33962264150944% ,loss = 5.462832003831863
[2018-04-17 19:47:34.920931]: ====================
[2018-04-17 19:47:34.925946]: Elapsed time since starting training: 0:27:01.090075
[2018-04-17 19:47:34.930958]: Estimated time left: 0:47:58.904411
[2018-04-17 19:47:34.935972]: ====================
[2018-04-17 19:47:35.005156]: [Epoch: 210(21.02102102102102%): Data: 0.0%]:Running loss: 0.21851328015327454
[2018-04-17 19:47:36.578840]: [Epoch: 210(21.02102102102102%): Data: 25.333333333333336%]:Running loss: 4.370216265320778
[2018-04-17 19:47:38.084343]: [Epoch: 210(21.02102102102102%): Data: 50.66666666666667%]:Running loss: 8.521824315190315
[2018-04-17 19:47:42.452458]: Test set accuracy: 94.33962264150944% ,loss = 5.462338775396347
[2018-04-17 19:47:42.574284]: ====================
[2018-04-17 19:47:42.579295]: Elapsed time since starting training: 0:27:08.743926
[2018-04-17 19:47:42.583807]: Estimated time left: 0:47:51.251562
[2018-04-17 19:47:42.588821]: ====================
[2018-04-17 19:47:42.702623]: [Epoch: 211(21.12112112112112%): Data: 0.0%]:Running loss: 0.21849355101585388
[2018-04-17 19:47:44.201107]: [Epoch: 211(21.12112112112112%): Data: 25.333333333333336%]:Running loss: 4.369825124740601
[2018-04-17 19:47:45.704104]: [Epoch: 211(21.12112112112112%): Data: 50.66666666666667%]:Running loss: 8.521063894033432
[2018-04-17 19:47:50.257211]: Test set accuracy: 94.33962264150944% ,loss = 5.461863800883293
[2018-04-17 19:47:50.371014]: ====================
[2018-04-17 19:47:50.376027]: Elapsed time since starting training: 0:27:16.540156
[2018-04-17 19:47:50.380038]: Estimated time left: 0:47:43.455331
[2018-04-17 19:47:50.384550]: ====================
[2018-04-17 19:47:50.457243]: [Epoch: 212(21.22122122122122%): Data: 0.0%]:Running loss: 0.21847455203533173
[2018-04-17 19:47:52.044463]: [Epoch: 212(21.22122122122122%): Data: 25.333333333333336%]:Running loss: 4.369442120194435
[2018-04-17 19:47:53.535427]: [Epoch: 212(21.22122122122122%): Data: 50.66666666666667%]:Running loss: 8.520320281386375
[2018-04-17 19:47:57.920087]: Test set accuracy: 94.33962264150944% ,loss = 5.461393669247627
[2018-04-17 19:47:58.089538]: ====================
[2018-04-17 19:47:58.094049]: Elapsed time since starting training: 0:27:24.258680
[2018-04-17 19:47:58.098561]: Estimated time left: 0:47:35.736808
[2018-04-17 19:47:58.104577]: ====================
[2018-04-17 19:47:58.178774]: [Epoch: 213(21.32132132132132%): Data: 0.0%]:Running loss: 0.2184557467699051
[2018-04-17 19:47:59.729397]: [Epoch: 213(21.32132132132132%): Data: 25.333333333333336%]:Running loss: 4.369068577885628
[2018-04-17 19:48:01.453484]: [Epoch: 213(21.32132132132132%): Data: 50.66666666666667%]:Running loss: 8.519592195749283
[2018-04-17 19:48:06.057724]: Test set accuracy: 94.33962264150944% ,loss = 5.460932105779648
[2018-04-17 19:48:06.238706]: ====================
[2018-04-17 19:48:06.246727]: Elapsed time since starting training: 0:27:32.410857
[2018-04-17 19:48:06.250738]: Estimated time left: 0:47:27.584631
[2018-04-17 19:48:06.255250]: ====================
[2018-04-17 19:48:06.326440]: [Epoch: 214(21.42142142142142%): Data: 0.0%]:Running loss: 0.2184372842311859
[2018-04-17 19:48:07.883078]: [Epoch: 214(21.42142142142142%): Data: 25.333333333333336%]:Running loss: 4.3687005043029785
[2018-04-17 19:48:09.422170]: [Epoch: 214(21.42142142142142%): Data: 50.66666666666667%]:Running loss: 8.518875941634178
[2018-04-17 19:48:13.708568]: Test set accuracy: 94.33962264150944% ,loss = 5.460486188530922
[2018-04-17 19:48:13.871502]: ====================
[2018-04-17 19:48:13.881027]: Elapsed time since starting training: 0:27:40.045658
[2018-04-17 19:48:13.885038]: Estimated time left: 0:47:19.950331
[2018-04-17 19:48:13.889549]: ====================
[2018-04-17 19:48:13.964750]: [Epoch: 215(21.52152152152152%): Data: 0.0%]:Running loss: 0.21841944754123688
[2018-04-17 19:48:15.681314]: [Epoch: 215(21.52152152152152%): Data: 25.333333333333336%]:Running loss: 4.368341282010078
[2018-04-17 19:48:17.198849]: [Epoch: 215(21.52152152152152%): Data: 50.66666666666667%]:Running loss: 8.51817798614502
[2018-04-17 19:48:21.611091]: Test set accuracy: 94.33962264150944% ,loss = 5.460040643811226
[2018-04-17 19:48:21.768009]: ====================
[2018-04-17 19:48:21.774025]: Elapsed time since starting training: 0:27:47.938154
[2018-04-17 19:48:21.779038]: Estimated time left: 0:47:12.056331
[2018-04-17 19:48:21.783550]: ====================
[2018-04-17 19:48:21.854740]: [Epoch: 216(21.62162162162162%): Data: 0.0%]:Running loss: 0.21840162575244904
[2018-04-17 19:48:23.566792]: [Epoch: 216(21.62162162162162%): Data: 25.333333333333336%]:Running loss: 4.367989659309387
[2018-04-17 19:48:25.264305]: [Epoch: 216(21.62162162162162%): Data: 50.66666666666667%]:Running loss: 8.51749336719513
[2018-04-17 19:48:29.590308]: Test set accuracy: 94.33962264150944% ,loss = 5.459610000252724
[2018-04-17 19:48:29.708122]: ====================
[2018-04-17 19:48:29.712633]: Elapsed time since starting training: 0:27:55.877264
[2018-04-17 19:48:29.718651]: Estimated time left: 0:47:04.117219
[2018-04-17 19:48:29.728175]: ====================
[2018-04-17 19:48:29.840473]: [Epoch: 217(21.72172172172172%): Data: 0.0%]:Running loss: 0.21838440001010895
[2018-04-17 19:48:31.383576]: [Epoch: 217(21.72172172172172%): Data: 25.333333333333336%]:Running loss: 4.36764457821846
[2018-04-17 19:48:32.925677]: [Epoch: 217(21.72172172172172%): Data: 50.66666666666667%]:Running loss: 8.516822785139084
[2018-04-17 19:48:37.259701]: Test set accuracy: 94.33962264150944% ,loss = 5.459188669919968
[2018-04-17 19:48:37.403584]: ====================
[2018-04-17 19:48:37.408597]: Elapsed time since starting training: 0:28:03.573228
[2018-04-17 19:48:37.413610]: Estimated time left: 0:46:56.421759
[2018-04-17 19:48:37.418123]: ====================
[2018-04-17 19:48:37.490315]: [Epoch: 218(21.82182182182182%): Data: 0.0%]:Running loss: 0.2183675467967987
[2018-04-17 19:48:39.046452]: [Epoch: 218(21.82182182182182%): Data: 25.333333333333336%]:Running loss: 4.367307409644127
[2018-04-17 19:48:40.622644]: [Epoch: 218(21.82182182182182%): Data: 50.66666666666667%]:Running loss: 8.516167521476746
[2018-04-17 19:48:45.021339]: Test set accuracy: 94.33962264150944% ,loss = 5.458775535225868
[2018-04-17 19:48:45.183271]: ====================
[2018-04-17 19:48:45.188283]: Elapsed time since starting training: 0:28:11.352914
[2018-04-17 19:48:45.194802]: Estimated time left: 0:46:48.641068
[2018-04-17 19:48:45.202320]: ====================
[2018-04-17 19:48:45.277019]: [Epoch: 219(21.92192192192192%): Data: 0.0%]:Running loss: 0.21835102140903473
[2018-04-17 19:48:46.827642]: [Epoch: 219(21.92192192192192%): Data: 25.333333333333336%]:Running loss: 4.366976827383041
[2018-04-17 19:48:48.368740]: [Epoch: 219(21.92192192192192%): Data: 50.66666666666667%]:Running loss: 8.51552365720272
[2018-04-17 19:48:52.881744]: Test set accuracy: 94.33962264150944% ,loss = 5.45835867524147
[2018-04-17 19:48:52.995547]: ====================
[2018-04-17 19:48:53.000060]: Elapsed time since starting training: 0:28:19.164691
[2018-04-17 19:48:53.008081]: Estimated time left: 0:46:40.827790
[2018-04-17 19:48:53.012593]: ====================
[2018-04-17 19:48:53.083282]: [Epoch: 220(22.02202202202202%): Data: 0.0%]:Running loss: 0.2183343470096588
[2018-04-17 19:48:54.672005]: [Epoch: 220(22.02202202202202%): Data: 25.333333333333336%]:Running loss: 4.366652145981789
[2018-04-17 19:48:56.216612]: [Epoch: 220(22.02202202202202%): Data: 50.66666666666667%]:Running loss: 8.514894112944603
[2018-04-17 19:49:00.800300]: Test set accuracy: 94.33962264150944% ,loss = 5.457974225282669
[2018-04-17 19:49:00.924129]: ====================
[2018-04-17 19:49:00.966742]: Elapsed time since starting training: 0:28:27.131373
[2018-04-17 19:49:00.973761]: Estimated time left: 0:46:32.862109
[2018-04-17 19:49:00.978774]: ====================
[2018-04-17 19:49:01.050466]: [Epoch: 221(22.12212212212212%): Data: 0.0%]:Running loss: 0.21831896901130676
[2018-04-17 19:49:02.625152]: [Epoch: 221(22.12212212212212%): Data: 25.333333333333336%]:Running loss: 4.366335645318031
[2018-04-17 19:49:04.125642]: [Epoch: 221(22.12212212212212%): Data: 50.66666666666667%]:Running loss: 8.514276668429375
[2018-04-17 19:49:08.563442]: Test set accuracy: 94.33962264150944% ,loss = 5.457582697272301
[2018-04-17 19:49:08.775507]: ====================
[2018-04-17 19:49:08.781021]: Elapsed time since starting training: 0:28:34.945652
[2018-04-17 19:49:08.786536]: Estimated time left: 0:46:25.049335
[2018-04-17 19:49:08.797565]: ====================
[2018-04-17 19:49:08.876776]: [Epoch: 222(22.22222222222222%): Data: 0.0%]:Running loss: 0.21830330789089203
[2018-04-17 19:49:10.557745]: [Epoch: 222(22.22222222222222%): Data: 25.333333333333336%]:Running loss: 4.366023078560829
[2018-04-17 19:49:12.061248]: [Epoch: 222(22.22222222222222%): Data: 50.66666666666667%]:Running loss: 8.51366962492466
[2018-04-17 19:49:16.497545]: Test set accuracy: 94.33962264150944% ,loss = 5.4572004824876785
[2018-04-17 19:49:16.695571]: ====================
[2018-04-17 19:49:16.703593]: Elapsed time since starting training: 0:28:42.868224
[2018-04-17 19:49:16.708606]: Estimated time left: 0:46:17.126763
[2018-04-17 19:49:16.714121]: ====================
[2018-04-17 19:49:16.791827]: [Epoch: 223(22.32232232232232%): Data: 0.0%]:Running loss: 0.21828801929950714
[2018-04-17 19:49:18.414648]: [Epoch: 223(22.32232232232232%): Data: 25.333333333333336%]:Running loss: 4.365719690918922
[2018-04-17 19:49:19.964768]: [Epoch: 223(22.32232232232232%): Data: 50.66666666666667%]:Running loss: 8.513078644871712
[2018-04-17 19:49:24.203039]: Test set accuracy: 94.33962264150944% ,loss = 5.4568275809288025
[2018-04-17 19:49:24.329373]: ====================
[2018-04-17 19:49:24.378504]: Elapsed time since starting training: 0:28:50.542634
[2018-04-17 19:49:24.385021]: Estimated time left: 0:46:09.450848
[2018-04-17 19:49:24.393043]: ====================
[2018-04-17 19:49:24.463730]: [Epoch: 224(22.42242242242242%): Data: 0.0%]:Running loss: 0.2182731032371521
[2018-04-17 19:49:26.028893]: [Epoch: 224(22.42242242242242%): Data: 25.333333333333336%]:Running loss: 4.365422263741493
[2018-04-17 19:49:27.597063]: [Epoch: 224(22.42242242242242%): Data: 50.66666666666667%]:Running loss: 8.51249960064888
[2018-04-17 19:49:31.786201]: Test set accuracy: 94.33962264150944% ,loss = 5.4564520716667175
[2018-04-17 19:49:31.943621]: ====================
[2018-04-17 19:49:31.952643]: Elapsed time since starting training: 0:28:58.117274
[2018-04-17 19:49:31.957658]: Estimated time left: 0:46:01.878214
[2018-04-17 19:49:31.962168]: ====================
[2018-04-17 19:49:32.037369]: [Epoch: 225(22.52252252252252%): Data: 0.0%]:Running loss: 0.2182580828666687
[2018-04-17 19:49:33.547885]: [Epoch: 225(22.52252252252252%): Data: 25.333333333333336%]:Running loss: 4.3651289492845535
[2018-04-17 19:49:35.077955]: [Epoch: 225(22.52252252252252%): Data: 50.66666666666667%]:Running loss: 8.511930108070374
[2018-04-17 19:49:39.517258]: Test set accuracy: 94.33962264150944% ,loss = 5.456097796559334
[2018-04-17 19:49:39.702250]: ====================
[2018-04-17 19:49:39.707263]: Elapsed time since starting training: 0:29:05.871393
[2018-04-17 19:49:39.716287]: Estimated time left: 0:45:54.119082
[2018-04-17 19:49:39.720799]: ====================
[2018-04-17 19:49:39.791988]: [Epoch: 226(22.62262262262262%): Data: 0.0%]:Running loss: 0.21824391186237335
[2018-04-17 19:49:41.439872]: [Epoch: 226(22.62262262262262%): Data: 25.333333333333336%]:Running loss: 4.364843234419823
[2018-04-17 19:49:43.009544]: [Epoch: 226(22.62262262262262%): Data: 50.66666666666667%]:Running loss: 8.511374428868294
[2018-04-17 19:49:47.552623]: Test set accuracy: 94.33962264150944% ,loss = 5.455750226974487
[2018-04-17 19:49:47.710543]: ====================
[2018-04-17 19:49:47.715557]: Elapsed time since starting training: 0:29:13.880188
[2018-04-17 19:49:47.723077]: Estimated time left: 0:45:46.112292
[2018-04-17 19:49:47.728592]: ====================
[2018-04-17 19:49:47.799280]: [Epoch: 227(22.722722722722725%): Data: 0.0%]:Running loss: 0.2182300090789795
[2018-04-17 19:49:49.402543]: [Epoch: 227(22.722722722722725%): Data: 25.333333333333336%]:Running loss: 4.364562451839447
[2018-04-17 19:49:51.076495]: [Epoch: 227(22.722722722722725%): Data: 50.66666666666667%]:Running loss: 8.510828197002411
[2018-04-17 19:49:55.667702]: Test set accuracy: 94.33962264150944% ,loss = 5.455400794744492
[2018-04-17 19:49:55.781003]: ====================
[2018-04-17 19:49:55.785515]: Elapsed time since starting training: 0:29:21.950146
[2018-04-17 19:49:55.790027]: Estimated time left: 0:45:38.045342
[2018-04-17 19:49:55.797546]: ====================
[2018-04-17 19:49:55.927393]: [Epoch: 228(22.822822822822822%): Data: 0.0%]:Running loss: 0.21821603178977966
[2018-04-17 19:49:57.556724]: [Epoch: 228(22.822822822822822%): Data: 25.333333333333336%]:Running loss: 4.364287823438644
[2018-04-17 19:49:59.237695]: [Epoch: 228(22.822822822822822%): Data: 50.66666666666667%]:Running loss: 8.510293826460838
[2018-04-17 19:50:03.900091]: Test set accuracy: 94.33962264150944% ,loss = 5.455060303211212
[2018-04-17 19:50:04.020411]: ====================
[2018-04-17 19:50:04.024924]: Elapsed time since starting training: 0:29:30.189555
[2018-04-17 19:50:04.029937]: Estimated time left: 0:45:29.805934
[2018-04-17 19:50:04.034449]: ====================
[2018-04-17 19:50:04.190864]: [Epoch: 229(22.922922922922922%): Data: 0.0%]:Running loss: 0.2182024121284485
[2018-04-17 19:50:05.856794]: [Epoch: 229(22.922922922922922%): Data: 25.333333333333336%]:Running loss: 4.3640177845954895
[2018-04-17 19:50:07.526735]: [Epoch: 229(22.922922922922922%): Data: 50.66666666666667%]:Running loss: 8.509769171476364
[2018-04-17 19:50:11.993111]: Test set accuracy: 94.33962264150944% ,loss = 5.454730987548828
[2018-04-17 19:50:12.175596]: ====================
[2018-04-17 19:50:12.182615]: Elapsed time since starting training: 0:29:38.347246
[2018-04-17 19:50:12.189633]: Estimated time left: 0:45:21.645736
[2018-04-17 19:50:12.194145]: ====================
[2018-04-17 19:50:12.263830]: [Epoch: 230(23.023023023023022%): Data: 0.0%]:Running loss: 0.21818923950195312
[2018-04-17 19:50:13.944298]: [Epoch: 230(23.023023023023022%): Data: 25.333333333333336%]:Running loss: 4.363753378391266
[2018-04-17 19:50:15.677407]: [Epoch: 230(23.023023023023022%): Data: 50.66666666666667%]:Running loss: 8.509257405996323
[2018-04-17 19:50:20.349831]: Test set accuracy: 94.33962264150944% ,loss = 5.45441098511219
[2018-04-17 19:50:20.522791]: ====================
[2018-04-17 19:50:20.527303]: Elapsed time since starting training: 0:29:46.691934
[2018-04-17 19:50:20.531815]: Estimated time left: 0:45:13.303554
[2018-04-17 19:50:20.536828]: ====================
[2018-04-17 19:50:20.608519]: [Epoch: 231(23.123123123123122%): Data: 0.0%]:Running loss: 0.2181764394044876
[2018-04-17 19:50:22.274449]: [Epoch: 231(23.123123123123122%): Data: 25.333333333333336%]:Running loss: 4.363495662808418
[2018-04-17 19:50:23.899771]: [Epoch: 231(23.123123123123122%): Data: 50.66666666666667%]:Running loss: 8.508752897381783
[2018-04-17 19:50:28.379181]: Test set accuracy: 94.33962264150944% ,loss = 5.45409731566906
[2018-04-17 19:50:28.543618]: ====================
[2018-04-17 19:50:28.548632]: Elapsed time since starting training: 0:29:54.713263
[2018-04-17 19:50:28.553144]: Estimated time left: 0:45:05.282225
[2018-04-17 19:50:28.557656]: ====================
[2018-04-17 19:50:28.634862]: [Epoch: 232(23.223223223223226%): Data: 0.0%]:Running loss: 0.2181638926267624
[2018-04-17 19:50:30.324855]: [Epoch: 232(23.223223223223226%): Data: 25.333333333333336%]:Running loss: 4.363243639469147
[2018-04-17 19:50:31.978251]: [Epoch: 232(23.223223223223226%): Data: 50.66666666666667%]:Running loss: 8.508260652422905
[2018-04-17 19:50:36.581491]: Test set accuracy: 94.33962264150944% ,loss = 5.453783646225929
[2018-04-17 19:50:36.698302]: ====================
[2018-04-17 19:50:36.702814]: Elapsed time since starting training: 0:30:02.867445
[2018-04-17 19:50:36.711336]: Estimated time left: 0:44:57.124033
[2018-04-17 19:50:36.739912]: ====================
[2018-04-17 19:50:36.827645]: [Epoch: 233(23.323323323323322%): Data: 0.0%]:Running loss: 0.21815134584903717
[2018-04-17 19:50:38.431911]: [Epoch: 233(23.323323323323322%): Data: 25.333333333333336%]:Running loss: 4.362994626164436
[2018-04-17 19:50:40.011111]: [Epoch: 233(23.323323323323322%): Data: 50.66666666666667%]:Running loss: 8.507778778672218
[2018-04-17 19:50:44.548174]: Test set accuracy: 94.33962264150944% ,loss = 5.453479662537575
[2018-04-17 19:50:44.804859]: ====================
[2018-04-17 19:50:44.810372]: Elapsed time since starting training: 0:30:10.975003
[2018-04-17 19:50:44.814883]: Estimated time left: 0:44:49.020987
[2018-04-17 19:50:44.818894]: ====================
[2018-04-17 19:50:44.948238]: [Epoch: 234(23.423423423423422%): Data: 0.0%]:Running loss: 0.218139186501503
[2018-04-17 19:50:46.574562]: [Epoch: 234(23.423423423423422%): Data: 25.333333333333336%]:Running loss: 4.362750977277756
[2018-04-17 19:50:48.143735]: [Epoch: 234(23.423423423423422%): Data: 50.66666666666667%]:Running loss: 8.507304981350899
[2018-04-17 19:50:52.691828]: Test set accuracy: 94.33962264150944% ,loss = 5.453174933791161
[2018-04-17 19:50:52.810143]: ====================
[2018-04-17 19:50:52.816159]: Elapsed time since starting training: 0:30:18.980790
[2018-04-17 19:50:52.820169]: Estimated time left: 0:44:41.015200
[2018-04-17 19:50:52.825183]: ====================
[2018-04-17 19:50:52.955028]: [Epoch: 235(23.523523523523522%): Data: 0.0%]:Running loss: 0.21812699735164642
[2018-04-17 19:50:54.600905]: [Epoch: 235(23.523523523523522%): Data: 25.333333333333336%]:Running loss: 4.362513482570648
[2018-04-17 19:50:56.217703]: [Epoch: 235(23.523523523523522%): Data: 50.66666666666667%]:Running loss: 8.50684268772602
[2018-04-17 19:51:00.776712]: Test set accuracy: 94.33962264150944% ,loss = 5.452888831496239
[2018-04-17 19:51:00.938141]: ====================
[2018-04-17 19:51:00.942653]: Elapsed time since starting training: 0:30:27.107284
[2018-04-17 19:51:00.947166]: Estimated time left: 0:44:32.888203
[2018-04-17 19:51:00.951677]: ====================
[2018-04-17 19:51:01.024872]: [Epoch: 236(23.623623623623622%): Data: 0.0%]:Running loss: 0.21811555325984955
[2018-04-17 19:51:02.585020]: [Epoch: 236(23.623623623623622%): Data: 25.333333333333336%]:Running loss: 4.362280115485191
[2018-04-17 19:51:04.177756]: [Epoch: 236(23.623623623623622%): Data: 50.66666666666667%]:Running loss: 8.506387785077095
[2018-04-17 19:51:08.793027]: Test set accuracy: 94.33962264150944% ,loss = 5.4526060819625854
[2018-04-17 19:51:08.966489]: ====================
[2018-04-17 19:51:08.970499]: Elapsed time since starting training: 0:30:35.135130
[2018-04-17 19:51:08.976516]: Estimated time left: 0:44:24.859354
[2018-04-17 19:51:08.981027]: ====================
[2018-04-17 19:51:09.053721]: [Epoch: 237(23.723723723723726%): Data: 0.0%]:Running loss: 0.21810424327850342
[2018-04-17 19:51:10.663000]: [Epoch: 237(23.723723723723726%): Data: 25.333333333333336%]:Running loss: 4.362051323056221
[2018-04-17 19:51:12.316397]: [Epoch: 237(23.723723723723726%): Data: 50.66666666666667%]:Running loss: 8.505943015217781
[2018-04-17 19:51:17.118672]: Test set accuracy: 94.33962264150944% ,loss = 5.452319234609604
[2018-04-17 19:51:17.301658]: ====================
[2018-04-17 19:51:17.309680]: Elapsed time since starting training: 0:30:43.473809
[2018-04-17 19:51:17.315696]: Estimated time left: 0:44:16.519673
[2018-04-17 19:51:17.320208]: ====================
[2018-04-17 19:51:17.392901]: [Epoch: 238(23.823823823823822%): Data: 0.0%]:Running loss: 0.21809276938438416
[2018-04-17 19:51:19.184665]: [Epoch: 238(23.823823823823822%): Data: 25.333333333333336%]:Running loss: 4.3618259727954865
[2018-04-17 19:51:20.889197]: [Epoch: 238(23.823823823823822%): Data: 50.66666666666667%]:Running loss: 8.505506485700607
[2018-04-17 19:51:25.956170]: Test set accuracy: 94.33962264150944% ,loss = 5.4520439356565475
[2018-04-17 19:51:26.131637]: ====================
[2018-04-17 19:51:26.139157]: Elapsed time since starting training: 0:30:52.303286
[2018-04-17 19:51:26.144171]: Estimated time left: 0:44:07.691198
[2018-04-17 19:51:26.150187]: ====================
[2018-04-17 19:51:26.250954]: [Epoch: 239(23.923923923923923%): Data: 0.0%]:Running loss: 0.2180817574262619
[2018-04-17 19:51:27.936937]: [Epoch: 239(23.923923923923923%): Data: 25.333333333333336%]:Running loss: 4.361606761813164
[2018-04-17 19:51:29.787859]: [Epoch: 239(23.923923923923923%): Data: 50.66666666666667%]:Running loss: 8.505078837275505
[2018-04-17 19:51:35.133573]: Test set accuracy: 94.33962264150944% ,loss = 5.451777204871178
[2018-04-17 19:51:35.277456]: ====================
[2018-04-17 19:51:35.283472]: Elapsed time since starting training: 0:31:01.447602
[2018-04-17 19:51:35.288485]: Estimated time left: 0:43:58.547385
[2018-04-17 19:51:35.293498]: ====================
[2018-04-17 19:51:35.423343]: [Epoch: 240(24.024024024024023%): Data: 0.0%]:Running loss: 0.2180710881948471
[2018-04-17 19:51:37.124868]: [Epoch: 240(24.024024024024023%): Data: 25.333333333333336%]:Running loss: 4.361391678452492
[2018-04-17 19:51:38.737154]: [Epoch: 240(24.024024024024023%): Data: 50.66666666666667%]:Running loss: 8.504661098122597
[2018-04-17 19:51:43.552960]: Test set accuracy: 94.33962264150944% ,loss = 5.451515316963196
[2018-04-17 19:51:43.734443]: ====================
[2018-04-17 19:51:43.739457]: Elapsed time since starting training: 0:31:09.903587
[2018-04-17 19:51:43.748480]: Estimated time left: 0:43:50.087390
[2018-04-17 19:51:43.753994]: ====================
[2018-04-17 19:51:43.830197]: [Epoch: 241(24.124124124124123%): Data: 0.0%]:Running loss: 0.21806061267852783
[2018-04-17 19:51:45.217386]: [Epoch: 241(24.124124124124123%): Data: 25.333333333333336%]:Running loss: 4.361179873347282
[2018-04-17 19:51:46.635155]: [Epoch: 241(24.124124124124123%): Data: 50.66666666666667%]:Running loss: 8.50424873828888
[2018-04-17 19:51:50.743580]: Test set accuracy: 94.33962264150944% ,loss = 5.451245233416557
[2018-04-17 19:51:50.930577]: ====================
[2018-04-17 19:51:50.937094]: Elapsed time since starting training: 0:31:17.101725
[2018-04-17 19:51:50.942108]: Estimated time left: 0:43:42.893261
[2018-04-17 19:51:50.947121]: ====================
[2018-04-17 19:51:51.033350]: [Epoch: 242(24.224224224224226%): Data: 0.0%]:Running loss: 0.2180498093366623
[2018-04-17 19:51:52.403995]: [Epoch: 242(24.224224224224226%): Data: 25.333333333333336%]:Running loss: 4.360973060131073
[2018-04-17 19:51:53.794692]: [Epoch: 242(24.224224224224226%): Data: 50.66666666666667%]:Running loss: 8.503846436738968
[2018-04-17 19:51:58.216450]: Test set accuracy: 94.33962264150944% ,loss = 5.450988560914993
[2018-04-17 19:51:58.404951]: ====================
[2018-04-17 19:51:58.410967]: Elapsed time since starting training: 0:31:24.575598
[2018-04-17 19:51:58.415981]: Estimated time left: 0:43:35.419890
[2018-04-17 19:51:58.420994]: ====================
[2018-04-17 19:51:58.495693]: [Epoch: 243(24.324324324324326%): Data: 0.0%]:Running loss: 0.21803954243659973
[2018-04-17 19:52:00.218273]: [Epoch: 243(24.324324324324326%): Data: 25.333333333333336%]:Running loss: 4.360770285129547
[2018-04-17 19:52:01.824544]: [Epoch: 243(24.324324324324326%): Data: 50.66666666666667%]:Running loss: 8.503452941775322
[2018-04-17 19:52:06.496467]: Test set accuracy: 94.33962264150944% ,loss = 5.450746789574623
[2018-04-17 19:52:06.688478]: ====================
[2018-04-17 19:52:06.697501]: Elapsed time since starting training: 0:31:32.861631
[2018-04-17 19:52:06.702514]: Estimated time left: 0:43:27.132855
[2018-04-17 19:52:06.707026]: ====================
[2018-04-17 19:52:06.777715]: [Epoch: 244(24.424424424424423%): Data: 0.0%]:Running loss: 0.21802987158298492
[2018-04-17 19:52:08.443645]: [Epoch: 244(24.424424424424423%): Data: 25.333333333333336%]:Running loss: 4.360571637749672
[2018-04-17 19:52:10.038887]: [Epoch: 244(24.424424424424423%): Data: 50.66666666666667%]:Running loss: 8.503066450357437
[2018-04-17 19:52:14.761443]: Test set accuracy: 94.33962264150944% ,loss = 5.450500547885895
[2018-04-17 19:52:14.880259]: ====================
[2018-04-17 19:52:14.886777]: Elapsed time since starting training: 0:31:41.050906
[2018-04-17 19:52:14.890787]: Estimated time left: 0:43:18.944582
[2018-04-17 19:52:14.895299]: ====================
[2018-04-17 19:52:14.973508]: [Epoch: 245(24.524524524524523%): Data: 0.0%]:Running loss: 0.2180200219154358
[2018-04-17 19:52:16.746722]: [Epoch: 245(24.524524524524523%): Data: 25.333333333333336%]:Running loss: 4.360376670956612
[2018-04-17 19:52:18.447244]: [Epoch: 245(24.524524524524523%): Data: 50.66666666666667%]:Running loss: 8.502686262130737
[2018-04-17 19:52:22.978291]: Test set accuracy: 94.33962264150944% ,loss = 5.450267717242241
[2018-04-17 19:52:23.120168]: ====================
[2018-04-17 19:52:23.125182]: Elapsed time since starting training: 0:31:49.289813
[2018-04-17 19:52:23.129695]: Estimated time left: 0:43:10.705674
[2018-04-17 19:52:23.134708]: ====================
[2018-04-17 19:52:23.226451]: [Epoch: 246(24.624624624624623%): Data: 0.0%]:Running loss: 0.21801070868968964
[2018-04-17 19:52:24.895891]: [Epoch: 246(24.624624624624623%): Data: 25.333333333333336%]:Running loss: 4.360185548663139
[2018-04-17 19:52:26.485617]: [Epoch: 246(24.624624624624623%): Data: 50.66666666666667%]:Running loss: 8.502315327525139
[2018-04-17 19:52:31.154031]: Test set accuracy: 94.33962264150944% ,loss = 5.450023338198662
[2018-04-17 19:52:31.300420]: ====================
[2018-04-17 19:52:31.308942]: Elapsed time since starting training: 0:31:57.473073
[2018-04-17 19:52:31.313956]: Estimated time left: 0:43:02.521413
[2018-04-17 19:52:31.318970]: ====================
[2018-04-17 19:52:31.394170]: [Epoch: 247(24.724724724724727%): Data: 0.0%]:Running loss: 0.21800093352794647
[2018-04-17 19:52:33.018990]: [Epoch: 247(24.724724724724727%): Data: 25.333333333333336%]:Running loss: 4.359997823834419
[2018-04-17 19:52:34.556078]: [Epoch: 247(24.724724724724727%): Data: 50.66666666666667%]:Running loss: 8.501950934529305
[2018-04-17 19:52:38.996885]: Test set accuracy: 94.33962264150944% ,loss = 5.449798330664635
[2018-04-17 19:52:39.131743]: ====================
[2018-04-17 19:52:39.137259]: Elapsed time since starting training: 0:32:05.301890
[2018-04-17 19:52:39.142272]: Estimated time left: 0:42:54.693097
[2018-04-17 19:52:39.149291]: ====================
[2018-04-17 19:52:39.263594]: [Epoch: 248(24.824824824824827%): Data: 0.0%]:Running loss: 0.2179919332265854
[2018-04-17 19:52:40.913982]: [Epoch: 248(24.824824824824827%): Data: 25.333333333333336%]:Running loss: 4.3598155826330185
[2018-04-17 19:52:42.549832]: [Epoch: 248(24.824824824824827%): Data: 50.66666666666667%]:Running loss: 8.501594871282578
[2018-04-17 19:52:47.225766]: Test set accuracy: 94.33962264150944% ,loss = 5.44956848025322
[2018-04-17 19:52:47.357114]: ====================
[2018-04-17 19:52:47.362128]: Elapsed time since starting training: 0:32:13.526759
[2018-04-17 19:52:47.367141]: Estimated time left: 0:42:46.468228
[2018-04-17 19:52:47.372155]: ====================
[2018-04-17 19:52:47.489968]: [Epoch: 249(24.924924924924923%): Data: 0.0%]:Running loss: 0.21798273921012878
[2018-04-17 19:52:49.159407]: [Epoch: 249(24.924924924924923%): Data: 25.333333333333336%]:Running loss: 4.359635517001152
[2018-04-17 19:52:50.944653]: [Epoch: 249(24.924924924924923%): Data: 50.66666666666667%]:Running loss: 8.501245498657227
[2018-04-17 19:52:56.144482]: Test set accuracy: 94.33962264150944% ,loss = 5.449345335364342
[2018-04-17 19:52:56.360054]: ====================
[2018-04-17 19:52:56.365067]: Elapsed time since starting training: 0:32:22.529698
[2018-04-17 19:52:56.370581]: Estimated time left: 0:42:37.464788
[2018-04-17 19:52:56.375595]: ====================
[2018-04-17 19:52:56.464832]: [Epoch: 250(25.025025025025027%): Data: 0.0%]:Running loss: 0.21797381341457367
[2018-04-17 19:52:58.206463]: [Epoch: 250(25.025025025025027%): Data: 25.333333333333336%]:Running loss: 4.359459191560745
[2018-04-17 19:52:59.901971]: [Epoch: 250(25.025025025025027%): Data: 50.66666666666667%]:Running loss: 8.500902637839317
[2018-04-17 19:53:04.349297]: Test set accuracy: 94.33962264150944% ,loss = 5.449134483933449
[2018-04-17 19:53:04.517745]: ====================
[2018-04-17 19:53:04.522257]: Elapsed time since starting training: 0:32:30.686888
[2018-04-17 19:53:04.526769]: Estimated time left: 0:42:29.308600
[2018-04-17 19:53:04.530779]: ====================
[2018-04-17 19:53:04.600966]: [Epoch: 251(25.125125125125123%): Data: 0.0%]:Running loss: 0.21796537935733795
[2018-04-17 19:53:06.172657]: [Epoch: 251(25.125125125125123%): Data: 25.333333333333336%]:Running loss: 4.359286963939667
[2018-04-17 19:53:07.687674]: [Epoch: 251(25.125125125125123%): Data: 50.66666666666667%]:Running loss: 8.500565901398659
[2018-04-17 19:53:12.081356]: Test set accuracy: 94.33962264150944% ,loss = 5.448918044567108
[2018-04-17 19:53:12.248300]: ====================
[2018-04-17 19:53:12.252812]: Elapsed time since starting training: 0:32:38.417443
[2018-04-17 19:53:12.260332]: Estimated time left: 0:42:21.575037
[2018-04-17 19:53:12.268354]: ====================
[2018-04-17 19:53:12.339041]: [Epoch: 252(25.225225225225223%): Data: 0.0%]:Running loss: 0.21795672178268433
[2018-04-17 19:53:13.880139]: [Epoch: 252(25.225225225225223%): Data: 25.333333333333336%]:Running loss: 4.359116971492767
[2018-04-17 19:53:15.465355]: [Epoch: 252(25.225225225225223%): Data: 50.66666666666667%]:Running loss: 8.500237315893173
[2018-04-17 19:53:19.988882]: Test set accuracy: 94.33962264150944% ,loss = 5.4487161338329315
[2018-04-17 19:53:20.185906]: ====================
[2018-04-17 19:53:20.195933]: Elapsed time since starting training: 0:32:46.360564
[2018-04-17 19:53:20.200445]: Estimated time left: 0:42:13.634924
[2018-04-17 19:53:20.204957]: ====================
[2018-04-17 19:53:20.276147]: [Epoch: 253(25.325325325325327%): Data: 0.0%]:Running loss: 0.21794864535331726
[2018-04-17 19:53:21.836295]: [Epoch: 253(25.325325325325327%): Data: 25.333333333333336%]:Running loss: 4.358950853347778
[2018-04-17 19:53:23.382406]: [Epoch: 253(25.325325325325327%): Data: 50.66666666666667%]:Running loss: 8.49991424381733
[2018-04-17 19:53:27.775587]: Test set accuracy: 94.33962264150944% ,loss = 5.448510125279427
[2018-04-17 19:53:27.980632]: ====================
[2018-04-17 19:53:27.987652]: Elapsed time since starting training: 0:32:54.151781
[2018-04-17 19:53:27.996675]: Estimated time left: 0:42:05.839195
[2018-04-17 19:53:28.001187]: ====================
[2018-04-17 19:53:28.123512]: [Epoch: 254(25.425425425425423%): Data: 0.0%]:Running loss: 0.21794040501117706
[2018-04-17 19:53:29.702210]: [Epoch: 254(25.425425425425423%): Data: 25.333333333333336%]:Running loss: 4.358787536621094
[2018-04-17 19:53:31.258348]: [Epoch: 254(25.425425425425423%): Data: 50.66666666666667%]:Running loss: 8.499596893787384
[2018-04-17 19:53:35.692137]: Test set accuracy: 94.33962264150944% ,loss = 5.448313429951668
[2018-04-17 19:53:35.912223]: ====================
[2018-04-17 19:53:35.918740]: Elapsed time since starting training: 0:33:02.083371
[2018-04-17 19:53:35.925257]: Estimated time left: 0:41:57.910613
[2018-04-17 19:53:35.931775]: ====================
[2018-04-17 19:53:36.006974]: [Epoch: 255(25.525525525525527%): Data: 0.0%]:Running loss: 0.2179325371980667
[2018-04-17 19:53:37.628787]: [Epoch: 255(25.525525525525527%): Data: 25.333333333333336%]:Running loss: 4.358628988265991
[2018-04-17 19:53:39.099196]: [Epoch: 255(25.525525525525527%): Data: 50.66666666666667%]:Running loss: 8.4992865473032
[2018-04-17 19:53:43.329445]: Test set accuracy: 94.33962264150944% ,loss = 5.448120087385178
[2018-04-17 19:53:43.461295]: ====================
[2018-04-17 19:53:43.466810]: Elapsed time since starting training: 0:33:09.631441
[2018-04-17 19:53:43.476335]: Estimated time left: 0:41:50.359034
[2018-04-17 19:53:43.494383]: ====================
[2018-04-17 19:53:43.600666]: [Epoch: 256(25.625625625625624%): Data: 0.0%]:Running loss: 0.2179248034954071
[2018-04-17 19:53:45.207939]: [Epoch: 256(25.625625625625624%): Data: 25.333333333333336%]:Running loss: 4.358470574021339
[2018-04-17 19:53:46.710936]: [Epoch: 256(25.625625625625624%): Data: 50.66666666666667%]:Running loss: 8.498979732394218
[2018-04-17 19:53:51.069525]: Test set accuracy: 94.33962264150944% ,loss = 5.447926744818687
[2018-04-17 19:53:51.255520]: ====================
[2018-04-17 19:53:51.264042]: Elapsed time since starting training: 0:33:17.428673
[2018-04-17 19:53:51.272566]: Estimated time left: 0:41:42.562803
[2018-04-17 19:53:51.277579]: ====================
[2018-04-17 19:53:51.349269]: [Epoch: 257(25.725725725725724%): Data: 0.0%]:Running loss: 0.2179170697927475
[2018-04-17 19:53:53.054303]: [Epoch: 257(25.725725725725724%): Data: 25.333333333333336%]:Running loss: 4.358320102095604
[2018-04-17 19:53:54.701683]: [Epoch: 257(25.725725725725724%): Data: 50.66666666666667%]:Running loss: 8.498686328530312
[2018-04-17 19:53:59.031697]: Test set accuracy: 94.33962264150944% ,loss = 5.447732284665108
[2018-04-17 19:53:59.211675]: ====================
[2018-04-17 19:53:59.218193]: Elapsed time since starting training: 0:33:25.382323
[2018-04-17 19:53:59.224711]: Estimated time left: 0:41:34.610658
[2018-04-17 19:53:59.230225]: ====================
[2018-04-17 19:53:59.309438]: [Epoch: 258(25.825825825825827%): Data: 0.0%]:Running loss: 0.2179092913866043
[2018-04-17 19:54:00.899162]: [Epoch: 258(25.825825825825827%): Data: 25.333333333333336%]:Running loss: 4.358167335391045
[2018-04-17 19:54:02.448783]: [Epoch: 258(25.825825825825827%): Data: 50.66666666666667%]:Running loss: 8.498390331864357
[2018-04-17 19:54:06.826924]: Test set accuracy: 94.33962264150944% ,loss = 5.447544157505035
[2018-04-17 19:54:06.950252]: ====================
[2018-04-17 19:54:06.955265]: Elapsed time since starting training: 0:33:33.119896
[2018-04-17 19:54:06.969804]: Estimated time left: 0:41:26.866066
[2018-04-17 19:54:06.975820]: ====================
[2018-04-17 19:54:07.078593]: [Epoch: 259(25.925925925925924%): Data: 0.0%]:Running loss: 0.21790176630020142
[2018-04-17 19:54:08.679351]: [Epoch: 259(25.925925925925924%): Data: 25.333333333333336%]:Running loss: 4.358021557331085
[2018-04-17 19:54:10.128202]: [Epoch: 259(25.925925925925924%): Data: 50.66666666666667%]:Running loss: 8.498104900121689
[2018-04-17 19:54:14.424125]: Test set accuracy: 94.33962264150944% ,loss = 5.44736310839653
[2018-04-17 19:54:14.542440]: ====================
[2018-04-17 19:54:14.546952]: Elapsed time since starting training: 0:33:40.711583
[2018-04-17 19:54:14.554472]: Estimated time left: 0:41:19.280897
[2018-04-17 19:54:14.568008]: ====================
[2018-04-17 19:54:14.674792]: [Epoch: 260(26.026026026026027%): Data: 0.0%]:Running loss: 0.2178945243358612
[2018-04-17 19:54:16.164253]: [Epoch: 260(26.026026026026027%): Data: 25.333333333333336%]:Running loss: 4.3578760623931885
[2018-04-17 19:54:17.677276]: [Epoch: 260(26.026026026026027%): Data: 50.66666666666667%]:Running loss: 8.497822850942612
[2018-04-17 19:54:22.188270]: Test set accuracy: 94.33962264150944% ,loss = 5.447190999984741
[2018-04-17 19:54:22.315107]: ====================
[2018-04-17 19:54:22.319620]: Elapsed time since starting training: 0:33:48.484251
[2018-04-17 19:54:22.324633]: Estimated time left: 0:41:11.510736
[2018-04-17 19:54:22.329145]: ====================
[2018-04-17 19:54:22.445957]: [Epoch: 261(26.126126126126124%): Data: 0.0%]:Running loss: 0.21788763999938965
[2018-04-17 19:54:24.048216]: [Epoch: 261(26.126126126126124%): Data: 25.333333333333336%]:Running loss: 4.357733979821205
[2018-04-17 19:54:25.677047]: [Epoch: 261(26.126126126126124%): Data: 50.66666666666667%]:Running loss: 8.49754686653614
[2018-04-17 19:54:30.151449]: Test set accuracy: 94.33962264150944% ,loss = 5.447021499276161
[2018-04-17 19:54:30.316889]: ====================
[2018-04-17 19:54:30.322403]: Elapsed time since starting training: 0:33:56.486534
[2018-04-17 19:54:30.326916]: Estimated time left: 0:41:03.508453
[2018-04-17 19:54:30.331929]: ====================
[2018-04-17 19:54:30.403120]: [Epoch: 262(26.226226226226224%): Data: 0.0%]:Running loss: 0.21788085997104645
[2018-04-17 19:54:32.031450]: [Epoch: 262(26.226226226226224%): Data: 25.333333333333336%]:Running loss: 4.357595443725586
[2018-04-17 19:54:33.589591]: [Epoch: 262(26.226226226226224%): Data: 50.66666666666667%]:Running loss: 8.497276678681374
[2018-04-17 19:54:38.270036]: Test set accuracy: 94.33962264150944% ,loss = 5.446839332580566
[2018-04-17 19:54:38.441492]: ====================
[2018-04-17 19:54:38.446505]: Elapsed time since starting training: 0:34:04.611136
[2018-04-17 19:54:38.451018]: Estimated time left: 0:40:55.384351
[2018-04-17 19:54:38.455530]: ====================
[2018-04-17 19:54:38.532734]: [Epoch: 263(26.326326326326328%): Data: 0.0%]:Running loss: 0.21787357330322266
[2018-04-17 19:54:40.217213]: [Epoch: 263(26.326326326326328%): Data: 25.333333333333336%]:Running loss: 4.357458159327507
[2018-04-17 19:54:41.776861]: [Epoch: 263(26.326326326326328%): Data: 50.66666666666667%]:Running loss: 8.497010946273804
[2018-04-17 19:54:46.208144]: Test set accuracy: 94.33962264150944% ,loss = 5.446675419807434
[2018-04-17 19:54:46.375589]: ====================
[2018-04-17 19:54:46.382106]: Elapsed time since starting training: 0:34:12.546236
[2018-04-17 19:54:46.387621]: Estimated time left: 0:40:47.447748
[2018-04-17 19:54:46.394639]: ====================
[2018-04-17 19:54:46.464826]: [Epoch: 264(26.426426426426424%): Data: 0.0%]:Running loss: 0.21786701679229736
[2018-04-17 19:54:48.019961]: [Epoch: 264(26.426426426426424%): Data: 25.333333333333336%]:Running loss: 4.357325702905655
[2018-04-17 19:54:49.530477]: [Epoch: 264(26.426426426426424%): Data: 50.66666666666667%]:Running loss: 8.496752053499222
[2018-04-17 19:54:53.940203]: Test set accuracy: 94.33962264150944% ,loss = 5.446509271860123
[2018-04-17 19:54:54.069547]: ====================
[2018-04-17 19:54:54.074561]: Elapsed time since starting training: 0:34:20.239192
[2018-04-17 19:54:54.082582]: Estimated time left: 0:40:39.752787
[2018-04-17 19:54:54.100630]: ====================
[2018-04-17 19:54:54.195883]: [Epoch: 265(26.526526526526528%): Data: 0.0%]:Running loss: 0.2178603708744049
[2018-04-17 19:54:55.719936]: [Epoch: 265(26.526526526526528%): Data: 25.333333333333336%]:Running loss: 4.3571939915418625
[2018-04-17 19:54:57.255518]: [Epoch: 265(26.526526526526528%): Data: 50.66666666666667%]:Running loss: 8.496497392654419
[2018-04-17 19:55:01.559462]: Test set accuracy: 94.33962264150944% ,loss = 5.4463498294353485
[2018-04-17 19:55:01.738439]: ====================
[2018-04-17 19:55:01.745959]: Elapsed time since starting training: 0:34:27.910088
[2018-04-17 19:55:01.752978]: Estimated time left: 0:40:32.082391
[2018-04-17 19:55:01.758994]: ====================
[2018-04-17 19:55:01.837202]: [Epoch: 266(26.626626626626624%): Data: 0.0%]:Running loss: 0.21785399317741394
[2018-04-17 19:55:03.482075]: [Epoch: 266(26.626626626626624%): Data: 25.333333333333336%]:Running loss: 4.357065632939339
[2018-04-17 19:55:04.978554]: [Epoch: 266(26.626626626626624%): Data: 50.66666666666667%]:Running loss: 8.496247291564941
[2018-04-17 19:55:09.378253]: Test set accuracy: 94.33962264150944% ,loss = 5.446195602416992
[2018-04-17 19:55:09.560739]: ====================
[2018-04-17 19:55:09.566754]: Elapsed time since starting training: 0:34:35.730884
[2018-04-17 19:55:09.573774]: Estimated time left: 0:40:24.261595
[2018-04-17 19:55:09.579789]: ====================
[2018-04-17 19:55:09.656994]: [Epoch: 267(26.726726726726728%): Data: 0.0%]:Running loss: 0.2178478240966797
[2018-04-17 19:55:11.201100]: [Epoch: 267(26.726726726726728%): Data: 25.333333333333336%]:Running loss: 4.356939226388931
[2018-04-17 19:55:12.733173]: [Epoch: 267(26.726726726726728%): Data: 50.66666666666667%]:Running loss: 8.496001690626144
[2018-04-17 19:55:17.092766]: Test set accuracy: 94.33962264150944% ,loss = 5.446041002869606
[2018-04-17 19:55:17.239658]: ====================
[2018-04-17 19:55:17.244669]: Elapsed time since starting training: 0:34:43.409300
[2018-04-17 19:55:17.249683]: Estimated time left: 0:40:16.585686
[2018-04-17 19:55:17.254195]: ====================
[2018-04-17 19:55:17.329897]: [Epoch: 268(26.826826826826828%): Data: 0.0%]:Running loss: 0.21784164011478424
[2018-04-17 19:55:18.951208]: [Epoch: 268(26.826826826826828%): Data: 25.333333333333336%]:Running loss: 4.356816753745079
[2018-04-17 19:55:20.460721]: [Epoch: 268(26.826826826826828%): Data: 50.66666666666667%]:Running loss: 8.495762273669243
[2018-04-17 19:55:24.660889]: Test set accuracy: 94.33962264150944% ,loss = 5.445893853902817
[2018-04-17 19:55:24.818308]: ====================
[2018-04-17 19:55:24.823321]: Elapsed time since starting training: 0:34:50.987451
[2018-04-17 19:55:24.830842]: Estimated time left: 0:40:09.004527
[2018-04-17 19:55:24.835353]: ====================
[2018-04-17 19:55:24.906542]: [Epoch: 269(26.926926926926924%): Data: 0.0%]:Running loss: 0.21783575415611267
[2018-04-17 19:55:26.559938]: [Epoch: 269(26.926926926926924%): Data: 25.333333333333336%]:Running loss: 4.356695801019669
[2018-04-17 19:55:28.170221]: [Epoch: 269(26.926926926926924%): Data: 50.66666666666667%]:Running loss: 8.495527267456055
[2018-04-17 19:55:33.064233]: Test set accuracy: 94.33962264150944% ,loss = 5.44574074447155
[2018-04-17 19:55:33.369546]: ====================
[2018-04-17 19:55:33.377066]: Elapsed time since starting training: 0:34:59.541697
[2018-04-17 19:55:33.382580]: Estimated time left: 0:40:00.452789
[2018-04-17 19:55:33.388095]: ====================
[2018-04-17 19:55:33.504906]: [Epoch: 270(27.027027027027028%): Data: 0.0%]:Running loss: 0.217829629778862
[2018-04-17 19:55:35.197406]: [Epoch: 270(27.027027027027028%): Data: 25.333333333333336%]:Running loss: 4.356576889753342
[2018-04-17 19:55:36.485835]: [Epoch: 270(27.027027027027028%): Data: 50.66666666666667%]:Running loss: 8.495295599102974
[2018-04-17 19:55:40.883028]: Test set accuracy: 94.33962264150944% ,loss = 5.445599555969238
[2018-04-17 19:55:41.094591]: ====================
[2018-04-17 19:55:41.100606]: Elapsed time since starting training: 0:35:07.265237
[2018-04-17 19:55:41.106622]: Estimated time left: 0:39:52.729248
[2018-04-17 19:55:41.112638]: ====================
[2018-04-17 19:55:41.185832]: [Epoch: 271(27.127127127127125%): Data: 0.0%]:Running loss: 0.21782398223876953
[2018-04-17 19:55:42.987123]: [Epoch: 271(27.127127127127125%): Data: 25.333333333333336%]:Running loss: 4.356460511684418
[2018-04-17 19:55:44.696168]: [Epoch: 271(27.127127127127125%): Data: 50.66666666666667%]:Running loss: 8.49506875872612
[2018-04-17 19:55:49.965177]: Test set accuracy: 94.33962264150944% ,loss = 5.445452779531479
[2018-04-17 19:55:50.098531]: ====================
[2018-04-17 19:55:50.111066]: Elapsed time since starting training: 0:35:16.275697
[2018-04-17 19:55:50.132623]: Estimated time left: 0:39:43.703249
[2018-04-17 19:55:50.157689]: ====================
[2018-04-17 19:55:50.276505]: [Epoch: 272(27.227227227227228%): Data: 0.0%]:Running loss: 0.21781811118125916
[2018-04-17 19:55:51.919373]: [Epoch: 272(27.227227227227228%): Data: 25.333333333333336%]:Running loss: 4.356345131993294
[2018-04-17 19:55:53.689078]: [Epoch: 272(27.227227227227228%): Data: 50.66666666666667%]:Running loss: 8.49484521150589
[2018-04-17 19:55:58.428681]: Test set accuracy: 94.33962264150944% ,loss = 5.445306748151779
[2018-04-17 19:55:58.631220]: ====================
[2018-04-17 19:55:58.644756]: Elapsed time since starting training: 0:35:24.809387
[2018-04-17 19:55:58.649770]: Estimated time left: 0:39:35.185599
[2018-04-17 19:55:58.656788]: ====================
[2018-04-17 19:55:58.728478]: [Epoch: 273(27.32732732732733%): Data: 0.0%]:Running loss: 0.21781226992607117
[2018-04-17 19:56:00.544808]: [Epoch: 273(27.32732732732733%): Data: 25.333333333333336%]:Running loss: 4.356233716011047
[2018-04-17 19:56:02.304488]: [Epoch: 273(27.32732732732733%): Data: 50.66666666666667%]:Running loss: 8.49462804198265
[2018-04-17 19:56:07.407055]: Test set accuracy: 94.33962264150944% ,loss = 5.445174127817154
[2018-04-17 19:56:07.619620]: ====================
[2018-04-17 19:56:07.630148]: Elapsed time since starting training: 0:35:33.794779
[2018-04-17 19:56:07.662234]: Estimated time left: 0:39:26.173637
[2018-04-17 19:56:07.670255]: ====================
[2018-04-17 19:56:07.745956]: [Epoch: 274(27.427427427427425%): Data: 0.0%]:Running loss: 0.21780696511268616
[2018-04-17 19:56:09.310616]: [Epoch: 274(27.427427427427425%): Data: 25.333333333333336%]:Running loss: 4.3561242669820786
[2018-04-17 19:56:10.909869]: [Epoch: 274(27.427427427427425%): Data: 50.66666666666667%]:Running loss: 8.494415387511253
[2018-04-17 19:56:15.210814]: Test set accuracy: 94.33962264150944% ,loss = 5.445043370127678
[2018-04-17 19:56:15.354698]: ====================
[2018-04-17 19:56:15.360211]: Elapsed time since starting training: 0:35:41.524842
[2018-04-17 19:56:15.365726]: Estimated time left: 0:39:18.470132
[2018-04-17 19:56:15.370238]: ====================
[2018-04-17 19:56:15.481534]: [Epoch: 275(27.52752752752753%): Data: 0.0%]:Running loss: 0.21780173480510712
[2018-04-17 19:56:16.987539]: [Epoch: 275(27.52752752752753%): Data: 25.333333333333336%]:Running loss: 4.3560159504413605
[2018-04-17 19:56:18.554207]: [Epoch: 275(27.52752752752753%): Data: 50.66666666666667%]:Running loss: 8.494205206632614
[2018-04-17 19:56:22.946383]: Test set accuracy: 94.33962264150944% ,loss = 5.444904416799545
[2018-04-17 19:56:23.073220]: ====================
[2018-04-17 19:56:23.078234]: Elapsed time since starting training: 0:35:49.242865
[2018-04-17 19:56:23.083748]: Estimated time left: 0:39:10.751621
[2018-04-17 19:56:23.088761]: ====================
[2018-04-17 19:56:23.210586]: [Epoch: 276(27.627627627627625%): Data: 0.0%]:Running loss: 0.2177961766719818
[2018-04-17 19:56:24.816355]: [Epoch: 276(27.627627627627625%): Data: 25.333333333333336%]:Running loss: 4.355910658836365
[2018-04-17 19:56:26.424130]: [Epoch: 276(27.627627627627625%): Data: 50.66666666666667%]:Running loss: 8.494000658392906
[2018-04-17 19:56:30.732586]: Test set accuracy: 94.33962264150944% ,loss = 5.444778874516487
[2018-04-17 19:56:30.897024]: ====================
[2018-04-17 19:56:30.902538]: Elapsed time since starting training: 0:35:57.066668
[2018-04-17 19:56:30.907050]: Estimated time left: 0:39:02.928319
[2018-04-17 19:56:30.914570]: ====================
[2018-04-17 19:56:30.988768]: [Epoch: 277(27.72772772772773%): Data: 0.0%]:Running loss: 0.21779115498065948
[2018-04-17 19:56:32.498783]: [Epoch: 277(27.72772772772773%): Data: 25.333333333333336%]:Running loss: 4.3558074831962585
[2018-04-17 19:56:34.273001]: [Epoch: 277(27.72772772772773%): Data: 50.66666666666667%]:Running loss: 8.493798077106476
[2018-04-17 19:56:38.521296]: Test set accuracy: 94.33962264150944% ,loss = 5.4446496069431305
[2018-04-17 19:56:38.697766]: ====================
[2018-04-17 19:56:38.705285]: Elapsed time since starting training: 0:36:04.869916
[2018-04-17 19:56:38.710800]: Estimated time left: 0:38:55.125070
[2018-04-17 19:56:38.716316]: ====================
[2018-04-17 19:56:38.790513]: [Epoch: 278(27.82782782782783%): Data: 0.0%]:Running loss: 0.21778598427772522
[2018-04-17 19:56:40.309051]: [Epoch: 278(27.82782782782783%): Data: 25.333333333333336%]:Running loss: 4.355705052614212
[2018-04-17 19:56:41.834607]: [Epoch: 278(27.82782782782783%): Data: 50.66666666666667%]:Running loss: 8.493600860238075
[2018-04-17 19:56:46.250348]: Test set accuracy: 94.33962264150944% ,loss = 5.444526299834251
[2018-04-17 19:56:46.409772]: ====================
[2018-04-17 19:56:46.414785]: Elapsed time since starting training: 0:36:12.579416
[2018-04-17 19:56:46.419800]: Estimated time left: 0:38:47.416072
[2018-04-17 19:56:46.424311]: ====================
[2018-04-17 19:56:46.499510]: [Epoch: 279(27.927927927927925%): Data: 0.0%]:Running loss: 0.21778105199337006
[2018-04-17 19:56:48.072695]: [Epoch: 279(27.927927927927925%): Data: 25.333333333333336%]:Running loss: 4.355604931712151
[2018-04-17 19:56:49.652895]: [Epoch: 279(27.927927927927925%): Data: 50.66666666666667%]:Running loss: 8.493405550718307
[2018-04-17 19:56:54.187954]: Test set accuracy: 94.33962264150944% ,loss = 5.444406718015671
[2018-04-17 19:56:54.368936]: ====================
[2018-04-17 19:56:54.374450]: Elapsed time since starting training: 0:36:20.539081
[2018-04-17 19:56:54.379463]: Estimated time left: 0:38:39.455906
[2018-04-17 19:56:54.384978]: ====================
[2018-04-17 19:56:54.455666]: [Epoch: 280(28.02802802802803%): Data: 0.0%]:Running loss: 0.21777626872062683
[2018-04-17 19:56:56.087505]: [Epoch: 280(28.02802802802803%): Data: 25.333333333333336%]:Running loss: 4.355508342385292
[2018-04-17 19:56:57.642139]: [Epoch: 280(28.02802802802803%): Data: 50.66666666666667%]:Running loss: 8.493217214941978
[2018-04-17 19:57:02.144610]: Test set accuracy: 94.33962264150944% ,loss = 5.444275215268135
[2018-04-17 19:57:02.309048]: ====================
[2018-04-17 19:57:02.316568]: Elapsed time since starting training: 0:36:28.480697
[2018-04-17 19:57:02.320578]: Estimated time left: 0:38:31.514791
[2018-04-17 19:57:02.325090]: ====================
[2018-04-17 19:57:02.397784]: [Epoch: 281(28.128128128128125%): Data: 0.0%]:Running loss: 0.2177710086107254
[2018-04-17 19:57:03.972471]: [Epoch: 281(28.128128128128125%): Data: 25.333333333333336%]:Running loss: 4.3554113656282425
[2018-04-17 19:57:05.519584]: [Epoch: 281(28.128128128128125%): Data: 50.66666666666667%]:Running loss: 8.49302938580513
[2018-04-17 19:57:09.846089]: Test set accuracy: 94.33962264150944% ,loss = 5.444164946675301
[2018-04-17 19:57:10.006516]: ====================
[2018-04-17 19:57:10.011530]: Elapsed time since starting training: 0:36:36.175659
[2018-04-17 19:57:10.016542]: Estimated time left: 0:38:23.818827
[2018-04-17 19:57:10.022562]: ====================
[2018-04-17 19:57:10.098259]: [Epoch: 282(28.22822822822823%): Data: 0.0%]:Running loss: 0.21776659786701202
[2018-04-17 19:57:11.695005]: [Epoch: 282(28.22822822822823%): Data: 25.333333333333336%]:Running loss: 4.355318620800972
[2018-04-17 19:57:13.230087]: [Epoch: 282(28.22822822822823%): Data: 50.66666666666667%]:Running loss: 8.49284815788269
[2018-04-17 19:57:17.682425]: Test set accuracy: 94.33962264150944% ,loss = 5.444051697850227
[2018-04-17 19:57:17.871929]: ====================
[2018-04-17 19:57:17.877444]: Elapsed time since starting training: 0:36:44.042075
[2018-04-17 19:57:17.883962]: Estimated time left: 0:38:15.951407
[2018-04-17 19:57:17.888975]: ====================
[2018-04-17 19:57:17.964676]: [Epoch: 283(28.32832832832833%): Data: 0.0%]:Running loss: 0.2177620679140091
[2018-04-17 19:57:19.621582]: [Epoch: 283(28.32832832832833%): Data: 25.333333333333336%]:Running loss: 4.355225369334221
[2018-04-17 19:57:21.202285]: [Epoch: 283(28.32832832832833%): Data: 50.66666666666667%]:Running loss: 8.492667451500893
[2018-04-17 19:57:25.720298]: Test set accuracy: 94.33962264150944% ,loss = 5.443935841321945
[2018-04-17 19:57:25.870698]: ====================
[2018-04-17 19:57:25.875711]: Elapsed time since starting training: 0:36:52.040342
[2018-04-17 19:57:25.880725]: Estimated time left: 0:38:07.954644
[2018-04-17 19:57:25.886239]: ====================
[2018-04-17 19:57:26.016586]: [Epoch: 284(28.428428428428425%): Data: 0.0%]:Running loss: 0.2177574336528778
[2018-04-17 19:57:27.595786]: [Epoch: 284(28.428428428428425%): Data: 25.333333333333336%]:Running loss: 4.355134800076485
[2018-04-17 19:57:29.165459]: [Epoch: 284(28.428428428428425%): Data: 50.66666666666667%]:Running loss: 8.492491453886032
[2018-04-17 19:57:33.574688]: Test set accuracy: 94.33962264150944% ,loss = 5.443817749619484
[2018-04-17 19:57:33.764194]: ====================
[2018-04-17 19:57:33.771712]: Elapsed time since starting training: 0:36:59.936343
[2018-04-17 19:57:33.776726]: Estimated time left: 0:38:00.058643
[2018-04-17 19:57:33.784747]: ====================
[2018-04-17 19:57:33.854432]: [Epoch: 285(28.52852852852853%): Data: 0.0%]:Running loss: 0.21775270998477936
[2018-04-17 19:57:35.496298]: [Epoch: 285(28.52852852852853%): Data: 25.333333333333336%]:Running loss: 4.355046302080154
[2018-04-17 19:57:37.037898]: [Epoch: 285(28.52852852852853%): Data: 50.66666666666667%]:Running loss: 8.492319241166115
[2018-04-17 19:57:41.500764]: Test set accuracy: 94.33962264150944% ,loss = 5.443719029426575
[2018-04-17 19:57:41.619580]: ====================
[2018-04-17 19:57:41.626097]: Elapsed time since starting training: 0:37:07.790227
[2018-04-17 19:57:41.631111]: Estimated time left: 0:37:52.204760
[2018-04-17 19:57:41.635623]: ====================
[2018-04-17 19:57:41.710323]: [Epoch: 286(28.628628628628626%): Data: 0.0%]:Running loss: 0.217748761177063
[2018-04-17 19:57:43.348176]: [Epoch: 286(28.628628628628626%): Data: 25.333333333333336%]:Running loss: 4.354959711432457
[2018-04-17 19:57:45.100335]: [Epoch: 286(28.628628628628626%): Data: 50.66666666666667%]:Running loss: 8.492149263620377
[2018-04-17 19:57:49.451906]: Test set accuracy: 94.33962264150944% ,loss = 5.443611741065979
[2018-04-17 19:57:49.620354]: ====================
[2018-04-17 19:57:49.626370]: Elapsed time since starting training: 0:37:15.791001
[2018-04-17 19:57:49.636898]: Estimated time left: 0:37:44.198471
[2018-04-17 19:57:49.641410]: ====================
[2018-04-17 19:57:49.712098]: [Epoch: 287(28.72872872872873%): Data: 0.0%]:Running loss: 0.21774446964263916
[2018-04-17 19:57:51.243670]: [Epoch: 287(28.72872872872873%): Data: 25.333333333333336%]:Running loss: 4.3548741191625595
[2018-04-17 19:57:52.887040]: [Epoch: 287(28.72872872872873%): Data: 50.66666666666667%]:Running loss: 8.491984501481056
[2018-04-17 19:57:57.217054]: Test set accuracy: 94.33962264150944% ,loss = 5.443505570292473
[2018-04-17 19:57:57.336872]: ====================
[2018-04-17 19:57:57.341885]: Elapsed time since starting training: 0:37:23.506015
[2018-04-17 19:57:57.348904]: Estimated time left: 0:37:36.486465
[2018-04-17 19:57:57.353917]: ====================
[2018-04-17 19:57:57.467720]: [Epoch: 288(28.82882882882883%): Data: 0.0%]:Running loss: 0.2177402228116989
[2018-04-17 19:57:59.074995]: [Epoch: 288(28.82882882882883%): Data: 25.333333333333336%]:Running loss: 4.354789897799492
[2018-04-17 19:58:00.610075]: [Epoch: 288(28.82882882882883%): Data: 50.66666666666667%]:Running loss: 8.491820380091667
[2018-04-17 19:58:05.053390]: Test set accuracy: 94.33962264150944% ,loss = 5.4433997720479965
[2018-04-17 19:58:05.234371]: ====================
[2018-04-17 19:58:05.238884]: Elapsed time since starting training: 0:37:31.403515
[2018-04-17 19:58:05.244399]: Estimated time left: 0:37:28.590970
[2018-04-17 19:58:05.249913]: ====================
[2018-04-17 19:58:05.323609]: [Epoch: 289(28.928928928928926%): Data: 0.0%]:Running loss: 0.21773599088191986
[2018-04-17 19:58:06.886264]: [Epoch: 289(28.928928928928926%): Data: 25.333333333333336%]:Running loss: 4.354707971215248
[2018-04-17 19:58:08.390765]: [Epoch: 289(28.928928928928926%): Data: 50.66666666666667%]:Running loss: 8.491659790277481
[2018-04-17 19:58:12.819039]: Test set accuracy: 94.33962264150944% ,loss = 5.443299189209938
[2018-04-17 19:58:12.941866]: ====================
[2018-04-17 19:58:12.946377]: Elapsed time since starting training: 0:37:39.111008
[2018-04-17 19:58:12.952895]: Estimated time left: 0:37:20.882474
[2018-04-17 19:58:12.958410]: ====================
[2018-04-17 19:58:13.068703]: [Epoch: 290(29.02902902902903%): Data: 0.0%]:Running loss: 0.21773196756839752
[2018-04-17 19:58:14.686504]: [Epoch: 290(29.02902902902903%): Data: 25.333333333333336%]:Running loss: 4.354628264904022
[2018-04-17 19:58:16.158419]: [Epoch: 290(29.02902902902903%): Data: 50.66666666666667%]:Running loss: 8.491504475474358
[2018-04-17 19:58:20.606245]: Test set accuracy: 94.33962264150944% ,loss = 5.4431963711977005
[2018-04-17 19:58:20.782213]: ====================
[2018-04-17 19:58:20.788730]: Elapsed time since starting training: 0:37:46.953361
[2018-04-17 19:58:20.795248]: Estimated time left: 0:37:13.040121
[2018-04-17 19:58:20.799760]: ====================
[2018-04-17 19:58:20.869946]: [Epoch: 291(29.129129129129126%): Data: 0.0%]:Running loss: 0.21772785484790802
[2018-04-17 19:58:22.511313]: [Epoch: 291(29.129129129129126%): Data: 25.333333333333336%]:Running loss: 4.354548379778862
[2018-04-17 19:58:24.187268]: [Epoch: 291(29.129129129129126%): Data: 50.66666666666667%]:Running loss: 8.49135072529316
[2018-04-17 19:58:28.662670]: Test set accuracy: 94.33962264150944% ,loss = 5.443096905946732
[2018-04-17 19:58:28.866212]: ====================
[2018-04-17 19:58:28.873230]: Elapsed time since starting training: 0:37:55.037861
[2018-04-17 19:58:28.879246]: Estimated time left: 0:37:04.956123
[2018-04-17 19:58:28.885263]: ====================
[2018-04-17 19:58:28.969486]: [Epoch: 292(29.22922922922923%): Data: 0.0%]:Running loss: 0.21772387623786926
[2018-04-17 19:58:30.698584]: [Epoch: 292(29.22922922922923%): Data: 25.333333333333336%]:Running loss: 4.3544695526361465
[2018-04-17 19:58:32.353484]: [Epoch: 292(29.22922922922923%): Data: 50.66666666666667%]:Running loss: 8.491199761629105
[2018-04-17 19:58:36.955722]: Test set accuracy: 94.33962264150944% ,loss = 5.443009734153748
[2018-04-17 19:58:37.129685]: ====================
[2018-04-17 19:58:37.134697]: Elapsed time since starting training: 0:38:03.299328
[2018-04-17 19:58:37.139209]: Estimated time left: 0:36:56.696661
[2018-04-17 19:58:37.143722]: ====================
[2018-04-17 19:58:37.216916]: [Epoch: 293(29.32932932932933%): Data: 0.0%]:Running loss: 0.2177203893661499
[2018-04-17 19:58:38.829204]: [Epoch: 293(29.32932932932933%): Data: 25.333333333333336%]:Running loss: 4.354395240545273
[2018-04-17 19:58:40.406398]: [Epoch: 293(29.32932932932933%): Data: 50.66666666666667%]:Running loss: 8.491051658987999
[2018-04-17 19:58:44.936442]: Test set accuracy: 94.33962264150944% ,loss = 5.442910268902779
[2018-04-17 19:58:45.109403]: ====================
[2018-04-17 19:58:45.114416]: Elapsed time since starting training: 0:38:11.278545
[2018-04-17 19:58:45.120933]: Estimated time left: 0:36:48.714938
[2018-04-17 19:58:45.125946]: ====================
[2018-04-17 19:58:45.196133]: [Epoch: 294(29.429429429429426%): Data: 0.0%]:Running loss: 0.21771641075611115
[2018-04-17 19:58:46.886628]: [Epoch: 294(29.429429429429426%): Data: 25.333333333333336%]:Running loss: 4.354320913553238
[2018-04-17 19:58:48.518969]: [Epoch: 294(29.429429429429426%): Data: 50.66666666666667%]:Running loss: 8.490907654166222
[2018-04-17 19:58:53.085611]: Test set accuracy: 94.33962264150944% ,loss = 5.4428186267614365
[2018-04-17 19:58:53.229994]: ====================
[2018-04-17 19:58:53.239520]: Elapsed time since starting training: 0:38:19.404151
[2018-04-17 19:58:53.244533]: Estimated time left: 0:36:40.591337
[2018-04-17 19:58:53.249547]: ====================
[2018-04-17 19:58:53.372874]: [Epoch: 295(29.52952952952953%): Data: 0.0%]:Running loss: 0.21771274507045746
[2018-04-17 19:58:54.952076]: [Epoch: 295(29.52952952952953%): Data: 25.333333333333336%]:Running loss: 4.354246571660042
[2018-04-17 19:58:56.535785]: [Epoch: 295(29.52952952952953%): Data: 50.66666666666667%]:Running loss: 8.490762650966644
[2018-04-17 19:59:01.168603]: Test set accuracy: 94.33962264150944% ,loss = 5.442726984620094
[2018-04-17 19:59:01.294438]: ====================
[2018-04-17 19:59:01.298950]: Elapsed time since starting training: 0:38:27.463581
[2018-04-17 19:59:01.303964]: Estimated time left: 0:36:32.531405
[2018-04-17 19:59:01.318000]: ====================
[2018-04-17 19:59:01.434812]: [Epoch: 296(29.629629629629626%): Data: 0.0%]:Running loss: 0.21770907938480377
[2018-04-17 19:59:03.051109]: [Epoch: 296(29.629629629629626%): Data: 25.333333333333336%]:Running loss: 4.3541747480630875
[2018-04-17 19:59:04.593209]: [Epoch: 296(29.629629629629626%): Data: 50.66666666666667%]:Running loss: 8.490624368190765
[2018-04-17 19:59:08.953804]: Test set accuracy: 94.33962264150944% ,loss = 5.4426394402980804
[2018-04-17 19:59:09.127767]: ====================
[2018-04-17 19:59:09.134284]: Elapsed time since starting training: 0:38:35.298915
[2018-04-17 19:59:09.139298]: Estimated time left: 0:36:24.696573
[2018-04-17 19:59:09.143308]: ====================
[2018-04-17 19:59:09.228534]: [Epoch: 297(29.72972972972973%): Data: 0.0%]:Running loss: 0.21770557761192322
[2018-04-17 19:59:10.828801]: [Epoch: 297(29.72972972972973%): Data: 25.333333333333336%]:Running loss: 4.354104608297348
[2018-04-17 19:59:12.357856]: [Epoch: 297(29.72972972972973%): Data: 50.66666666666667%]:Running loss: 8.490486159920692
[2018-04-17 19:59:16.603645]: Test set accuracy: 94.33962264150944% ,loss = 5.442550033330917
[2018-04-17 19:59:16.759560]: ====================
[2018-04-17 19:59:16.764574]: Elapsed time since starting training: 0:38:42.929205
[2018-04-17 19:59:16.769085]: Estimated time left: 0:36:17.066284
[2018-04-17 19:59:16.773597]: ====================
[2018-04-17 19:59:16.845287]: [Epoch: 298(29.82982982982983%): Data: 0.0%]:Running loss: 0.2177020013332367
[2018-04-17 19:59:18.454567]: [Epoch: 298(29.82982982982983%): Data: 25.333333333333336%]:Running loss: 4.354036450386047
[2018-04-17 19:59:20.027751]: [Epoch: 298(29.82982982982983%): Data: 50.66666666666667%]:Running loss: 8.49035269021988
[2018-04-17 19:59:24.340719]: Test set accuracy: 94.33962264150944% ,loss = 5.442472547292709
[2018-04-17 19:59:24.565315]: ====================
[2018-04-17 19:59:24.571331]: Elapsed time since starting training: 0:38:50.735962
[2018-04-17 19:59:24.576846]: Estimated time left: 0:36:09.258523
[2018-04-17 19:59:24.585870]: ====================
[2018-04-17 19:59:24.662072]: [Epoch: 299(29.929929929929934%): Data: 0.0%]:Running loss: 0.21769890189170837
[2018-04-17 19:59:26.390167]: [Epoch: 299(29.929929929929934%): Data: 25.333333333333336%]:Running loss: 4.353967368602753
[2018-04-17 19:59:27.869100]: [Epoch: 299(29.929929929929934%): Data: 50.66666666666667%]:Running loss: 8.490220695734024
[2018-04-17 19:59:32.215156]: Test set accuracy: 94.33962264150944% ,loss = 5.442384630441666
[2018-04-17 19:59:32.395135]: ====================
[2018-04-17 19:59:32.400651]: Elapsed time since starting training: 0:38:58.565282
[2018-04-17 19:59:32.405662]: Estimated time left: 0:36:01.429707
[2018-04-17 19:59:32.410174]: ====================
[2018-04-17 19:59:32.479358]: [Epoch: 300(30.03003003003003%): Data: 0.0%]:Running loss: 0.21769538521766663
[2018-04-17 19:59:34.104180]: [Epoch: 300(30.03003003003003%): Data: 25.333333333333336%]:Running loss: 4.353901073336601
[2018-04-17 19:59:35.696915]: [Epoch: 300(30.03003003003003%): Data: 50.66666666666667%]:Running loss: 8.490090996026993
[2018-04-17 19:59:40.031439]: Test set accuracy: 94.33962264150944% ,loss = 5.442309752106667
[2018-04-17 19:59:40.196378]: ====================
[2018-04-17 19:59:40.200890]: Elapsed time since starting training: 0:39:06.365521
[2018-04-17 19:59:40.205903]: Estimated time left: 0:35:53.629466
[2018-04-17 19:59:40.210415]: ====================
[2018-04-17 19:59:40.286618]: [Epoch: 301(30.130130130130127%): Data: 0.0%]:Running loss: 0.21769239008426666
[2018-04-17 19:59:41.841753]: [Epoch: 301(30.130130130130127%): Data: 25.333333333333336%]:Running loss: 4.353836551308632
[2018-04-17 19:59:43.427971]: [Epoch: 301(30.130130130130127%): Data: 50.66666666666667%]:Running loss: 8.489965066313744
[2018-04-17 19:59:47.809622]: Test set accuracy: 94.33962264150944% ,loss = 5.442223325371742
[2018-04-17 19:59:47.965035]: ====================
[2018-04-17 19:59:47.970048]: Elapsed time since starting training: 0:39:14.134679
[2018-04-17 19:59:47.974560]: Estimated time left: 0:35:45.860809
[2018-04-17 19:59:47.982080]: ====================
[2018-04-17 19:59:48.051264]: [Epoch: 302(30.23023023023023%): Data: 0.0%]:Running loss: 0.2176889330148697
[2018-04-17 19:59:49.547242]: [Epoch: 302(30.23023023023023%): Data: 25.333333333333336%]:Running loss: 4.353771805763245
[2018-04-17 19:59:51.073801]: [Epoch: 302(30.23023023023023%): Data: 50.66666666666667%]:Running loss: 8.489839166402817
[2018-04-17 19:59:55.452443]: Test set accuracy: 94.33962264150944% ,loss = 5.442146584391594
[2018-04-17 19:59:55.588806]: ====================
[2018-04-17 19:59:55.611366]: Elapsed time since starting training: 0:39:21.775997
[2018-04-17 19:59:55.637435]: Estimated time left: 0:35:38.198435
[2018-04-17 19:59:55.643452]: ====================
[2018-04-17 19:59:55.717148]: [Epoch: 303(30.33033033033033%): Data: 0.0%]:Running loss: 0.21768586337566376
[2018-04-17 19:59:57.253733]: [Epoch: 303(30.33033033033033%): Data: 25.333333333333336%]:Running loss: 4.353708326816559
[2018-04-17 19:59:58.785807]: [Epoch: 303(30.33033033033033%): Data: 50.66666666666667%]:Running loss: 8.489716723561287
[2018-04-17 20:00:03.499340]: Test set accuracy: 94.33962264150944% ,loss = 5.442066490650177
[2018-04-17 20:00:03.622167]: ====================
[2018-04-17 20:00:03.626679]: Elapsed time since starting training: 0:39:29.791310
[2018-04-17 20:00:03.634199]: Estimated time left: 0:35:30.201170
[2018-04-17 20:00:03.638711]: ====================
[2018-04-17 20:00:03.757527]: [Epoch: 304(30.430430430430434%): Data: 0.0%]:Running loss: 0.21768265962600708
[2018-04-17 20:00:05.362294]: [Epoch: 304(30.430430430430434%): Data: 25.333333333333336%]:Running loss: 4.353648126125336
[2018-04-17 20:00:06.922442]: [Epoch: 304(30.430430430430434%): Data: 50.66666666666667%]:Running loss: 8.489598453044891
[2018-04-17 20:00:11.610909]: Test set accuracy: 94.33962264150944% ,loss = 5.441995710134506
[2018-04-17 20:00:11.800413]: ====================
[2018-04-17 20:00:11.806930]: Elapsed time since starting training: 0:39:37.971561
[2018-04-17 20:00:11.811443]: Estimated time left: 0:35:22.023926
[2018-04-17 20:00:11.816456]: ====================
[2018-04-17 20:00:11.888146]: [Epoch: 305(30.53053053053053%): Data: 0.0%]:Running loss: 0.21767982840538025
[2018-04-17 20:00:13.525500]: [Epoch: 305(30.53053053053053%): Data: 25.333333333333336%]:Running loss: 4.353586256504059
[2018-04-17 20:00:15.094672]: [Epoch: 305(30.53053053053053%): Data: 50.66666666666667%]:Running loss: 8.48947910964489
[2018-04-17 20:00:19.694406]: Test set accuracy: 94.33962264150944% ,loss = 5.441921576857567
[2018-04-17 20:00:19.820241]: ====================
[2018-04-17 20:00:19.827761]: Elapsed time since starting training: 0:39:45.991891
[2018-04-17 20:00:19.840796]: Estimated time left: 0:35:13.994573
[2018-04-17 20:00:19.876891]: ====================
[2018-04-17 20:00:19.984678]: [Epoch: 306(30.630630630630627%): Data: 0.0%]:Running loss: 0.21767686307430267
[2018-04-17 20:00:21.627046]: [Epoch: 306(30.630630630630627%): Data: 25.333333333333336%]:Running loss: 4.353528320789337
[2018-04-17 20:00:23.190202]: [Epoch: 306(30.630630630630627%): Data: 50.66666666666667%]:Running loss: 8.489364922046661
[2018-04-17 20:00:27.879169]: Test set accuracy: 94.33962264150944% ,loss = 5.441843345761299
[2018-04-17 20:00:28.050124]: ====================
[2018-04-17 20:00:28.055138]: Elapsed time since starting training: 0:39:54.219268
[2018-04-17 20:00:28.059649]: Estimated time left: 0:35:05.775720
[2018-04-17 20:00:28.066668]: ====================
[2018-04-17 20:00:28.139361]: [Epoch: 307(30.73073073073073%): Data: 0.0%]:Running loss: 0.21767373383045197
[2018-04-17 20:00:29.712545]: [Epoch: 307(30.73073073073073%): Data: 25.333333333333336%]:Running loss: 4.353469207882881
[2018-04-17 20:00:31.280213]: [Epoch: 307(30.73073073073073%): Data: 50.66666666666667%]:Running loss: 8.48925095796585
[2018-04-17 20:00:35.881949]: Test set accuracy: 94.33962264150944% ,loss = 5.441776663064957
[2018-04-17 20:00:36.006781]: ====================
[2018-04-17 20:00:36.011293]: Elapsed time since starting training: 0:40:02.175924
[2018-04-17 20:00:36.015805]: Estimated time left: 0:34:57.819564
[2018-04-17 20:00:36.020818]: ====================
[2018-04-17 20:00:36.153170]: [Epoch: 308(30.83083083083083%): Data: 0.0%]:Running loss: 0.21767106652259827
[2018-04-17 20:00:37.674215]: [Epoch: 308(30.83083083083083%): Data: 25.333333333333336%]:Running loss: 4.353412285447121
[2018-04-17 20:00:39.293019]: [Epoch: 308(30.83083083083083%): Data: 50.66666666666667%]:Running loss: 8.489139676094055
[2018-04-17 20:00:43.870189]: Test set accuracy: 94.33962264150944% ,loss = 5.441707372665405
[2018-04-17 20:00:44.161465]: ====================
[2018-04-17 20:00:44.167480]: Elapsed time since starting training: 0:40:10.331610
[2018-04-17 20:00:44.172493]: Estimated time left: 0:34:49.662876
[2018-04-17 20:00:44.178008]: ====================
[2018-04-17 20:00:44.254712]: [Epoch: 309(30.930930930930934%): Data: 0.0%]:Running loss: 0.2176682949066162
[2018-04-17 20:00:45.820375]: [Epoch: 309(30.930930930930934%): Data: 25.333333333333336%]:Running loss: 4.353355661034584
[2018-04-17 20:00:47.453723]: [Epoch: 309(30.930930930930934%): Data: 50.66666666666667%]:Running loss: 8.489030241966248
[2018-04-17 20:00:51.894526]: Test set accuracy: 94.33962264150944% ,loss = 5.441632866859436
[2018-04-17 20:00:52.082025]: ====================
[2018-04-17 20:00:52.088542]: Elapsed time since starting training: 0:40:18.253173
[2018-04-17 20:00:52.093556]: Estimated time left: 0:34:41.742315
[2018-04-17 20:00:52.099573]: ====================
[2018-04-17 20:00:52.173267]: [Epoch: 310(31.03103103103103%): Data: 0.0%]:Running loss: 0.21766531467437744
[2018-04-17 20:00:53.911892]: [Epoch: 310(31.03103103103103%): Data: 25.333333333333336%]:Running loss: 4.353301763534546
[2018-04-17 20:00:55.498609]: [Epoch: 310(31.03103103103103%): Data: 50.66666666666667%]:Running loss: 8.488924607634544
[2018-04-17 20:00:59.995066]: Test set accuracy: 94.33962264150944% ,loss = 5.441568046808243
[2018-04-17 20:01:00.164015]: ====================
[2018-04-17 20:01:00.178553]: Elapsed time since starting training: 0:40:26.343184
[2018-04-17 20:01:00.184068]: Estimated time left: 0:34:33.651802
[2018-04-17 20:01:00.189081]: ====================
[2018-04-17 20:01:00.262276]: [Epoch: 311(31.131131131131127%): Data: 0.0%]:Running loss: 0.2176627218723297
[2018-04-17 20:01:01.938233]: [Epoch: 311(31.131131131131127%): Data: 25.333333333333336%]:Running loss: 4.353248134255409
[2018-04-17 20:01:03.500386]: [Epoch: 311(31.131131131131127%): Data: 50.66666666666667%]:Running loss: 8.48881995677948
[2018-04-17 20:01:08.022912]: Test set accuracy: 94.33962264150944% ,loss = 5.4415058344602585
[2018-04-17 20:01:08.219434]: ====================
[2018-04-17 20:01:08.230464]: Elapsed time since starting training: 0:40:34.395095
[2018-04-17 20:01:08.234975]: Estimated time left: 0:34:25.600394
[2018-04-17 20:01:08.239488]: ====================
[2018-04-17 20:01:08.309675]: [Epoch: 312(31.23123123123123%): Data: 0.0%]:Running loss: 0.21766023337841034
[2018-04-17 20:01:09.852777]: [Epoch: 312(31.23123123123123%): Data: 25.333333333333336%]:Running loss: 4.353194668889046
[2018-04-17 20:01:11.444509]: [Epoch: 312(31.23123123123123%): Data: 50.66666666666667%]:Running loss: 8.48871697485447
[2018-04-17 20:01:15.888326]: Test set accuracy: 94.33962264150944% ,loss = 5.441436171531677
[2018-04-17 20:01:16.111921]: ====================
[2018-04-17 20:01:16.117435]: Elapsed time since starting training: 0:40:42.282066
[2018-04-17 20:01:16.122448]: Estimated time left: 0:34:17.713422
[2018-04-17 20:01:16.127963]: ====================
[2018-04-17 20:01:16.203164]: [Epoch: 313(31.33133133133133%): Data: 0.0%]:Running loss: 0.2176574468612671
[2018-04-17 20:01:17.858566]: [Epoch: 313(31.33133133133133%): Data: 25.333333333333336%]:Running loss: 4.353142693638802
[2018-04-17 20:01:19.384622]: [Epoch: 313(31.33133133133133%): Data: 50.66666666666667%]:Running loss: 8.488615408539772
[2018-04-17 20:01:23.963798]: Test set accuracy: 94.33962264150944% ,loss = 5.441374704241753
[2018-04-17 20:01:24.091639]: ====================
[2018-04-17 20:01:24.096150]: Elapsed time since starting training: 0:40:50.260781
[2018-04-17 20:01:24.100663]: Estimated time left: 0:34:09.734706
[2018-04-17 20:01:24.105676]: ====================
[2018-04-17 20:01:24.216971]: [Epoch: 314(31.431431431431434%): Data: 0.0%]:Running loss: 0.2176549881696701
[2018-04-17 20:01:25.802689]: [Epoch: 314(31.431431431431434%): Data: 25.333333333333336%]:Running loss: 4.353091806173325
[2018-04-17 20:01:27.394921]: [Epoch: 314(31.431431431431434%): Data: 50.66666666666667%]:Running loss: 8.488515809178352
[2018-04-17 20:01:31.978109]: Test set accuracy: 94.33962264150944% ,loss = 5.44130764901638
[2018-04-17 20:01:32.136529]: ====================
[2018-04-17 20:01:32.141543]: Elapsed time since starting training: 0:40:58.306174
[2018-04-17 20:01:32.146055]: Estimated time left: 0:34:01.689314
[2018-04-17 20:01:32.153575]: ====================
[2018-04-17 20:01:32.243815]: [Epoch: 315(31.53153153153153%): Data: 0.0%]:Running loss: 0.2176523059606552
[2018-04-17 20:01:33.882672]: [Epoch: 315(31.53153153153153%): Data: 25.333333333333336%]:Running loss: 4.3530413210392
[2018-04-17 20:01:35.424271]: [Epoch: 315(31.53153153153153%): Data: 50.66666666666667%]:Running loss: 8.488417729735374
[2018-04-17 20:01:39.873602]: Test set accuracy: 94.33962264150944% ,loss = 5.441252514719963
[2018-04-17 20:01:40.036034]: ====================
[2018-04-17 20:01:40.041047]: Elapsed time since starting training: 0:41:06.205678
[2018-04-17 20:01:40.045560]: Estimated time left: 0:33:53.789809
[2018-04-17 20:01:40.050071]: ====================
[2018-04-17 20:01:40.123266]: [Epoch: 316(31.631631631631627%): Data: 0.0%]:Running loss: 0.21765010058879852
[2018-04-17 20:01:41.741068]: [Epoch: 316(31.631631631631627%): Data: 25.333333333333336%]:Running loss: 4.352992430329323
[2018-04-17 20:01:43.279660]: [Epoch: 316(31.631631631631627%): Data: 50.66666666666667%]:Running loss: 8.488323658704758
[2018-04-17 20:01:47.762579]: Test set accuracy: 94.33962264150944% ,loss = 5.441184714436531
[2018-04-17 20:01:47.960104]: ====================
[2018-04-17 20:01:47.968126]: Elapsed time since starting training: 0:41:14.132757
[2018-04-17 20:01:47.972638]: Estimated time left: 0:33:45.862731
[2018-04-17 20:01:47.978152]: ====================
[2018-04-17 20:01:48.052350]: [Epoch: 317(31.73173173173173%): Data: 0.0%]:Running loss: 0.21764738857746124
[2018-04-17 20:01:49.631047]: [Epoch: 317(31.73173173173173%): Data: 25.333333333333336%]:Running loss: 4.352944657206535
[2018-04-17 20:01:51.186183]: [Epoch: 317(31.73173173173173%): Data: 50.66666666666667%]:Running loss: 8.48823007941246
[2018-04-17 20:01:55.678126]: Test set accuracy: 94.33962264150944% ,loss = 5.441127344965935
[2018-04-17 20:01:55.854094]: ====================
[2018-04-17 20:01:55.858607]: Elapsed time since starting training: 0:41:22.022736
[2018-04-17 20:01:55.863119]: Estimated time left: 0:33:37.972250
[2018-04-17 20:01:55.872644]: ====================
[2018-04-17 20:01:55.945338]: [Epoch: 318(31.83183183183183%): Data: 0.0%]:Running loss: 0.2176450937986374
[2018-04-17 20:01:57.647362]: [Epoch: 318(31.83183183183183%): Data: 25.333333333333336%]:Running loss: 4.3528968542814255
[2018-04-17 20:01:59.294241]: [Epoch: 318(31.83183183183183%): Data: 50.66666666666667%]:Running loss: 8.488138109445572
[2018-04-17 20:02:03.723017]: Test set accuracy: 94.33962264150944% ,loss = 5.441074818372726
[2018-04-17 20:02:03.868906]: ====================
[2018-04-17 20:02:03.878932]: Elapsed time since starting training: 0:41:30.043563
[2018-04-17 20:02:03.885450]: Estimated time left: 0:33:29.950421
[2018-04-17 20:02:03.889460]: ====================
[2018-04-17 20:02:03.958644]: [Epoch: 319(31.931931931931935%): Data: 0.0%]:Running loss: 0.21764299273490906
[2018-04-17 20:02:05.599007]: [Epoch: 319(31.931931931931935%): Data: 25.333333333333336%]:Running loss: 4.352851539850235
[2018-04-17 20:02:07.248893]: [Epoch: 319(31.931931931931935%): Data: 50.66666666666667%]:Running loss: 8.488049060106277
[2018-04-17 20:02:11.612496]: Test set accuracy: 94.33962264150944% ,loss = 5.441012606024742
[2018-04-17 20:02:11.807514]: ====================
[2018-04-17 20:02:11.814533]: Elapsed time since starting training: 0:41:37.979164
[2018-04-17 20:02:11.819045]: Estimated time left: 0:33:22.016324
[2018-04-17 20:02:11.823557]: ====================
[2018-04-17 20:02:11.895247]: [Epoch: 320(32.032032032032035%): Data: 0.0%]:Running loss: 0.21764050424098969
[2018-04-17 20:02:13.564689]: [Epoch: 320(32.032032032032035%): Data: 25.333333333333336%]:Running loss: 4.352804780006409
[2018-04-17 20:02:15.333389]: [Epoch: 320(32.032032032032035%): Data: 50.66666666666667%]:Running loss: 8.487958684563637
[2018-04-17 20:02:19.879477]: Test set accuracy: 94.33962264150944% ,loss = 5.440958961844444
[2018-04-17 20:02:20.023360]: ====================
[2018-04-17 20:02:20.028373]: Elapsed time since starting training: 0:41:46.193004
[2018-04-17 20:02:20.033387]: Estimated time left: 0:33:13.801982
[2018-04-17 20:02:20.056949]: ====================
[2018-04-17 20:02:20.130645]: [Epoch: 321(32.13213213213213%): Data: 0.0%]:Running loss: 0.21763835847377777
[2018-04-17 20:02:21.841695]: [Epoch: 321(32.13213213213213%): Data: 25.333333333333336%]:Running loss: 4.352760523557663
[2018-04-17 20:02:23.428415]: [Epoch: 321(32.13213213213213%): Data: 50.66666666666667%]:Running loss: 8.487870678305626
[2018-04-17 20:02:27.816582]: Test set accuracy: 94.33962264150944% ,loss = 5.440905690193176
[2018-04-17 20:02:27.983024]: ====================
[2018-04-17 20:02:27.990545]: Elapsed time since starting training: 0:41:54.154675
[2018-04-17 20:02:27.995559]: Estimated time left: 0:33:05.840312
[2018-04-17 20:02:28.000070]: ====================
[2018-04-17 20:02:28.074770]: [Epoch: 322(32.232232232232235%): Data: 0.0%]:Running loss: 0.21763622760772705
[2018-04-17 20:02:29.742202]: [Epoch: 322(32.232232232232235%): Data: 25.333333333333336%]:Running loss: 4.35271780192852
[2018-04-17 20:02:31.390084]: [Epoch: 322(32.232232232232235%): Data: 50.66666666666667%]:Running loss: 8.487788662314415
[2018-04-17 20:02:35.814355]: Test set accuracy: 94.33962264150944% ,loss = 5.44084720313549
[2018-04-17 20:02:35.984809]: ====================
[2018-04-17 20:02:35.989320]: Elapsed time since starting training: 0:42:02.153951
[2018-04-17 20:02:35.993833]: Estimated time left: 0:32:57.841536
[2018-04-17 20:02:35.999347]: ====================
[2018-04-17 20:02:36.072542]: [Epoch: 323(32.33233233233233%): Data: 0.0%]:Running loss: 0.21763388812541962
[2018-04-17 20:02:37.593085]: [Epoch: 323(32.33233233233233%): Data: 25.333333333333336%]:Running loss: 4.35267448425293
[2018-04-17 20:02:39.149724]: [Epoch: 323(32.33233233233233%): Data: 50.66666666666667%]:Running loss: 8.48770572245121
[2018-04-17 20:02:43.482750]: Test set accuracy: 94.33962264150944% ,loss = 5.440796539187431
[2018-04-17 20:02:43.608083]: ====================
[2018-04-17 20:02:43.612595]: Elapsed time since starting training: 0:42:09.777226
[2018-04-17 20:02:43.617608]: Estimated time left: 0:32:50.217761
[2018-04-17 20:02:43.622120]: ====================
[2018-04-17 20:02:43.699327]: [Epoch: 324(32.432432432432435%): Data: 0.0%]:Running loss: 0.21763186156749725
[2018-04-17 20:02:45.241927]: [Epoch: 324(32.432432432432435%): Data: 25.333333333333336%]:Running loss: 4.352631479501724
[2018-04-17 20:02:46.832657]: [Epoch: 324(32.432432432432435%): Data: 50.66666666666667%]:Running loss: 8.487620815634727
[2018-04-17 20:02:51.185230]: Test set accuracy: 94.33962264150944% ,loss = 5.440745875239372
[2018-04-17 20:02:51.366212]: ====================
[2018-04-17 20:02:51.372228]: Elapsed time since starting training: 0:42:17.536859
[2018-04-17 20:02:51.377743]: Estimated time left: 0:32:42.458128
[2018-04-17 20:02:51.386265]: ====================
[2018-04-17 20:02:51.457955]: [Epoch: 325(32.532532532532535%): Data: 0.0%]:Running loss: 0.2176298350095749
[2018-04-17 20:02:53.022616]: [Epoch: 325(32.532532532532535%): Data: 25.333333333333336%]:Running loss: 4.35258986055851
[2018-04-17 20:02:54.539148]: [Epoch: 325(32.532532532532535%): Data: 50.66666666666667%]:Running loss: 8.487540870904922
[2018-04-17 20:02:58.850622]: Test set accuracy: 94.33962264150944% ,loss = 5.440688878297806
[2018-04-17 20:02:58.988011]: ====================
[2018-04-17 20:02:59.010572]: Elapsed time since starting training: 0:42:25.175203
[2018-04-17 20:02:59.034635]: Estimated time left: 0:32:34.800734
[2018-04-17 20:02:59.040651]: ====================
[2018-04-17 20:02:59.112844]: [Epoch: 326(32.63263263263263%): Data: 0.0%]:Running loss: 0.21762755513191223
[2018-04-17 20:03:00.637899]: [Epoch: 326(32.63263263263263%): Data: 25.333333333333336%]:Running loss: 4.352549836039543
[2018-04-17 20:03:02.148916]: [Epoch: 326(32.63263263263263%): Data: 50.66666666666667%]:Running loss: 8.487462043762207
[2018-04-17 20:03:06.539090]: Test set accuracy: 94.33962264150944% ,loss = 5.4406434297561646
[2018-04-17 20:03:06.710545]: ====================
[2018-04-17 20:03:06.723079]: Elapsed time since starting training: 0:42:32.887710
[2018-04-17 20:03:06.737617]: Estimated time left: 0:32:27.097752
[2018-04-17 20:03:06.742631]: ====================
[2018-04-17 20:03:06.818833]: [Epoch: 327(32.732732732732735%): Data: 0.0%]:Running loss: 0.21762573719024658
[2018-04-17 20:03:08.506320]: [Epoch: 327(32.732732732732735%): Data: 25.333333333333336%]:Running loss: 4.352509871125221
[2018-04-17 20:03:10.018340]: [Epoch: 327(32.732732732732735%): Data: 50.66666666666667%]:Running loss: 8.48738431930542
[2018-04-17 20:03:14.273656]: Test set accuracy: 94.33962264150944% ,loss = 5.440598726272583
[2018-04-17 20:03:14.436589]: ====================
[2018-04-17 20:03:14.441101]: Elapsed time since starting training: 0:42:40.605732
[2018-04-17 20:03:14.446114]: Estimated time left: 0:32:19.389255
[2018-04-17 20:03:14.450626]: ====================
[2018-04-17 20:03:14.521816]: [Epoch: 328(32.83283283283283%): Data: 0.0%]:Running loss: 0.21762394905090332
[2018-04-17 20:03:16.057399]: [Epoch: 328(32.83283283283283%): Data: 25.333333333333336%]:Running loss: 4.352470368146896
[2018-04-17 20:03:17.579446]: [Epoch: 328(32.83283283283283%): Data: 50.66666666666667%]:Running loss: 8.487307399511337
[2018-04-17 20:03:21.834761]: Test set accuracy: 94.33962264150944% ,loss = 5.440544709563255
[2018-04-17 20:03:22.000701]: ====================
[2018-04-17 20:03:22.005715]: Elapsed time since starting training: 0:42:48.170346
[2018-04-17 20:03:22.010227]: Estimated time left: 0:32:11.825142
[2018-04-17 20:03:22.015240]: ====================
[2018-04-17 20:03:22.091443]: [Epoch: 329(32.932932932932935%): Data: 0.0%]:Running loss: 0.2176217883825302
[2018-04-17 20:03:23.609479]: [Epoch: 329(32.932932932932935%): Data: 25.333333333333336%]:Running loss: 4.352432429790497
[2018-04-17 20:03:25.322534]: [Epoch: 329(32.932932932932935%): Data: 50.66666666666667%]:Running loss: 8.487233653664589
[2018-04-17 20:03:30.111268]: Test set accuracy: 94.33962264150944% ,loss = 5.4404933005571365
[2018-04-17 20:03:30.287738]: ====================
[2018-04-17 20:03:30.332857]: Elapsed time since starting training: 0:42:56.487963
[2018-04-17 20:03:30.356420]: Estimated time left: 0:32:03.478949
[2018-04-17 20:03:30.361934]: ====================
[2018-04-17 20:03:30.438136]: [Epoch: 330(33.033033033033036%): Data: 0.0%]:Running loss: 0.21761973202228546
[2018-04-17 20:03:32.025859]: [Epoch: 330(33.033033033033036%): Data: 25.333333333333336%]:Running loss: 4.352394193410873
[2018-04-17 20:03:33.617090]: [Epoch: 330(33.033033033033036%): Data: 50.66666666666667%]:Running loss: 8.487160325050354
[2018-04-17 20:03:38.352180]: Test set accuracy: 94.33962264150944% ,loss = 5.440453439950943
[2018-04-17 20:03:38.500582]: ====================
[2018-04-17 20:03:38.506089]: Elapsed time since starting training: 0:43:04.670720
[2018-04-17 20:03:38.512105]: Estimated time left: 0:31:55.323264
[2018-04-17 20:03:38.517620]: ====================
[2018-04-17 20:03:38.592319]: [Epoch: 331(33.133133133133136%): Data: 0.0%]:Running loss: 0.21761813759803772
[2018-04-17 20:03:40.103837]: [Epoch: 331(33.133133133133136%): Data: 25.333333333333336%]:Running loss: 4.352357417345047
[2018-04-17 20:03:41.985343]: [Epoch: 331(33.133133133133136%): Data: 50.66666666666667%]:Running loss: 8.48708787560463
[2018-04-17 20:03:46.821199]: Test set accuracy: 94.33962264150944% ,loss = 5.440410226583481
[2018-04-17 20:03:47.016719]: ====================
[2018-04-17 20:03:47.024740]: Elapsed time since starting training: 0:43:13.188870
[2018-04-17 20:03:47.030756]: Estimated time left: 0:31:46.804613
[2018-04-17 20:03:47.036772]: ====================
[2018-04-17 20:03:47.117487]: [Epoch: 332(33.233233233233236%): Data: 0.0%]:Running loss: 0.21761640906333923
[2018-04-17 20:03:48.864632]: [Epoch: 332(33.233233233233236%): Data: 25.333333333333336%]:Running loss: 4.352320641279221
[2018-04-17 20:03:50.524045]: [Epoch: 332(33.233233233233236%): Data: 50.66666666666667%]:Running loss: 8.487016886472702
[2018-04-17 20:03:55.059104]: Test set accuracy: 94.33962264150944% ,loss = 5.440367013216019
[2018-04-17 20:03:55.268159]: ====================
[2018-04-17 20:03:55.275680]: Elapsed time since starting training: 0:43:21.440311
[2018-04-17 20:03:55.281696]: Estimated time left: 0:31:38.553673
[2018-04-17 20:03:55.287210]: ====================
[2018-04-17 20:03:55.406027]: [Epoch: 333(33.33333333333333%): Data: 0.0%]:Running loss: 0.21761468052864075
[2018-04-17 20:03:57.123093]: [Epoch: 333(33.33333333333333%): Data: 25.333333333333336%]:Running loss: 4.352285951375961
[2018-04-17 20:03:58.756435]: [Epoch: 333(33.33333333333333%): Data: 50.66666666666667%]:Running loss: 8.4869484603405
[2018-04-17 20:04:03.497541]: Test set accuracy: 94.33962264150944% ,loss = 5.440316721796989
[2018-04-17 20:04:03.774779]: ====================
[2018-04-17 20:04:03.779290]: Elapsed time since starting training: 0:43:29.943921
[2018-04-17 20:04:03.785808]: Estimated time left: 0:31:30.049561
[2018-04-17 20:04:03.790821]: ====================
[2018-04-17 20:04:03.858000]: [Epoch: 334(33.433433433433436%): Data: 0.0%]:Running loss: 0.21761266887187958
[2018-04-17 20:04:05.482820]: [Epoch: 334(33.433433433433436%): Data: 25.333333333333336%]:Running loss: 4.352250412106514
[2018-04-17 20:04:07.260053]: [Epoch: 334(33.433433433433436%): Data: 50.66666666666667%]:Running loss: 8.486880540847778
[2018-04-17 20:04:12.368136]: Test set accuracy: 94.33962264150944% ,loss = 5.440279096364975
[2018-04-17 20:04:12.585714]: ====================
[2018-04-17 20:04:12.591229]: Elapsed time since starting training: 0:43:38.755359
[2018-04-17 20:04:12.598751]: Estimated time left: 0:31:21.237120
[2018-04-17 20:04:12.604765]: ====================
[2018-04-17 20:04:12.675955]: [Epoch: 335(33.533533533533536%): Data: 0.0%]:Running loss: 0.217611163854599
[2018-04-17 20:04:14.361437]: [Epoch: 335(33.533533533533536%): Data: 25.333333333333336%]:Running loss: 4.352216511964798
[2018-04-17 20:04:16.064965]: [Epoch: 335(33.533533533533536%): Data: 50.66666666666667%]:Running loss: 8.486812710762024
[2018-04-17 20:04:20.618574]: Test set accuracy: 94.33962264150944% ,loss = 5.440231412649155
[2018-04-17 20:04:20.824121]: ====================
[2018-04-17 20:04:20.832644]: Elapsed time since starting training: 0:43:46.996773
[2018-04-17 20:04:20.837155]: Estimated time left: 0:31:12.998214
[2018-04-17 20:04:20.841165]: ====================
[2018-04-17 20:04:20.913859]: [Epoch: 336(33.633633633633636%): Data: 0.0%]:Running loss: 0.2176092565059662
[2018-04-17 20:04:22.464983]: [Epoch: 336(33.633633633633636%): Data: 25.333333333333336%]:Running loss: 4.352182477712631
[2018-04-17 20:04:24.014604]: [Epoch: 336(33.633633633633636%): Data: 50.66666666666667%]:Running loss: 8.486747205257416
[2018-04-17 20:04:28.327572]: Test set accuracy: 94.33962264150944% ,loss = 5.440189689397812
[2018-04-17 20:04:28.464937]: ====================
[2018-04-17 20:04:28.472958]: Elapsed time since starting training: 0:43:54.637589
[2018-04-17 20:04:28.486996]: Estimated time left: 0:31:05.348373
[2018-04-17 20:04:28.517077]: ====================
[2018-04-17 20:04:28.601300]: [Epoch: 337(33.733733733733736%): Data: 0.0%]:Running loss: 0.21760758757591248
[2018-04-17 20:04:30.153427]: [Epoch: 337(33.733733733733736%): Data: 25.333333333333336%]:Running loss: 4.352149844169617
[2018-04-17 20:04:31.610802]: [Epoch: 337(33.733733733733736%): Data: 50.66666666666667%]:Running loss: 8.486684054136276
[2018-04-17 20:04:35.939813]: Test set accuracy: 94.33962264150944% ,loss = 5.440157651901245
[2018-04-17 20:04:36.163407]: ====================
[2018-04-17 20:04:36.168922]: Elapsed time since starting training: 0:44:02.333553
[2018-04-17 20:04:36.173935]: Estimated time left: 0:30:57.661434
[2018-04-17 20:04:36.178949]: ====================
[2018-04-17 20:04:36.317317]: [Epoch: 338(33.83383383383383%): Data: 0.0%]:Running loss: 0.2176063060760498
[2018-04-17 20:04:37.950659]: [Epoch: 338(33.83383383383383%): Data: 25.333333333333336%]:Running loss: 4.352117285132408
[2018-04-17 20:04:39.655192]: [Epoch: 338(33.83383383383383%): Data: 50.66666666666667%]:Running loss: 8.486620530486107
[2018-04-17 20:04:44.846496]: Test set accuracy: 94.33962264150944% ,loss = 5.440112203359604
[2018-04-17 20:04:45.080116]: ====================
[2018-04-17 20:04:45.087135]: Elapsed time since starting training: 0:44:11.251766
[2018-04-17 20:04:45.093151]: Estimated time left: 0:30:48.742218
[2018-04-17 20:04:45.098165]: ====================
[2018-04-17 20:04:45.186901]: [Epoch: 339(33.933933933933936%): Data: 0.0%]:Running loss: 0.21760448813438416
[2018-04-17 20:04:46.959114]: [Epoch: 339(33.933933933933936%): Data: 25.333333333333336%]:Running loss: 4.352085396647453
[2018-04-17 20:04:48.643091]: [Epoch: 339(33.933933933933936%): Data: 50.66666666666667%]:Running loss: 8.486558392643929
[2018-04-17 20:04:53.923632]: Test set accuracy: 94.33962264150944% ,loss = 5.440077558159828
[2018-04-17 20:04:54.167781]: ====================
[2018-04-17 20:04:54.187834]: Elapsed time since starting training: 0:44:20.351964
[2018-04-17 20:04:54.217914]: Estimated time left: 0:30:39.617455
[2018-04-17 20:04:54.222426]: ====================
[2018-04-17 20:04:54.296122]: [Epoch: 340(34.034034034034036%): Data: 0.0%]:Running loss: 0.21760310232639313
[2018-04-17 20:04:56.004170]: [Epoch: 340(34.034034034034036%): Data: 25.333333333333336%]:Running loss: 4.352053880691528
[2018-04-17 20:04:57.651049]: [Epoch: 340(34.034034034034036%): Data: 50.66666666666667%]:Running loss: 8.486497223377228
[2018-04-17 20:05:02.465851]: Test set accuracy: 94.33962264150944% ,loss = 5.440030992031097
[2018-04-17 20:05:02.640817]: ====================
[2018-04-17 20:05:02.645329]: Elapsed time since starting training: 0:44:28.809960
[2018-04-17 20:05:02.650843]: Estimated time left: 0:30:31.184526
[2018-04-17 20:05:02.657361]: ====================
[2018-04-17 20:05:02.734065]: [Epoch: 341(34.134134134134136%): Data: 0.0%]:Running loss: 0.2176012396812439
[2018-04-17 20:05:04.646149]: [Epoch: 341(34.134134134134136%): Data: 25.333333333333336%]:Running loss: 4.352023333311081
[2018-04-17 20:05:06.413348]: [Epoch: 341(34.134134134134136%): Data: 50.66666666666667%]:Running loss: 8.48643784224987
[2018-04-17 20:05:10.898774]: Test set accuracy: 94.33962264150944% ,loss = 5.439998954534531
[2018-04-17 20:05:11.029121]: ====================
[2018-04-17 20:05:11.033634]: Elapsed time since starting training: 0:44:37.198265
[2018-04-17 20:05:11.038145]: Estimated time left: 0:30:22.797224
[2018-04-17 20:05:11.050177]: ====================
[2018-04-17 20:05:11.148939]: [Epoch: 342(34.234234234234236%): Data: 0.0%]:Running loss: 0.21759995818138123
[2018-04-17 20:05:12.760224]: [Epoch: 342(34.234234234234236%): Data: 25.333333333333336%]:Running loss: 4.351993203163147
[2018-04-17 20:05:14.327892]: [Epoch: 342(34.234234234234236%): Data: 50.66666666666667%]:Running loss: 8.486379221081734
[2018-04-17 20:05:18.819335]: Test set accuracy: 94.33962264150944% ,loss = 5.439957603812218
[2018-04-17 20:05:19.010844]: ====================
[2018-04-17 20:05:19.016860]: Elapsed time since starting training: 0:44:45.181491
[2018-04-17 20:05:19.021372]: Estimated time left: 0:30:14.813997
[2018-04-17 20:05:19.026386]: ====================
[2018-04-17 20:05:19.095069]: [Epoch: 343(34.33433433433433%): Data: 0.0%]:Running loss: 0.2175983041524887
[2018-04-17 20:05:20.598065]: [Epoch: 343(34.33433433433433%): Data: 25.333333333333336%]:Running loss: 4.351963311433792
[2018-04-17 20:05:22.231407]: [Epoch: 343(34.33433433433433%): Data: 50.66666666666667%]:Running loss: 8.48632150888443
[2018-04-17 20:05:26.597016]: Test set accuracy: 94.33962264150944% ,loss = 5.439925566315651
[2018-04-17 20:05:26.771981]: ====================
[2018-04-17 20:05:26.777496]: Elapsed time since starting training: 0:44:52.942127
[2018-04-17 20:05:26.782008]: Estimated time left: 0:30:07.053361
[2018-04-17 20:05:26.787022]: ====================
[2018-04-17 20:05:26.859214]: [Epoch: 344(34.434434434434436%): Data: 0.0%]:Running loss: 0.21759702265262604
[2018-04-17 20:05:28.525645]: [Epoch: 344(34.434434434434436%): Data: 25.333333333333336%]:Running loss: 4.351935192942619
[2018-04-17 20:05:30.028139]: [Epoch: 344(34.434434434434436%): Data: 50.66666666666667%]:Running loss: 8.486265659332275
[2018-04-17 20:05:34.348126]: Test set accuracy: 94.33962264150944% ,loss = 5.439889058470726
[2018-04-17 20:05:34.526601]: ====================
[2018-04-17 20:05:34.531121]: Elapsed time since starting training: 0:45:00.695752
[2018-04-17 20:05:34.536628]: Estimated time left: 0:29:59.298741
[2018-04-17 20:05:34.542142]: ====================
[2018-04-17 20:05:34.616339]: [Epoch: 345(34.53453453453454%): Data: 0.0%]:Running loss: 0.21759556233882904
[2018-04-17 20:05:36.148413]: [Epoch: 345(34.53453453453454%): Data: 25.333333333333336%]:Running loss: 4.351906880736351
[2018-04-17 20:05:37.733127]: [Epoch: 345(34.53453453453454%): Data: 50.66666666666667%]:Running loss: 8.486210867762566
[2018-04-17 20:05:42.009998]: Test set accuracy: 94.33962264150944% ,loss = 5.439850687980652
[2018-04-17 20:05:42.143354]: ====================
[2018-04-17 20:05:42.148367]: Elapsed time since starting training: 0:45:08.312998
[2018-04-17 20:05:42.153380]: Estimated time left: 0:29:51.681989
[2018-04-17 20:05:42.158394]: ====================
[2018-04-17 20:05:42.280718]: [Epoch: 346(34.63463463463464%): Data: 0.0%]:Running loss: 0.21759402751922607
[2018-04-17 20:05:43.778201]: [Epoch: 346(34.63463463463464%): Data: 25.333333333333336%]:Running loss: 4.351879298686981
[2018-04-17 20:05:45.383471]: [Epoch: 346(34.63463463463464%): Data: 50.66666666666667%]:Running loss: 8.48615700006485
[2018-04-17 20:05:49.672875]: Test set accuracy: 94.33962264150944% ,loss = 5.439814552664757
[2018-04-17 20:05:49.813248]: ====================
[2018-04-17 20:05:49.817761]: Elapsed time since starting training: 0:45:15.981889
[2018-04-17 20:05:49.821771]: Estimated time left: 0:29:44.014100
[2018-04-17 20:05:49.826283]: ====================
[2018-04-17 20:05:49.947105]: [Epoch: 347(34.73473473473474%): Data: 0.0%]:Running loss: 0.21759258210659027
[2018-04-17 20:05:51.375403]: [Epoch: 347(34.73473473473474%): Data: 25.333333333333336%]:Running loss: 4.351850628852844
[2018-04-17 20:05:52.895945]: [Epoch: 347(34.73473473473474%): Data: 50.66666666666667%]:Running loss: 8.486101940274239
[2018-04-17 20:05:57.486651]: Test set accuracy: 94.33962264150944% ,loss = 5.439784005284309
[2018-04-17 20:05:57.755366]: ====================
[2018-04-17 20:05:57.760881]: Elapsed time since starting training: 0:45:23.925512
[2018-04-17 20:05:57.765894]: Estimated time left: 0:29:36.069976
[2018-04-17 20:05:57.770405]: ====================
[2018-04-17 20:05:57.845606]: [Epoch: 348(34.83483483483483%): Data: 0.0%]:Running loss: 0.21759136021137238
[2018-04-17 20:05:59.353615]: [Epoch: 348(34.83483483483483%): Data: 25.333333333333336%]:Running loss: 4.351823046803474
[2018-04-17 20:06:00.854110]: [Epoch: 348(34.83483483483483%): Data: 50.66666666666667%]:Running loss: 8.486049100756645
[2018-04-17 20:06:05.296421]: Test set accuracy: 94.33962264150944% ,loss = 5.439747124910355
[2018-04-17 20:06:05.474395]: ====================
[2018-04-17 20:06:05.479408]: Elapsed time since starting training: 0:45:31.644039
[2018-04-17 20:06:05.484422]: Estimated time left: 0:29:28.350947
[2018-04-17 20:06:05.490939]: ====================
[2018-04-17 20:06:05.566139]: [Epoch: 349(34.93493493493494%): Data: 0.0%]:Running loss: 0.21758988499641418
[2018-04-17 20:06:07.062623]: [Epoch: 349(34.93493493493494%): Data: 25.333333333333336%]:Running loss: 4.3517968356609344
[2018-04-17 20:06:08.500446]: [Epoch: 349(34.93493493493494%): Data: 50.66666666666667%]:Running loss: 8.485997378826141
[2018-04-17 20:06:12.912177]: Test set accuracy: 94.33962264150944% ,loss = 5.439715459942818
[2018-04-17 20:06:13.038011]: ====================
[2018-04-17 20:06:13.043025]: Elapsed time since starting training: 0:45:39.207656
[2018-04-17 20:06:13.048038]: Estimated time left: 0:29:20.787331
[2018-04-17 20:06:13.054555]: ====================
[2018-04-17 20:06:13.152816]: [Epoch: 350(35.03503503503504%): Data: 0.0%]:Running loss: 0.2175886183977127
[2018-04-17 20:06:14.643781]: [Epoch: 350(35.03503503503504%): Data: 25.333333333333336%]:Running loss: 4.351771697402
[2018-04-17 20:06:16.102660]: [Epoch: 350(35.03503503503504%): Data: 50.66666666666667%]:Running loss: 8.48594805598259
[2018-04-17 20:06:20.437185]: Test set accuracy: 94.33962264150944% ,loss = 5.439690873026848
[2018-04-17 20:06:20.620674]: ====================
[2018-04-17 20:06:20.626188]: Elapsed time since starting training: 0:45:46.790819
[2018-04-17 20:06:20.631201]: Estimated time left: 0:29:13.204168
[2018-04-17 20:06:20.636215]: ====================
[2018-04-17 20:06:20.709409]: [Epoch: 351(35.13513513513514%): Data: 0.0%]:Running loss: 0.2175876349210739
[2018-04-17 20:06:22.373334]: [Epoch: 351(35.13513513513514%): Data: 25.333333333333336%]:Running loss: 4.3517467230558395
[2018-04-17 20:06:23.919946]: [Epoch: 351(35.13513513513514%): Data: 50.66666666666667%]:Running loss: 8.485899358987808
[2018-04-17 20:06:28.416402]: Test set accuracy: 94.33962264150944% ,loss = 5.439655110239983
[2018-04-17 20:06:28.596381]: ====================
[2018-04-17 20:06:28.601895]: Elapsed time since starting training: 0:45:54.766025
[2018-04-17 20:06:28.606908]: Estimated time left: 0:29:05.228461
[2018-04-17 20:06:28.613927]: ====================
[2018-04-17 20:06:28.684114]: [Epoch: 352(35.23523523523524%): Data: 0.0%]:Running loss: 0.2175862044095993
[2018-04-17 20:06:30.189116]: [Epoch: 352(35.23523523523524%): Data: 25.333333333333336%]:Running loss: 4.35172076523304
[2018-04-17 20:06:31.767313]: [Epoch: 352(35.23523523523524%): Data: 50.66666666666667%]:Running loss: 8.48585033416748
[2018-04-17 20:06:36.318914]: Test set accuracy: 94.33962264150944% ,loss = 5.439618229866028
[2018-04-17 20:06:36.505913]: ====================
[2018-04-17 20:06:36.511427]: Elapsed time since starting training: 0:46:02.676058
[2018-04-17 20:06:36.516440]: Estimated time left: 0:28:57.318929
[2018-04-17 20:06:36.520952]: ====================
[2018-04-17 20:06:36.590136]: [Epoch: 353(35.33533533533533%): Data: 0.0%]:Running loss: 0.2175847291946411
[2018-04-17 20:06:38.222477]: [Epoch: 353(35.33533533533533%): Data: 25.333333333333336%]:Running loss: 4.3516963720321655
[2018-04-17 20:06:39.762070]: [Epoch: 353(35.33533533533533%): Data: 50.66666666666667%]:Running loss: 8.485801935195923
[2018-04-17 20:06:44.322697]: Test set accuracy: 94.33962264150944% ,loss = 5.439591407775879
[2018-04-17 20:06:44.493151]: ====================
[2018-04-17 20:06:44.497662]: Elapsed time since starting training: 0:46:10.662293
[2018-04-17 20:06:44.502174]: Estimated time left: 0:28:49.333195
[2018-04-17 20:06:44.508692]: ====================
[2018-04-17 20:06:44.577374]: [Epoch: 354(35.43543543543544%): Data: 0.0%]:Running loss: 0.21758365631103516
[2018-04-17 20:06:46.121481]: [Epoch: 354(35.43543543543544%): Data: 25.333333333333336%]:Running loss: 4.351672410964966
[2018-04-17 20:06:47.792423]: [Epoch: 354(35.43543543543544%): Data: 50.66666666666667%]:Running loss: 8.485755503177643
[2018-04-17 20:06:52.419225]: Test set accuracy: 94.33962264150944% ,loss = 5.439559370279312
[2018-04-17 20:06:52.599707]: ====================
[2018-04-17 20:06:52.609230]: Elapsed time since starting training: 0:46:18.773861
[2018-04-17 20:06:52.615246]: Estimated time left: 0:28:41.220624
[2018-04-17 20:06:52.620762]: ====================
[2018-04-17 20:06:52.709497]: [Epoch: 355(35.53553553553554%): Data: 0.0%]:Running loss: 0.21758237481117249
[2018-04-17 20:06:54.355374]: [Epoch: 355(35.53553553553554%): Data: 25.333333333333336%]:Running loss: 4.351649358868599
[2018-04-17 20:06:56.180226]: [Epoch: 355(35.53553553553554%): Data: 50.66666666666667%]:Running loss: 8.48571090400219
[2018-04-17 20:07:01.464276]: Test set accuracy: 94.33962264150944% ,loss = 5.439538881182671
[2018-04-17 20:07:01.690879]: ====================
[2018-04-17 20:07:01.696895]: Elapsed time since starting training: 0:46:27.861526
[2018-04-17 20:07:01.708426]: Estimated time left: 0:28:32.127444
[2018-04-17 20:07:01.713439]: ====================
[2018-04-17 20:07:01.791648]: [Epoch: 356(35.63563563563564%): Data: 0.0%]:Running loss: 0.21758155524730682
[2018-04-17 20:07:03.512221]: [Epoch: 356(35.63563563563564%): Data: 25.333333333333336%]:Running loss: 4.351625695824623
[2018-04-17 20:07:04.789117]: [Epoch: 356(35.63563563563564%): Data: 50.66666666666667%]:Running loss: 8.48566448688507
[2018-04-17 20:07:09.806960]: Test set accuracy: 94.33962264150944% ,loss = 5.439508706331253
[2018-04-17 20:07:10.065647]: ====================
[2018-04-17 20:07:10.075173]: Elapsed time since starting training: 0:46:36.239804
[2018-04-17 20:07:10.081690]: Estimated time left: 0:28:23.753679
[2018-04-17 20:07:10.087204]: ====================
[2018-04-17 20:07:10.165412]: [Epoch: 357(35.73573573573574%): Data: 0.0%]:Running loss: 0.21758034825325012
[2018-04-17 20:07:11.965202]: [Epoch: 357(35.73573573573574%): Data: 25.333333333333336%]:Running loss: 4.351603701710701
[2018-04-17 20:07:13.736412]: [Epoch: 357(35.73573573573574%): Data: 50.66666666666667%]:Running loss: 8.485621526837349
[2018-04-17 20:07:18.604355]: Test set accuracy: 94.33962264150944% ,loss = 5.439478158950806
[2018-04-17 20:07:18.732195]: ====================
[2018-04-17 20:07:18.736707]: Elapsed time since starting training: 0:46:44.901338
[2018-04-17 20:07:18.741721]: Estimated time left: 0:28:15.093648
[2018-04-17 20:07:18.746233]: ====================
[2018-04-17 20:07:18.820430]: [Epoch: 358(35.83583583583583%): Data: 0.0%]:Running loss: 0.21757912635803223
[2018-04-17 20:07:20.490371]: [Epoch: 358(35.83583583583583%): Data: 25.333333333333336%]:Running loss: 4.351580187678337
[2018-04-17 20:07:22.095638]: [Epoch: 358(35.83583583583583%): Data: 50.66666666666667%]:Running loss: 8.485576033592224
[2018-04-17 20:07:26.802153]: Test set accuracy: 94.33962264150944% ,loss = 5.439449846744537
[2018-04-17 20:07:26.935508]: ====================
[2018-04-17 20:07:26.940521]: Elapsed time since starting training: 0:46:53.104650
[2018-04-17 20:07:26.945033]: Estimated time left: 0:28:06.890336
[2018-04-17 20:07:26.950046]: ====================
[2018-04-17 20:07:27.065854]: [Epoch: 359(35.93593593593594%): Data: 0.0%]:Running loss: 0.2175779938697815
[2018-04-17 20:07:28.692179]: [Epoch: 359(35.93593593593594%): Data: 25.333333333333336%]:Running loss: 4.351559087634087
[2018-04-17 20:07:30.280903]: [Epoch: 359(35.93593593593594%): Data: 50.66666666666667%]:Running loss: 8.485534951090813
[2018-04-17 20:07:35.020505]: Test set accuracy: 94.33962264150944% ,loss = 5.439421534538269
[2018-04-17 20:07:35.159374]: ====================
[2018-04-17 20:07:35.164889]: Elapsed time since starting training: 0:47:01.329520
[2018-04-17 20:07:35.169903]: Estimated time left: 0:27:58.665466
[2018-04-17 20:07:35.174917]: ====================
[2018-04-17 20:07:35.264154]: [Epoch: 360(36.03603603603604%): Data: 0.0%]:Running loss: 0.21757686138153076
[2018-04-17 20:07:36.923065]: [Epoch: 360(36.03603603603604%): Data: 25.333333333333336%]:Running loss: 4.35153803229332
[2018-04-17 20:07:38.483213]: [Epoch: 360(36.03603603603604%): Data: 50.66666666666667%]:Running loss: 8.485493376851082
[2018-04-17 20:07:43.238858]: Test set accuracy: 94.33962264150944% ,loss = 5.439392849802971
[2018-04-17 20:07:43.387253]: ====================
[2018-04-17 20:07:43.408811]: Elapsed time since starting training: 0:47:09.573442
[2018-04-17 20:07:43.416330]: Estimated time left: 0:27:50.419039
[2018-04-17 20:07:43.420842]: ====================
[2018-04-17 20:07:43.494538]: [Epoch: 361(36.13613613613614%): Data: 0.0%]:Running loss: 0.21757571399211884
[2018-04-17 20:07:45.000542]: [Epoch: 361(36.13613613613614%): Data: 25.333333333333336%]:Running loss: 4.351515978574753
[2018-04-17 20:07:46.566707]: [Epoch: 361(36.13613613613614%): Data: 50.66666666666667%]:Running loss: 8.485451057553291
[2018-04-17 20:07:51.107280]: Test set accuracy: 94.33962264150944% ,loss = 5.439376458525658
[2018-04-17 20:07:51.280241]: ====================
[2018-04-17 20:07:51.316336]: Elapsed time since starting training: 0:47:17.480967
[2018-04-17 20:07:51.323857]: Estimated time left: 0:27:42.511512
[2018-04-17 20:07:51.344410]: ====================
[2018-04-17 20:07:51.429135]: [Epoch: 362(36.23623623623624%): Data: 0.0%]:Running loss: 0.2175750583410263
[2018-04-17 20:07:53.012347]: [Epoch: 362(36.23623623623624%): Data: 25.333333333333336%]:Running loss: 4.3514953553676605
[2018-04-17 20:07:54.577508]: [Epoch: 362(36.23623623623624%): Data: 50.66666666666667%]:Running loss: 8.485411286354065
[2018-04-17 20:07:59.261963]: Test set accuracy: 94.33962264150944% ,loss = 5.43934591114521
[2018-04-17 20:07:59.494081]: ====================
[2018-04-17 20:07:59.500097]: Elapsed time since starting training: 0:47:25.664728
[2018-04-17 20:07:59.507616]: Estimated time left: 0:27:34.327753
[2018-04-17 20:07:59.517142]: ====================
[2018-04-17 20:07:59.598860]: [Epoch: 363(36.33633633633634%): Data: 0.0%]:Running loss: 0.2175738364458084
[2018-04-17 20:08:01.251263]: [Epoch: 363(36.33633633633634%): Data: 25.333333333333336%]:Running loss: 4.3514739871025085
[2018-04-17 20:08:02.879600]: [Epoch: 363(36.33633633633634%): Data: 50.66666666666667%]:Running loss: 8.485371232032776
[2018-04-17 20:08:07.488846]: Test set accuracy: 94.33962264150944% ,loss = 5.439325049519539
[2018-04-17 20:08:07.629720]: ====================
[2018-04-17 20:08:07.635736]: Elapsed time since starting training: 0:47:33.800367
[2018-04-17 20:08:07.640749]: Estimated time left: 0:27:26.194620
[2018-04-17 20:08:07.645763]: ====================
[2018-04-17 20:08:07.715448]: [Epoch: 364(36.43643643643644%): Data: 0.0%]:Running loss: 0.21757300198078156
[2018-04-17 20:08:08.985325]: [Epoch: 364(36.43643643643644%): Data: 25.333333333333336%]:Running loss: 4.351455330848694
[2018-04-17 20:08:10.275254]: [Epoch: 364(36.43643643643644%): Data: 50.66666666666667%]:Running loss: 8.485332012176514
[2018-04-17 20:08:14.957204]: Test set accuracy: 94.33962264150944% ,loss = 5.439300835132599
[2018-04-17 20:08:15.203864]: ====================
[2018-04-17 20:08:15.209379]: Elapsed time since starting training: 0:47:41.374010
[2018-04-17 20:08:15.215897]: Estimated time left: 0:27:18.619472
[2018-04-17 20:08:15.220910]: ====================
[2018-04-17 20:08:15.299619]: [Epoch: 365(36.53653653653654%): Data: 0.0%]:Running loss: 0.21757203340530396
[2018-04-17 20:08:17.051277]: [Epoch: 365(36.53653653653654%): Data: 25.333333333333336%]:Running loss: 4.3514354676008224
[2018-04-17 20:08:18.759820]: [Epoch: 365(36.53653653653654%): Data: 50.66666666666667%]:Running loss: 8.485294237732887
[2018-04-17 20:08:24.048884]: Test set accuracy: 94.33962264150944% ,loss = 5.439277365803719
[2018-04-17 20:08:24.292029]: ====================
[2018-04-17 20:08:24.297545]: Elapsed time since starting training: 0:47:50.462176
[2018-04-17 20:08:24.303560]: Estimated time left: 0:27:09.531809
[2018-04-17 20:08:24.314088]: ====================
[2018-04-17 20:08:24.388286]: [Epoch: 366(36.63663663663664%): Data: 0.0%]:Running loss: 0.21757109463214874
[2018-04-17 20:08:26.278312]: [Epoch: 366(36.63663663663664%): Data: 25.333333333333336%]:Running loss: 4.351415723562241
[2018-04-17 20:08:28.079602]: [Epoch: 366(36.63663663663664%): Data: 50.66666666666667%]:Running loss: 8.485256537795067
[2018-04-17 20:08:33.193198]: Test set accuracy: 94.33962264150944% ,loss = 5.4392509162425995
[2018-04-17 20:08:33.417796]: ====================
[2018-04-17 20:08:33.424814]: Elapsed time since starting training: 0:47:59.588943
[2018-04-17 20:08:33.430328]: Estimated time left: 0:27:00.405542
[2018-04-17 20:08:33.435342]: ====================
[2018-04-17 20:08:33.513049]: [Epoch: 367(36.73673673673674%): Data: 0.0%]:Running loss: 0.21757003664970398
[2018-04-17 20:08:35.425635]: [Epoch: 367(36.73673673673674%): Data: 25.333333333333336%]:Running loss: 4.351396664977074
[2018-04-17 20:08:37.257004]: [Epoch: 367(36.73673673673674%): Data: 50.66666666666667%]:Running loss: 8.485220432281494
[2018-04-17 20:08:42.207667]: Test set accuracy: 94.33962264150944% ,loss = 5.43922558426857
[2018-04-17 20:08:42.357064]: ====================
[2018-04-17 20:08:42.379123]: Elapsed time since starting training: 0:48:08.543253
[2018-04-17 20:08:42.400681]: Estimated time left: 0:26:51.434688
[2018-04-17 20:08:42.412211]: ====================
[2018-04-17 20:08:42.488413]: [Epoch: 368(36.83683683683684%): Data: 0.0%]:Running loss: 0.2175690233707428
[2018-04-17 20:08:44.056586]: [Epoch: 368(36.83683683683684%): Data: 25.333333333333336%]:Running loss: 4.351379215717316
[2018-04-17 20:08:45.641800]: [Epoch: 368(36.83683683683684%): Data: 50.66666666666667%]:Running loss: 8.485184222459793
[2018-04-17 20:08:50.029967]: Test set accuracy: 94.33962264150944% ,loss = 5.43920062482357
[2018-04-17 20:08:50.196409]: ====================
[2018-04-17 20:08:50.236516]: Elapsed time since starting training: 0:48:16.400646
[2018-04-17 20:08:50.245540]: Estimated time left: 0:26:43.589829
[2018-04-17 20:08:50.250053]: ====================
[2018-04-17 20:08:50.322745]: [Epoch: 369(36.93693693693694%): Data: 0.0%]:Running loss: 0.2175680249929428
[2018-04-17 20:08:51.856323]: [Epoch: 369(36.93693693693694%): Data: 25.333333333333336%]:Running loss: 4.351359710097313
[2018-04-17 20:08:53.441037]: [Epoch: 369(36.93693693693694%): Data: 50.66666666666667%]:Running loss: 8.485147774219513
[2018-04-17 20:08:57.938997]: Test set accuracy: 94.33962264150944% ,loss = 5.439184233546257
[2018-04-17 20:08:58.126496]: ====================
[2018-04-17 20:08:58.131007]: Elapsed time since starting training: 0:48:24.295638
[2018-04-17 20:08:58.137023]: Estimated time left: 0:26:35.698346
[2018-04-17 20:08:58.141535]: ====================
[2018-04-17 20:08:58.217237]: [Epoch: 370(37.03703703703704%): Data: 0.0%]:Running loss: 0.21756736934185028
[2018-04-17 20:08:59.798943]: [Epoch: 370(37.03703703703704%): Data: 25.333333333333336%]:Running loss: 4.351342350244522
[2018-04-17 20:09:01.468381]: [Epoch: 370(37.03703703703704%): Data: 50.66666666666667%]:Running loss: 8.485112994909286
[2018-04-17 20:09:05.991910]: Test set accuracy: 94.33962264150944% ,loss = 5.439161881804466
[2018-04-17 20:09:06.125765]: ====================
[2018-04-17 20:09:06.131280]: Elapsed time since starting training: 0:48:32.295911
[2018-04-17 20:09:06.136293]: Estimated time left: 0:26:27.699076
[2018-04-17 20:09:06.141308]: ====================
[2018-04-17 20:09:06.257115]: [Epoch: 371(37.13713713713714%): Data: 0.0%]:Running loss: 0.21756647527217865
[2018-04-17 20:09:07.773145]: [Epoch: 371(37.13713713713714%): Data: 25.333333333333336%]:Running loss: 4.351325497031212
[2018-04-17 20:09:09.379919]: [Epoch: 371(37.13713713713714%): Data: 50.66666666666667%]:Running loss: 8.485080152750015
[2018-04-17 20:09:13.703414]: Test set accuracy: 94.33962264150944% ,loss = 5.439141020178795
[2018-04-17 20:09:13.884897]: ====================
[2018-04-17 20:09:13.890412]: Elapsed time since starting training: 0:48:40.055043
[2018-04-17 20:09:13.895426]: Estimated time left: 0:26:19.940445
[2018-04-17 20:09:13.899937]: ====================
[2018-04-17 20:09:13.979650]: [Epoch: 372(37.23723723723724%): Data: 0.0%]:Running loss: 0.2175656408071518
[2018-04-17 20:09:15.556341]: [Epoch: 372(37.23723723723724%): Data: 25.333333333333336%]:Running loss: 4.35130800306797
[2018-04-17 20:09:17.198708]: [Epoch: 372(37.23723723723724%): Data: 50.66666666666667%]:Running loss: 8.485046789050102
[2018-04-17 20:09:21.632498]: Test set accuracy: 94.33962264150944% ,loss = 5.439118668437004
[2018-04-17 20:09:21.795431]: ====================
[2018-04-17 20:09:21.800444]: Elapsed time since starting training: 0:48:47.964574
[2018-04-17 20:09:21.805457]: Estimated time left: 0:26:12.029912
[2018-04-17 20:09:21.809969]: ====================
[2018-04-17 20:09:21.885169]: [Epoch: 373(37.33733733733734%): Data: 0.0%]:Running loss: 0.21756474673748016
[2018-04-17 20:09:23.363113]: [Epoch: 373(37.33733733733734%): Data: 25.333333333333336%]:Running loss: 4.3512911051511765
[2018-04-17 20:09:24.882640]: [Epoch: 373(37.33733733733734%): Data: 50.66666666666667%]:Running loss: 8.48501342535019
[2018-04-17 20:09:29.419203]: Test set accuracy: 94.33962264150944% ,loss = 5.439095199108124
[2018-04-17 20:09:29.603191]: ====================
[2018-04-17 20:09:29.609709]: Elapsed time since starting training: 0:48:55.774340
[2018-04-17 20:09:29.617229]: Estimated time left: 0:26:04.218140
[2018-04-17 20:09:29.623245]: ====================
[2018-04-17 20:09:29.694434]: [Epoch: 374(37.43743743743744%): Data: 0.0%]:Running loss: 0.21756380796432495
[2018-04-17 20:09:31.273633]: [Epoch: 374(37.43743743743744%): Data: 25.333333333333336%]:Running loss: 4.3512748926877975
[2018-04-17 20:09:32.951595]: [Epoch: 374(37.43743743743744%): Data: 50.66666666666667%]:Running loss: 8.484981030225754
[2018-04-17 20:09:37.934846]: Test set accuracy: 94.33962264150944% ,loss = 5.439072102308273
[2018-04-17 20:09:38.171475]: ====================
[2018-04-17 20:09:38.178994]: Elapsed time since starting training: 0:49:04.343625
[2018-04-17 20:09:38.184509]: Estimated time left: 0:25:55.650860
[2018-04-17 20:09:38.188520]: ====================
[2018-04-17 20:09:38.255698]: [Epoch: 375(37.53753753753754%): Data: 0.0%]:Running loss: 0.21756288409233093
[2018-04-17 20:09:40.127175]: [Epoch: 375(37.53753753753754%): Data: 25.333333333333336%]:Running loss: 4.351258143782616
[2018-04-17 20:09:41.722416]: [Epoch: 375(37.53753753753754%): Data: 50.66666666666667%]:Running loss: 8.484948769211769
[2018-04-17 20:09:46.235417]: Test set accuracy: 94.33962264150944% ,loss = 5.439054220914841
[2018-04-17 20:09:46.425422]: ====================
[2018-04-17 20:09:46.431438]: Elapsed time since starting training: 0:49:12.595568
[2018-04-17 20:09:46.435950]: Estimated time left: 0:25:47.399419
[2018-04-17 20:09:46.441464]: ====================
[2018-04-17 20:09:46.518671]: [Epoch: 376(37.63763763763764%): Data: 0.0%]:Running loss: 0.21756216883659363
[2018-04-17 20:09:48.164045]: [Epoch: 376(37.63763763763764%): Data: 25.333333333333336%]:Running loss: 4.351241260766983
[2018-04-17 20:09:49.740737]: [Epoch: 376(37.63763763763764%): Data: 50.66666666666667%]:Running loss: 8.48491720855236
[2018-04-17 20:09:54.216138]: Test set accuracy: 94.33962264150944% ,loss = 5.4390352219343185
[2018-04-17 20:09:54.406644]: ====================
[2018-04-17 20:09:54.413161]: Elapsed time since starting training: 0:49:20.577792
[2018-04-17 20:09:54.418676]: Estimated time left: 0:25:39.416693
[2018-04-17 20:09:54.423689]: ====================
[2018-04-17 20:09:54.496383]: [Epoch: 377(37.73773773773774%): Data: 0.0%]:Running loss: 0.21756140887737274
[2018-04-17 20:09:56.076584]: [Epoch: 377(37.73773773773774%): Data: 25.333333333333336%]:Running loss: 4.351226165890694
[2018-04-17 20:09:57.713437]: [Epoch: 377(37.73773773773774%): Data: 50.66666666666667%]:Running loss: 8.484888017177582
[2018-04-17 20:10:02.243984]: Test set accuracy: 94.33962264150944% ,loss = 5.439017340540886
[2018-04-17 20:10:02.429477]: ====================
[2018-04-17 20:10:02.440005]: Elapsed time since starting training: 0:49:28.604134
[2018-04-17 20:10:02.445018]: Estimated time left: 0:25:31.390852
[2018-04-17 20:10:02.449530]: ====================
[2018-04-17 20:10:02.525232]: [Epoch: 378(37.83783783783784%): Data: 0.0%]:Running loss: 0.21756069362163544
[2018-04-17 20:10:04.168602]: [Epoch: 378(37.83783783783784%): Data: 25.333333333333336%]:Running loss: 4.351210579276085
[2018-04-17 20:10:05.820493]: [Epoch: 378(37.83783783783784%): Data: 50.66666666666667%]:Running loss: 8.484856724739075
[2018-04-17 20:10:10.393151]: Test set accuracy: 94.33962264150944% ,loss = 5.438998341560364
[2018-04-17 20:10:10.579147]: ====================
[2018-04-17 20:10:10.586667]: Elapsed time since starting training: 0:49:36.751298
[2018-04-17 20:10:10.593184]: Estimated time left: 0:25:23.242687
[2018-04-17 20:10:10.597695]: ====================
[2018-04-17 20:10:10.673397]: [Epoch: 379(37.93793793793794%): Data: 0.0%]:Running loss: 0.21755993366241455
[2018-04-17 20:10:12.256613]: [Epoch: 379(37.93793793793794%): Data: 25.333333333333336%]:Running loss: 4.351195931434631
[2018-04-17 20:10:13.816763]: [Epoch: 379(37.93793793793794%): Data: 50.66666666666667%]:Running loss: 8.484828367829323
[2018-04-17 20:10:18.393933]: Test set accuracy: 94.33962264150944% ,loss = 5.4389797151088715
[2018-04-17 20:10:18.563885]: ====================
[2018-04-17 20:10:18.569399]: Elapsed time since starting training: 0:49:44.733530
[2018-04-17 20:10:18.573912]: Estimated time left: 0:25:15.261457
[2018-04-17 20:10:18.578423]: ====================
[2018-04-17 20:10:18.650615]: [Epoch: 380(38.03803803803804%): Data: 0.0%]:Running loss: 0.21755918860435486
[2018-04-17 20:10:20.255885]: [Epoch: 380(38.03803803803804%): Data: 25.333333333333336%]:Running loss: 4.351180464029312
[2018-04-17 20:10:21.622517]: [Epoch: 380(38.03803803803804%): Data: 50.66666666666667%]:Running loss: 8.484798297286034
[2018-04-17 20:10:25.777566]: Test set accuracy: 94.33962264150944% ,loss = 5.438960716128349
[2018-04-17 20:10:25.977599]: ====================
[2018-04-17 20:10:25.984116]: Elapsed time since starting training: 0:49:52.148747
[2018-04-17 20:10:25.990132]: Estimated time left: 0:25:07.845739
[2018-04-17 20:10:25.997150]: ====================
[2018-04-17 20:10:26.066835]: [Epoch: 381(38.13813813813814%): Data: 0.0%]:Running loss: 0.21755842864513397
[2018-04-17 20:10:27.429960]: [Epoch: 381(38.13813813813814%): Data: 25.333333333333336%]:Running loss: 4.351166129112244
[2018-04-17 20:10:28.779548]: [Epoch: 381(38.13813813813814%): Data: 50.66666666666667%]:Running loss: 8.484769806265831
[2018-04-17 20:10:32.845861]: Test set accuracy: 94.33962264150944% ,loss = 5.43893501162529
[2018-04-17 20:10:33.004783]: ====================
[2018-04-17 20:10:33.029348]: Elapsed time since starting training: 0:49:59.193979
[2018-04-17 20:10:33.039878]: Estimated time left: 0:25:00.795994
[2018-04-17 20:10:33.052409]: ====================
[2018-04-17 20:10:33.130617]: [Epoch: 382(38.23823823823824%): Data: 0.0%]:Running loss: 0.2175574004650116
[2018-04-17 20:10:34.498254]: [Epoch: 382(38.23823823823824%): Data: 25.333333333333336%]:Running loss: 4.351152136921883
[2018-04-17 20:10:35.876920]: [Epoch: 382(38.23823823823824%): Data: 50.66666666666667%]:Running loss: 8.484742194414139
[2018-04-17 20:10:40.541824]: Test set accuracy: 94.33962264150944% ,loss = 5.438932031393051
[2018-04-17 20:10:40.782465]: ====================
[2018-04-17 20:10:40.787979]: Elapsed time since starting training: 0:50:06.952610
[2018-04-17 20:10:40.792992]: Estimated time left: 0:24:53.042377
[2018-04-17 20:10:40.800512]: ====================
[2018-04-17 20:10:40.875210]: [Epoch: 383(38.33833833833834%): Data: 0.0%]:Running loss: 0.21755728125572205
[2018-04-17 20:10:42.672991]: [Epoch: 383(38.33833833833834%): Data: 25.333333333333336%]:Running loss: 4.351138338446617
[2018-04-17 20:10:44.203060]: [Epoch: 383(38.33833833833834%): Data: 50.66666666666667%]:Running loss: 8.484716042876244
[2018-04-17 20:10:48.600753]: Test set accuracy: 94.33962264150944% ,loss = 5.438904836773872
[2018-04-17 20:10:48.789756]: ====================
[2018-04-17 20:10:48.801286]: Elapsed time since starting training: 0:50:14.965917
[2018-04-17 20:10:48.806801]: Estimated time left: 0:24:45.028568
[2018-04-17 20:10:48.811814]: ====================
[2018-04-17 20:10:48.885510]: [Epoch: 384(38.43843843843844%): Data: 0.0%]:Running loss: 0.2175561934709549
[2018-04-17 20:10:50.529382]: [Epoch: 384(38.43843843843844%): Data: 25.333333333333336%]:Running loss: 4.351123690605164
[2018-04-17 20:10:52.149189]: [Epoch: 384(38.43843843843844%): Data: 50.66666666666667%]:Running loss: 8.48468892276287
[2018-04-17 20:10:56.623084]: Test set accuracy: 94.33962264150944% ,loss = 5.4388877004384995
[2018-04-17 20:10:56.821612]: ====================
[2018-04-17 20:10:56.827628]: Elapsed time since starting training: 0:50:22.992259
[2018-04-17 20:10:56.836652]: Estimated time left: 0:24:36.998717
[2018-04-17 20:10:56.841164]: ====================
[2018-04-17 20:10:56.911358]: [Epoch: 385(38.53853853853854%): Data: 0.0%]:Running loss: 0.21755550801753998
[2018-04-17 20:10:58.591317]: [Epoch: 385(38.53853853853854%): Data: 25.333333333333336%]:Running loss: 4.3511107712984085
[2018-04-17 20:11:00.214133]: [Epoch: 385(38.53853853853854%): Data: 50.66666666666667%]:Running loss: 8.484662294387817
[2018-04-17 20:11:04.688530]: Test set accuracy: 94.33962264150944% ,loss = 5.4388731718063354
[2018-04-17 20:11:04.995847]: ====================
[2018-04-17 20:11:05.001363]: Elapsed time since starting training: 0:50:31.165492
[2018-04-17 20:11:05.008380]: Estimated time left: 0:24:28.826989
[2018-04-17 20:11:05.012892]: ====================
[2018-04-17 20:11:05.084082]: [Epoch: 386(38.63863863863864%): Data: 0.0%]:Running loss: 0.21755492687225342
[2018-04-17 20:11:06.752519]: [Epoch: 386(38.63863863863864%): Data: 25.333333333333336%]:Running loss: 4.3510971665382385
[2018-04-17 20:11:08.472592]: [Epoch: 386(38.63863863863864%): Data: 50.66666666666667%]:Running loss: 8.484636351466179
[2018-04-17 20:11:12.899864]: Test set accuracy: 94.33962264150944% ,loss = 5.438858270645142
[2018-04-17 20:11:13.103907]: ====================
[2018-04-17 20:11:13.116440]: Elapsed time since starting training: 0:50:39.281071
[2018-04-17 20:11:13.121453]: Estimated time left: 0:24:20.714417
[2018-04-17 20:11:13.125965]: ====================
[2018-04-17 20:11:13.201165]: [Epoch: 387(38.73873873873874%): Data: 0.0%]:Running loss: 0.21755433082580566
[2018-04-17 20:11:14.832504]: [Epoch: 387(38.73873873873874%): Data: 25.333333333333336%]:Running loss: 4.3510831743478775
[2018-04-17 20:11:16.467350]: [Epoch: 387(38.73873873873874%): Data: 50.66666666666667%]:Running loss: 8.484609603881836
[2018-04-17 20:11:20.976840]: Test set accuracy: 94.33962264150944% ,loss = 5.4388415068387985
[2018-04-17 20:11:21.168350]: ====================
[2018-04-17 20:11:21.174366]: Elapsed time since starting training: 0:50:47.338495
[2018-04-17 20:11:21.179881]: Estimated time left: 0:24:12.655990
[2018-04-17 20:11:21.184894]: ====================
[2018-04-17 20:11:21.251571]: [Epoch: 388(38.83883883883884%): Data: 0.0%]:Running loss: 0.21755366027355194
[2018-04-17 20:11:22.801694]: [Epoch: 388(38.83883883883884%): Data: 25.333333333333336%]:Running loss: 4.351071134209633
[2018-04-17 20:11:24.371877]: [Epoch: 388(38.83883883883884%): Data: 50.66666666666667%]:Running loss: 8.4845851957798
[2018-04-17 20:11:28.985649]: Test set accuracy: 94.33962264150944% ,loss = 5.438829958438873
[2018-04-17 20:11:29.133543]: ====================
[2018-04-17 20:11:29.139058]: Elapsed time since starting training: 0:50:55.303187
[2018-04-17 20:11:29.144572]: Estimated time left: 0:24:04.690797
[2018-04-17 20:11:29.149585]: ====================
[2018-04-17 20:11:29.278929]: [Epoch: 389(38.93893893893894%): Data: 0.0%]:Running loss: 0.21755319833755493
[2018-04-17 20:11:30.811505]: [Epoch: 389(38.93893893893894%): Data: 25.333333333333336%]:Running loss: 4.351058155298233
[2018-04-17 20:11:32.460890]: [Epoch: 389(38.93893893893894%): Data: 50.66666666666667%]:Running loss: 8.484560519456863
[2018-04-17 20:11:37.035554]: Test set accuracy: 94.33962264150944% ,loss = 5.438804626464844
[2018-04-17 20:11:37.204002]: ====================
[2018-04-17 20:11:37.215533]: Elapsed time since starting training: 0:51:03.380164
[2018-04-17 20:11:37.225058]: Estimated time left: 0:23:56.610812
[2018-04-17 20:11:37.244109]: ====================
[2018-04-17 20:11:37.318808]: [Epoch: 390(39.03903903903904%): Data: 0.0%]:Running loss: 0.21755218505859375
[2018-04-17 20:11:38.823809]: [Epoch: 390(39.03903903903904%): Data: 25.333333333333336%]:Running loss: 4.3510459661483765
[2018-04-17 20:11:40.402005]: [Epoch: 390(39.03903903903904%): Data: 50.66666666666667%]:Running loss: 8.484536975622177
[2018-04-17 20:11:45.094984]: Test set accuracy: 94.33962264150944% ,loss = 5.4387930780649185
[2018-04-17 20:11:45.298525]: ====================
[2018-04-17 20:11:45.307049]: Elapsed time since starting training: 0:51:11.471178
[2018-04-17 20:11:45.314066]: Estimated time left: 0:23:48.521803
[2018-04-17 20:11:45.318579]: ====================
[2018-04-17 20:11:45.386258]: [Epoch: 391(39.13913913913914%): Data: 0.0%]:Running loss: 0.21755172312259674
[2018-04-17 20:11:46.955431]: [Epoch: 391(39.13913913913914%): Data: 25.333333333333336%]:Running loss: 4.351034000515938
[2018-04-17 20:11:48.515580]: [Epoch: 391(39.13913913913914%): Data: 50.66666666666667%]:Running loss: 8.484513238072395
[2018-04-17 20:11:53.118318]: Test set accuracy: 94.33962264150944% ,loss = 5.438780784606934
[2018-04-17 20:11:53.319353]: ====================
[2018-04-17 20:11:53.328376]: Elapsed time since starting training: 0:51:19.492506
[2018-04-17 20:11:53.333391]: Estimated time left: 0:23:40.501978
[2018-04-17 20:11:53.338905]: ====================
[2018-04-17 20:11:53.409092]: [Epoch: 392(39.23923923923924%): Data: 0.0%]:Running loss: 0.21755123138427734
[2018-04-17 20:11:55.013357]: [Epoch: 392(39.23923923923924%): Data: 25.333333333333336%]:Running loss: 4.351022452116013
[2018-04-17 20:11:56.598071]: [Epoch: 392(39.23923923923924%): Data: 50.66666666666667%]:Running loss: 8.484490141272545
[2018-04-17 20:12:01.230890]: Test set accuracy: 94.33962264150944% ,loss = 5.438767373561859
[2018-04-17 20:12:01.473033]: ====================
[2018-04-17 20:12:01.481556]: Elapsed time since starting training: 0:51:27.645686
[2018-04-17 20:12:01.487572]: Estimated time left: 0:23:32.347797
[2018-04-17 20:12:01.493588]: ====================
[2018-04-17 20:12:01.570293]: [Epoch: 393(39.33933933933934%): Data: 0.0%]:Running loss: 0.21755069494247437
[2018-04-17 20:12:03.207646]: [Epoch: 393(39.33933933933934%): Data: 25.333333333333336%]:Running loss: 4.351009637117386
[2018-04-17 20:12:04.721671]: [Epoch: 393(39.33933933933934%): Data: 50.66666666666667%]:Running loss: 8.484466418623924
[2018-04-17 20:12:09.288314]: Test set accuracy: 94.33962264150944% ,loss = 5.438753962516785
[2018-04-17 20:12:09.503888]: ====================
[2018-04-17 20:12:09.508900]: Elapsed time since starting training: 0:51:35.673531
[2018-04-17 20:12:09.514415]: Estimated time left: 0:23:24.321455
[2018-04-17 20:12:09.522436]: ====================
[2018-04-17 20:12:09.630223]: [Epoch: 394(39.43943943943944%): Data: 0.0%]:Running loss: 0.2175501585006714
[2018-04-17 20:12:11.266073]: [Epoch: 394(39.43943943943944%): Data: 25.333333333333336%]:Running loss: 4.350998744368553
[2018-04-17 20:12:12.842765]: [Epoch: 394(39.43943943943944%): Data: 50.66666666666667%]:Running loss: 8.484444692730904
[2018-04-17 20:12:17.347242]: Test set accuracy: 94.33962264150944% ,loss = 5.438738316297531
[2018-04-17 20:12:17.558805]: ====================
[2018-04-17 20:12:17.563317]: Elapsed time since starting training: 0:51:43.727948
[2018-04-17 20:12:17.567829]: Estimated time left: 0:23:16.267540
[2018-04-17 20:12:17.573357]: ====================
[2018-04-17 20:12:17.647541]: [Epoch: 395(39.53953953953954%): Data: 0.0%]:Running loss: 0.21754953265190125
[2018-04-17 20:12:19.242782]: [Epoch: 395(39.53953953953954%): Data: 25.333333333333336%]:Running loss: 4.350987032055855
[2018-04-17 20:12:20.897683]: [Epoch: 395(39.53953953953954%): Data: 50.66666666666667%]:Running loss: 8.484422072768211
[2018-04-17 20:12:25.351024]: Test set accuracy: 94.33962264150944% ,loss = 5.438718572258949
[2018-04-17 20:12:25.534011]: ====================
[2018-04-17 20:12:25.540529]: Elapsed time since starting training: 0:51:51.704658
[2018-04-17 20:12:25.545542]: Estimated time left: 0:23:08.289827
[2018-04-17 20:12:25.550054]: ====================
[2018-04-17 20:12:25.625755]: [Epoch: 396(39.63963963963964%): Data: 0.0%]:Running loss: 0.21754874289035797
[2018-04-17 20:12:27.252581]: [Epoch: 396(39.63963963963964%): Data: 25.333333333333336%]:Running loss: 4.35097661614418
[2018-04-17 20:12:28.799194]: [Epoch: 396(39.63963963963964%): Data: 50.66666666666667%]:Running loss: 8.484401360154152
[2018-04-17 20:12:33.429004]: Test set accuracy: 94.33962264150944% ,loss = 5.438709259033203
[2018-04-17 20:12:33.671649]: ====================
[2018-04-17 20:12:33.680673]: Elapsed time since starting training: 0:51:59.844803
[2018-04-17 20:12:33.685185]: Estimated time left: 0:23:00.150184
[2018-04-17 20:12:33.690700]: ====================
[2018-04-17 20:12:33.793975]: [Epoch: 397(39.73973973973974%): Data: 0.0%]:Running loss: 0.21754837036132812
[2018-04-17 20:12:35.323541]: [Epoch: 397(39.73973973973974%): Data: 25.333333333333336%]:Running loss: 4.350966289639473
[2018-04-17 20:12:36.817013]: [Epoch: 397(39.73973973973974%): Data: 50.66666666666667%]:Running loss: 8.484381020069122
[2018-04-17 20:12:41.372626]: Test set accuracy: 94.33962264150944% ,loss = 5.438700318336487
[2018-04-17 20:12:41.585191]: ====================
[2018-04-17 20:12:41.590204]: Elapsed time since starting training: 0:52:07.754835
[2018-04-17 20:12:41.594717]: Estimated time left: 0:22:52.240652
[2018-04-17 20:12:41.603239]: ====================
[2018-04-17 20:12:41.672423]: [Epoch: 398(39.83983983983984%): Data: 0.0%]:Running loss: 0.21754801273345947
[2018-04-17 20:12:43.277190]: [Epoch: 398(39.83983983983984%): Data: 25.333333333333336%]:Running loss: 4.3509552627801895
[2018-04-17 20:12:44.854384]: [Epoch: 398(39.83983983983984%): Data: 50.66666666666667%]:Running loss: 8.484360218048096
[2018-04-17 20:12:49.437571]: Test set accuracy: 94.33962264150944% ,loss = 5.438682809472084
[2018-04-17 20:12:49.666178]: ====================
[2018-04-17 20:12:49.673699]: Elapsed time since starting training: 0:52:15.836826
[2018-04-17 20:12:49.680717]: Estimated time left: 0:22:44.154652
[2018-04-17 20:12:49.686232]: ====================
[2018-04-17 20:12:49.756919]: [Epoch: 399(39.93993993993994%): Data: 0.0%]:Running loss: 0.21754731237888336
[2018-04-17 20:12:51.489527]: [Epoch: 399(39.93993993993994%): Data: 25.333333333333336%]:Running loss: 4.350944742560387
[2018-04-17 20:12:53.101815]: [Epoch: 399(39.93993993993994%): Data: 50.66666666666667%]:Running loss: 8.484339147806168
[2018-04-17 20:12:57.749171]: Test set accuracy: 94.33962264150944% ,loss = 5.438670888543129
[2018-04-17 20:12:57.958729]: ====================
[2018-04-17 20:12:57.966749]: Elapsed time since starting training: 0:52:24.131380
[2018-04-17 20:12:57.971262]: Estimated time left: 0:22:35.864609
[2018-04-17 20:12:57.975773]: ====================
[2018-04-17 20:12:58.047465]: [Epoch: 400(40.04004004004004%): Data: 0.0%]:Running loss: 0.21754683554172516
[2018-04-17 20:12:59.649223]: [Epoch: 400(40.04004004004004%): Data: 25.333333333333336%]:Running loss: 4.350934207439423
[2018-04-17 20:13:01.178790]: [Epoch: 400(40.04004004004004%): Data: 50.66666666666667%]:Running loss: 8.484318643808365
[2018-04-17 20:13:05.669736]: Test set accuracy: 94.33962264150944% ,loss = 5.4386623203754425
[2018-04-17 20:13:05.864253]: ====================
[2018-04-17 20:13:05.869768]: Elapsed time since starting training: 0:52:32.034399
[2018-04-17 20:13:05.874782]: Estimated time left: 0:22:27.960587
[2018-04-17 20:13:05.883806]: ====================
[2018-04-17 20:13:05.978056]: [Epoch: 401(40.14014014014014%): Data: 0.0%]:Running loss: 0.2175464928150177
[2018-04-17 20:13:07.505117]: [Epoch: 401(40.14014014014014%): Data: 25.333333333333336%]:Running loss: 4.350924029946327
[2018-04-17 20:13:09.069276]: [Epoch: 401(40.14014014014014%): Data: 50.66666666666667%]:Running loss: 8.48429949581623
[2018-04-17 20:13:13.772782]: Test set accuracy: 94.33962264150944% ,loss = 5.438641831278801
[2018-04-17 20:13:13.988356]: ====================
[2018-04-17 20:13:13.996376]: Elapsed time since starting training: 0:52:40.161007
[2018-04-17 20:13:14.000889]: Estimated time left: 0:22:19.834480
[2018-04-17 20:13:14.006404]: ====================
[2018-04-17 20:13:14.076590]: [Epoch: 402(40.24024024024024%): Data: 0.0%]:Running loss: 0.21754567325115204
[2018-04-17 20:13:15.717454]: [Epoch: 402(40.24024024024024%): Data: 25.333333333333336%]:Running loss: 4.350914031267166
[2018-04-17 20:13:17.355809]: [Epoch: 402(40.24024024024024%): Data: 50.66666666666667%]:Running loss: 8.484280243515968
[2018-04-17 20:13:21.983615]: Test set accuracy: 94.33962264150944% ,loss = 5.438636988401413
[2018-04-17 20:13:22.176128]: ====================
[2018-04-17 20:13:22.181642]: Elapsed time since starting training: 0:52:48.345772
[2018-04-17 20:13:22.186655]: Estimated time left: 0:22:11.649216
[2018-04-17 20:13:22.191668]: ====================
[2018-04-17 20:13:22.265865]: [Epoch: 403(40.34034034034034%): Data: 0.0%]:Running loss: 0.21754547953605652
[2018-04-17 20:13:23.926281]: [Epoch: 403(40.34034034034034%): Data: 25.333333333333336%]:Running loss: 4.350905060768127
[2018-04-17 20:13:25.546087]: [Epoch: 403(40.34034034034034%): Data: 50.66666666666667%]:Running loss: 8.48426142334938
[2018-04-17 20:13:30.322291]: Test set accuracy: 94.33962264150944% ,loss = 5.43861910700798
[2018-04-17 20:13:30.470184]: ====================
[2018-04-17 20:13:30.478206]: Elapsed time since starting training: 0:52:56.642837
[2018-04-17 20:13:30.512798]: Estimated time left: 0:22:03.322571
[2018-04-17 20:13:30.519315]: ====================
[2018-04-17 20:13:30.614067]: [Epoch: 404(40.44044044044044%): Data: 0.0%]:Running loss: 0.2175447642803192
[2018-04-17 20:13:32.252925]: [Epoch: 404(40.44044044044044%): Data: 25.333333333333336%]:Running loss: 4.350894570350647
[2018-04-17 20:13:33.774471]: [Epoch: 404(40.44044044044044%): Data: 50.66666666666667%]:Running loss: 8.484242022037506
[2018-04-17 20:13:38.165647]: Test set accuracy: 94.33962264150944% ,loss = 5.438613146543503
[2018-04-17 20:13:38.380720]: ====================
[2018-04-17 20:13:38.385231]: Elapsed time since starting training: 0:53:04.549862
[2018-04-17 20:13:38.389742]: Estimated time left: 0:21:55.445627
[2018-04-17 20:13:38.397263]: ====================
[2018-04-17 20:13:38.467449]: [Epoch: 405(40.54054054054054%): Data: 0.0%]:Running loss: 0.2175445258617401
[2018-04-17 20:13:40.048654]: [Epoch: 405(40.54054054054054%): Data: 25.333333333333336%]:Running loss: 4.350885763764381
[2018-04-17 20:13:41.642392]: [Epoch: 405(40.54054054054054%): Data: 50.66666666666667%]:Running loss: 8.484224274754524
[2018-04-17 20:13:46.318826]: Test set accuracy: 94.33962264150944% ,loss = 5.43859489262104
[2018-04-17 20:13:46.461205]: ====================
[2018-04-17 20:13:46.466217]: Elapsed time since starting training: 0:53:12.630848
[2018-04-17 20:13:46.470730]: Estimated time left: 0:21:47.364639
[2018-04-17 20:13:46.476750]: ====================
[2018-04-17 20:13:46.568991]: [Epoch: 406(40.64064064064064%): Data: 0.0%]:Running loss: 0.2175437957048416
[2018-04-17 20:13:48.159219]: [Epoch: 406(40.64064064064064%): Data: 25.333333333333336%]:Running loss: 4.350876286625862
[2018-04-17 20:13:49.813117]: [Epoch: 406(40.64064064064064%): Data: 50.66666666666667%]:Running loss: 8.484206303954124
[2018-04-17 20:13:54.565253]: Test set accuracy: 94.33962264150944% ,loss = 5.438587814569473
[2018-04-17 20:13:54.721670]: ====================
[2018-04-17 20:13:54.727184]: Elapsed time since starting training: 0:53:20.891815
[2018-04-17 20:13:54.732197]: Estimated time left: 0:21:39.103172
[2018-04-17 20:13:54.737211]: ====================
[2018-04-17 20:13:54.838480]: [Epoch: 407(40.74074074074074%): Data: 0.0%]:Running loss: 0.21754351258277893
[2018-04-17 20:13:56.375567]: [Epoch: 407(40.74074074074074%): Data: 25.333333333333336%]:Running loss: 4.350866958498955
[2018-04-17 20:13:57.909645]: [Epoch: 407(40.74074074074074%): Data: 50.66666666666667%]:Running loss: 8.484188675880432
[2018-04-17 20:14:02.251190]: Test set accuracy: 94.33962264150944% ,loss = 5.43857142329216
[2018-04-17 20:14:02.452726]: ====================
[2018-04-17 20:14:02.467265]: Elapsed time since starting training: 0:53:28.631896
[2018-04-17 20:14:02.473281]: Estimated time left: 0:21:31.362088
[2018-04-17 20:14:02.479297]: ====================
[2018-04-17 20:14:02.557003]: [Epoch: 408(40.84084084084084%): Data: 0.0%]:Running loss: 0.2175428569316864
[2018-04-17 20:14:04.191850]: [Epoch: 408(40.84084084084084%): Data: 25.333333333333336%]:Running loss: 4.350858315825462
[2018-04-17 20:14:05.757012]: [Epoch: 408(40.84084084084084%): Data: 50.66666666666667%]:Running loss: 8.484171077609062
[2018-04-17 20:14:10.171750]: Test set accuracy: 94.33962264150944% ,loss = 5.438563227653503
[2018-04-17 20:14:10.361756]: ====================
[2018-04-17 20:14:10.367772]: Elapsed time since starting training: 0:53:36.532403
[2018-04-17 20:14:10.373788]: Estimated time left: 0:21:23.462082
[2018-04-17 20:14:10.379804]: ====================
[2018-04-17 20:14:10.456508]: [Epoch: 409(40.94094094094094%): Data: 0.0%]:Running loss: 0.21754252910614014
[2018-04-17 20:14:12.163047]: [Epoch: 409(40.94094094094094%): Data: 25.333333333333336%]:Running loss: 4.350849390029907
[2018-04-17 20:14:13.804911]: [Epoch: 409(40.94094094094094%): Data: 50.66666666666667%]:Running loss: 8.48415394127369
[2018-04-17 20:14:18.125399]: Test set accuracy: 94.33962264150944% ,loss = 5.438555032014847
[2018-04-17 20:14:18.285826]: ====================
[2018-04-17 20:14:18.290338]: Elapsed time since starting training: 0:53:44.454969
[2018-04-17 20:14:18.294850]: Estimated time left: 0:21:15.540519
[2018-04-17 20:14:18.299362]: ====================
[2018-04-17 20:14:18.376567]: [Epoch: 410(41.04104104104104%): Data: 0.0%]:Running loss: 0.21754220128059387
[2018-04-17 20:14:19.954763]: [Epoch: 410(41.04104104104104%): Data: 25.333333333333336%]:Running loss: 4.350841119885445
[2018-04-17 20:14:21.607158]: [Epoch: 410(41.04104104104104%): Data: 50.66666666666667%]:Running loss: 8.484137669205666
[2018-04-17 20:14:26.069523]: Test set accuracy: 94.33962264150944% ,loss = 5.438540503382683
[2018-04-17 20:14:26.231956]: ====================
[2018-04-17 20:14:26.256019]: Elapsed time since starting training: 0:53:52.420148
[2018-04-17 20:14:26.261533]: Estimated time left: 0:21:07.574337
[2018-04-17 20:14:26.271059]: ====================
[2018-04-17 20:14:26.342248]: [Epoch: 411(41.14114114114114%): Data: 0.0%]:Running loss: 0.2175416201353073
[2018-04-17 20:14:27.884849]: [Epoch: 411(41.14114114114114%): Data: 25.333333333333336%]:Running loss: 4.350832596421242
[2018-04-17 20:14:29.373809]: [Epoch: 411(41.14114114114114%): Data: 50.66666666666667%]:Running loss: 8.484121292829514
[2018-04-17 20:14:33.956995]: Test set accuracy: 94.33962264150944% ,loss = 5.438527464866638
[2018-04-17 20:14:34.125443]: ====================
[2018-04-17 20:14:34.132963]: Elapsed time since starting training: 0:54:00.297093
[2018-04-17 20:14:34.136974]: Estimated time left: 0:20:59.698395
[2018-04-17 20:14:34.141486]: ====================
[2018-04-17 20:14:34.216686]: [Epoch: 412(41.24124124124124%): Data: 0.0%]:Running loss: 0.21754109859466553
[2018-04-17 20:14:35.820450]: [Epoch: 412(41.24124124124124%): Data: 25.333333333333336%]:Running loss: 4.3508240431547165
[2018-04-17 20:14:37.429729]: [Epoch: 412(41.24124124124124%): Data: 50.66666666666667%]:Running loss: 8.48410551249981
[2018-04-17 20:14:41.821908]: Test set accuracy: 94.33962264150944% ,loss = 5.438525229692459
[2018-04-17 20:14:41.972809]: ====================
[2018-04-17 20:14:41.980329]: Elapsed time since starting training: 0:54:08.144960
[2018-04-17 20:14:41.985342]: Estimated time left: 0:20:51.850027
[2018-04-17 20:14:41.990356]: ====================
[2018-04-17 20:14:42.068063]: [Epoch: 413(41.34134134134134%): Data: 0.0%]:Running loss: 0.21754100918769836
[2018-04-17 20:14:43.615678]: [Epoch: 413(41.34134134134134%): Data: 25.333333333333336%]:Running loss: 4.350816786289215
[2018-04-17 20:14:45.158781]: [Epoch: 413(41.34134134134134%): Data: 50.66666666666667%]:Running loss: 8.48409029841423
[2018-04-17 20:14:50.022212]: Test set accuracy: 94.33962264150944% ,loss = 5.438510701060295
[2018-04-17 20:14:50.174618]: ====================
[2018-04-17 20:14:50.180134]: Elapsed time since starting training: 0:54:16.344262
[2018-04-17 20:14:50.184143]: Estimated time left: 0:20:43.651226
[2018-04-17 20:14:50.189157]: ====================
[2018-04-17 20:14:50.270874]: [Epoch: 414(41.44144144144144%): Data: 0.0%]:Running loss: 0.2175404280424118
[2018-04-17 20:14:52.012004]: [Epoch: 414(41.44144144144144%): Data: 25.333333333333336%]:Running loss: 4.3508079797029495
[2018-04-17 20:14:53.685957]: [Epoch: 414(41.44144144144144%): Data: 50.66666666666667%]:Running loss: 8.484073504805565
[2018-04-17 20:14:58.639626]: Test set accuracy: 94.33962264150944% ,loss = 5.43849840760231
[2018-04-17 20:14:58.833642]: ====================
[2018-04-17 20:14:58.851190]: Elapsed time since starting training: 0:54:25.015319
[2018-04-17 20:14:58.857205]: Estimated time left: 0:20:34.978665
[2018-04-17 20:14:58.862218]: ====================
[2018-04-17 20:14:58.939925]: [Epoch: 415(41.54154154154154%): Data: 0.0%]:Running loss: 0.2175399363040924
[2018-04-17 20:15:00.620393]: [Epoch: 415(41.54154154154154%): Data: 25.333333333333336%]:Running loss: 4.350800260901451
[2018-04-17 20:15:02.105341]: [Epoch: 415(41.54154154154154%): Data: 50.66666666666667%]:Running loss: 8.484058573842049
[2018-04-17 20:15:06.813360]: Test set accuracy: 94.33962264150944% ,loss = 5.438493192195892
[2018-04-17 20:15:06.935686]: ====================
[2018-04-17 20:15:06.941200]: Elapsed time since starting training: 0:54:33.105330
[2018-04-17 20:15:06.945712]: Estimated time left: 0:20:26.889657
[2018-04-17 20:15:06.953232]: ====================
[2018-04-17 20:15:07.065531]: [Epoch: 416(41.64164164164164%): Data: 0.0%]:Running loss: 0.2175397276878357
[2018-04-17 20:15:08.678820]: [Epoch: 416(41.64164164164164%): Data: 25.333333333333336%]:Running loss: 4.3507926017045975
[2018-04-17 20:15:10.275567]: [Epoch: 416(41.64164164164164%): Data: 50.66666666666667%]:Running loss: 8.484043419361115
[2018-04-17 20:15:14.666742]: Test set accuracy: 94.33962264150944% ,loss = 5.438479408621788
[2018-04-17 20:15:14.839201]: ====================
[2018-04-17 20:15:14.848726]: Elapsed time since starting training: 0:54:41.013357
[2018-04-17 20:15:14.854241]: Estimated time left: 0:20:18.981128
[2018-04-17 20:15:14.859755]: ====================
[2018-04-17 20:15:14.932951]: [Epoch: 417(41.74174174174174%): Data: 0.0%]:Running loss: 0.21753917634487152
[2018-04-17 20:15:16.601888]: [Epoch: 417(41.74174174174174%): Data: 25.333333333333336%]:Running loss: 4.350784435868263
[2018-04-17 20:15:18.201141]: [Epoch: 417(41.74174174174174%): Data: 50.66666666666667%]:Running loss: 8.484028115868568
[2018-04-17 20:15:22.746225]: Test set accuracy: 94.33962264150944% ,loss = 5.438469350337982
[2018-04-17 20:15:22.900636]: ====================
[2018-04-17 20:15:22.905657]: Elapsed time since starting training: 0:54:49.070288
[2018-04-17 20:15:22.910161]: Estimated time left: 0:20:10.925208
[2018-04-17 20:15:22.914677]: ====================
[2018-04-17 20:15:22.993384]: [Epoch: 418(41.84184184184184%): Data: 0.0%]:Running loss: 0.2175387740135193
[2018-04-17 20:15:24.680369]: [Epoch: 418(41.84184184184184%): Data: 25.333333333333336%]:Running loss: 4.350777313113213
[2018-04-17 20:15:26.179856]: [Epoch: 418(41.84184184184184%): Data: 50.66666666666667%]:Running loss: 8.484013497829437
[2018-04-17 20:15:30.585570]: Test set accuracy: 94.33962264150944% ,loss = 5.438460037112236
[2018-04-17 20:15:30.716920]: ====================
[2018-04-17 20:15:30.723938]: Elapsed time since starting training: 0:54:56.888068
[2018-04-17 20:15:30.743490]: Estimated time left: 0:20:03.091879
[2018-04-17 20:15:30.757528]: ====================
[2018-04-17 20:15:30.854285]: [Epoch: 419(41.94194194194194%): Data: 0.0%]:Running loss: 0.21753840148448944
[2018-04-17 20:15:32.529740]: [Epoch: 419(41.94194194194194%): Data: 25.333333333333336%]:Running loss: 4.350770354270935
[2018-04-17 20:15:34.087383]: [Epoch: 419(41.94194194194194%): Data: 50.66666666666667%]:Running loss: 8.484000608325005
[2018-04-17 20:15:38.449480]: Test set accuracy: 94.33962264150944% ,loss = 5.4384492337703705
[2018-04-17 20:15:38.560779]: ====================
[2018-04-17 20:15:38.567294]: Elapsed time since starting training: 0:55:04.731925
[2018-04-17 20:15:38.577821]: Estimated time left: 0:19:55.258049
[2018-04-17 20:15:38.589855]: ====================
[2018-04-17 20:15:38.709672]: [Epoch: 420(42.04204204204204%): Data: 0.0%]:Running loss: 0.21753796935081482
[2018-04-17 20:15:40.313938]: [Epoch: 420(42.04204204204204%): Data: 25.333333333333336%]:Running loss: 4.350763157010078
[2018-04-17 20:15:41.981372]: [Epoch: 420(42.04204204204204%): Data: 50.66666666666667%]:Running loss: 8.48398631811142
[2018-04-17 20:15:46.381572]: Test set accuracy: 94.33962264150944% ,loss = 5.438448488712311
[2018-04-17 20:15:46.654297]: ====================
[2018-04-17 20:15:46.658809]: Elapsed time since starting training: 0:55:12.823440
[2018-04-17 20:15:46.663321]: Estimated time left: 0:19:47.172048
[2018-04-17 20:15:46.667833]: ====================
[2018-04-17 20:15:46.740526]: [Epoch: 421(42.14214214214214%): Data: 0.0%]:Running loss: 0.21753793954849243
[2018-04-17 20:15:48.294157]: [Epoch: 421(42.14214214214214%): Data: 25.333333333333336%]:Running loss: 4.350756481289864
[2018-04-17 20:15:49.871852]: [Epoch: 421(42.14214214214214%): Data: 50.66666666666667%]:Running loss: 8.483972951769829
[2018-04-17 20:15:54.594911]: Test set accuracy: 94.33962264150944% ,loss = 5.438437685370445
[2018-04-17 20:15:54.767871]: ====================
[2018-04-17 20:15:54.772884]: Elapsed time since starting training: 0:55:20.937515
[2018-04-17 20:15:54.777897]: Estimated time left: 0:19:39.057472
[2018-04-17 20:15:54.782911]: ====================
[2018-04-17 20:15:54.854100]: [Epoch: 422(42.24224224224224%): Data: 0.0%]:Running loss: 0.2175375074148178
[2018-04-17 20:15:56.467390]: [Epoch: 422(42.24224224224224%): Data: 25.333333333333336%]:Running loss: 4.350749596953392
[2018-04-17 20:15:57.989938]: [Epoch: 422(42.24224224224224%): Data: 50.66666666666667%]:Running loss: 8.483959466218948
[2018-04-17 20:16:02.582149]: Test set accuracy: 94.33962264150944% ,loss = 5.43842613697052
[2018-04-17 20:16:02.693445]: ====================
[2018-04-17 20:16:02.698459]: Elapsed time since starting training: 0:55:28.862588
[2018-04-17 20:16:02.702971]: Estimated time left: 0:19:31.132901
[2018-04-17 20:16:02.707482]: ====================
[2018-04-17 20:16:02.822287]: [Epoch: 423(42.34234234234234%): Data: 0.0%]:Running loss: 0.2175370454788208
[2018-04-17 20:16:04.360879]: [Epoch: 423(42.34234234234234%): Data: 25.333333333333336%]:Running loss: 4.350742936134338
[2018-04-17 20:16:05.905485]: [Epoch: 423(42.34234234234234%): Data: 50.66666666666667%]:Running loss: 8.483946695923805
[2018-04-17 20:16:10.343286]: Test set accuracy: 94.33962264150944% ,loss = 5.4384250193834305
[2018-04-17 20:16:10.497696]: ====================
[2018-04-17 20:16:10.502209]: Elapsed time since starting training: 0:55:36.666840
[2018-04-17 20:16:10.506720]: Estimated time left: 0:19:23.328649
[2018-04-17 20:16:10.511232]: ====================
[2018-04-17 20:16:10.594956]: [Epoch: 424(42.44244244244244%): Data: 0.0%]:Running loss: 0.21753700077533722
[2018-04-17 20:16:12.160116]: [Epoch: 424(42.44244244244244%): Data: 25.333333333333336%]:Running loss: 4.3507359623909
[2018-04-17 20:16:13.680159]: [Epoch: 424(42.44244244244244%): Data: 50.66666666666667%]:Running loss: 8.483933180570602
[2018-04-17 20:16:18.202684]: Test set accuracy: 94.33962264150944% ,loss = 5.438412725925446
[2018-04-17 20:16:18.342055]: ====================
[2018-04-17 20:16:18.349074]: Elapsed time since starting training: 0:55:44.513205
[2018-04-17 20:16:18.355591]: Estimated time left: 0:19:15.479778
[2018-04-17 20:16:18.360603]: ====================
[2018-04-17 20:16:18.437809]: [Epoch: 425(42.54254254254254%): Data: 0.0%]:Running loss: 0.21753650903701782
[2018-04-17 20:16:20.041072]: [Epoch: 425(42.54254254254254%): Data: 25.333333333333336%]:Running loss: 4.350729197263718
[2018-04-17 20:16:21.561615]: [Epoch: 425(42.54254254254254%): Data: 50.66666666666667%]:Running loss: 8.483920305967331
[2018-04-17 20:16:26.001922]: Test set accuracy: 94.33962264150944% ,loss = 5.43840117752552
[2018-04-17 20:16:26.149314]: ====================
[2018-04-17 20:16:26.156834]: Elapsed time since starting training: 0:55:52.321465
[2018-04-17 20:16:26.161847]: Estimated time left: 0:19:07.673522
[2018-04-17 20:16:26.166861]: ====================
[2018-04-17 20:16:26.235543]: [Epoch: 426(42.64264264264264%): Data: 0.0%]:Running loss: 0.2175360471010208
[2018-04-17 20:16:27.803211]: [Epoch: 426(42.64264264264264%): Data: 25.333333333333336%]:Running loss: 4.35072261095047
[2018-04-17 20:16:29.387926]: [Epoch: 426(42.64264264264264%): Data: 50.66666666666667%]:Running loss: 8.48390717804432
[2018-04-17 20:16:33.929000]: Test set accuracy: 94.33962264150944% ,loss = 5.438397452235222
[2018-04-17 20:16:34.078397]: ====================
[2018-04-17 20:16:34.084414]: Elapsed time since starting training: 0:56:00.248545
[2018-04-17 20:16:34.089928]: Estimated time left: 0:18:59.745441
[2018-04-17 20:16:34.094440]: ====================
[2018-04-17 20:16:34.167635]: [Epoch: 427(42.74274274274275%): Data: 0.0%]:Running loss: 0.21753589808940887
[2018-04-17 20:16:35.703217]: [Epoch: 427(42.74274274274275%): Data: 25.333333333333336%]:Running loss: 4.350716769695282
[2018-04-17 20:16:37.265372]: [Epoch: 427(42.74274274274275%): Data: 50.66666666666667%]:Running loss: 8.483895495533943
[2018-04-17 20:16:41.729742]: Test set accuracy: 94.33962264150944% ,loss = 5.4383885115385056
[2018-04-17 20:16:41.921251]: ====================
[2018-04-17 20:16:41.928771]: Elapsed time since starting training: 0:56:08.093402
[2018-04-17 20:16:41.935290]: Estimated time left: 0:18:51.900582
[2018-04-17 20:16:41.939801]: ====================
[2018-04-17 20:16:42.015002]: [Epoch: 428(42.84284284284284%): Data: 0.0%]:Running loss: 0.21753554046154022
[2018-04-17 20:16:43.706498]: [Epoch: 428(42.84284284284284%): Data: 25.333333333333336%]:Running loss: 4.350709930062294
[2018-04-17 20:16:45.303243]: [Epoch: 428(42.84284284284284%): Data: 50.66666666666667%]:Running loss: 8.483883455395699
[2018-04-17 20:16:50.271956]: Test set accuracy: 94.33962264150944% ,loss = 5.438380688428879
[2018-04-17 20:16:50.400799]: ====================
[2018-04-17 20:16:50.408819]: Elapsed time since starting training: 0:56:16.573450
[2018-04-17 20:16:50.413833]: Estimated time left: 0:18:43.422038
[2018-04-17 20:16:50.418846]: ====================
[2018-04-17 20:16:50.523123]: [Epoch: 429(42.94294294294294%): Data: 0.0%]:Running loss: 0.21753522753715515
[2018-04-17 20:16:52.387581]: [Epoch: 429(42.94294294294294%): Data: 25.333333333333336%]:Running loss: 4.350704610347748
[2018-04-17 20:16:53.861500]: [Epoch: 429(42.94294294294294%): Data: 50.66666666666667%]:Running loss: 8.483872964978218
[2018-04-17 20:16:58.579546]: Test set accuracy: 94.33962264150944% ,loss = 5.4383739829063416
[2018-04-17 20:16:58.718916]: ====================
[2018-04-17 20:16:58.749497]: Elapsed time since starting training: 0:56:24.914128
[2018-04-17 20:16:58.790105]: Estimated time left: 0:18:35.045264
[2018-04-17 20:16:58.807151]: ====================
[2018-04-17 20:16:58.882352]: [Epoch: 430(43.04304304304304%): Data: 0.0%]:Running loss: 0.21753495931625366
[2018-04-17 20:17:00.727257]: [Epoch: 430(43.04304304304304%): Data: 25.333333333333336%]:Running loss: 4.35069827735424
[2018-04-17 20:17:02.316983]: [Epoch: 430(43.04304304304304%): Data: 50.66666666666667%]:Running loss: 8.483860850334167
[2018-04-17 20:17:06.716682]: Test set accuracy: 94.33962264150944% ,loss = 5.438367277383804
[2018-04-17 20:17:06.923733]: ====================
[2018-04-17 20:17:06.932256]: Elapsed time since starting training: 0:56:33.096385
[2018-04-17 20:17:06.937770]: Estimated time left: 0:18:26.898100
[2018-04-17 20:17:06.942282]: ====================
[2018-04-17 20:17:07.074133]: [Epoch: 431(43.14314314314314%): Data: 0.0%]:Running loss: 0.21753469109535217
[2018-04-17 20:17:08.749086]: [Epoch: 431(43.14314314314314%): Data: 25.333333333333336%]:Running loss: 4.350692301988602
[2018-04-17 20:17:10.417021]: [Epoch: 431(43.14314314314314%): Data: 50.66666666666667%]:Running loss: 8.483848989009857
[2018-04-17 20:17:14.827749]: Test set accuracy: 94.33962264150944% ,loss = 5.438359826803207
[2018-04-17 20:17:14.988677]: ====================
[2018-04-17 20:17:14.994192]: Elapsed time since starting training: 0:56:41.158823
[2018-04-17 20:17:15.002213]: Estimated time left: 0:18:18.833657
[2018-04-17 20:17:15.009232]: ====================
[2018-04-17 20:17:15.088443]: [Epoch: 432(43.24324324324324%): Data: 0.0%]:Running loss: 0.2175343930721283
[2018-04-17 20:17:16.699226]: [Epoch: 432(43.24324324324324%): Data: 25.333333333333336%]:Running loss: 4.350686892867088
[2018-04-17 20:17:18.285945]: [Epoch: 432(43.24324324324324%): Data: 50.66666666666667%]:Running loss: 8.483837842941284
[2018-04-17 20:17:22.876651]: Test set accuracy: 94.33962264150944% ,loss = 5.4383497685194016
[2018-04-17 20:17:23.032064]: ====================
[2018-04-17 20:17:23.037078]: Elapsed time since starting training: 0:56:49.201709
[2018-04-17 20:17:23.043596]: Estimated time left: 0:18:10.792275
[2018-04-17 20:17:23.048107]: ====================
[2018-04-17 20:17:23.119798]: [Epoch: 433(43.34334334334334%): Data: 0.0%]:Running loss: 0.21753399074077606
[2018-04-17 20:17:24.753141]: [Epoch: 433(43.34334334334334%): Data: 25.333333333333336%]:Running loss: 4.350681468844414
[2018-04-17 20:17:26.316799]: [Epoch: 433(43.34334334334334%): Data: 50.66666666666667%]:Running loss: 8.483828023076057
[2018-04-17 20:17:30.752092]: Test set accuracy: 94.33962264150944% ,loss = 5.438343062996864
[2018-04-17 20:17:30.905500]: ====================
[2018-04-17 20:17:30.910013]: Elapsed time since starting training: 0:56:57.074644
[2018-04-17 20:17:30.918534]: Estimated time left: 0:18:02.916835
[2018-04-17 20:17:30.923047]: ====================
[2018-04-17 20:17:30.991729]: [Epoch: 434(43.44344344344344%): Data: 0.0%]:Running loss: 0.21753372251987457
[2018-04-17 20:17:32.587973]: [Epoch: 434(43.44344344344344%): Data: 25.333333333333336%]:Running loss: 4.350674986839294
[2018-04-17 20:17:34.184218]: [Epoch: 434(43.44344344344344%): Data: 50.66666666666667%]:Running loss: 8.48381519317627
[2018-04-17 20:17:38.732311]: Test set accuracy: 94.33962264150944% ,loss = 5.438334494829178
[2018-04-17 20:17:38.846114]: ====================
[2018-04-17 20:17:38.850626]: Elapsed time since starting training: 0:57:05.015257
[2018-04-17 20:17:38.855138]: Estimated time left: 0:17:54.980231
[2018-04-17 20:17:38.859650]: ====================
[2018-04-17 20:17:38.985484]: [Epoch: 435(43.54354354354354%): Data: 0.0%]:Running loss: 0.21753337979316711
[2018-04-17 20:17:40.586241]: [Epoch: 435(43.54354354354354%): Data: 25.333333333333336%]:Running loss: 4.350669413805008
[2018-04-17 20:17:42.164439]: [Epoch: 435(43.54354354354354%): Data: 50.66666666666667%]:Running loss: 8.483804851770401
[2018-04-17 20:17:46.717544]: Test set accuracy: 94.33962264150944% ,loss = 5.438337102532387
[2018-04-17 20:17:46.869448]: ====================
[2018-04-17 20:17:46.873960]: Elapsed time since starting training: 0:57:13.038591
[2018-04-17 20:17:46.882483]: Estimated time left: 0:17:46.953388
[2018-04-17 20:17:46.886994]: ====================
[2018-04-17 20:17:46.963698]: [Epoch: 436(43.64364364364364%): Data: 0.0%]:Running loss: 0.21753348410129547
[2018-04-17 20:17:48.556434]: [Epoch: 436(43.64364364364364%): Data: 25.333333333333336%]:Running loss: 4.3506646156311035
[2018-04-17 20:17:50.012305]: [Epoch: 436(43.64364364364364%): Data: 50.66666666666667%]:Running loss: 8.483794435858727
[2018-04-17 20:17:54.514777]: Test set accuracy: 94.33962264150944% ,loss = 5.438325926661491
[2018-04-17 20:17:54.721327]: ====================
[2018-04-17 20:17:54.728846]: Elapsed time since starting training: 0:57:20.893477
[2018-04-17 20:17:54.734361]: Estimated time left: 0:17:39.101008
[2018-04-17 20:17:54.739374]: ====================
[2018-04-17 20:17:54.815577]: [Epoch: 437(43.74374374374375%): Data: 0.0%]:Running loss: 0.21753303706645966
[2018-04-17 20:17:56.523117]: [Epoch: 437(43.74374374374375%): Data: 25.333333333333336%]:Running loss: 4.350659415125847
[2018-04-17 20:17:58.009569]: [Epoch: 437(43.74374374374375%): Data: 50.66666666666667%]:Running loss: 8.483784198760986
[2018-04-17 20:18:02.553652]: Test set accuracy: 94.33962264150944% ,loss = 5.438319593667984
[2018-04-17 20:18:02.759199]: ====================
[2018-04-17 20:18:02.765716]: Elapsed time since starting training: 0:57:28.930347
[2018-04-17 20:18:02.771231]: Estimated time left: 0:17:31.064138
[2018-04-17 20:18:02.775742]: ====================
[2018-04-17 20:18:02.853951]: [Epoch: 438(43.84384384384384%): Data: 0.0%]:Running loss: 0.21753278374671936
[2018-04-17 20:18:04.561993]: [Epoch: 438(43.84384384384384%): Data: 25.333333333333336%]:Running loss: 4.350654676556587
[2018-04-17 20:18:06.202354]: [Epoch: 438(43.84384384384384%): Data: 50.66666666666667%]:Running loss: 8.483775407075882
[2018-04-17 20:18:10.530362]: Test set accuracy: 94.33962264150944% ,loss = 5.438314378261566
[2018-04-17 20:18:10.650682]: ====================
[2018-04-17 20:18:10.656197]: Elapsed time since starting training: 0:57:36.820326
[2018-04-17 20:18:10.660709]: Estimated time left: 0:17:23.174660
[2018-04-17 20:18:10.665221]: ====================
[2018-04-17 20:18:10.776016]: [Epoch: 439(43.94394394394394%): Data: 0.0%]:Running loss: 0.21753257513046265
[2018-04-17 20:18:12.547726]: [Epoch: 439(43.94394394394394%): Data: 25.333333333333336%]:Running loss: 4.350649729371071
[2018-04-17 20:18:14.196611]: [Epoch: 439(43.94394394394394%): Data: 50.66666666666667%]:Running loss: 8.483765125274658
[2018-04-17 20:18:18.831936]: Test set accuracy: 94.33962264150944% ,loss = 5.438310652971268
[2018-04-17 20:18:18.987350]: ====================
[2018-04-17 20:18:18.991360]: Elapsed time since starting training: 0:57:45.155991
[2018-04-17 20:18:18.998880]: Estimated time left: 0:17:14.836489
[2018-04-17 20:18:19.003893]: ====================
[2018-04-17 20:18:19.078090]: [Epoch: 440(44.04404404404404%): Data: 0.0%]:Running loss: 0.2175324261188507
[2018-04-17 20:18:20.744020]: [Epoch: 440(44.04404404404404%): Data: 25.333333333333336%]:Running loss: 4.350644633173943
[2018-04-17 20:18:22.296649]: [Epoch: 440(44.04404404404404%): Data: 50.66666666666667%]:Running loss: 8.483755335211754
[2018-04-17 20:18:26.787590]: Test set accuracy: 94.33962264150944% ,loss = 5.438297614455223
[2018-04-17 20:18:26.978097]: ====================
[2018-04-17 20:18:26.983110]: Elapsed time since starting training: 0:57:53.147741
[2018-04-17 20:18:26.991131]: Estimated time left: 0:17:06.844238
[2018-04-17 20:18:26.996144]: ====================
[2018-04-17 20:18:27.058811]: [Epoch: 441(44.14414414414414%): Data: 0.0%]:Running loss: 0.21753190457820892
[2018-04-17 20:18:28.836037]: [Epoch: 441(44.14414414414414%): Data: 25.333333333333336%]:Running loss: 4.350639387965202
[2018-04-17 20:18:30.430277]: [Epoch: 441(44.14414414414414%): Data: 50.66666666666667%]:Running loss: 8.48374579846859
[2018-04-17 20:18:34.743243]: Test set accuracy: 94.33962264150944% ,loss = 5.438292399048805
[2018-04-17 20:18:34.853036]: ====================
[2018-04-17 20:18:34.858049]: Elapsed time since starting training: 0:58:01.022680
[2018-04-17 20:18:34.863564]: Estimated time left: 0:16:58.972306
[2018-04-17 20:18:34.868076]: ====================
[2018-04-17 20:18:34.944279]: [Epoch: 442(44.24424424424424%): Data: 0.0%]:Running loss: 0.2175316959619522
[2018-04-17 20:18:36.515457]: [Epoch: 442(44.24424424424424%): Data: 25.333333333333336%]:Running loss: 4.350634947419167
[2018-04-17 20:18:38.068597]: [Epoch: 442(44.24424424424424%): Data: 50.66666666666667%]:Running loss: 8.483736976981163
[2018-04-17 20:18:42.551506]: Test set accuracy: 94.33962264150944% ,loss = 5.4382868111133575
[2018-04-17 20:18:42.666813]: ====================
[2018-04-17 20:18:42.671826]: Elapsed time since starting training: 0:58:08.835955
[2018-04-17 20:18:42.676338]: Estimated time left: 0:16:51.159533
[2018-04-17 20:18:42.680850]: ====================
[2018-04-17 20:18:42.845287]: [Epoch: 443(44.34434434434434%): Data: 0.0%]:Running loss: 0.2175314724445343
[2018-04-17 20:18:44.526758]: [Epoch: 443(44.34434434434434%): Data: 25.333333333333336%]:Running loss: 4.350629821419716
[2018-04-17 20:18:46.071868]: [Epoch: 443(44.34434434434434%): Data: 50.66666666666667%]:Running loss: 8.483727753162384
[2018-04-17 20:18:50.460536]: Test set accuracy: 94.33962264150944% ,loss = 5.43828047811985
[2018-04-17 20:18:50.575843]: ====================
[2018-04-17 20:18:50.580355]: Elapsed time since starting training: 0:58:16.744485
[2018-04-17 20:18:50.584867]: Estimated time left: 0:16:43.250502
[2018-04-17 20:18:50.589378]: ====================
[2018-04-17 20:18:50.662573]: [Epoch: 444(44.44444444444444%): Data: 0.0%]:Running loss: 0.217531219124794
[2018-04-17 20:18:52.205175]: [Epoch: 444(44.44444444444444%): Data: 25.333333333333336%]:Running loss: 4.350625425577164
[2018-04-17 20:18:53.638487]: [Epoch: 444(44.44444444444444%): Data: 50.66666666666667%]:Running loss: 8.483718872070312
[2018-04-17 20:18:58.110377]: Test set accuracy: 94.33962264150944% ,loss = 5.438275262713432
[2018-04-17 20:18:58.279828]: ====================
[2018-04-17 20:18:58.285342]: Elapsed time since starting training: 0:58:24.449973
[2018-04-17 20:18:58.291358]: Estimated time left: 0:16:35.544512
[2018-04-17 20:18:58.295870]: ====================
[2018-04-17 20:18:58.364052]: [Epoch: 445(44.54454454454454%): Data: 0.0%]:Running loss: 0.2175310105085373
[2018-04-17 20:19:00.122729]: [Epoch: 445(44.54454454454454%): Data: 25.333333333333336%]:Running loss: 4.350620403885841
[2018-04-17 20:19:01.768103]: [Epoch: 445(44.54454454454454%): Data: 50.66666666666667%]:Running loss: 8.48370911180973
[2018-04-17 20:19:06.278094]: Test set accuracy: 94.33962264150944% ,loss = 5.438268929719925
[2018-04-17 20:19:06.474116]: ====================
[2018-04-17 20:19:06.489157]: Elapsed time since starting training: 0:58:32.653788
[2018-04-17 20:19:06.497177]: Estimated time left: 0:16:27.338192
[2018-04-17 20:19:06.503195]: ====================
[2018-04-17 20:19:06.601956]: [Epoch: 446(44.64464464464464%): Data: 0.0%]:Running loss: 0.217530757188797
[2018-04-17 20:19:08.842414]: [Epoch: 446(44.64464464464464%): Data: 25.333333333333336%]:Running loss: 4.350616052746773
[2018-04-17 20:19:11.033239]: [Epoch: 446(44.64464464464464%): Data: 50.66666666666667%]:Running loss: 8.48370036482811
[2018-04-17 20:19:17.363859]: Test set accuracy: 94.33962264150944% ,loss = 5.438262969255447
[2018-04-17 20:19:17.565395]: ====================
[2018-04-17 20:19:17.570409]: Elapsed time since starting training: 0:58:43.735040
[2018-04-17 20:19:17.576925]: Estimated time left: 0:16:16.258444
[2018-04-17 20:19:17.581939]: ====================
[2018-04-17 20:19:17.653629]: [Epoch: 447(44.74474474474475%): Data: 0.0%]:Running loss: 0.2175305187702179
[2018-04-17 20:19:19.322069]: [Epoch: 447(44.74474474474475%): Data: 25.333333333333336%]:Running loss: 4.350611925125122
[2018-04-17 20:19:21.612155]: [Epoch: 447(44.74474474474475%): Data: 50.66666666666667%]:Running loss: 8.483691722154617
[2018-04-17 20:19:26.372313]: Test set accuracy: 94.33962264150944% ,loss = 5.438262224197388
[2018-04-17 20:19:26.493134]: ====================
[2018-04-17 20:19:26.497144]: Elapsed time since starting training: 0:58:52.661775
[2018-04-17 20:19:26.502158]: Estimated time left: 0:16:07.333211
[2018-04-17 20:19:26.507171]: ====================
[2018-04-17 20:19:26.592899]: [Epoch: 448(44.84484484484484%): Data: 0.0%]:Running loss: 0.2175304889678955
[2018-04-17 20:19:28.139511]: [Epoch: 448(44.84484484484484%): Data: 25.333333333333336%]:Running loss: 4.350607454776764
[2018-04-17 20:19:29.810454]: [Epoch: 448(44.84484484484484%): Data: 50.66666666666667%]:Running loss: 8.483683407306671
[2018-04-17 20:19:34.326964]: Test set accuracy: 94.33962264150944% ,loss = 5.438249558210373
[2018-04-17 20:19:34.490900]: ====================
[2018-04-17 20:19:34.494910]: Elapsed time since starting training: 0:59:00.659541
[2018-04-17 20:19:34.498921]: Estimated time left: 0:15:59.336448
[2018-04-17 20:19:34.502932]: ====================
[2018-04-17 20:19:34.588660]: [Epoch: 449(44.94494494494494%): Data: 0.0%]:Running loss: 0.21752998232841492
[2018-04-17 20:19:36.147805]: [Epoch: 449(44.94494494494494%): Data: 25.333333333333336%]:Running loss: 4.350602447986603
[2018-04-17 20:19:37.809225]: [Epoch: 449(44.94494494494494%): Data: 50.66666666666667%]:Running loss: 8.483674123883247
[2018-04-17 20:19:42.322223]: Test set accuracy: 94.33962264150944% ,loss = 5.438249185681343
[2018-04-17 20:19:42.479642]: ====================
[2018-04-17 20:19:42.484154]: Elapsed time since starting training: 0:59:08.648785
[2018-04-17 20:19:42.489669]: Estimated time left: 0:15:51.346202
[2018-04-17 20:19:42.494180]: ====================
[2018-04-17 20:19:42.572890]: [Epoch: 450(45.04504504504504%): Data: 0.0%]:Running loss: 0.21752996742725372
[2018-04-17 20:19:44.138051]: [Epoch: 450(45.04504504504504%): Data: 25.333333333333336%]:Running loss: 4.350599884986877
[2018-04-17 20:19:45.673634]: [Epoch: 450(45.04504504504504%): Data: 50.66666666666667%]:Running loss: 8.4836685359478
[2018-04-17 20:19:50.266346]: Test set accuracy: 94.33962264150944% ,loss = 5.438245087862015
[2018-04-17 20:19:50.447328]: ====================
[2018-04-17 20:19:50.452842]: Elapsed time since starting training: 0:59:16.617473
[2018-04-17 20:19:50.457856]: Estimated time left: 0:15:43.377513
[2018-04-17 20:19:50.462869]: ====================
[2018-04-17 20:19:50.541077]: [Epoch: 451(45.14514514514514%): Data: 0.0%]:Running loss: 0.2175298035144806
[2018-04-17 20:19:52.129301]: [Epoch: 451(45.14514514514514%): Data: 25.333333333333336%]:Running loss: 4.350595980882645
[2018-04-17 20:19:53.692457]: [Epoch: 451(45.14514514514514%): Data: 50.66666666666667%]:Running loss: 8.483661010861397
[2018-04-17 20:19:58.119728]: Test set accuracy: 94.33962264150944% ,loss = 5.4382432252168655
[2018-04-17 20:19:58.270630]: ====================
[2018-04-17 20:19:58.276145]: Elapsed time since starting training: 0:59:24.440776
[2018-04-17 20:19:58.280656]: Estimated time left: 0:15:35.554713
[2018-04-17 20:19:58.287677]: ====================
[2018-04-17 20:19:58.364379]: [Epoch: 452(45.24524524524524%): Data: 0.0%]:Running loss: 0.21752972900867462
[2018-04-17 20:19:59.935056]: [Epoch: 452(45.24524524524524%): Data: 25.333333333333336%]:Running loss: 4.350590854883194
[2018-04-17 20:20:01.435547]: [Epoch: 452(45.24524524524524%): Data: 50.66666666666667%]:Running loss: 8.483651533722878
[2018-04-17 20:20:05.837250]: Test set accuracy: 94.33962264150944% ,loss = 5.43823167681694
[2018-04-17 20:20:06.013218]: ====================
[2018-04-17 20:20:06.018231]: Elapsed time since starting training: 0:59:32.182862
[2018-04-17 20:20:06.024247]: Estimated time left: 0:15:27.811122
[2018-04-17 20:20:06.029260]: ====================
[2018-04-17 20:20:06.099948]: [Epoch: 453(45.34534534534534%): Data: 0.0%]:Running loss: 0.2175292670726776
[2018-04-17 20:20:07.738304]: [Epoch: 453(45.34534534534534%): Data: 25.333333333333336%]:Running loss: 4.350588157773018
[2018-04-17 20:20:09.366634]: [Epoch: 453(45.34534534534534%): Data: 50.66666666666667%]:Running loss: 8.483645409345627
[2018-04-17 20:20:14.107741]: Test set accuracy: 94.33962264150944% ,loss = 5.438227206468582
[2018-04-17 20:20:14.220040]: ====================
[2018-04-17 20:20:14.226055]: Elapsed time since starting training: 0:59:40.390186
[2018-04-17 20:20:14.230567]: Estimated time left: 0:15:19.604802
[2018-04-17 20:20:14.235581]: ====================
[2018-04-17 20:20:14.317302]: [Epoch: 454(45.44544544544545%): Data: 0.0%]:Running loss: 0.2175290882587433
[2018-04-17 20:20:15.902513]: [Epoch: 454(45.44544544544545%): Data: 25.333333333333336%]:Running loss: 4.350583344697952
[2018-04-17 20:20:17.575461]: [Epoch: 454(45.44544544544545%): Data: 50.66666666666667%]:Running loss: 8.483636915683746
[2018-04-17 20:20:22.239363]: Test set accuracy: 94.33962264150944% ,loss = 5.438227578997612
[2018-04-17 20:20:22.398285]: ====================
[2018-04-17 20:20:22.402797]: Elapsed time since starting training: 0:59:48.567428
[2018-04-17 20:20:22.407822]: Estimated time left: 0:15:11.427547
[2018-04-17 20:20:22.412323]: ====================
[2018-04-17 20:20:22.495544]: [Epoch: 455(45.545545545545544%): Data: 0.0%]:Running loss: 0.21752910315990448
[2018-04-17 20:20:24.139916]: [Epoch: 455(45.545545545545544%): Data: 25.333333333333336%]:Running loss: 4.350579664111137
[2018-04-17 20:20:25.759222]: [Epoch: 455(45.545545545545544%): Data: 50.66666666666667%]:Running loss: 8.483629181981087
[2018-04-17 20:20:30.090238]: Test set accuracy: 94.33962264150944% ,loss = 5.438223108649254
[2018-04-17 20:20:30.278238]: ====================
[2018-04-17 20:20:30.283253]: Elapsed time since starting training: 0:59:56.447884
[2018-04-17 20:20:30.287763]: Estimated time left: 0:15:03.547606
[2018-04-17 20:20:30.292777]: ====================
[2018-04-17 20:20:30.365973]: [Epoch: 456(45.645645645645644%): Data: 0.0%]:Running loss: 0.21752892434597015
[2018-04-17 20:20:32.067997]: [Epoch: 456(45.645645645645644%): Data: 25.333333333333336%]:Running loss: 4.35057657957077
[2018-04-17 20:20:33.718887]: [Epoch: 456(45.645645645645644%): Data: 50.66666666666667%]:Running loss: 8.483622789382935
[2018-04-17 20:20:38.203812]: Test set accuracy: 94.33962264150944% ,loss = 5.4382216185331345
[2018-04-17 20:20:38.366745]: ====================
[2018-04-17 20:20:38.370756]: Elapsed time since starting training: 1:00:04.535387
[2018-04-17 20:20:38.376271]: Estimated time left: 0:14:55.459098
[2018-04-17 20:20:38.381284]: ====================
[2018-04-17 20:20:38.463001]: [Epoch: 457(45.74574574574575%): Data: 0.0%]:Running loss: 0.21752886474132538
[2018-04-17 20:20:40.071277]: [Epoch: 457(45.74574574574575%): Data: 25.333333333333336%]:Running loss: 4.3505717515945435
[2018-04-17 20:20:41.687576]: [Epoch: 457(45.74574574574575%): Data: 50.66666666666667%]:Running loss: 8.483614042401314
[2018-04-17 20:20:46.581589]: Test set accuracy: 94.33962264150944% ,loss = 5.43820858001709
[2018-04-17 20:20:46.743519]: ====================
[2018-04-17 20:20:46.748532]: Elapsed time since starting training: 1:00:12.913163
[2018-04-17 20:20:46.756554]: Estimated time left: 0:14:47.079317
[2018-04-17 20:20:46.761568]: ====================
[2018-04-17 20:20:46.841782]: [Epoch: 458(45.845845845845844%): Data: 0.0%]:Running loss: 0.2175283432006836
[2018-04-17 20:20:48.378867]: [Epoch: 458(45.845845845845844%): Data: 25.333333333333336%]:Running loss: 4.3505686819553375
[2018-04-17 20:20:49.916456]: [Epoch: 458(45.845845845845844%): Data: 50.66666666666667%]:Running loss: 8.48360837996006
[2018-04-17 20:20:54.322672]: Test set accuracy: 94.33962264150944% ,loss = 5.438204109668732
[2018-04-17 20:20:54.527717]: ====================
[2018-04-17 20:20:54.538747]: Elapsed time since starting training: 1:00:20.703378
[2018-04-17 20:20:54.545264]: Estimated time left: 0:14:39.290105
[2018-04-17 20:20:54.550277]: ====================
[2018-04-17 20:20:54.619964]: [Epoch: 459(45.94594594594595%): Data: 0.0%]:Running loss: 0.21752816438674927
[2018-04-17 20:20:56.232751]: [Epoch: 459(45.94594594594595%): Data: 25.333333333333336%]:Running loss: 4.350565522909164
[2018-04-17 20:20:57.864089]: [Epoch: 459(45.94594594594595%): Data: 50.66666666666667%]:Running loss: 8.483601495623589
[2018-04-17 20:21:01.922379]: Test set accuracy: 94.33962264150944% ,loss = 5.438203737139702
[2018-04-17 20:21:02.040705]: ====================
[2018-04-17 20:21:02.046209]: Elapsed time since starting training: 1:00:28.210338
[2018-04-17 20:21:02.051222]: Estimated time left: 0:14:31.784649
[2018-04-17 20:21:02.055735]: ====================
[2018-04-17 20:21:02.129931]: [Epoch: 460(46.046046046046044%): Data: 0.0%]:Running loss: 0.21752814948558807
[2018-04-17 20:21:03.689078]: [Epoch: 460(46.046046046046044%): Data: 25.333333333333336%]:Running loss: 4.350561261177063
[2018-04-17 20:21:05.221151]: [Epoch: 460(46.046046046046044%): Data: 50.66666666666667%]:Running loss: 8.4835936576128
[2018-04-17 20:21:10.528263]: Test set accuracy: 94.33962264150944% ,loss = 5.438195168972015
[2018-04-17 20:21:10.779431]: ====================
[2018-04-17 20:21:10.786950]: Elapsed time since starting training: 1:00:36.951080
[2018-04-17 20:21:10.795472]: Estimated time left: 0:14:23.039897
[2018-04-17 20:21:10.800486]: ====================
[2018-04-17 20:21:10.882704]: [Epoch: 461(46.146146146146144%): Data: 0.0%]:Running loss: 0.21752780675888062
[2018-04-17 20:21:12.496997]: [Epoch: 461(46.146146146146144%): Data: 25.333333333333336%]:Running loss: 4.3505586087703705
[2018-04-17 20:21:14.295780]: [Epoch: 461(46.146146146146144%): Data: 50.66666666666667%]:Running loss: 8.483587935566902
[2018-04-17 20:21:19.349719]: Test set accuracy: 94.33962264150944% ,loss = 5.4381974041461945
[2018-04-17 20:21:19.478060]: ====================
[2018-04-17 20:21:19.483073]: Elapsed time since starting training: 1:00:45.647704
[2018-04-17 20:21:19.488588]: Estimated time left: 0:14:14.346781
[2018-04-17 20:21:19.495105]: ====================
[2018-04-17 20:21:19.568300]: [Epoch: 462(46.246246246246244%): Data: 0.0%]:Running loss: 0.21752789616584778
[2018-04-17 20:21:21.261803]: [Epoch: 462(46.246246246246244%): Data: 25.333333333333336%]:Running loss: 4.350554972887039
[2018-04-17 20:21:23.060587]: [Epoch: 462(46.246246246246244%): Data: 50.66666666666667%]:Running loss: 8.483581393957138
[2018-04-17 20:21:28.408806]: Test set accuracy: 94.33962264150944% ,loss = 5.438186600804329
[2018-04-17 20:21:28.616860]: ====================
[2018-04-17 20:21:28.622876]: Elapsed time since starting training: 1:00:54.787005
[2018-04-17 20:21:28.637415]: Estimated time left: 0:14:05.197954
[2018-04-17 20:21:28.643431]: ====================
[2018-04-17 20:21:28.780796]: [Epoch: 463(46.346346346346344%): Data: 0.0%]:Running loss: 0.21752746403217316
[2018-04-17 20:21:30.374533]: [Epoch: 463(46.346346346346344%): Data: 25.333333333333336%]:Running loss: 4.3505517691373825
[2018-04-17 20:21:31.935685]: [Epoch: 463(46.346346346346344%): Data: 50.66666666666667%]:Running loss: 8.483574330806732
[2018-04-17 20:21:36.264696]: Test set accuracy: 94.33962264150944% ,loss = 5.438186973333359
[2018-04-17 20:21:36.414093]: ====================
[2018-04-17 20:21:36.418605]: Elapsed time since starting training: 1:01:02.583236
[2018-04-17 20:21:36.426125]: Estimated time left: 0:13:57.409244
[2018-04-17 20:21:36.431139]: ====================
[2018-04-17 20:21:36.507843]: [Epoch: 464(46.44644644644645%): Data: 0.0%]:Running loss: 0.21752747893333435
[2018-04-17 20:21:38.062977]: [Epoch: 464(46.44644644644645%): Data: 25.333333333333336%]:Running loss: 4.350548818707466
[2018-04-17 20:21:39.725899]: [Epoch: 464(46.44644644644645%): Data: 50.66666666666667%]:Running loss: 8.483569577336311
[2018-04-17 20:21:44.055912]: Test set accuracy: 94.33962264150944% ,loss = 5.438179522752762
[2018-04-17 20:21:44.334654]: ====================
[2018-04-17 20:21:44.342679]: Elapsed time since starting training: 1:01:10.507310
[2018-04-17 20:21:44.347688]: Estimated time left: 0:13:49.487681
[2018-04-17 20:21:44.352701]: ====================
[2018-04-17 20:21:44.424393]: [Epoch: 465(46.546546546546544%): Data: 0.0%]:Running loss: 0.21752718091011047
[2018-04-17 20:21:45.977522]: [Epoch: 465(46.546546546546544%): Data: 25.333333333333336%]:Running loss: 4.3505453914403915
[2018-04-17 20:21:47.575271]: [Epoch: 465(46.546546546546544%): Data: 50.66666666666667%]:Running loss: 8.483563244342804
[2018-04-17 20:21:52.156953]: Test set accuracy: 94.33962264150944% ,loss = 5.438177660107613
[2018-04-17 20:21:52.292814]: ====================
[2018-04-17 20:21:52.299331]: Elapsed time since starting training: 1:01:18.463962
[2018-04-17 20:21:52.315374]: Estimated time left: 0:13:41.519995
[2018-04-17 20:21:52.366510]: ====================
[2018-04-17 20:21:52.445721]: [Epoch: 466(46.646646646646644%): Data: 0.0%]:Running loss: 0.2175271064043045
[2018-04-17 20:21:53.985817]: [Epoch: 466(46.646646646646644%): Data: 25.333333333333336%]:Running loss: 4.350542649626732
[2018-04-17 20:21:55.631692]: [Epoch: 466(46.646646646646644%): Data: 50.66666666666667%]:Running loss: 8.483557805418968
[2018-04-17 20:22:00.176777]: Test set accuracy: 94.33962264150944% ,loss = 5.438167974352837
[2018-04-17 20:22:00.328681]: ====================
[2018-04-17 20:22:00.333193]: Elapsed time since starting training: 1:01:26.497323
[2018-04-17 20:22:00.337705]: Estimated time left: 0:13:33.498165
[2018-04-17 20:22:00.342719]: ====================
[2018-04-17 20:22:00.414912]: [Epoch: 467(46.74674674674675%): Data: 0.0%]:Running loss: 0.21752671897411346
[2018-04-17 20:22:01.966035]: [Epoch: 467(46.74674674674675%): Data: 25.333333333333336%]:Running loss: 4.3505387008190155
[2018-04-17 20:22:03.671069]: [Epoch: 467(46.74674674674675%): Data: 50.66666666666667%]:Running loss: 8.483550176024437
[2018-04-17 20:22:08.130927]: Test set accuracy: 94.33962264150944% ,loss = 5.438169836997986
[2018-04-17 20:22:08.305893]: ====================
[2018-04-17 20:22:08.310906]: Elapsed time since starting training: 1:01:34.475537
[2018-04-17 20:22:08.315919]: Estimated time left: 0:13:25.519450
[2018-04-17 20:22:08.322436]: ====================
[2018-04-17 20:22:08.399642]: [Epoch: 468(46.846846846846844%): Data: 0.0%]:Running loss: 0.21752679347991943
[2018-04-17 20:22:09.959790]: [Epoch: 468(46.846846846846844%): Data: 25.333333333333336%]:Running loss: 4.3505363166332245
[2018-04-17 20:22:11.553528]: [Epoch: 468(46.846846846846844%): Data: 50.66666666666667%]:Running loss: 8.483545362949371
[2018-04-17 20:22:15.979803]: Test set accuracy: 94.33962264150944% ,loss = 5.438170954585075
[2018-04-17 20:22:16.120678]: ====================
[2018-04-17 20:22:16.125691]: Elapsed time since starting training: 1:01:42.290322
[2018-04-17 20:22:16.130704]: Estimated time left: 0:13:17.704665
[2018-04-17 20:22:16.135216]: ====================
[2018-04-17 20:22:16.206907]: [Epoch: 469(46.94694694694695%): Data: 0.0%]:Running loss: 0.21752683818340302
[2018-04-17 20:22:17.740485]: [Epoch: 469(46.94694694694695%): Data: 25.333333333333336%]:Running loss: 4.350533559918404
[2018-04-17 20:22:19.355279]: [Epoch: 469(46.94694694694695%): Data: 50.66666666666667%]:Running loss: 8.48353998363018
[2018-04-17 20:22:23.790075]: Test set accuracy: 94.33962264150944% ,loss = 5.43816015124321
[2018-04-17 20:22:23.965040]: ====================
[2018-04-17 20:22:23.969552]: Elapsed time since starting training: 1:01:50.133682
[2018-04-17 20:22:23.974064]: Estimated time left: 0:13:09.861305
[2018-04-17 20:22:23.980080]: ====================
[2018-04-17 20:22:24.061797]: [Epoch: 470(47.047047047047045%): Data: 0.0%]:Running loss: 0.2175264060497284
[2018-04-17 20:22:25.669071]: [Epoch: 470(47.047047047047045%): Data: 25.333333333333336%]:Running loss: 4.350530534982681
[2018-04-17 20:22:27.295395]: [Epoch: 470(47.047047047047045%): Data: 50.66666666666667%]:Running loss: 8.483533591032028
[2018-04-17 20:22:31.957792]: Test set accuracy: 94.33962264150944% ,loss = 5.43815940618515
[2018-04-17 20:22:32.105185]: ====================
[2018-04-17 20:22:32.109195]: Elapsed time since starting training: 1:01:58.273826
[2018-04-17 20:22:32.114209]: Estimated time left: 0:13:01.721662
[2018-04-17 20:22:32.118721]: ====================
[2018-04-17 20:22:32.191915]: [Epoch: 471(47.147147147147145%): Data: 0.0%]:Running loss: 0.217526376247406
[2018-04-17 20:22:33.808213]: [Epoch: 471(47.147147147147145%): Data: 25.333333333333336%]:Running loss: 4.350527346134186
[2018-04-17 20:22:35.340287]: [Epoch: 471(47.147147147147145%): Data: 50.66666666666667%]:Running loss: 8.483528390526772
[2018-04-17 20:22:39.789116]: Test set accuracy: 94.33962264150944% ,loss = 5.43815903365612
[2018-04-17 20:22:39.978119]: ====================
[2018-04-17 20:22:39.986641]: Elapsed time since starting training: 1:02:06.151272
[2018-04-17 20:22:39.991153]: Estimated time left: 0:12:53.844717
[2018-04-17 20:22:39.996167]: ====================
[2018-04-17 20:22:40.072871]: [Epoch: 472(47.247247247247245%): Data: 0.0%]:Running loss: 0.2175263613462448
[2018-04-17 20:22:41.752337]: [Epoch: 472(47.247247247247245%): Data: 25.333333333333336%]:Running loss: 4.350524619221687
[2018-04-17 20:22:43.419770]: [Epoch: 472(47.247247247247245%): Data: 50.66666666666667%]:Running loss: 8.483522459864616
[2018-04-17 20:22:47.921741]: Test set accuracy: 94.33962264150944% ,loss = 5.438158288598061
[2018-04-17 20:22:48.066125]: ====================
[2018-04-17 20:22:48.070136]: Elapsed time since starting training: 1:02:14.234767
[2018-04-17 20:22:48.074647]: Estimated time left: 0:12:45.760722
[2018-04-17 20:22:48.079160]: ====================
[2018-04-17 20:22:48.152355]: [Epoch: 473(47.347347347347345%): Data: 0.0%]:Running loss: 0.21752633154392242
[2018-04-17 20:22:49.708492]: [Epoch: 473(47.347347347347345%): Data: 25.333333333333336%]:Running loss: 4.350522398948669
[2018-04-17 20:22:51.271147]: [Epoch: 473(47.347347347347345%): Data: 50.66666666666667%]:Running loss: 8.483517199754715
[2018-04-17 20:22:55.681875]: Test set accuracy: 94.33962264150944% ,loss = 5.438154935836792
[2018-04-17 20:22:55.798686]: ====================
[2018-04-17 20:22:55.803198]: Elapsed time since starting training: 1:02:21.967829
[2018-04-17 20:22:55.807710]: Estimated time left: 0:12:38.027659
[2018-04-17 20:22:55.812723]: ====================
[2018-04-17 20:22:55.882909]: [Epoch: 474(47.44744744744745%): Data: 0.0%]:Running loss: 0.21752619743347168
[2018-04-17 20:22:57.458599]: [Epoch: 474(47.44744744744745%): Data: 25.333333333333336%]:Running loss: 4.350519046187401
[2018-04-17 20:22:59.005713]: [Epoch: 474(47.44744744744745%): Data: 50.66666666666667%]:Running loss: 8.48351202905178
[2018-04-17 20:23:03.433486]: Test set accuracy: 94.33962264150944% ,loss = 5.438148230314255
[2018-04-17 20:23:03.608953]: ====================
[2018-04-17 20:23:03.621486]: Elapsed time since starting training: 1:02:29.786117
[2018-04-17 20:23:03.636025]: Estimated time left: 0:12:30.199344
[2018-04-17 20:23:03.640537]: ====================
[2018-04-17 20:23:03.715736]: [Epoch: 475(47.547547547547545%): Data: 0.0%]:Running loss: 0.2175259292125702
[2018-04-17 20:23:05.328525]: [Epoch: 475(47.547547547547545%): Data: 25.333333333333336%]:Running loss: 4.350516691803932
[2018-04-17 20:23:06.938306]: [Epoch: 475(47.547547547547545%): Data: 50.66666666666667%]:Running loss: 8.483506977558136
[2018-04-17 20:23:11.484394]: Test set accuracy: 94.33962264150944% ,loss = 5.438141152262688
[2018-04-17 20:23:11.603711]: ====================
[2018-04-17 20:23:11.608223]: Elapsed time since starting training: 1:02:37.772854
[2018-04-17 20:23:11.612735]: Estimated time left: 0:12:22.222634
[2018-04-17 20:23:11.619754]: ====================
[2018-04-17 20:23:11.735061]: [Epoch: 476(47.647647647647645%): Data: 0.0%]:Running loss: 0.2175256460905075
[2018-04-17 20:23:13.307240]: [Epoch: 476(47.647647647647645%): Data: 25.333333333333336%]:Running loss: 4.350514084100723
[2018-04-17 20:23:14.857364]: [Epoch: 476(47.647647647647645%): Data: 50.66666666666667%]:Running loss: 8.48350203037262
[2018-04-17 20:23:19.433530]: Test set accuracy: 94.33962264150944% ,loss = 5.438134074211121
[2018-04-17 20:23:19.572401]: ====================
[2018-04-17 20:23:19.577413]: Elapsed time since starting training: 1:02:45.741543
[2018-04-17 20:23:19.589445]: Estimated time left: 0:12:14.245924
[2018-04-17 20:23:19.608997]: ====================
[2018-04-17 20:23:19.707760]: [Epoch: 477(47.74774774774775%): Data: 0.0%]:Running loss: 0.21752536296844482
[2018-04-17 20:23:21.248857]: [Epoch: 477(47.74774774774775%): Data: 25.333333333333336%]:Running loss: 4.3505111038684845
[2018-04-17 20:23:22.832569]: [Epoch: 477(47.74774774774775%): Data: 50.66666666666667%]:Running loss: 8.483496874570847
[2018-04-17 20:23:27.235275]: Test set accuracy: 94.33962264150944% ,loss = 5.4381363093853
[2018-04-17 20:23:27.434805]: ====================
[2018-04-17 20:23:27.440320]: Elapsed time since starting training: 1:02:53.604951
[2018-04-17 20:23:27.445334]: Estimated time left: 0:12:06.390537
[2018-04-17 20:23:27.449345]: ====================
[2018-04-17 20:23:27.522037]: [Epoch: 478(47.847847847847845%): Data: 0.0%]:Running loss: 0.217525452375412
[2018-04-17 20:23:29.141344]: [Epoch: 478(47.847847847847845%): Data: 25.333333333333336%]:Running loss: 4.350509211421013
[2018-04-17 20:23:30.690964]: [Epoch: 478(47.847847847847845%): Data: 50.66666666666667%]:Running loss: 8.483492955565453
[2018-04-17 20:23:35.086652]: Test set accuracy: 94.33962264150944% ,loss = 5.438130721449852
[2018-04-17 20:23:35.276658]: ====================
[2018-04-17 20:23:35.286684]: Elapsed time since starting training: 1:03:01.451315
[2018-04-17 20:23:35.291196]: Estimated time left: 0:11:58.544173
[2018-04-17 20:23:35.296209]: ====================
[2018-04-17 20:23:35.379431]: [Epoch: 479(47.94794794794795%): Data: 0.0%]:Running loss: 0.21752522885799408
[2018-04-17 20:23:36.968656]: [Epoch: 479(47.94794794794795%): Data: 25.333333333333336%]:Running loss: 4.350506916642189
[2018-04-17 20:23:38.529306]: [Epoch: 479(47.94794794794795%): Data: 50.66666666666667%]:Running loss: 8.483487725257874
[2018-04-17 20:23:42.885388]: Test set accuracy: 94.33962264150944% ,loss = 5.438132211565971
[2018-04-17 20:23:43.002199]: ====================
[2018-04-17 20:23:43.010722]: Elapsed time since starting training: 1:03:09.174853
[2018-04-17 20:23:43.016237]: Estimated time left: 0:11:50.819132
[2018-04-17 20:23:43.021752]: ====================
[2018-04-17 20:23:43.099459]: [Epoch: 480(48.048048048048045%): Data: 0.0%]:Running loss: 0.21752528846263885
[2018-04-17 20:23:44.697206]: [Epoch: 480(48.048048048048045%): Data: 25.333333333333336%]:Running loss: 4.350504904985428
[2018-04-17 20:23:46.261365]: [Epoch: 480(48.048048048048045%): Data: 50.66666666666667%]:Running loss: 8.483483359217644
[2018-04-17 20:23:50.726739]: Test set accuracy: 94.33962264150944% ,loss = 5.438124015927315
[2018-04-17 20:23:50.893182]: ====================
[2018-04-17 20:23:50.901203]: Elapsed time since starting training: 1:03:17.065332
[2018-04-17 20:23:50.905715]: Estimated time left: 0:11:42.930156
[2018-04-17 20:23:50.909725]: ====================
[2018-04-17 20:23:50.981918]: [Epoch: 481(48.148148148148145%): Data: 0.0%]:Running loss: 0.2175249606370926
[2018-04-17 20:23:52.558109]: [Epoch: 481(48.148148148148145%): Data: 25.333333333333336%]:Running loss: 4.350502595305443
[2018-04-17 20:23:54.166385]: [Epoch: 481(48.148148148148145%): Data: 50.66666666666667%]:Running loss: 8.483479455113411
[2018-04-17 20:23:58.447276]: Test set accuracy: 94.33962264150944% ,loss = 5.4381269961595535
[2018-04-17 20:23:58.600676]: ====================
[2018-04-17 20:23:58.605188]: Elapsed time since starting training: 1:03:24.769819
[2018-04-17 20:23:58.609699]: Estimated time left: 0:11:35.225670
[2018-04-17 20:23:58.614212]: ====================
[2018-04-17 20:23:58.690414]: [Epoch: 482(48.248248248248245%): Data: 0.0%]:Running loss: 0.21752507984638214
[2018-04-17 20:24:00.200931]: [Epoch: 482(48.248248248248245%): Data: 25.333333333333336%]:Running loss: 4.350500047206879
[2018-04-17 20:24:01.808204]: [Epoch: 482(48.248248248248245%): Data: 50.66666666666667%]:Running loss: 8.483473777770996
[2018-04-17 20:24:06.286612]: Test set accuracy: 94.33962264150944% ,loss = 5.4381199181079865
[2018-04-17 20:24:06.409439]: ====================
[2018-04-17 20:24:06.413952]: Elapsed time since starting training: 1:03:32.578583
[2018-04-17 20:24:06.418463]: Estimated time left: 0:11:27.416906
[2018-04-17 20:24:06.423477]: ====================
[2018-04-17 20:24:06.550815]: [Epoch: 483(48.348348348348345%): Data: 0.0%]:Running loss: 0.21752479672431946
[2018-04-17 20:24:08.084393]: [Epoch: 483(48.348348348348345%): Data: 25.333333333333336%]:Running loss: 4.350497797131538
[2018-04-17 20:24:09.700189]: [Epoch: 483(48.348348348348345%): Data: 50.66666666666667%]:Running loss: 8.483469486236572
[2018-04-17 20:24:14.385648]: Test set accuracy: 94.33962264150944% ,loss = 5.438122525811195
[2018-04-17 20:24:14.580667]: ====================
[2018-04-17 20:24:14.587184]: Elapsed time since starting training: 1:03:40.751815
[2018-04-17 20:24:14.591695]: Estimated time left: 0:11:19.243674
[2018-04-17 20:24:14.595706]: ====================
[2018-04-17 20:24:14.664892]: [Epoch: 484(48.44844844844845%): Data: 0.0%]:Running loss: 0.21752490103244781
[2018-04-17 20:24:16.429583]: [Epoch: 484(48.44844844844845%): Data: 25.333333333333336%]:Running loss: 4.350495830178261
[2018-04-17 20:24:18.062424]: [Epoch: 484(48.44844844844845%): Data: 50.66666666666667%]:Running loss: 8.483466014266014
[2018-04-17 20:24:22.353840]: Test set accuracy: 94.33962264150944% ,loss = 5.438115820288658
[2018-04-17 20:24:22.488699]: ====================
[2018-04-17 20:24:22.493211]: Elapsed time since starting training: 1:03:48.657842
[2018-04-17 20:24:22.499729]: Estimated time left: 0:11:11.336142
[2018-04-17 20:24:22.507248]: ====================
[2018-04-17 20:24:22.579941]: [Epoch: 485(48.548548548548546%): Data: 0.0%]:Running loss: 0.21752463281154633
[2018-04-17 20:24:24.020271]: [Epoch: 485(48.548548548548546%): Data: 25.333333333333336%]:Running loss: 4.350492760539055
[2018-04-17 20:24:25.325742]: [Epoch: 485(48.548548548548546%): Data: 50.66666666666667%]:Running loss: 8.483460679650307
[2018-04-17 20:24:28.809505]: Test set accuracy: 94.33962264150944% ,loss = 5.4381173104047775
[2018-04-17 20:24:28.928321]: ====================
[2018-04-17 20:24:28.933335]: Elapsed time since starting training: 1:03:55.097966
[2018-04-17 20:24:28.937847]: Estimated time left: 0:11:04.897522
[2018-04-17 20:24:28.943362]: ====================
[2018-04-17 20:24:29.008034]: [Epoch: 486(48.64864864864865%): Data: 0.0%]:Running loss: 0.2175246924161911
[2018-04-17 20:24:30.312001]: [Epoch: 486(48.64864864864865%): Data: 25.333333333333336%]:Running loss: 4.350491046905518
[2018-04-17 20:24:31.586389]: [Epoch: 486(48.64864864864865%): Data: 50.66666666666667%]:Running loss: 8.483456641435623
[2018-04-17 20:24:35.125299]: Test set accuracy: 94.33962264150944% ,loss = 5.438108742237091
[2018-04-17 20:24:35.249630]: ====================
[2018-04-17 20:24:35.254142]: Elapsed time since starting training: 1:04:01.418271
[2018-04-17 20:24:35.258152]: Estimated time left: 0:10:58.577217
[2018-04-17 20:24:35.262665]: ====================
[2018-04-17 20:24:35.330344]: [Epoch: 487(48.74874874874875%): Data: 0.0%]:Running loss: 0.21752434968948364
[2018-04-17 20:24:36.644338]: [Epoch: 487(48.74874874874875%): Data: 25.333333333333336%]:Running loss: 4.35048833489418
[2018-04-17 20:24:37.839516]: [Epoch: 487(48.74874874874875%): Data: 50.66666666666667%]:Running loss: 8.483452886343002
[2018-04-17 20:24:41.037018]: Test set accuracy: 94.33962264150944% ,loss = 5.43811172246933
[2018-04-17 20:24:41.139791]: ====================
[2018-04-17 20:24:41.145807]: Elapsed time since starting training: 1:04:07.310438
[2018-04-17 20:24:41.150320]: Estimated time left: 0:10:52.685049
[2018-04-17 20:24:41.154832]: ====================
[2018-04-17 20:24:41.218500]: [Epoch: 488(48.848848848848846%): Data: 0.0%]:Running loss: 0.2175244688987732
[2018-04-17 20:24:42.520463]: [Epoch: 488(48.848848848848846%): Data: 25.333333333333336%]:Running loss: 4.350486680865288
[2018-04-17 20:24:43.783822]: [Epoch: 488(48.848848848848846%): Data: 50.66666666666667%]:Running loss: 8.483447849750519
[2018-04-17 20:24:47.279617]: Test set accuracy: 94.33962264150944% ,loss = 5.438104644417763
[2018-04-17 20:24:47.396428]: ====================
[2018-04-17 20:24:47.401441]: Elapsed time since starting training: 1:04:13.565571
[2018-04-17 20:24:47.406455]: Estimated time left: 0:10:46.428914
[2018-04-17 20:24:47.411468]: ====================
[2018-04-17 20:24:47.485164]: [Epoch: 489(48.94894894894895%): Data: 0.0%]:Running loss: 0.2175241857767105
[2018-04-17 20:24:48.766571]: [Epoch: 489(48.94894894894895%): Data: 25.333333333333336%]:Running loss: 4.350484192371368
[2018-04-17 20:24:50.049482]: [Epoch: 489(48.94894894894895%): Data: 50.66666666666667%]:Running loss: 8.48344400525093
[2018-04-17 20:24:53.617469]: Test set accuracy: 94.33962264150944% ,loss = 5.438104271888733
[2018-04-17 20:24:53.728766]: ====================
[2018-04-17 20:24:53.733779]: Elapsed time since starting training: 1:04:19.898410
[2018-04-17 20:24:53.738792]: Estimated time left: 0:10:40.096577
[2018-04-17 20:24:53.743805]: ====================
[2018-04-17 20:24:53.812989]: [Epoch: 490(49.049049049049046%): Data: 0.0%]:Running loss: 0.21752417087554932
[2018-04-17 20:24:55.100914]: [Epoch: 490(49.049049049049046%): Data: 25.333333333333336%]:Running loss: 4.350482016801834
[2018-04-17 20:24:56.426940]: [Epoch: 490(49.049049049049046%): Data: 50.66666666666667%]:Running loss: 8.483440041542053
[2018-04-17 20:24:59.949807]: Test set accuracy: 94.33962264150944% ,loss = 5.438098683953285
[2018-04-17 20:25:00.066116]: ====================
[2018-04-17 20:25:00.070628]: Elapsed time since starting training: 1:04:26.234758
[2018-04-17 20:25:00.075140]: Estimated time left: 0:10:33.760729
[2018-04-17 20:25:00.079151]: ====================
[2018-04-17 20:25:00.151844]: [Epoch: 491(49.14914914914915%): Data: 0.0%]:Running loss: 0.2175239473581314
[2018-04-17 20:25:01.427737]: [Epoch: 491(49.14914914914915%): Data: 25.333333333333336%]:Running loss: 4.35048046708107
[2018-04-17 20:25:02.719171]: [Epoch: 491(49.14914914914915%): Data: 50.66666666666667%]:Running loss: 8.48343662917614
[2018-04-17 20:25:06.245053]: Test set accuracy: 94.33962264150944% ,loss = 5.438097193837166
[2018-04-17 20:25:06.359357]: ====================
[2018-04-17 20:25:06.364370]: Elapsed time since starting training: 1:04:32.528500
[2018-04-17 20:25:06.369383]: Estimated time left: 0:10:27.465986
[2018-04-17 20:25:06.373895]: ====================
[2018-04-17 20:25:06.451602]: [Epoch: 492(49.249249249249246%): Data: 0.0%]:Running loss: 0.21752388775348663
[2018-04-17 20:25:07.724487]: [Epoch: 492(49.249249249249246%): Data: 25.333333333333336%]:Running loss: 4.3504782021045685
[2018-04-17 20:25:08.994363]: [Epoch: 492(49.249249249249246%): Data: 50.66666666666667%]:Running loss: 8.483432367444038
[2018-04-17 20:25:12.480131]: Test set accuracy: 94.33962264150944% ,loss = 5.438091233372688
[2018-04-17 20:25:12.592933]: ====================
[2018-04-17 20:25:12.597444]: Elapsed time since starting training: 1:04:38.762075
[2018-04-17 20:25:12.601955]: Estimated time left: 0:10:21.233414
[2018-04-17 20:25:12.606468]: ====================
[2018-04-17 20:25:12.679161]: [Epoch: 493(49.349349349349346%): Data: 0.0%]:Running loss: 0.21752364933490753
[2018-04-17 20:25:13.969091]: [Epoch: 493(49.349349349349346%): Data: 25.333333333333336%]:Running loss: 4.350477248430252
[2018-04-17 20:25:15.251500]: [Epoch: 493(49.349349349349346%): Data: 50.66666666666667%]:Running loss: 8.483429417014122
[2018-04-17 20:25:18.758826]: Test set accuracy: 94.33962264150944% ,loss = 5.438099429011345
[2018-04-17 20:25:18.863605]: ====================
[2018-04-17 20:25:18.868118]: Elapsed time since starting training: 1:04:45.032247
[2018-04-17 20:25:18.872629]: Estimated time left: 0:10:14.962740
[2018-04-17 20:25:18.877141]: ====================
[2018-04-17 20:25:18.952341]: [Epoch: 494(49.44944944944945%): Data: 0.0%]:Running loss: 0.2175239771604538
[2018-04-17 20:25:20.284383]: [Epoch: 494(49.44944944944945%): Data: 25.333333333333336%]:Running loss: 4.350474968552589
[2018-04-17 20:25:21.571306]: [Epoch: 494(49.44944944944945%): Data: 50.66666666666667%]:Running loss: 8.48342514038086
[2018-04-17 20:25:25.057575]: Test set accuracy: 94.33962264150944% ,loss = 5.438093468546867
[2018-04-17 20:25:25.170375]: ====================
[2018-04-17 20:25:25.174888]: Elapsed time since starting training: 1:04:51.339519
[2018-04-17 20:25:25.179399]: Estimated time left: 0:10:08.655970
[2018-04-17 20:25:25.183911]: ====================
[2018-04-17 20:25:25.258610]: [Epoch: 495(49.549549549549546%): Data: 0.0%]:Running loss: 0.2175237387418747
[2018-04-17 20:25:26.561073]: [Epoch: 495(49.549549549549546%): Data: 25.333333333333336%]:Running loss: 4.350472524762154
[2018-04-17 20:25:27.842480]: [Epoch: 495(49.549549549549546%): Data: 50.66666666666667%]:Running loss: 8.48342177271843
[2018-04-17 20:25:31.380387]: Test set accuracy: 94.33962264150944% ,loss = 5.438091233372688
[2018-04-17 20:25:31.487674]: ====================
[2018-04-17 20:25:31.491683]: Elapsed time since starting training: 1:04:57.656314
[2018-04-17 20:25:31.497198]: Estimated time left: 0:10:02.338673
[2018-04-17 20:25:31.503715]: ====================
[2018-04-17 20:25:31.568387]: [Epoch: 496(49.64964964964965%): Data: 0.0%]:Running loss: 0.21752364933490753
[2018-04-17 20:25:32.839266]: [Epoch: 496(49.64964964964965%): Data: 25.333333333333336%]:Running loss: 4.350471511483192
[2018-04-17 20:25:34.136216]: [Epoch: 496(49.64964964964965%): Data: 50.66666666666667%]:Running loss: 8.483419120311737
[2018-04-17 20:25:37.652564]: Test set accuracy: 94.33962264150944% ,loss = 5.438084900379181
[2018-04-17 20:25:37.769877]: ====================
[2018-04-17 20:25:37.775893]: Elapsed time since starting training: 1:05:03.940023
[2018-04-17 20:25:37.779903]: Estimated time left: 0:09:56.055466
[2018-04-17 20:25:37.784917]: ====================
[2018-04-17 20:25:37.854602]: [Epoch: 497(49.74974974974975%): Data: 0.0%]:Running loss: 0.21752339601516724
[2018-04-17 20:25:39.130996]: [Epoch: 497(49.74974974974975%): Data: 25.333333333333336%]:Running loss: 4.350469321012497
[2018-04-17 20:25:40.411903]: [Epoch: 497(49.74974974974975%): Data: 50.66666666666667%]:Running loss: 8.483415067195892
[2018-04-17 20:25:43.971367]: Test set accuracy: 94.33962264150944% ,loss = 5.438081547617912
[2018-04-17 20:25:44.087676]: ====================
[2018-04-17 20:25:44.092690]: Elapsed time since starting training: 1:05:10.256819
[2018-04-17 20:25:44.097201]: Estimated time left: 0:09:49.738669
[2018-04-17 20:25:44.101713]: ====================
[2018-04-17 20:25:44.175409]: [Epoch: 498(49.849849849849846%): Data: 0.0%]:Running loss: 0.2175232619047165
[2018-04-17 20:25:45.456316]: [Epoch: 498(49.849849849849846%): Data: 25.333333333333336%]:Running loss: 4.350468754768372
[2018-04-17 20:25:46.761786]: [Epoch: 498(49.849849849849846%): Data: 50.66666666666667%]:Running loss: 8.483412072062492
[2018-04-17 20:25:50.289166]: Test set accuracy: 94.33962264150944% ,loss = 5.438075959682465
[2018-04-17 20:25:50.403971]: ====================
[2018-04-17 20:25:50.408984]: Elapsed time since starting training: 1:05:16.573615
[2018-04-17 20:25:50.413496]: Estimated time left: 0:09:43.421873
[2018-04-17 20:25:50.418009]: ====================
[2018-04-17 20:25:50.490200]: [Epoch: 499(49.94994994994995%): Data: 0.0%]:Running loss: 0.21752303838729858
[2018-04-17 20:25:51.793666]: [Epoch: 499(49.94994994994995%): Data: 25.333333333333336%]:Running loss: 4.350465893745422
[2018-04-17 20:25:53.088108]: [Epoch: 499(49.94994994994995%): Data: 50.66666666666667%]:Running loss: 8.483407884836197
[2018-04-17 20:25:56.689183]: Test set accuracy: 94.33962264150944% ,loss = 5.438083037734032
[2018-04-17 20:25:56.799477]: ====================
[2018-04-17 20:25:56.803988]: Elapsed time since starting training: 1:05:22.968619
[2018-04-17 20:25:56.808500]: Estimated time left: 0:09:37.026869
[2018-04-17 20:25:56.813012]: ====================
[2018-04-17 20:25:56.881194]: [Epoch: 500(50.050050050050054%): Data: 0.0%]:Running loss: 0.21752332150936127
[2018-04-17 20:25:58.147561]: [Epoch: 500(50.050050050050054%): Data: 25.333333333333336%]:Running loss: 4.350464478135109
[2018-04-17 20:25:59.474088]: [Epoch: 500(50.050050050050054%): Data: 50.66666666666667%]:Running loss: 8.483405351638794
[2018-04-17 20:26:02.930779]: Test set accuracy: 94.33962264150944% ,loss = 5.4380785673856735
[2018-04-17 20:26:03.039569]: ====================
[2018-04-17 20:26:03.044582]: Elapsed time since starting training: 1:05:29.209213
[2018-04-17 20:26:03.048593]: Estimated time left: 0:09:30.786776
[2018-04-17 20:26:03.052603]: ====================
[2018-04-17 20:26:03.123291]: [Epoch: 501(50.150150150150154%): Data: 0.0%]:Running loss: 0.21752314269542694
[2018-04-17 20:26:04.417733]: [Epoch: 501(50.150150150150154%): Data: 25.333333333333336%]:Running loss: 4.350462481379509
[2018-04-17 20:26:05.720197]: [Epoch: 501(50.150150150150154%): Data: 50.66666666666667%]:Running loss: 8.483402520418167
[2018-04-17 20:26:10.077282]: Test set accuracy: 94.33962264150944% ,loss = 5.438075587153435
[2018-04-17 20:26:10.208130]: ====================
[2018-04-17 20:26:10.212641]: Elapsed time since starting training: 1:05:36.377272
[2018-04-17 20:26:10.217655]: Estimated time left: 0:09:23.617714
[2018-04-17 20:26:10.223171]: ====================
[2018-04-17 20:26:10.291351]: [Epoch: 502(50.25025025025025%): Data: 0.0%]:Running loss: 0.2175230234861374
[2018-04-17 20:26:11.904641]: [Epoch: 502(50.25025025025025%): Data: 25.333333333333336%]:Running loss: 4.350460812449455
[2018-04-17 20:26:13.531467]: [Epoch: 502(50.25025025025025%): Data: 50.66666666666667%]:Running loss: 8.48339831829071
[2018-04-17 20:26:18.411442]: Test set accuracy: 94.33962264150944% ,loss = 5.438068136572838
[2018-04-17 20:26:18.562845]: ====================
[2018-04-17 20:26:18.567357]: Elapsed time since starting training: 1:05:44.731988
[2018-04-17 20:26:18.571869]: Estimated time left: 0:09:15.263500
[2018-04-17 20:26:18.576882]: ====================
[2018-04-17 20:26:18.649575]: [Epoch: 503(50.35035035035035%): Data: 0.0%]:Running loss: 0.2175227254629135
[2018-04-17 20:26:19.989639]: [Epoch: 503(50.35035035035035%): Data: 25.333333333333336%]:Running loss: 4.350459694862366
[2018-04-17 20:26:21.346747]: [Epoch: 503(50.35035035035035%): Data: 50.66666666666667%]:Running loss: 8.483395114541054
[2018-04-17 20:26:24.894180]: Test set accuracy: 94.33962264150944% ,loss = 5.438074842095375
[2018-04-17 20:26:25.003470]: ====================
[2018-04-17 20:26:25.008985]: Elapsed time since starting training: 1:05:51.173616
[2018-04-17 20:26:25.013497]: Estimated time left: 0:09:08.821872
[2018-04-17 20:26:25.018009]: ====================
[2018-04-17 20:26:25.091204]: [Epoch: 504(50.45045045045045%): Data: 0.0%]:Running loss: 0.217522993683815
[2018-04-17 20:26:26.380632]: [Epoch: 504(50.45045045045045%): Data: 25.333333333333336%]:Running loss: 4.350457802414894
[2018-04-17 20:26:27.680087]: [Epoch: 504(50.45045045045045%): Data: 50.66666666666667%]:Running loss: 8.483392462134361
[2018-04-17 20:26:31.316757]: Test set accuracy: 94.33962264150944% ,loss = 5.438068509101868
[2018-04-17 20:26:31.432565]: ====================
[2018-04-17 20:26:31.437077]: Elapsed time since starting training: 1:05:57.601708
[2018-04-17 20:26:31.444096]: Estimated time left: 0:09:02.391273
[2018-04-17 20:26:31.448608]: ====================
[2018-04-17 20:26:31.536842]: [Epoch: 505(50.550550550550554%): Data: 0.0%]:Running loss: 0.2175227403640747
[2018-04-17 20:26:32.872895]: [Epoch: 505(50.550550550550554%): Data: 25.333333333333336%]:Running loss: 4.350455790758133
[2018-04-17 20:26:34.176862]: [Epoch: 505(50.550550550550554%): Data: 50.66666666666667%]:Running loss: 8.483389154076576
[2018-04-17 20:26:37.783452]: Test set accuracy: 94.33962264150944% ,loss = 5.438065156340599
[2018-04-17 20:26:38.022087]: ====================
[2018-04-17 20:26:38.028103]: Elapsed time since starting training: 1:06:04.192233
[2018-04-17 20:26:38.032615]: Estimated time left: 0:08:55.802754
[2018-04-17 20:26:38.037628]: ====================
[2018-04-17 20:26:38.112828]: [Epoch: 506(50.650650650650654%): Data: 0.0%]:Running loss: 0.21752260625362396
[2018-04-17 20:26:39.403259]: [Epoch: 506(50.650650650650654%): Data: 25.333333333333336%]:Running loss: 4.350454419851303
[2018-04-17 20:26:40.718758]: [Epoch: 506(50.650650650650654%): Data: 50.66666666666667%]:Running loss: 8.483385547995567
[2018-04-17 20:26:44.314318]: Test set accuracy: 94.33962264150944% ,loss = 5.438069254159927
[2018-04-17 20:26:44.431129]: ====================
[2018-04-17 20:26:44.435640]: Elapsed time since starting training: 1:06:10.599770
[2018-04-17 20:26:44.440654]: Estimated time left: 0:08:49.394715
[2018-04-17 20:26:44.445667]: ====================
[2018-04-17 20:26:44.515853]: [Epoch: 507(50.750750750750754%): Data: 0.0%]:Running loss: 0.2175227701663971
[2018-04-17 20:26:45.893517]: [Epoch: 507(50.750750750750754%): Data: 25.333333333333336%]:Running loss: 4.350453600287437
[2018-04-17 20:26:47.220044]: [Epoch: 507(50.750750750750754%): Data: 50.66666666666667%]:Running loss: 8.483383655548096
[2018-04-17 20:26:50.917877]: Test set accuracy: 94.33962264150944% ,loss = 5.43806366622448
[2018-04-17 20:26:51.032683]: ====================
[2018-04-17 20:26:51.039199]: Elapsed time since starting training: 1:06:17.203830
[2018-04-17 20:26:51.043711]: Estimated time left: 0:08:42.791658
[2018-04-17 20:26:51.049728]: ====================
[2018-04-17 20:26:51.128938]: [Epoch: 508(50.85085085085085%): Data: 0.0%]:Running loss: 0.2175225466489792
[2018-04-17 20:26:52.434911]: [Epoch: 508(50.85085085085085%): Data: 25.333333333333336%]:Running loss: 4.35045100748539
[2018-04-17 20:26:53.729352]: [Epoch: 508(50.85085085085085%): Data: 50.66666666666667%]:Running loss: 8.483379125595093
[2018-04-17 20:26:57.430694]: Test set accuracy: 94.33962264150944% ,loss = 5.438067391514778
[2018-04-17 20:26:57.548507]: ====================
[2018-04-17 20:26:57.553521]: Elapsed time since starting training: 1:06:23.718152
[2018-04-17 20:26:57.558534]: Estimated time left: 0:08:36.277336
[2018-04-17 20:26:57.563046]: ====================
[2018-04-17 20:26:57.635238]: [Epoch: 509(50.95095095095095%): Data: 0.0%]:Running loss: 0.21752269566059113
[2018-04-17 20:26:58.954245]: [Epoch: 509(50.95095095095095%): Data: 25.333333333333336%]:Running loss: 4.350449874997139
[2018-04-17 20:27:00.264730]: [Epoch: 509(50.95095095095095%): Data: 50.66666666666667%]:Running loss: 8.483376935124397
[2018-04-17 20:27:03.952536]: Test set accuracy: 94.33962264150944% ,loss = 5.438065156340599
[2018-04-17 20:27:04.073356]: ====================
[2018-04-17 20:27:04.077869]: Elapsed time since starting training: 1:06:30.242500
[2018-04-17 20:27:04.081879]: Estimated time left: 0:08:29.753490
[2018-04-17 20:27:04.086391]: ====================
[2018-04-17 20:27:04.160088]: [Epoch: 510(51.051051051051054%): Data: 0.0%]:Running loss: 0.21752260625362396
[2018-04-17 20:27:05.493633]: [Epoch: 510(51.051051051051054%): Data: 25.333333333333336%]:Running loss: 4.3504496812820435
[2018-04-17 20:27:06.792602]: [Epoch: 510(51.051051051051054%): Data: 50.66666666666667%]:Running loss: 8.483375489711761
[2018-04-17 20:27:10.534538]: Test set accuracy: 94.33962264150944% ,loss = 5.43806292116642
[2018-04-17 20:27:10.647337]: ====================
[2018-04-17 20:27:10.651849]: Elapsed time since starting training: 1:06:36.816480
[2018-04-17 20:27:10.659870]: Estimated time left: 0:08:23.175499
[2018-04-17 20:27:10.665386]: ====================
[2018-04-17 20:27:10.736074]: [Epoch: 511(51.151151151151154%): Data: 0.0%]:Running loss: 0.2175225168466568
[2018-04-17 20:27:12.052574]: [Epoch: 511(51.151151151151154%): Data: 25.333333333333336%]:Running loss: 4.350447714328766
[2018-04-17 20:27:13.355538]: [Epoch: 511(51.151151151151154%): Data: 50.66666666666667%]:Running loss: 8.483372792601585
[2018-04-17 20:27:16.995717]: Test set accuracy: 94.33962264150944% ,loss = 5.438059568405151
[2018-04-17 20:27:17.117040]: ====================
[2018-04-17 20:27:17.122065]: Elapsed time since starting training: 1:06:43.286696
[2018-04-17 20:27:17.126565]: Estimated time left: 0:08:16.708804
[2018-04-17 20:27:17.131077]: ====================
[2018-04-17 20:27:17.198256]: [Epoch: 512(51.25125125125125%): Data: 0.0%]:Running loss: 0.21752238273620605
[2018-04-17 20:27:18.507236]: [Epoch: 512(51.25125125125125%): Data: 25.333333333333336%]:Running loss: 4.35044626891613
[2018-04-17 20:27:19.812711]: [Epoch: 512(51.25125125125125%): Data: 50.66666666666667%]:Running loss: 8.483369141817093
[2018-04-17 20:27:23.467426]: Test set accuracy: 94.33962264150944% ,loss = 5.4380591958761215
[2018-04-17 20:27:23.589250]: ====================
[2018-04-17 20:27:23.594263]: Elapsed time since starting training: 1:06:49.758392
[2018-04-17 20:27:23.598776]: Estimated time left: 0:08:10.236593
[2018-04-17 20:27:23.603287]: ====================
[2018-04-17 20:27:23.681996]: [Epoch: 513(51.35135135135135%): Data: 0.0%]:Running loss: 0.21752236783504486
[2018-04-17 20:27:25.008022]: [Epoch: 513(51.35135135135135%): Data: 25.333333333333336%]:Running loss: 4.350444957613945
[2018-04-17 20:27:26.374656]: [Epoch: 513(51.35135135135135%): Data: 50.66666666666667%]:Running loss: 8.483367010951042
[2018-04-17 20:27:30.563795]: Test set accuracy: 94.33962264150944% ,loss = 5.438056960701942
[2018-04-17 20:27:30.695646]: ====================
[2018-04-17 20:27:30.702664]: Elapsed time since starting training: 1:06:56.867295
[2018-04-17 20:27:30.707677]: Estimated time left: 0:08:03.127692
[2018-04-17 20:27:30.712691]: ====================
[2018-04-17 20:27:30.794909]: [Epoch: 514(51.45145145145145%): Data: 0.0%]:Running loss: 0.2175222784280777
[2018-04-17 20:27:32.224210]: [Epoch: 514(51.45145145145145%): Data: 25.333333333333336%]:Running loss: 4.350444585084915
[2018-04-17 20:27:33.541713]: [Epoch: 514(51.45145145145145%): Data: 50.66666666666667%]:Running loss: 8.483365133404732
[2018-04-17 20:27:37.097167]: Test set accuracy: 94.33962264150944% ,loss = 5.438054725527763
[2018-04-17 20:27:37.202948]: ====================
[2018-04-17 20:27:37.207962]: Elapsed time since starting training: 1:07:03.372092
[2018-04-17 20:27:37.213477]: Estimated time left: 0:07:56.622394
[2018-04-17 20:27:37.217989]: ====================
[2018-04-17 20:27:37.284164]: [Epoch: 515(51.551551551551555%): Data: 0.0%]:Running loss: 0.21752218902111053
[2018-04-17 20:27:38.626734]: [Epoch: 515(51.551551551551555%): Data: 25.333333333333336%]:Running loss: 4.350442454218864
[2018-04-17 20:27:39.955768]: [Epoch: 515(51.551551551551555%): Data: 50.66666666666667%]:Running loss: 8.483362764120102
[2018-04-17 20:27:43.851126]: Test set accuracy: 94.33962264150944% ,loss = 5.438052862882614
[2018-04-17 20:27:43.988491]: ====================
[2018-04-17 20:27:43.993003]: Elapsed time since starting training: 1:07:10.157634
[2018-04-17 20:27:43.998518]: Estimated time left: 0:07:49.836851
[2018-04-17 20:27:44.003531]: ====================
[2018-04-17 20:27:44.075723]: [Epoch: 516(51.651651651651655%): Data: 0.0%]:Running loss: 0.21752211451530457
[2018-04-17 20:27:45.371167]: [Epoch: 516(51.651651651651655%): Data: 25.333333333333336%]:Running loss: 4.350442081689835
[2018-04-17 20:27:46.666110]: [Epoch: 516(51.651651651651655%): Data: 50.66666666666667%]:Running loss: 8.48336061835289
[2018-04-17 20:27:50.246129]: Test set accuracy: 94.33962264150944% ,loss = 5.438050627708435
[2018-04-17 20:27:50.372968]: ====================
[2018-04-17 20:27:50.382492]: Elapsed time since starting training: 1:07:16.547123
[2018-04-17 20:27:50.387506]: Estimated time left: 0:07:43.447863
[2018-04-17 20:27:50.396530]: ====================
[2018-04-17 20:27:50.468722]: [Epoch: 517(51.751751751751755%): Data: 0.0%]:Running loss: 0.2175220251083374
[2018-04-17 20:27:51.750630]: [Epoch: 517(51.751751751751755%): Data: 25.333333333333336%]:Running loss: 4.350439697504044
[2018-04-17 20:27:53.040573]: [Epoch: 517(51.751751751751755%): Data: 50.66666666666667%]:Running loss: 8.483357414603233
[2018-04-17 20:27:56.741902]: Test set accuracy: 94.33962264150944% ,loss = 5.438048392534256
[2018-04-17 20:27:56.874756]: ====================
[2018-04-17 20:27:56.880771]: Elapsed time since starting training: 1:07:23.044902
[2018-04-17 20:27:56.885785]: Estimated time left: 0:07:36.949584
[2018-04-17 20:27:56.890798]: ====================
[2018-04-17 20:27:56.959982]: [Epoch: 518(51.85185185185185%): Data: 0.0%]:Running loss: 0.21752193570137024
[2018-04-17 20:27:58.419363]: [Epoch: 518(51.85185185185185%): Data: 25.333333333333336%]:Running loss: 4.350439086556435
[2018-04-17 20:27:59.863202]: [Epoch: 518(51.85185185185185%): Data: 50.66666666666667%]:Running loss: 8.483356028795242
[2018-04-17 20:28:04.068383]: Test set accuracy: 94.33962264150944% ,loss = 5.4380446672439575
[2018-04-17 20:28:04.191711]: ====================
[2018-04-17 20:28:04.196724]: Elapsed time since starting training: 1:07:30.361355
[2018-04-17 20:28:04.201237]: Estimated time left: 0:07:29.634132
[2018-04-17 20:28:04.205748]: ====================
[2018-04-17 20:28:04.272426]: [Epoch: 519(51.95195195195195%): Data: 0.0%]:Running loss: 0.2175217866897583
[2018-04-17 20:28:05.668638]: [Epoch: 519(51.95195195195195%): Data: 25.333333333333336%]:Running loss: 4.350436970591545
[2018-04-17 20:28:07.017725]: [Epoch: 519(51.95195195195195%): Data: 50.66666666666667%]:Running loss: 8.483353108167648
[2018-04-17 20:28:11.337211]: Test set accuracy: 94.33962264150944% ,loss = 5.438043549656868
[2018-04-17 20:28:11.451014]: ====================
[2018-04-17 20:28:11.455525]: Elapsed time since starting training: 1:07:37.620156
[2018-04-17 20:28:11.460038]: Estimated time left: 0:07:22.375331
[2018-04-17 20:28:11.466054]: ====================
[2018-04-17 20:28:11.533232]: [Epoch: 520(52.052052052052055%): Data: 0.0%]:Running loss: 0.21752174198627472
[2018-04-17 20:28:13.078843]: [Epoch: 520(52.052052052052055%): Data: 25.333333333333336%]:Running loss: 4.350436598062515
[2018-04-17 20:28:14.486585]: [Epoch: 520(52.052052052052055%): Data: 50.66666666666667%]:Running loss: 8.483350932598114
[2018-04-17 20:28:18.229537]: Test set accuracy: 94.33962264150944% ,loss = 5.4380398243665695
[2018-04-17 20:28:18.348354]: ====================
[2018-04-17 20:28:18.352866]: Elapsed time since starting training: 1:07:44.517497
[2018-04-17 20:28:18.357377]: Estimated time left: 0:07:15.477992
[2018-04-17 20:28:18.362391]: ====================
[2018-04-17 20:28:18.438594]: [Epoch: 521(52.152152152152155%): Data: 0.0%]:Running loss: 0.21752159297466278
[2018-04-17 20:28:19.812748]: [Epoch: 521(52.152152152152155%): Data: 25.333333333333336%]:Running loss: 4.350434944033623
[2018-04-17 20:28:21.138272]: [Epoch: 521(52.152152152152155%): Data: 50.66666666666667%]:Running loss: 8.483348578214645
[2018-04-17 20:28:25.376040]: Test set accuracy: 94.33962264150944% ,loss = 5.438036471605301
[2018-04-17 20:28:25.533458]: ====================
[2018-04-17 20:28:25.537971]: Elapsed time since starting training: 1:07:51.702100
[2018-04-17 20:28:25.543987]: Estimated time left: 0:07:08.291382
[2018-04-17 20:28:25.553512]: ====================
[2018-04-17 20:28:25.629214]: [Epoch: 522(52.25225225225225%): Data: 0.0%]:Running loss: 0.21752145886421204
[2018-04-17 20:28:26.960252]: [Epoch: 522(52.25225225225225%): Data: 25.333333333333336%]:Running loss: 4.350433811545372
[2018-04-17 20:28:28.261713]: [Epoch: 522(52.25225225225225%): Data: 50.66666666666667%]:Running loss: 8.48334613442421
[2018-04-17 20:28:31.841231]: Test set accuracy: 94.33962264150944% ,loss = 5.4380446672439575
[2018-04-17 20:28:31.956537]: ====================
[2018-04-17 20:28:31.961551]: Elapsed time since starting training: 1:07:58.125681
[2018-04-17 20:28:31.966564]: Estimated time left: 0:07:01.868805
[2018-04-17 20:28:31.971077]: ====================
[2018-04-17 20:28:32.040761]: [Epoch: 523(52.35235235235235%): Data: 0.0%]:Running loss: 0.2175217866897583
[2018-04-17 20:28:33.345732]: [Epoch: 523(52.35235235235235%): Data: 25.333333333333336%]:Running loss: 4.350433275103569
[2018-04-17 20:28:34.612099]: [Epoch: 523(52.35235235235235%): Data: 50.66666666666667%]:Running loss: 8.48334389925003
[2018-04-17 20:28:38.146998]: Test set accuracy: 94.33962264150944% ,loss = 5.438042059540749
[2018-04-17 20:28:38.267820]: ====================
[2018-04-17 20:28:38.272833]: Elapsed time since starting training: 1:08:04.437464
[2018-04-17 20:28:38.277846]: Estimated time left: 0:06:55.557523
[2018-04-17 20:28:38.283862]: ====================
[2018-04-17 20:28:38.356055]: [Epoch: 524(52.45245245245245%): Data: 0.0%]:Running loss: 0.21752168238162994
[2018-04-17 20:28:39.650998]: [Epoch: 524(52.45245245245245%): Data: 25.333333333333336%]:Running loss: 4.350432187318802
[2018-04-17 20:28:41.016127]: [Epoch: 524(52.45245245245245%): Data: 50.66666666666667%]:Running loss: 8.48334176838398
[2018-04-17 20:28:44.753565]: Test set accuracy: 94.33962264150944% ,loss = 5.43803870677948
[2018-04-17 20:28:44.877394]: ====================
[2018-04-17 20:28:44.882407]: Elapsed time since starting training: 1:08:11.047038
[2018-04-17 20:28:44.887922]: Estimated time left: 0:06:48.947447
[2018-04-17 20:28:44.892434]: ====================
[2018-04-17 20:28:44.965629]: [Epoch: 525(52.552552552552555%): Data: 0.0%]:Running loss: 0.2175215482711792
[2018-04-17 20:28:46.281628]: [Epoch: 525(52.552552552552555%): Data: 25.333333333333336%]:Running loss: 4.350430712103844
[2018-04-17 20:28:47.519419]: [Epoch: 525(52.552552552552555%): Data: 50.66666666666667%]:Running loss: 8.483339458703995
[2018-04-17 20:28:51.025743]: Test set accuracy: 94.33962264150944% ,loss = 5.438037216663361
[2018-04-17 20:28:51.140548]: ====================
[2018-04-17 20:28:51.145561]: Elapsed time since starting training: 1:08:17.309691
[2018-04-17 20:28:51.150074]: Estimated time left: 0:06:42.685295
[2018-04-17 20:28:51.155087]: ====================
[2018-04-17 20:28:51.222265]: [Epoch: 526(52.652652652652655%): Data: 0.0%]:Running loss: 0.21752148866653442
[2018-04-17 20:28:52.529742]: [Epoch: 526(52.652652652652655%): Data: 25.333333333333336%]:Running loss: 4.350429520010948
[2018-04-17 20:28:53.807639]: [Epoch: 526(52.652652652652655%): Data: 50.66666666666667%]:Running loss: 8.483338564634323
[2018-04-17 20:28:57.417739]: Test set accuracy: 94.33962264150944% ,loss = 5.4380349814891815
[2018-04-17 20:28:57.542570]: ====================
[2018-04-17 20:28:57.548085]: Elapsed time since starting training: 1:08:23.712716
[2018-04-17 20:28:57.552598]: Estimated time left: 0:06:36.282771
[2018-04-17 20:28:57.557110]: ====================
[2018-04-17 20:28:57.626294]: [Epoch: 527(52.752752752752755%): Data: 0.0%]:Running loss: 0.21752139925956726
[2018-04-17 20:28:58.882634]: [Epoch: 527(52.752752752752755%): Data: 25.333333333333336%]:Running loss: 4.350428685545921
[2018-04-17 20:29:00.151508]: [Epoch: 527(52.752752752752755%): Data: 50.66666666666667%]:Running loss: 8.483335688710213
[2018-04-17 20:29:03.726513]: Test set accuracy: 94.33962264150944% ,loss = 5.438031628727913
[2018-04-17 20:29:03.844828]: ====================
[2018-04-17 20:29:03.850343]: Elapsed time since starting training: 1:08:30.014974
[2018-04-17 20:29:03.855858]: Estimated time left: 0:06:29.980012
[2018-04-17 20:29:03.860370]: ====================
[2018-04-17 20:29:03.929554]: [Epoch: 528(52.85285285285285%): Data: 0.0%]:Running loss: 0.21752126514911652
[2018-04-17 20:29:05.181884]: [Epoch: 528(52.85285285285285%): Data: 25.333333333333336%]:Running loss: 4.350427195429802
[2018-04-17 20:29:06.447249]: [Epoch: 528(52.85285285285285%): Data: 50.66666666666667%]:Running loss: 8.483333483338356
[2018-04-17 20:29:09.971619]: Test set accuracy: 94.33962264150944% ,loss = 5.438037216663361
[2018-04-17 20:29:10.089433]: ====================
[2018-04-17 20:29:10.093945]: Elapsed time since starting training: 1:08:36.258576
[2018-04-17 20:29:10.098959]: Estimated time left: 0:06:23.736912
[2018-04-17 20:29:10.103470]: ====================
[2018-04-17 20:29:10.176665]: [Epoch: 529(52.95295295295295%): Data: 0.0%]:Running loss: 0.21752148866653442
[2018-04-17 20:29:11.471607]: [Epoch: 529(52.95295295295295%): Data: 25.333333333333336%]:Running loss: 4.350426375865936
[2018-04-17 20:29:12.745996]: [Epoch: 529(52.95295295295295%): Data: 50.66666666666667%]:Running loss: 8.483330741524696
[2018-04-17 20:29:16.348576]: Test set accuracy: 94.33962264150944% ,loss = 5.438033863902092
[2018-04-17 20:29:16.472405]: ====================
[2018-04-17 20:29:16.478421]: Elapsed time since starting training: 1:08:42.643052
[2018-04-17 20:29:16.483936]: Estimated time left: 0:06:17.351433
[2018-04-17 20:29:16.488447]: ====================
[2018-04-17 20:29:16.558635]: [Epoch: 530(53.053053053053056%): Data: 0.0%]:Running loss: 0.21752135455608368
[2018-04-17 20:29:17.818985]: [Epoch: 530(53.053053053053056%): Data: 25.333333333333336%]:Running loss: 4.350425541400909
[2018-04-17 20:29:19.074825]: [Epoch: 530(53.053053053053056%): Data: 50.66666666666667%]:Running loss: 8.483329594135284
[2018-04-17 20:29:22.645319]: Test set accuracy: 94.33962264150944% ,loss = 5.438036471605301
[2018-04-17 20:29:22.770151]: ====================
[2018-04-17 20:29:22.775164]: Elapsed time since starting training: 1:08:48.939795
[2018-04-17 20:29:22.780178]: Estimated time left: 0:06:11.055682
[2018-04-17 20:29:22.785692]: ====================
[2018-04-17 20:29:22.852871]: [Epoch: 531(53.153153153153156%): Data: 0.0%]:Running loss: 0.21752145886421204
[2018-04-17 20:29:24.106709]: [Epoch: 531(53.153153153153156%): Data: 25.333333333333336%]:Running loss: 4.350424543023109
[2018-04-17 20:29:25.383103]: [Epoch: 531(53.153153153153156%): Data: 50.66666666666667%]:Running loss: 8.483328208327293
[2018-04-17 20:29:28.935549]: Test set accuracy: 94.33962264150944% ,loss = 5.438026785850525
[2018-04-17 20:29:29.051859]: ====================
[2018-04-17 20:29:29.056370]: Elapsed time since starting training: 1:08:55.220501
[2018-04-17 20:29:29.060883]: Estimated time left: 0:06:04.774988
[2018-04-17 20:29:29.065895]: ====================
[2018-04-17 20:29:29.137085]: [Epoch: 532(53.25325325325325%): Data: 0.0%]:Running loss: 0.217521071434021
[2018-04-17 20:29:30.393927]: [Epoch: 532(53.25325325325325%): Data: 25.333333333333336%]:Running loss: 4.350423112511635
[2018-04-17 20:29:31.668315]: [Epoch: 532(53.25325325325325%): Data: 50.66666666666667%]:Running loss: 8.483324974775314
[2018-04-17 20:29:35.183161]: Test set accuracy: 94.33962264150944% ,loss = 5.438027903437614
[2018-04-17 20:29:35.304985]: ====================
[2018-04-17 20:29:35.310500]: Elapsed time since starting training: 1:09:01.475131
[2018-04-17 20:29:35.316015]: Estimated time left: 0:05:58.519354
[2018-04-17 20:29:35.320527]: ====================
[2018-04-17 20:29:35.388207]: [Epoch: 533(53.35335335335335%): Data: 0.0%]:Running loss: 0.21752111613750458
[2018-04-17 20:29:36.685657]: [Epoch: 533(53.35335335335335%): Data: 25.333333333333336%]:Running loss: 4.350422918796539
[2018-04-17 20:29:37.952024]: [Epoch: 533(53.35335335335335%): Data: 50.66666666666667%]:Running loss: 8.483324408531189
[2018-04-17 20:29:41.633312]: Test set accuracy: 94.33962264150944% ,loss = 5.438028275966644
[2018-04-17 20:29:41.747617]: ====================
[2018-04-17 20:29:41.752630]: Elapsed time since starting training: 1:09:07.916759
[2018-04-17 20:29:41.756640]: Estimated time left: 0:05:52.078729
[2018-04-17 20:29:41.761153]: ====================
[2018-04-17 20:29:41.828832]: [Epoch: 534(53.453453453453456%): Data: 0.0%]:Running loss: 0.21752113103866577
[2018-04-17 20:29:43.448639]: [Epoch: 534(53.453453453453456%): Data: 25.333333333333336%]:Running loss: 4.350420966744423
[2018-04-17 20:29:44.794719]: [Epoch: 534(53.453453453453456%): Data: 50.66666666666667%]:Running loss: 8.483322560787201
[2018-04-17 20:29:48.919687]: Test set accuracy: 94.33962264150944% ,loss = 5.438030511140823
[2018-04-17 20:29:49.083623]: ====================
[2018-04-17 20:29:49.089138]: Elapsed time since starting training: 1:09:15.253769
[2018-04-17 20:29:49.093649]: Estimated time left: 0:05:44.741720
[2018-04-17 20:29:49.098663]: ====================
[2018-04-17 20:29:49.177372]: [Epoch: 535(53.553553553553556%): Data: 0.0%]:Running loss: 0.21752122044563293
[2018-04-17 20:29:50.549019]: [Epoch: 535(53.553553553553556%): Data: 25.333333333333336%]:Running loss: 4.3504213988780975
[2018-04-17 20:29:52.089616]: [Epoch: 535(53.553553553553556%): Data: 50.66666666666667%]:Running loss: 8.483321398496628
[2018-04-17 20:29:55.655597]: Test set accuracy: 94.33962264150944% ,loss = 5.4380204528570175
[2018-04-17 20:29:55.779427]: ====================
[2018-04-17 20:29:55.785944]: Elapsed time since starting training: 1:09:21.950575
[2018-04-17 20:29:55.790456]: Estimated time left: 0:05:38.045414
[2018-04-17 20:29:55.794968]: ====================
[2018-04-17 20:29:55.867662]: [Epoch: 536(53.653653653653656%): Data: 0.0%]:Running loss: 0.2175208181142807
[2018-04-17 20:29:57.143053]: [Epoch: 536(53.653653653653656%): Data: 25.333333333333336%]:Running loss: 4.350420817732811
[2018-04-17 20:29:58.412929]: [Epoch: 536(53.653653653653656%): Data: 50.66666666666667%]:Running loss: 8.483318522572517
[2018-04-17 20:30:01.996457]: Test set accuracy: 94.33962264150944% ,loss = 5.438024178147316
[2018-04-17 20:30:02.123295]: ====================
[2018-04-17 20:30:02.130314]: Elapsed time since starting training: 1:09:28.294945
[2018-04-17 20:30:02.135327]: Estimated time left: 0:05:31.700042
[2018-04-17 20:30:02.142346]: ====================
[2018-04-17 20:30:02.214036]: [Epoch: 537(53.753753753753756%): Data: 0.0%]:Running loss: 0.21752096712589264
[2018-04-17 20:30:03.547582]: [Epoch: 537(53.753753753753756%): Data: 25.333333333333336%]:Running loss: 4.350419044494629
[2018-04-17 20:30:04.870099]: [Epoch: 537(53.753753753753756%): Data: 50.66666666666667%]:Running loss: 8.483317732810974
[2018-04-17 20:30:08.665190]: Test set accuracy: 94.33962264150944% ,loss = 5.438023805618286
[2018-04-17 20:30:08.793030]: ====================
[2018-04-17 20:30:08.797542]: Elapsed time since starting training: 1:09:34.962173
[2018-04-17 20:30:08.802054]: Estimated time left: 0:05:25.033315
[2018-04-17 20:30:08.807569]: ====================
[2018-04-17 20:30:08.870236]: [Epoch: 538(53.85385385385385%): Data: 0.0%]:Running loss: 0.21752095222473145
[2018-04-17 20:30:10.171194]: [Epoch: 538(53.85385385385385%): Data: 25.333333333333336%]:Running loss: 4.350418731570244
[2018-04-17 20:30:11.421519]: [Epoch: 538(53.85385385385385%): Data: 50.66666666666667%]:Running loss: 8.483316421508789
[2018-04-17 20:30:14.991010]: Test set accuracy: 94.33962264150944% ,loss = 5.438024550676346
[2018-04-17 20:30:15.102306]: ====================
[2018-04-17 20:30:15.107821]: Elapsed time since starting training: 1:09:41.272452
[2018-04-17 20:30:15.112333]: Estimated time left: 0:05:18.723036
[2018-04-17 20:30:15.118349]: ====================
[2018-04-17 20:30:15.184024]: [Epoch: 539(53.953953953953956%): Data: 0.0%]:Running loss: 0.21752098202705383
[2018-04-17 20:30:16.493505]: [Epoch: 539(53.953953953953956%): Data: 25.333333333333336%]:Running loss: 4.35041780769825
[2018-04-17 20:30:17.751851]: [Epoch: 539(53.953953953953956%): Data: 50.66666666666667%]:Running loss: 8.48331506550312
[2018-04-17 20:30:21.365459]: Test set accuracy: 94.33962264150944% ,loss = 5.438026785850525
[2018-04-17 20:30:21.479268]: ====================
[2018-04-17 20:30:21.486782]: Elapsed time since starting training: 1:09:47.649910
[2018-04-17 20:30:21.491294]: Estimated time left: 0:05:12.344576
[2018-04-17 20:30:21.495807]: ====================
[2018-04-17 20:30:21.564490]: [Epoch: 540(54.054054054054056%): Data: 0.0%]:Running loss: 0.217521071434021
[2018-04-17 20:30:22.858430]: [Epoch: 540(54.054054054054056%): Data: 25.333333333333336%]:Running loss: 4.350416839122772
[2018-04-17 20:30:24.158887]: [Epoch: 540(54.054054054054056%): Data: 50.66666666666667%]:Running loss: 8.483313873410225
[2018-04-17 20:30:27.763974]: Test set accuracy: 94.33962264150944% ,loss = 5.438015982508659
[2018-04-17 20:30:27.883291]: ====================
[2018-04-17 20:30:27.888305]: Elapsed time since starting training: 1:09:54.052936
[2018-04-17 20:30:27.893318]: Estimated time left: 0:05:05.942553
[2018-04-17 20:30:27.898832]: ====================
[2018-04-17 20:30:27.974534]: [Epoch: 541(54.154154154154156%): Data: 0.0%]:Running loss: 0.21752063930034637
[2018-04-17 20:30:29.285519]: [Epoch: 541(54.154154154154156%): Data: 25.333333333333336%]:Running loss: 4.350416645407677
[2018-04-17 20:30:30.584473]: [Epoch: 541(54.154154154154156%): Data: 50.66666666666667%]:Running loss: 8.483311787247658
[2018-04-17 20:30:34.201591]: Test set accuracy: 94.33962264150944% ,loss = 5.438018217682838
[2018-04-17 20:30:34.316898]: ====================
[2018-04-17 20:30:34.321410]: Elapsed time since starting training: 1:10:00.486041
[2018-04-17 20:30:34.325922]: Estimated time left: 0:04:59.509447
[2018-04-17 20:30:34.330433]: ====================
[2018-04-17 20:30:34.404130]: [Epoch: 542(54.25425425425425%): Data: 0.0%]:Running loss: 0.21752072870731354
[2018-04-17 20:30:35.722635]: [Epoch: 542(54.25425425425425%): Data: 25.333333333333336%]:Running loss: 4.350416049361229
[2018-04-17 20:30:37.027104]: [Epoch: 542(54.25425425425425%): Data: 50.66666666666667%]:Running loss: 8.48331019282341
[2018-04-17 20:30:40.510867]: Test set accuracy: 94.33962264150944% ,loss = 5.438019335269928
[2018-04-17 20:30:40.625672]: ====================
[2018-04-17 20:30:40.629683]: Elapsed time since starting training: 1:10:06.794314
[2018-04-17 20:30:40.634195]: Estimated time left: 0:04:53.201675
[2018-04-17 20:30:40.639209]: ====================
[2018-04-17 20:30:40.704382]: [Epoch: 543(54.35435435435435%): Data: 0.0%]:Running loss: 0.21752077341079712
[2018-04-17 20:30:41.893051]: [Epoch: 543(54.35435435435435%): Data: 25.333333333333336%]:Running loss: 4.350413963198662
[2018-04-17 20:30:43.091730]: [Epoch: 543(54.35435435435435%): Data: 50.66666666666667%]:Running loss: 8.483307883143425
[2018-04-17 20:30:46.602565]: Test set accuracy: 94.33962264150944% ,loss = 5.438018590211868
[2018-04-17 20:30:46.714362]: ====================
[2018-04-17 20:30:46.718874]: Elapsed time since starting training: 1:10:12.883505
[2018-04-17 20:30:46.722885]: Estimated time left: 0:04:47.112484
[2018-04-17 20:30:46.727898]: ====================
[2018-04-17 20:30:46.797584]: [Epoch: 544(54.454454454454456%): Data: 0.0%]:Running loss: 0.21752074360847473
[2018-04-17 20:30:48.056431]: [Epoch: 544(54.454454454454456%): Data: 25.333333333333336%]:Running loss: 4.35041381418705
[2018-04-17 20:30:49.344857]: [Epoch: 544(54.454454454454456%): Data: 50.66666666666667%]:Running loss: 8.483307048678398
[2018-04-17 20:30:52.906828]: Test set accuracy: 94.33962264150944% ,loss = 5.438021570444107
[2018-04-17 20:30:53.127415]: ====================
[2018-04-17 20:30:53.131927]: Elapsed time since starting training: 1:10:19.296558
[2018-04-17 20:30:53.136940]: Estimated time left: 0:04:40.698429
[2018-04-17 20:30:53.141953]: ====================
[2018-04-17 20:30:53.213142]: [Epoch: 545(54.55455455455456%): Data: 0.0%]:Running loss: 0.21752086281776428
[2018-04-17 20:30:54.462464]: [Epoch: 545(54.55455455455456%): Data: 25.333333333333336%]:Running loss: 4.350413486361504
[2018-04-17 20:30:55.723317]: [Epoch: 545(54.55455455455456%): Data: 50.66666666666667%]:Running loss: 8.483305633068085
[2018-04-17 20:30:59.256211]: Test set accuracy: 94.33962264150944% ,loss = 5.438011512160301
[2018-04-17 20:30:59.371518]: ====================
[2018-04-17 20:30:59.377032]: Elapsed time since starting training: 1:10:25.541663
[2018-04-17 20:30:59.381544]: Estimated time left: 0:04:34.453825
[2018-04-17 20:30:59.386558]: ====================
[2018-04-17 20:30:59.454239]: [Epoch: 546(54.65465465465466%): Data: 0.0%]:Running loss: 0.21752046048641205
[2018-04-17 20:31:00.721106]: [Epoch: 546(54.65465465465466%): Data: 25.333333333333336%]:Running loss: 4.350412487983704
[2018-04-17 20:31:01.956892]: [Epoch: 546(54.65465465465466%): Data: 50.66666666666667%]:Running loss: 8.483303681015968
[2018-04-17 20:31:05.399045]: Test set accuracy: 94.33962264150944% ,loss = 5.43801337480545
[2018-04-17 20:31:05.509839]: ====================
[2018-04-17 20:31:05.514352]: Elapsed time since starting training: 1:10:31.678983
[2018-04-17 20:31:05.518863]: Estimated time left: 0:04:28.316506
[2018-04-17 20:31:05.523876]: ====================
[2018-04-17 20:31:05.590565]: [Epoch: 547(54.75475475475476%): Data: 0.0%]:Running loss: 0.21752053499221802
[2018-04-17 20:31:06.912569]: [Epoch: 547(54.75475475475476%): Data: 25.333333333333336%]:Running loss: 4.350412055850029
[2018-04-17 20:31:08.232077]: [Epoch: 547(54.75475475475476%): Data: 50.66666666666667%]:Running loss: 8.48330269753933
[2018-04-17 20:31:11.784524]: Test set accuracy: 94.33962264150944% ,loss = 5.438011512160301
[2018-04-17 20:31:11.916374]: ====================
[2018-04-17 20:31:11.921388]: Elapsed time since starting training: 1:10:38.086019
[2018-04-17 20:31:11.926401]: Estimated time left: 0:04:21.909470
[2018-04-17 20:31:11.930913]: ====================
[2018-04-17 20:31:12.000104]: [Epoch: 548(54.85485485485485%): Data: 0.0%]:Running loss: 0.21752046048641205
[2018-04-17 20:31:13.261952]: [Epoch: 548(54.85485485485485%): Data: 25.333333333333336%]:Running loss: 4.350411280989647
[2018-04-17 20:31:14.544863]: [Epoch: 548(54.85485485485485%): Data: 50.66666666666667%]:Running loss: 8.483301743865013
[2018-04-17 20:31:18.126888]: Test set accuracy: 94.33962264150944% ,loss = 5.43801337480545
[2018-04-17 20:31:18.251220]: ====================
[2018-04-17 20:31:18.257234]: Elapsed time since starting training: 1:10:44.421365
[2018-04-17 20:31:18.261245]: Estimated time left: 0:04:15.574124
[2018-04-17 20:31:18.266760]: ====================
[2018-04-17 20:31:18.337950]: [Epoch: 549(54.95495495495496%): Data: 0.0%]:Running loss: 0.21752053499221802
[2018-04-17 20:31:19.672999]: [Epoch: 549(54.95495495495496%): Data: 25.333333333333336%]:Running loss: 4.350410103797913
[2018-04-17 20:31:20.986492]: [Epoch: 549(54.95495495495496%): Data: 50.66666666666667%]:Running loss: 8.483299896121025
[2018-04-17 20:31:24.606116]: Test set accuracy: 94.33962264150944% ,loss = 5.438011884689331
[2018-04-17 20:31:24.725434]: ====================
[2018-04-17 20:31:24.729945]: Elapsed time since starting training: 1:10:50.894576
[2018-04-17 20:31:24.734457]: Estimated time left: 0:04:09.100912
[2018-04-17 20:31:24.740473]: ====================
[2018-04-17 20:31:24.815172]: [Epoch: 550(55.05505505505506%): Data: 0.0%]:Running loss: 0.21752047538757324
[2018-04-17 20:31:26.091065]: [Epoch: 550(55.05505505505506%): Data: 25.333333333333336%]:Running loss: 4.350408896803856
[2018-04-17 20:31:27.363949]: [Epoch: 550(55.05505505505506%): Data: 50.66666666666667%]:Running loss: 8.483298733830452
[2018-04-17 20:31:30.915893]: Test set accuracy: 94.33962264150944% ,loss = 5.43801411986351
[2018-04-17 20:31:31.035713]: ====================
[2018-04-17 20:31:31.041728]: Elapsed time since starting training: 1:10:57.205858
[2018-04-17 20:31:31.045739]: Estimated time left: 0:04:02.789630
[2018-04-17 20:31:31.050251]: ====================
[2018-04-17 20:31:31.121441]: [Epoch: 551(55.15515515515516%): Data: 0.0%]:Running loss: 0.2175205647945404
[2018-04-17 20:31:32.415882]: [Epoch: 551(55.15515515515516%): Data: 25.333333333333336%]:Running loss: 4.350409314036369
[2018-04-17 20:31:33.693709]: [Epoch: 551(55.15515515515516%): Data: 50.66666666666667%]:Running loss: 8.483297035098076
[2018-04-17 20:31:37.209057]: Test set accuracy: 94.33962264150944% ,loss = 5.438012629747391
[2018-04-17 20:31:37.320855]: ====================
[2018-04-17 20:31:37.325868]: Elapsed time since starting training: 1:11:03.489997
[2018-04-17 20:31:37.329878]: Estimated time left: 0:03:56.505491
[2018-04-17 20:31:37.334390]: ====================
[2018-04-17 20:31:37.402070]: [Epoch: 552(55.25525525525525%): Data: 0.0%]:Running loss: 0.21752050518989563
[2018-04-17 20:31:38.654901]: [Epoch: 552(55.25525525525525%): Data: 25.333333333333336%]:Running loss: 4.350408628582954
[2018-04-17 20:31:39.914751]: [Epoch: 552(55.25525525525525%): Data: 50.66666666666667%]:Running loss: 8.483295947313309
[2018-04-17 20:31:43.419570]: Test set accuracy: 94.33962264150944% ,loss = 5.43801411986351
[2018-04-17 20:31:43.549416]: ====================
[2018-04-17 20:31:43.554930]: Elapsed time since starting training: 1:11:09.719060
[2018-04-17 20:31:43.558941]: Estimated time left: 0:03:50.276428
[2018-04-17 20:31:43.562952]: ====================
[2018-04-17 20:31:43.634644]: [Epoch: 553(55.35535535535535%): Data: 0.0%]:Running loss: 0.2175205647945404
[2018-04-17 20:31:44.906525]: [Epoch: 553(55.35535535535535%): Data: 25.333333333333336%]:Running loss: 4.350407138466835
[2018-04-17 20:31:46.256113]: [Epoch: 553(55.35535535535535%): Data: 50.66666666666667%]:Running loss: 8.483293741941452
[2018-04-17 20:31:49.947929]: Test set accuracy: 94.33962264150944% ,loss = 5.438002571463585
[2018-04-17 20:31:50.064741]: ====================
[2018-04-17 20:31:50.069252]: Elapsed time since starting training: 1:11:16.233883
[2018-04-17 20:31:50.074767]: Estimated time left: 0:03:43.760602
[2018-04-17 20:31:50.079780]: ====================
[2018-04-17 20:31:50.152475]: [Epoch: 554(55.45545545545546%): Data: 0.0%]:Running loss: 0.2175201028585434
[2018-04-17 20:31:51.425358]: [Epoch: 554(55.45545545545546%): Data: 25.333333333333336%]:Running loss: 4.350405767560005
[2018-04-17 20:31:52.758402]: [Epoch: 554(55.45545545545546%): Data: 50.66666666666667%]:Running loss: 8.483291685581207
[2018-04-17 20:31:56.325888]: Test set accuracy: 94.33962264150944% ,loss = 5.438004434108734
[2018-04-17 20:31:56.441195]: ====================
[2018-04-17 20:31:56.445707]: Elapsed time since starting training: 1:11:22.609836
[2018-04-17 20:31:56.449717]: Estimated time left: 0:03:37.385652
[2018-04-17 20:31:56.455232]: ====================
[2018-04-17 20:31:56.524918]: [Epoch: 555(55.55555555555556%): Data: 0.0%]:Running loss: 0.21752017736434937
[2018-04-17 20:31:57.834400]: [Epoch: 555(55.55555555555556%): Data: 25.333333333333336%]:Running loss: 4.350406542420387
[2018-04-17 20:31:59.125834]: [Epoch: 555(55.55555555555556%): Data: 50.66666666666667%]:Running loss: 8.483291581273079
[2018-04-17 20:32:02.658727]: Test set accuracy: 94.33962264150944% ,loss = 5.438004061579704
[2018-04-17 20:32:02.776040]: ====================
[2018-04-17 20:32:02.780050]: Elapsed time since starting training: 1:11:28.944681
[2018-04-17 20:32:02.785565]: Estimated time left: 0:03:31.049804
[2018-04-17 20:32:02.791581]: ====================
[2018-04-17 20:32:02.860764]: [Epoch: 556(55.65565565565566%): Data: 0.0%]:Running loss: 0.21752016246318817
[2018-04-17 20:32:04.159719]: [Epoch: 556(55.65565565565566%): Data: 25.333333333333336%]:Running loss: 4.35040582716465
[2018-04-17 20:32:05.447141]: [Epoch: 556(55.65565565565566%): Data: 50.66666666666667%]:Running loss: 8.483291149139404
[2018-04-17 20:32:09.021145]: Test set accuracy: 94.33962264150944% ,loss = 5.438004434108734
[2018-04-17 20:32:09.137956]: ====================
[2018-04-17 20:32:09.142969]: Elapsed time since starting training: 1:11:35.307600
[2018-04-17 20:32:09.147983]: Estimated time left: 0:03:24.687386
[2018-04-17 20:32:09.152494]: ====================
[2018-04-17 20:32:09.226691]: [Epoch: 557(55.75575575575576%): Data: 0.0%]:Running loss: 0.21752017736434937
[2018-04-17 20:32:10.488547]: [Epoch: 557(55.75575575575576%): Data: 25.333333333333336%]:Running loss: 4.350405544042587
[2018-04-17 20:32:11.783490]: [Epoch: 557(55.75575575575576%): Data: 50.66666666666667%]:Running loss: 8.483289614319801
[2018-04-17 20:32:15.284800]: Test set accuracy: 94.33962264150944% ,loss = 5.438004806637764
[2018-04-17 20:32:15.430688]: ====================
[2018-04-17 20:32:15.435701]: Elapsed time since starting training: 1:11:41.600332
[2018-04-17 20:32:15.445226]: Estimated time left: 0:03:18.390143
[2018-04-17 20:32:15.450240]: ====================
[2018-04-17 20:32:15.527446]: [Epoch: 558(55.85585585585585%): Data: 0.0%]:Running loss: 0.21752019226551056
[2018-04-17 20:32:16.829407]: [Epoch: 558(55.85585585585585%): Data: 25.333333333333336%]:Running loss: 4.350403606891632
[2018-04-17 20:32:18.078234]: [Epoch: 558(55.85585585585585%): Data: 50.66666666666667%]:Running loss: 8.483286738395691
[2018-04-17 20:32:21.693841]: Test set accuracy: 94.33962264150944% ,loss = 5.438004806637764
[2018-04-17 20:32:21.808647]: ====================
[2018-04-17 20:32:21.813661]: Elapsed time since starting training: 1:11:47.977790
[2018-04-17 20:32:21.818674]: Estimated time left: 0:03:12.017197
[2018-04-17 20:32:21.823687]: ====================
[2018-04-17 20:32:21.892870]: [Epoch: 559(55.95595595595596%): Data: 0.0%]:Running loss: 0.21752019226551056
[2018-04-17 20:32:23.173777]: [Epoch: 559(55.95595595595596%): Data: 25.333333333333336%]:Running loss: 4.350403279066086
[2018-04-17 20:32:24.409563]: [Epoch: 559(55.95595595595596%): Data: 50.66666666666667%]:Running loss: 8.48328623175621
[2018-04-17 20:32:27.901849]: Test set accuracy: 94.33962264150944% ,loss = 5.438007041811943
[2018-04-17 20:32:28.026681]: ====================
[2018-04-17 20:32:28.031192]: Elapsed time since starting training: 1:11:54.195823
[2018-04-17 20:32:28.036206]: Estimated time left: 0:03:05.799163
[2018-04-17 20:32:28.041721]: ====================
[2018-04-17 20:32:28.113411]: [Epoch: 560(56.05605605605606%): Data: 0.0%]:Running loss: 0.21752028167247772
[2018-04-17 20:32:29.382285]: [Epoch: 560(56.05605605605606%): Data: 25.333333333333336%]:Running loss: 4.35040245950222
[2018-04-17 20:32:30.627596]: [Epoch: 560(56.05605605605606%): Data: 50.66666666666667%]:Running loss: 8.483285516500473
[2018-04-17 20:32:34.161994]: Test set accuracy: 94.33962264150944% ,loss = 5.438002571463585
[2018-04-17 20:32:34.278805]: ====================
[2018-04-17 20:32:34.283318]: Elapsed time since starting training: 1:12:00.447446
[2018-04-17 20:32:34.288831]: Estimated time left: 0:02:59.547039
[2018-04-17 20:32:34.293344]: ====================
[2018-04-17 20:32:34.362028]: [Epoch: 561(56.15615615615616%): Data: 0.0%]:Running loss: 0.2175201028585434
[2018-04-17 20:32:35.634910]: [Epoch: 561(56.15615615615616%): Data: 25.333333333333336%]:Running loss: 4.350403249263763
[2018-04-17 20:32:36.875709]: [Epoch: 561(56.15615615615616%): Data: 50.66666666666667%]:Running loss: 8.48328572511673
[2018-04-17 20:32:40.410108]: Test set accuracy: 94.33962264150944% ,loss = 5.438007414340973
[2018-04-17 20:32:40.521404]: ====================
[2018-04-17 20:32:40.526918]: Elapsed time since starting training: 1:12:06.691048
[2018-04-17 20:32:40.530930]: Estimated time left: 0:02:53.304439
[2018-04-17 20:32:40.535441]: ====================
[2018-04-17 20:32:40.606129]: [Epoch: 562(56.25625625625625%): Data: 0.0%]:Running loss: 0.21752029657363892
[2018-04-17 20:32:41.908092]: [Epoch: 562(56.25625625625625%): Data: 25.333333333333336%]:Running loss: 4.35040283203125
[2018-04-17 20:32:43.180474]: [Epoch: 562(56.25625625625625%): Data: 50.66666666666667%]:Running loss: 8.48328423500061
[2018-04-17 20:32:46.641677]: Test set accuracy: 94.33962264150944% ,loss = 5.437998846173286
[2018-04-17 20:32:46.756984]: ====================
[2018-04-17 20:32:46.761496]: Elapsed time since starting training: 1:12:12.925626
[2018-04-17 20:32:46.766008]: Estimated time left: 0:02:47.069361
[2018-04-17 20:32:46.770519]: ====================
[2018-04-17 20:32:46.846723]: [Epoch: 563(56.35635635635635%): Data: 0.0%]:Running loss: 0.21751995384693146
[2018-04-17 20:32:48.107575]: [Epoch: 563(56.35635635635635%): Data: 25.333333333333336%]:Running loss: 4.350400865077972
[2018-04-17 20:32:49.375948]: [Epoch: 563(56.35635635635635%): Data: 50.66666666666667%]:Running loss: 8.483283042907715
[2018-04-17 20:32:52.886783]: Test set accuracy: 94.33962264150944% ,loss = 5.438002571463585
[2018-04-17 20:32:52.998581]: ====================
[2018-04-17 20:32:53.003595]: Elapsed time since starting training: 1:12:19.167723
[2018-04-17 20:32:53.009109]: Estimated time left: 0:02:40.826260
[2018-04-17 20:32:53.013621]: ====================
[2018-04-17 20:32:53.082303]: [Epoch: 564(56.45645645645646%): Data: 0.0%]:Running loss: 0.2175201028585434
[2018-04-17 20:32:54.356692]: [Epoch: 564(56.45645645645646%): Data: 25.333333333333336%]:Running loss: 4.350400432944298
[2018-04-17 20:32:55.610525]: [Epoch: 564(56.45645645645646%): Data: 50.66666666666667%]:Running loss: 8.483281448483467
[2018-04-17 20:32:59.158961]: Test set accuracy: 94.33962264150944% ,loss = 5.437995865941048
[2018-04-17 20:32:59.275771]: ====================
[2018-04-17 20:32:59.280284]: Elapsed time since starting training: 1:12:25.444413
[2018-04-17 20:32:59.285297]: Estimated time left: 0:02:34.550574
[2018-04-17 20:32:59.289308]: ====================
[2018-04-17 20:32:59.363504]: [Epoch: 565(56.55655655655656%): Data: 0.0%]:Running loss: 0.2175198346376419
[2018-04-17 20:33:00.611824]: [Epoch: 565(56.55655655655656%): Data: 25.333333333333336%]:Running loss: 4.350399732589722
[2018-04-17 20:33:01.877690]: [Epoch: 565(56.55655655655656%): Data: 50.66666666666667%]:Running loss: 8.483279913663864
[2018-04-17 20:33:05.462221]: Test set accuracy: 94.33962264150944% ,loss = 5.437998846173286
[2018-04-17 20:33:05.577027]: ====================
[2018-04-17 20:33:05.582045]: Elapsed time since starting training: 1:12:31.746676
[2018-04-17 20:33:05.587053]: Estimated time left: 0:02:28.248817
[2018-04-17 20:33:05.591565]: ====================
[2018-04-17 20:33:05.661752]: [Epoch: 566(56.65665665665666%): Data: 0.0%]:Running loss: 0.21751995384693146
[2018-04-17 20:33:06.921601]: [Epoch: 566(56.65665665665666%): Data: 25.333333333333336%]:Running loss: 4.350400418043137
[2018-04-17 20:33:08.211531]: [Epoch: 566(56.65665665665666%): Data: 50.66666666666667%]:Running loss: 8.483280673623085
[2018-04-17 20:33:11.686772]: Test set accuracy: 94.33962264150944% ,loss = 5.438002198934555
[2018-04-17 20:33:11.809097]: ====================
[2018-04-17 20:33:11.814111]: Elapsed time since starting training: 1:12:37.978242
[2018-04-17 20:33:11.818623]: Estimated time left: 0:02:22.017247
[2018-04-17 20:33:11.823636]: ====================
[2018-04-17 20:33:11.896832]: [Epoch: 567(56.75675675675676%): Data: 0.0%]:Running loss: 0.2175200879573822
[2018-04-17 20:33:13.181757]: [Epoch: 567(56.75675675675676%): Data: 25.333333333333336%]:Running loss: 4.35039921104908
[2018-04-17 20:33:14.450120]: [Epoch: 567(56.75675675675676%): Data: 50.66666666666667%]:Running loss: 8.48327861726284
[2018-04-17 20:33:18.322917]: Test set accuracy: 94.33962264150944% ,loss = 5.438005179166794
[2018-04-17 20:33:18.452763]: ====================
[2018-04-17 20:33:18.457776]: Elapsed time since starting training: 1:12:44.622407
[2018-04-17 20:33:18.462790]: Estimated time left: 0:02:15.372579
[2018-04-17 20:33:18.467803]: ====================
[2018-04-17 20:33:18.542502]: [Epoch: 568(56.85685685685685%): Data: 0.0%]:Running loss: 0.21752020716667175
[2018-04-17 20:33:20.064549]: [Epoch: 568(56.85685685685685%): Data: 25.333333333333336%]:Running loss: 4.350398033857346
[2018-04-17 20:33:21.587598]: [Epoch: 568(56.85685685685685%): Data: 50.66666666666667%]:Running loss: 8.483276948332787
[2018-04-17 20:33:25.434828]: Test set accuracy: 94.33962264150944% ,loss = 5.437997728586197
[2018-04-17 20:33:25.553644]: ====================
[2018-04-17 20:33:25.558657]: Elapsed time since starting training: 1:12:51.723288
[2018-04-17 20:33:25.563169]: Estimated time left: 0:02:08.272200
[2018-04-17 20:33:25.567681]: ====================
[2018-04-17 20:33:25.641377]: [Epoch: 569(56.95695695695696%): Data: 0.0%]:Running loss: 0.21751990914344788
[2018-04-17 20:33:27.003499]: [Epoch: 569(56.95695695695696%): Data: 25.333333333333336%]:Running loss: 4.350399315357208
[2018-04-17 20:33:28.348577]: [Epoch: 569(56.95695695695696%): Data: 50.66666666666667%]:Running loss: 8.483276531100273
[2018-04-17 20:33:31.905032]: Test set accuracy: 94.33962264150944% ,loss = 5.437998101115227
[2018-04-17 20:33:32.012819]: ====================
[2018-04-17 20:33:32.018334]: Elapsed time since starting training: 1:12:58.182464
[2018-04-17 20:33:32.022846]: Estimated time left: 0:02:01.812523
[2018-04-17 20:33:32.027859]: ====================
[2018-04-17 20:33:32.105566]: [Epoch: 570(57.05705705705706%): Data: 0.0%]:Running loss: 0.21751992404460907
[2018-04-17 20:33:33.428082]: [Epoch: 570(57.05705705705706%): Data: 25.333333333333336%]:Running loss: 4.350399062037468
[2018-04-17 20:33:34.766641]: [Epoch: 570(57.05705705705706%): Data: 50.66666666666667%]:Running loss: 8.483276680111885
[2018-04-17 20:33:38.330116]: Test set accuracy: 94.33962264150944% ,loss = 5.4379913955926895
[2018-04-17 20:33:38.443920]: ====================
[2018-04-17 20:33:38.448933]: Elapsed time since starting training: 1:13:04.613564
[2018-04-17 20:33:38.454447]: Estimated time left: 0:01:55.380922
[2018-04-17 20:33:38.460463]: ====================
[2018-04-17 20:33:38.527641]: [Epoch: 571(57.15715715715716%): Data: 0.0%]:Running loss: 0.21751965582370758
[2018-04-17 20:33:39.741875]: [Epoch: 571(57.15715715715716%): Data: 25.333333333333336%]:Running loss: 4.350396901369095
[2018-04-17 20:33:40.968633]: [Epoch: 571(57.15715715715716%): Data: 50.66666666666667%]:Running loss: 8.483275592327118
[2018-04-17 20:33:44.343606]: Test set accuracy: 94.33962264150944% ,loss = 5.437994003295898
[2018-04-17 20:33:44.449889]: ====================
[2018-04-17 20:33:44.454401]: Elapsed time since starting training: 1:13:10.618531
[2018-04-17 20:33:44.458913]: Estimated time left: 0:01:49.376957
[2018-04-17 20:33:44.462924]: ====================
[2018-04-17 20:33:44.536619]: [Epoch: 572(57.25725725725725%): Data: 0.0%]:Running loss: 0.21751976013183594
[2018-04-17 20:33:45.840587]: [Epoch: 572(57.25725725725725%): Data: 25.333333333333336%]:Running loss: 4.35039696097374
[2018-04-17 20:33:47.169621]: [Epoch: 572(57.25725725725725%): Data: 50.66666666666667%]:Running loss: 8.48327499628067
[2018-04-17 20:33:50.738610]: Test set accuracy: 94.33962264150944% ,loss = 5.437996983528137
[2018-04-17 20:33:50.859933]: ====================
[2018-04-17 20:33:50.864947]: Elapsed time since starting training: 1:13:17.029076
[2018-04-17 20:33:50.868957]: Estimated time left: 0:01:42.966412
[2018-04-17 20:33:50.873469]: ====================
[2018-04-17 20:33:50.943154]: [Epoch: 573(57.35735735735735%): Data: 0.0%]:Running loss: 0.2175198793411255
[2018-04-17 20:33:52.274194]: [Epoch: 573(57.35735735735735%): Data: 25.333333333333336%]:Running loss: 4.350398227572441
[2018-04-17 20:33:53.602225]: [Epoch: 573(57.35735735735735%): Data: 50.66666666666667%]:Running loss: 8.483274802565575
[2018-04-17 20:33:57.274079]: Test set accuracy: 94.33962264150944% ,loss = 5.4379902780056
[2018-04-17 20:33:57.395905]: ====================
[2018-04-17 20:33:57.399913]: Elapsed time since starting training: 1:13:23.564544
[2018-04-17 20:33:57.404928]: Estimated time left: 0:01:36.430441
[2018-04-17 20:33:57.410943]: ====================
[2018-04-17 20:33:57.485146]: [Epoch: 574(57.45745745745746%): Data: 0.0%]:Running loss: 0.217519611120224
[2018-04-17 20:33:58.749502]: [Epoch: 574(57.45745745745746%): Data: 25.333333333333336%]:Running loss: 4.350396141409874
[2018-04-17 20:33:59.981779]: [Epoch: 574(57.45745745745746%): Data: 50.66666666666667%]:Running loss: 8.483273029327393
[2018-04-17 20:34:03.537238]: Test set accuracy: 94.33962264150944% ,loss = 5.437993630766869
[2018-04-17 20:34:03.657557]: ====================
[2018-04-17 20:34:03.663072]: Elapsed time since starting training: 1:13:29.827202
[2018-04-17 20:34:03.667586]: Estimated time left: 0:01:30.167783
[2018-04-17 20:34:03.672598]: ====================
[2018-04-17 20:34:03.743285]: [Epoch: 575(57.55755755755756%): Data: 0.0%]:Running loss: 0.21751974523067474
[2018-04-17 20:34:05.032715]: [Epoch: 575(57.55755755755756%): Data: 25.333333333333336%]:Running loss: 4.350395023822784
[2018-04-17 20:34:06.315625]: [Epoch: 575(57.55755755755756%): Data: 50.66666666666667%]:Running loss: 8.483271822333336
[2018-04-17 20:34:09.898151]: Test set accuracy: 94.33962264150944% ,loss = 5.437996610999107
[2018-04-17 20:34:10.016967]: ====================
[2018-04-17 20:34:10.021981]: Elapsed time since starting training: 1:13:36.186111
[2018-04-17 20:34:10.026493]: Estimated time left: 0:01:23.808876
[2018-04-17 20:34:10.031004]: ====================
[2018-04-17 20:34:10.104199]: [Epoch: 576(57.65765765765766%): Data: 0.0%]:Running loss: 0.2175198644399643
[2018-04-17 20:34:11.360038]: [Epoch: 576(57.65765765765766%): Data: 25.333333333333336%]:Running loss: 4.350396066904068
[2018-04-17 20:34:12.612368]: [Epoch: 576(57.65765765765766%): Data: 50.66666666666667%]:Running loss: 8.483270466327667
[2018-04-17 20:34:16.119192]: Test set accuracy: 94.33962264150944% ,loss = 5.437998846173286
[2018-04-17 20:34:16.257059]: ====================
[2018-04-17 20:34:16.264579]: Elapsed time since starting training: 1:13:42.428709
[2018-04-17 20:34:16.272099]: Estimated time left: 0:01:17.563270
[2018-04-17 20:34:16.279620]: ====================
[2018-04-17 20:34:16.358830]: [Epoch: 577(57.75775775775776%): Data: 0.0%]:Running loss: 0.21751995384693146
[2018-04-17 20:34:17.633218]: [Epoch: 577(57.75775775775776%): Data: 25.333333333333336%]:Running loss: 4.350394904613495
[2018-04-17 20:34:18.906103]: [Epoch: 577(57.75775775775776%): Data: 50.66666666666667%]:Running loss: 8.483269661664963
[2018-04-17 20:34:22.457045]: Test set accuracy: 94.33962264150944% ,loss = 5.437992513179779
[2018-04-17 20:34:22.587893]: ====================
[2018-04-17 20:34:22.592405]: Elapsed time since starting training: 1:13:48.757036
[2018-04-17 20:34:22.597428]: Estimated time left: 0:01:11.237941
[2018-04-17 20:34:22.602933]: ====================
[2018-04-17 20:34:22.679145]: [Epoch: 578(57.85785785785785%): Data: 0.0%]:Running loss: 0.21751970052719116
[2018-04-17 20:34:23.947508]: [Epoch: 578(57.85785785785785%): Data: 25.333333333333336%]:Running loss: 4.350394353270531
[2018-04-17 20:34:25.217886]: [Epoch: 578(57.85785785785785%): Data: 50.66666666666667%]:Running loss: 8.483270063996315
[2018-04-17 20:34:28.798407]: Test set accuracy: 94.33962264150944% ,loss = 5.437995493412018
[2018-04-17 20:34:28.918727]: ====================
[2018-04-17 20:34:28.923740]: Elapsed time since starting training: 1:13:55.087870
[2018-04-17 20:34:28.929255]: Estimated time left: 0:01:04.906616
[2018-04-17 20:34:28.933767]: ====================
[2018-04-17 20:34:29.003452]: [Epoch: 579(57.95795795795796%): Data: 0.0%]:Running loss: 0.2175198197364807
[2018-04-17 20:34:30.303910]: [Epoch: 579(57.95795795795796%): Data: 25.333333333333336%]:Running loss: 4.350395545363426
[2018-04-17 20:34:31.581807]: [Epoch: 579(57.95795795795796%): Data: 50.66666666666667%]:Running loss: 8.48326925933361
[2018-04-17 20:34:35.160828]: Test set accuracy: 94.33962264150944% ,loss = 5.437983945012093
[2018-04-17 20:34:35.281149]: ====================
[2018-04-17 20:34:35.287164]: Elapsed time since starting training: 1:14:01.451306
[2018-04-17 20:34:35.291676]: Estimated time left: 0:00:58.544194
[2018-04-17 20:34:35.296689]: ====================
[2018-04-17 20:34:35.365873]: [Epoch: 580(58.05805805805806%): Data: 0.0%]:Running loss: 0.2175193578004837
[2018-04-17 20:34:36.645277]: [Epoch: 580(58.05805805805806%): Data: 25.333333333333336%]:Running loss: 4.350394010543823
[2018-04-17 20:34:37.909136]: [Epoch: 580(58.05805805805806%): Data: 50.66666666666667%]:Running loss: 8.483267605304718
[2018-04-17 20:34:41.453059]: Test set accuracy: 94.33962264150944% ,loss = 5.437988787889481
[2018-04-17 20:34:41.570372]: ====================
[2018-04-17 20:34:41.575886]: Elapsed time since starting training: 1:14:07.740015
[2018-04-17 20:34:41.580899]: Estimated time left: 0:00:52.254470
[2018-04-17 20:34:41.585912]: ====================
[2018-04-17 20:34:41.654096]: [Epoch: 581(58.15815815815816%): Data: 0.0%]:Running loss: 0.21751955151557922
[2018-04-17 20:34:42.913943]: [Epoch: 581(58.15815815815816%): Data: 25.333333333333336%]:Running loss: 4.350392296910286
[2018-04-17 20:34:44.152738]: [Epoch: 581(58.15815815815816%): Data: 50.66666666666667%]:Running loss: 8.483267337083817
[2018-04-17 20:34:47.620458]: Test set accuracy: 94.33962264150944% ,loss = 5.43798990547657
[2018-04-17 20:34:47.743787]: ====================
[2018-04-17 20:34:47.752309]: Elapsed time since starting training: 1:14:13.916940
[2018-04-17 20:34:47.758827]: Estimated time left: 0:00:46.076542
[2018-04-17 20:34:47.763839]: ====================
[2018-04-17 20:34:47.837035]: [Epoch: 582(58.25825825825825%): Data: 0.0%]:Running loss: 0.2175195962190628
[2018-04-17 20:34:49.117438]: [Epoch: 582(58.25825825825825%): Data: 25.333333333333336%]:Running loss: 4.350393384695053
[2018-04-17 20:34:50.379294]: [Epoch: 582(58.25825825825825%): Data: 50.66666666666667%]:Running loss: 8.483267173171043
[2018-04-17 20:34:53.903164]: Test set accuracy: 94.33962264150944% ,loss = 5.437992513179779
[2018-04-17 20:34:54.028497]: ====================
[2018-04-17 20:34:54.033010]: Elapsed time since starting training: 1:14:20.197641
[2018-04-17 20:34:54.038030]: Estimated time left: 0:00:39.797339
[2018-04-17 20:34:54.043537]: ====================
[2018-04-17 20:34:54.112721]: [Epoch: 583(58.35835835835835%): Data: 0.0%]:Running loss: 0.21751970052719116
[2018-04-17 20:34:55.374576]: [Epoch: 583(58.35835835835835%): Data: 25.333333333333336%]:Running loss: 4.3503930270671844
[2018-04-17 20:34:56.682554]: [Epoch: 583(58.35835835835835%): Data: 50.66666666666667%]:Running loss: 8.48326487839222
[2018-04-17 20:35:00.236003]: Test set accuracy: 94.33962264150944% ,loss = 5.437985435128212
[2018-04-17 20:35:00.353816]: ====================
[2018-04-17 20:35:00.358830]: Elapsed time since starting training: 1:14:26.522959
[2018-04-17 20:35:00.363843]: Estimated time left: 0:00:33.472028
[2018-04-17 20:35:00.368856]: ====================
[2018-04-17 20:35:00.441549]: [Epoch: 584(58.45845845845846%): Data: 0.0%]:Running loss: 0.21751941740512848
[2018-04-17 20:35:01.702401]: [Epoch: 584(58.45845845845846%): Data: 25.333333333333336%]:Running loss: 4.350391626358032
[2018-04-17 20:35:02.979798]: [Epoch: 584(58.45845845845846%): Data: 50.66666666666667%]:Running loss: 8.483264520764351
[2018-04-17 20:35:06.525727]: Test set accuracy: 94.33962264150944% ,loss = 5.437987670302391
[2018-04-17 20:35:06.646548]: ====================
[2018-04-17 20:35:06.652063]: Elapsed time since starting training: 1:14:32.816694
[2018-04-17 20:35:06.656575]: Estimated time left: 0:00:27.178794
[2018-04-17 20:35:06.661087]: ====================
[2018-04-17 20:35:06.731776]: [Epoch: 585(58.55855855855856%): Data: 0.0%]:Running loss: 0.21751950681209564
[2018-04-17 20:35:08.009172]: [Epoch: 585(58.55855855855856%): Data: 25.333333333333336%]:Running loss: 4.3503913432359695
[2018-04-17 20:35:09.262504]: [Epoch: 585(58.55855855855856%): Data: 50.66666666666667%]:Running loss: 8.483263954520226
[2018-04-17 20:35:12.849041]: Test set accuracy: 94.33962264150944% ,loss = 5.43798916041851
[2018-04-17 20:35:13.066118]: ====================
[2018-04-17 20:35:13.071131]: Elapsed time since starting training: 1:14:39.235762
[2018-04-17 20:35:13.076646]: Estimated time left: 0:00:20.759224
[2018-04-17 20:35:13.081158]: ====================
[2018-04-17 20:35:13.149339]: [Epoch: 586(58.65865865865866%): Data: 0.0%]:Running loss: 0.21751956641674042
[2018-04-17 20:35:14.420720]: [Epoch: 586(58.65865865865866%): Data: 25.333333333333336%]:Running loss: 4.350392699241638
[2018-04-17 20:35:15.714660]: [Epoch: 586(58.65865865865866%): Data: 50.66666666666667%]:Running loss: 8.483262673020363
[2018-04-17 20:35:19.191906]: Test set accuracy: 94.33962264150944% ,loss = 5.43799102306366
[2018-04-17 20:35:19.330274]: ====================
[2018-04-17 20:35:19.335288]: Elapsed time since starting training: 1:14:45.499919
[2018-04-17 20:35:19.340301]: Estimated time left: 0:00:14.495068
[2018-04-17 20:35:19.344812]: ====================
[2018-04-17 20:35:19.416002]: [Epoch: 587(58.75875875875876%): Data: 0.0%]:Running loss: 0.2175196409225464
[2018-04-17 20:35:20.681367]: [Epoch: 587(58.75875875875876%): Data: 25.333333333333336%]:Running loss: 4.350392371416092
[2018-04-17 20:35:21.954753]: [Epoch: 587(58.75875875875876%): Data: 50.66666666666667%]:Running loss: 8.483263179659843
[2018-04-17 20:35:25.562345]: Test set accuracy: 94.33962264150944% ,loss = 5.437983199954033
[2018-04-17 20:35:25.691690]: ====================
[2018-04-17 20:35:25.697204]: Elapsed time since starting training: 1:14:51.861835
[2018-04-17 20:35:25.702217]: Estimated time left: 0:00:08.133152
[2018-04-17 20:35:25.707732]: ====================
[2018-04-17 20:35:25.774409]: [Epoch: 588(58.85885885885885%): Data: 0.0%]:Running loss: 0.21751932799816132
[2018-04-17 20:35:27.047795]: [Epoch: 588(58.85885885885885%): Data: 25.333333333333336%]:Running loss: 4.350390210747719
[2018-04-17 20:35:28.315669]: [Epoch: 588(58.85885885885885%): Data: 50.66666666666667%]:Running loss: 8.483262225985527
[2018-04-17 20:35:31.847056]: Test set accuracy: 94.33962264150944% ,loss = 5.437984690070152
[2018-04-17 20:35:31.967878]: ====================
[2018-04-17 20:35:31.972389]: Elapsed time since starting training: 1:14:58.137020
[2018-04-17 20:35:31.976902]: Estimated time left: 0:00:01.858969
[2018-04-17 20:35:31.981915]: ====================
[2018-04-17 20:35:32.051099]: [Epoch: 589(58.95895895895896%): Data: 0.0%]:Running loss: 0.2175193876028061
[2018-04-17 20:35:33.320975]: [Epoch: 589(58.95895895895896%): Data: 25.333333333333336%]:Running loss: 4.350390389561653
[2018-04-17 20:35:34.586841]: [Epoch: 589(58.95895895895896%): Data: 50.66666666666667%]:Running loss: 8.483261778950691
[2018-04-17 20:35:38.171874]: Test set accuracy: 94.33962264150944% ,loss = 5.437986180186272
[2018-04-17 20:35:38.287181]: ====================
[2018-04-17 20:35:38.291191]: Elapsed time since starting training: 1:15:04.455822
[2018-04-17 20:35:38.295202]: Estimated time left: -1 day, 23:59:55.540167
[2018-04-17 20:35:38.301720]: ====================
[2018-04-17 20:35:38.375916]: [Epoch: 590(59.05905905905906%): Data: 0.0%]:Running loss: 0.21751944720745087
[2018-04-17 20:35:39.659329]: [Epoch: 590(59.05905905905906%): Data: 25.333333333333336%]:Running loss: 4.3503910303115845
[2018-04-17 20:35:40.941739]: [Epoch: 590(59.05905905905906%): Data: 50.66666666666667%]:Running loss: 8.483261480927467
[2018-04-17 20:35:44.452073]: Test set accuracy: 94.33962264150944% ,loss = 5.437988042831421
[2018-04-17 20:35:44.570388]: ====================
[2018-04-17 20:35:44.575902]: Elapsed time since starting training: 1:15:10.740032
[2018-04-17 20:35:44.581417]: Estimated time left: -1 day, 23:59:49.253952
[2018-04-17 20:35:44.586430]: ====================
[2018-04-17 20:35:44.658622]: [Epoch: 591(59.15915915915916%): Data: 0.0%]:Running loss: 0.21751952171325684
[2018-04-17 20:35:45.976125]: [Epoch: 591(59.15915915915916%): Data: 25.333333333333336%]:Running loss: 4.350389942526817
[2018-04-17 20:35:47.249010]: [Epoch: 591(59.15915915915916%): Data: 50.66666666666667%]:Running loss: 8.483259677886963
[2018-04-17 20:35:50.856101]: Test set accuracy: 94.33962264150944% ,loss = 5.437992140650749
[2018-04-17 20:35:50.973915]: ====================
[2018-04-17 20:35:50.978928]: Elapsed time since starting training: 1:15:17.143058
[2018-04-17 20:35:50.983440]: Estimated time left: -1 day, 23:59:42.851929
[2018-04-17 20:35:50.988453]: ====================
[2018-04-17 20:35:51.058139]: [Epoch: 592(59.25925925925925%): Data: 0.0%]:Running loss: 0.21751968562602997
[2018-04-17 20:35:52.338041]: [Epoch: 592(59.25925925925925%): Data: 25.333333333333336%]:Running loss: 4.350388318300247
[2018-04-17 20:35:53.621454]: [Epoch: 592(59.25925925925925%): Data: 50.66666666666667%]:Running loss: 8.483257353305817
[2018-04-17 20:35:57.191446]: Test set accuracy: 94.33962264150944% ,loss = 5.437982454895973
[2018-04-17 20:35:57.320791]: ====================
[2018-04-17 20:35:57.327309]: Elapsed time since starting training: 1:15:23.491940
[2018-04-17 20:35:57.332823]: Estimated time left: -1 day, 23:59:36.502546
[2018-04-17 20:35:57.337335]: ====================
[2018-04-17 20:35:57.409026]: [Epoch: 593(59.35935935935935%): Data: 0.0%]:Running loss: 0.21751929819583893
[2018-04-17 20:35:58.674389]: [Epoch: 593(59.35935935935935%): Data: 25.333333333333336%]:Running loss: 4.350389197468758
[2018-04-17 20:35:59.956805]: [Epoch: 593(59.35935935935935%): Data: 50.66666666666667%]:Running loss: 8.48325826227665
[2018-04-17 20:36:03.506744]: Test set accuracy: 94.33962264150944% ,loss = 5.437985807657242
[2018-04-17 20:36:03.620046]: ====================
[2018-04-17 20:36:03.624558]: Elapsed time since starting training: 1:15:29.789189
[2018-04-17 20:36:03.629070]: Estimated time left: -1 day, 23:59:30.206801
[2018-04-17 20:36:03.633581]: ====================
[2018-04-17 20:36:03.700259]: [Epoch: 594(59.45945945945946%): Data: 0.0%]:Running loss: 0.21751943230628967
[2018-04-17 20:36:04.984674]: [Epoch: 594(59.45945945945946%): Data: 25.333333333333336%]:Running loss: 4.350388512015343
[2018-04-17 20:36:06.292652]: [Epoch: 594(59.45945945945946%): Data: 50.66666666666667%]:Running loss: 8.48325763642788
[2018-04-17 20:36:09.906762]: Test set accuracy: 94.33962264150944% ,loss = 5.437985807657242
[2018-04-17 20:36:10.022571]: ====================
[2018-04-17 20:36:10.027583]: Elapsed time since starting training: 1:15:36.191713
[2018-04-17 20:36:10.032095]: Estimated time left: -1 day, 23:59:23.803274
[2018-04-17 20:36:10.036607]: ====================
[2018-04-17 20:36:10.110806]: [Epoch: 595(59.55955955955956%): Data: 0.0%]:Running loss: 0.21751943230628967
[2018-04-17 20:36:11.374665]: [Epoch: 595(59.55955955955956%): Data: 25.333333333333336%]:Running loss: 4.350389242172241
[2018-04-17 20:36:12.683145]: [Epoch: 595(59.55955955955956%): Data: 50.66666666666667%]:Running loss: 8.483257472515106
[2018-04-17 20:36:16.195484]: Test set accuracy: 94.33962264150944% ,loss = 5.437983572483063
[2018-04-17 20:36:16.316305]: ====================
[2018-04-17 20:36:16.320817]: Elapsed time since starting training: 1:15:42.484946
[2018-04-17 20:36:16.325830]: Estimated time left: -1 day, 23:59:17.510040
[2018-04-17 20:36:16.329841]: ====================
[2018-04-17 20:36:16.399025]: [Epoch: 596(59.65965965965966%): Data: 0.0%]:Running loss: 0.2175193428993225
[2018-04-17 20:36:17.761648]: [Epoch: 596(59.65965965965966%): Data: 25.333333333333336%]:Running loss: 4.35038834810257
[2018-04-17 20:36:19.091183]: [Epoch: 596(59.65965965965966%): Data: 50.66666666666667%]:Running loss: 8.483257815241814
[2018-04-17 20:36:22.606531]: Test set accuracy: 94.33962264150944% ,loss = 5.4379913955926895
[2018-04-17 20:36:22.727352]: ====================
[2018-04-17 20:36:22.732365]: Elapsed time since starting training: 1:15:48.896495
[2018-04-17 20:36:22.736877]: Estimated time left: -1 day, 23:59:11.098492
[2018-04-17 20:36:22.741890]: ====================
[2018-04-17 20:36:22.818094]: [Epoch: 597(59.75975975975976%): Data: 0.0%]:Running loss: 0.21751965582370758
[2018-04-17 20:36:24.125569]: [Epoch: 597(59.75975975975976%): Data: 25.333333333333336%]:Running loss: 4.350387781858444
[2018-04-17 20:36:25.417004]: [Epoch: 597(59.75975975975976%): Data: 50.66666666666667%]:Running loss: 8.483255624771118
[2018-04-17 20:36:28.925332]: Test set accuracy: 94.33962264150944% ,loss = 5.437985807657242
[2018-04-17 20:36:29.043145]: ====================
[2018-04-17 20:36:29.048159]: Elapsed time since starting training: 1:15:55.212790
[2018-04-17 20:36:29.053172]: Estimated time left: -1 day, 23:59:04.782698
[2018-04-17 20:36:29.057684]: ====================
[2018-04-17 20:36:29.127872]: [Epoch: 598(59.85985985985987%): Data: 0.0%]:Running loss: 0.21751943230628967
[2018-04-17 20:36:30.411283]: [Epoch: 598(59.85985985985987%): Data: 25.333333333333336%]:Running loss: 4.350388377904892
[2018-04-17 20:36:31.686173]: [Epoch: 598(59.85985985985987%): Data: 50.66666666666667%]:Running loss: 8.48325590789318
[2018-04-17 20:36:35.262683]: Test set accuracy: 94.33962264150944% ,loss = 5.437982827425003
[2018-04-17 20:36:35.389521]: ====================
[2018-04-17 20:36:35.395537]: Elapsed time since starting training: 1:16:01.560168
[2018-04-17 20:36:35.401553]: Estimated time left: -1 day, 23:58:58.433816
[2018-04-17 20:36:35.407067]: ====================
[2018-04-17 20:36:35.484775]: [Epoch: 599(59.95995995995996%): Data: 0.0%]:Running loss: 0.21751931309700012
[2018-04-17 20:36:36.785231]: [Epoch: 599(59.95995995995996%): Data: 25.333333333333336%]:Running loss: 4.350387364625931
[2018-04-17 20:36:38.094714]: [Epoch: 599(59.95995995995996%): Data: 50.66666666666667%]:Running loss: 8.48325401544571
[2018-04-17 20:36:41.685762]: Test set accuracy: 94.33962264150944% ,loss = 5.437988042831421
[2018-04-17 20:36:41.797559]: ====================
[2018-04-17 20:36:41.803074]: Elapsed time since starting training: 1:16:07.967705
[2018-04-17 20:36:41.808087]: Estimated time left: -1 day, 23:58:52.027282
[2018-04-17 20:36:41.812599]: ====================
[2018-04-17 20:36:41.884791]: [Epoch: 600(60.06006006006006%): Data: 0.0%]:Running loss: 0.21751952171325684
[2018-04-17 20:36:43.190262]: [Epoch: 600(60.06006006006006%): Data: 25.333333333333336%]:Running loss: 4.350386679172516
[2018-04-17 20:36:44.478187]: [Epoch: 600(60.06006006006006%): Data: 50.66666666666667%]:Running loss: 8.483253419399261
[2018-04-17 20:36:47.992531]: Test set accuracy: 94.33962264150944% ,loss = 5.437983199954033
[2018-04-17 20:36:48.115859]: ====================
[2018-04-17 20:36:48.121375]: Elapsed time since starting training: 1:16:14.285504
[2018-04-17 20:36:48.126387]: Estimated time left: -1 day, 23:58:45.708982
[2018-04-17 20:36:48.130900]: ====================
[2018-04-17 20:36:48.200587]: [Epoch: 601(60.16016016016016%): Data: 0.0%]:Running loss: 0.21751932799816132
[2018-04-17 20:36:49.492019]: [Epoch: 601(60.16016016016016%): Data: 25.333333333333336%]:Running loss: 4.350385740399361
[2018-04-17 20:36:50.778941]: [Epoch: 601(60.16016016016016%): Data: 50.66666666666667%]:Running loss: 8.483254626393318
[2018-04-17 20:36:54.265712]: Test set accuracy: 94.33962264150944% ,loss = 5.437978357076645
[2018-04-17 20:36:54.383024]: ====================
[2018-04-17 20:36:54.388038]: Elapsed time since starting training: 1:16:20.552669
[2018-04-17 20:36:54.392549]: Estimated time left: -1 day, 23:58:39.443321
[2018-04-17 20:36:54.397061]: ====================
[2018-04-17 20:36:54.464243]: [Epoch: 602(60.26026026026025%): Data: 0.0%]:Running loss: 0.2175191342830658
[2018-04-17 20:36:55.787759]: [Epoch: 602(60.26026026026025%): Data: 25.333333333333336%]:Running loss: 4.350386276841164
[2018-04-17 20:36:57.069166]: [Epoch: 602(60.26026026026025%): Data: 50.66666666666667%]:Running loss: 8.483253583312035
[2018-04-17 20:37:00.653196]: Test set accuracy: 94.33962264150944% ,loss = 5.437985062599182
[2018-04-17 20:37:00.774520]: ====================
[2018-04-17 20:37:00.779031]: Elapsed time since starting training: 1:16:26.943662
[2018-04-17 20:37:00.784044]: Estimated time left: -1 day, 23:58:33.051827
[2018-04-17 20:37:00.789058]: ====================
[2018-04-17 20:37:00.859245]: [Epoch: 603(60.36036036036037%): Data: 0.0%]:Running loss: 0.21751940250396729
[2018-04-17 20:37:02.158198]: [Epoch: 603(60.36036036036037%): Data: 25.333333333333336%]:Running loss: 4.350387752056122
[2018-04-17 20:37:03.485226]: [Epoch: 603(60.36036036036037%): Data: 50.66666666666667%]:Running loss: 8.483255058526993
[2018-04-17 20:37:06.995059]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 20:37:07.115379]: ====================
[2018-04-17 20:37:07.120895]: Elapsed time since starting training: 1:16:33.285023
[2018-04-17 20:37:07.127411]: Estimated time left: -1 day, 23:58:26.708459
[2018-04-17 20:37:07.131923]: ====================
[2018-04-17 20:37:07.201609]: [Epoch: 604(60.46046046046046%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 20:37:08.555208]: [Epoch: 604(60.46046046046046%): Data: 25.333333333333336%]:Running loss: 4.350387126207352
[2018-04-17 20:37:09.854162]: [Epoch: 604(60.46046046046046%): Data: 50.66666666666667%]:Running loss: 8.48325303196907
[2018-04-17 20:37:13.421647]: Test set accuracy: 94.33962264150944% ,loss = 5.437986180186272
[2018-04-17 20:37:13.546982]: ====================
[2018-04-17 20:37:13.552495]: Elapsed time since starting training: 1:16:39.717126
[2018-04-17 20:37:13.557509]: Estimated time left: -1 day, 23:58:20.277860
[2018-04-17 20:37:13.562522]: ====================
[2018-04-17 20:37:13.633713]: [Epoch: 605(60.56056056056056%): Data: 0.0%]:Running loss: 0.21751944720745087
[2018-04-17 20:37:14.916121]: [Epoch: 605(60.56056056056056%): Data: 25.333333333333336%]:Running loss: 4.350386381149292
[2018-04-17 20:37:16.186499]: [Epoch: 605(60.56056056056056%): Data: 50.66666666666667%]:Running loss: 8.483251690864563
[2018-04-17 20:37:19.712876]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 20:37:19.851745]: ====================
[2018-04-17 20:37:19.856760]: Elapsed time since starting training: 1:16:46.021391
[2018-04-17 20:37:19.861772]: Estimated time left: -1 day, 23:58:13.973597
[2018-04-17 20:37:19.866284]: ====================
[2018-04-17 20:37:19.937473]: [Epoch: 606(60.66066066066066%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 20:37:21.189302]: [Epoch: 606(60.66066066066066%): Data: 25.333333333333336%]:Running loss: 4.350385308265686
[2018-04-17 20:37:22.455167]: [Epoch: 606(60.66066066066066%): Data: 50.66666666666667%]:Running loss: 8.483252391219139
[2018-04-17 20:37:26.007613]: Test set accuracy: 94.33962264150944% ,loss = 5.437977239489555
[2018-04-17 20:37:26.154504]: ====================
[2018-04-17 20:37:26.159016]: Elapsed time since starting training: 1:16:52.323647
[2018-04-17 20:37:26.164029]: Estimated time left: -1 day, 23:58:07.671340
[2018-04-17 20:37:26.171048]: ====================
[2018-04-17 20:37:26.247250]: [Epoch: 607(60.76076076076076%): Data: 0.0%]:Running loss: 0.21751908957958221
[2018-04-17 20:37:27.566258]: [Epoch: 607(60.76076076076076%): Data: 25.333333333333336%]:Running loss: 4.350384011864662
[2018-04-17 20:37:28.823099]: [Epoch: 607(60.76076076076076%): Data: 50.66666666666667%]:Running loss: 8.483250468969345
[2018-04-17 20:37:32.334938]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 20:37:32.457263]: ====================
[2018-04-17 20:37:32.461775]: Elapsed time since starting training: 1:16:58.626406
[2018-04-17 20:37:32.466788]: Estimated time left: -1 day, 23:58:01.369082
[2018-04-17 20:37:32.471300]: ====================
[2018-04-17 20:37:32.545498]: [Epoch: 608(60.86086086086087%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 20:37:33.819887]: [Epoch: 608(60.86086086086087%): Data: 25.333333333333336%]:Running loss: 4.350385278463364
[2018-04-17 20:37:35.101795]: [Epoch: 608(60.86086086086087%): Data: 50.66666666666667%]:Running loss: 8.48325166106224
[2018-04-17 20:37:38.623158]: Test set accuracy: 94.33962264150944% ,loss = 5.437979474663734
[2018-04-17 20:37:38.744983]: ====================
[2018-04-17 20:37:38.749494]: Elapsed time since starting training: 1:17:04.914125
[2018-04-17 20:37:38.755009]: Estimated time left: -1 day, 23:57:55.080360
[2018-04-17 20:37:38.759521]: ====================
[2018-04-17 20:37:38.833718]: [Epoch: 609(60.96096096096096%): Data: 0.0%]:Running loss: 0.21751917898654938
[2018-04-17 20:37:40.122144]: [Epoch: 609(60.96096096096096%): Data: 25.333333333333336%]:Running loss: 4.350386023521423
[2018-04-17 20:37:41.376479]: [Epoch: 609(60.96096096096096%): Data: 50.66666666666667%]:Running loss: 8.483251497149467
[2018-04-17 20:37:45.016658]: Test set accuracy: 94.33962264150944% ,loss = 5.437985807657242
[2018-04-17 20:37:45.134472]: ====================
[2018-04-17 20:37:45.139987]: Elapsed time since starting training: 1:17:11.304618
[2018-04-17 20:37:45.144498]: Estimated time left: -1 day, 23:57:48.690871
[2018-04-17 20:37:45.149512]: ====================
[2018-04-17 20:37:45.222706]: [Epoch: 610(61.06106106106106%): Data: 0.0%]:Running loss: 0.21751943230628967
[2018-04-17 20:37:46.491580]: [Epoch: 610(61.06106106106106%): Data: 25.333333333333336%]:Running loss: 4.350385785102844
[2018-04-17 20:37:47.760956]: [Epoch: 610(61.06106106106106%): Data: 50.66666666666667%]:Running loss: 8.48325066268444
[2018-04-17 20:37:51.257754]: Test set accuracy: 94.33962264150944% ,loss = 5.437980592250824
[2018-04-17 20:37:51.379076]: ====================
[2018-04-17 20:37:51.383589]: Elapsed time since starting training: 1:17:17.547718
[2018-04-17 20:37:51.388602]: Estimated time left: -1 day, 23:57:42.446767
[2018-04-17 20:37:51.393113]: ====================
[2018-04-17 20:37:51.462801]: [Epoch: 611(61.16116116116116%): Data: 0.0%]:Running loss: 0.21751922369003296
[2018-04-17 20:37:52.721646]: [Epoch: 611(61.16116116116116%): Data: 25.333333333333336%]:Running loss: 4.350384682416916
[2018-04-17 20:37:53.989015]: [Epoch: 611(61.16116116116116%): Data: 50.66666666666667%]:Running loss: 8.48325027525425
[2018-04-17 20:37:57.573552]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 20:37:57.688358]: ====================
[2018-04-17 20:37:57.693371]: Elapsed time since starting training: 1:17:23.858002
[2018-04-17 20:37:57.697884]: Estimated time left: -1 day, 23:57:36.137485
[2018-04-17 20:37:57.702897]: ====================
[2018-04-17 20:37:57.773083]: [Epoch: 612(61.261261261261254%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 20:37:59.026415]: [Epoch: 612(61.261261261261254%): Data: 25.333333333333336%]:Running loss: 4.3503832668066025
[2018-04-17 20:38:00.298799]: [Epoch: 612(61.261261261261254%): Data: 50.66666666666667%]:Running loss: 8.483248233795166
[2018-04-17 20:38:03.814146]: Test set accuracy: 94.33962264150944% ,loss = 5.437981337308884
[2018-04-17 20:38:03.937475]: ====================
[2018-04-17 20:38:03.942487]: Elapsed time since starting training: 1:17:30.107118
[2018-04-17 20:38:03.946999]: Estimated time left: -1 day, 23:57:29.888370
[2018-04-17 20:38:03.951512]: ====================
[2018-04-17 20:38:04.021698]: [Epoch: 613(61.36136136136137%): Data: 0.0%]:Running loss: 0.21751925349235535
[2018-04-17 20:38:05.288567]: [Epoch: 613(61.36136136136137%): Data: 25.333333333333336%]:Running loss: 4.350384086370468
[2018-04-17 20:38:06.554433]: [Epoch: 613(61.36136136136137%): Data: 50.66666666666667%]:Running loss: 8.483249858021736
[2018-04-17 20:38:10.039199]: Test set accuracy: 94.33962264150944% ,loss = 5.437977984547615
[2018-04-17 20:38:10.160020]: ====================
[2018-04-17 20:38:10.165033]: Elapsed time since starting training: 1:17:36.329664
[2018-04-17 20:38:10.170047]: Estimated time left: -1 day, 23:57:23.665824
[2018-04-17 20:38:10.175561]: ====================
[2018-04-17 20:38:10.247753]: [Epoch: 614(61.46146146146146%): Data: 0.0%]:Running loss: 0.2175191193819046
[2018-04-17 20:38:11.525150]: [Epoch: 614(61.46146146146146%): Data: 25.333333333333336%]:Running loss: 4.350385069847107
[2018-04-17 20:38:12.794024]: [Epoch: 614(61.46146146146146%): Data: 50.66666666666667%]:Running loss: 8.48325002193451
[2018-04-17 20:38:16.289317]: Test set accuracy: 94.33962264150944% ,loss = 5.437983572483063
[2018-04-17 20:38:16.414150]: ====================
[2018-04-17 20:38:16.419163]: Elapsed time since starting training: 1:17:42.583794
[2018-04-17 20:38:16.425179]: Estimated time left: -1 day, 23:57:17.410190
[2018-04-17 20:38:16.429691]: ====================
[2018-04-17 20:38:16.502384]: [Epoch: 615(61.56156156156156%): Data: 0.0%]:Running loss: 0.2175193428993225
[2018-04-17 20:38:17.814874]: [Epoch: 615(61.56156156156156%): Data: 25.333333333333336%]:Running loss: 4.350382953882217
[2018-04-17 20:38:19.079737]: [Epoch: 615(61.56156156156156%): Data: 50.66666666666667%]:Running loss: 8.483247324824333
[2018-04-17 20:38:22.614135]: Test set accuracy: 94.33962264150944% ,loss = 5.437979102134705
[2018-04-17 20:38:22.740973]: ====================
[2018-04-17 20:38:22.745484]: Elapsed time since starting training: 1:17:48.910115
[2018-04-17 20:38:22.749997]: Estimated time left: -1 day, 23:57:11.085372
[2018-04-17 20:38:22.755512]: ====================
[2018-04-17 20:38:22.829207]: [Epoch: 616(61.66166166166166%): Data: 0.0%]:Running loss: 0.21751916408538818
[2018-04-17 20:38:24.094071]: [Epoch: 616(61.66166166166166%): Data: 25.333333333333336%]:Running loss: 4.350384101271629
[2018-04-17 20:38:25.359435]: [Epoch: 616(61.66166166166166%): Data: 50.66666666666667%]:Running loss: 8.483249127864838
[2018-04-17 20:38:28.843198]: Test set accuracy: 94.33962264150944% ,loss = 5.437974631786346
[2018-04-17 20:38:28.968532]: ====================
[2018-04-17 20:38:28.976051]: Elapsed time since starting training: 1:17:55.140682
[2018-04-17 20:38:28.977556]: Estimated time left: -1 day, 23:57:04.857813
[2018-04-17 20:38:28.982569]: ====================
[2018-04-17 20:38:29.056266]: [Epoch: 617(61.76176176176176%): Data: 0.0%]:Running loss: 0.21751898527145386
[2018-04-17 20:38:30.332659]: [Epoch: 617(61.76176176176176%): Data: 25.333333333333336%]:Running loss: 4.3503827303647995
[2018-04-17 20:38:31.569949]: [Epoch: 617(61.76176176176176%): Data: 50.66666666666667%]:Running loss: 8.483246624469757
[2018-04-17 20:38:35.118384]: Test set accuracy: 94.33962264150944% ,loss = 5.437980592250824
[2018-04-17 20:38:35.232688]: ====================
[2018-04-17 20:38:35.236698]: Elapsed time since starting training: 1:18:01.401329
[2018-04-17 20:38:35.241211]: Estimated time left: -1 day, 23:56:58.594158
[2018-04-17 20:38:35.244719]: ====================
[2018-04-17 20:38:35.313402]: [Epoch: 618(61.86186186186187%): Data: 0.0%]:Running loss: 0.21751922369003296
[2018-04-17 20:38:36.598820]: [Epoch: 618(61.86186186186187%): Data: 25.333333333333336%]:Running loss: 4.350383505225182
[2018-04-17 20:38:37.872206]: [Epoch: 618(61.86186186186187%): Data: 50.66666666666667%]:Running loss: 8.483246833086014
[2018-04-17 20:38:41.461249]: Test set accuracy: 94.33962264150944% ,loss = 5.437977239489555
[2018-04-17 20:38:41.577559]: ====================
[2018-04-17 20:38:41.582071]: Elapsed time since starting training: 1:18:07.746702
[2018-04-17 20:38:41.587085]: Estimated time left: -1 day, 23:56:52.248786
[2018-04-17 20:38:41.593100]: ====================
[2018-04-17 20:38:41.661783]: [Epoch: 619(61.96196196196196%): Data: 0.0%]:Running loss: 0.21751908957958221
[2018-04-17 20:38:42.961238]: [Epoch: 619(61.96196196196196%): Data: 25.333333333333336%]:Running loss: 4.350382894277573
[2018-04-17 20:38:44.208053]: [Epoch: 619(61.96196196196196%): Data: 50.66666666666667%]:Running loss: 8.483247265219688
[2018-04-17 20:38:47.677779]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 20:38:47.792586]: ====================
[2018-04-17 20:38:47.797098]: Elapsed time since starting training: 1:18:13.961226
[2018-04-17 20:38:47.801608]: Estimated time left: -1 day, 23:56:46.034262
[2018-04-17 20:38:47.807124]: ====================
[2018-04-17 20:38:47.879315]: [Epoch: 620(62.06206206206206%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 20:38:49.151197]: [Epoch: 620(62.06206206206206%): Data: 25.333333333333336%]:Running loss: 4.350382328033447
[2018-04-17 20:38:50.414556]: [Epoch: 620(62.06206206206206%): Data: 50.66666666666667%]:Running loss: 8.483246564865112
[2018-04-17 20:38:53.871247]: Test set accuracy: 94.33962264150944% ,loss = 5.437977239489555
[2018-04-17 20:38:53.991066]: ====================
[2018-04-17 20:38:53.996079]: Elapsed time since starting training: 1:18:20.160710
[2018-04-17 20:38:54.000591]: Estimated time left: -1 day, 23:56:39.834778
[2018-04-17 20:38:54.006608]: ====================
[2018-04-17 20:38:54.078300]: [Epoch: 621(62.16216216216216%): Data: 0.0%]:Running loss: 0.21751908957958221
[2018-04-17 20:38:55.350180]: [Epoch: 621(62.16216216216216%): Data: 25.333333333333336%]:Running loss: 4.350382953882217
[2018-04-17 20:38:56.649133]: [Epoch: 621(62.16216216216216%): Data: 50.66666666666667%]:Running loss: 8.483247697353363
[2018-04-17 20:39:00.261238]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 20:39:00.384566]: ====================
[2018-04-17 20:39:00.388577]: Elapsed time since starting training: 1:18:26.553208
[2018-04-17 20:39:00.392587]: Estimated time left: -1 day, 23:56:33.442782
[2018-04-17 20:39:00.396598]: ====================
[2018-04-17 20:39:00.464279]: [Epoch: 622(62.262262262262254%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 20:39:01.740672]: [Epoch: 622(62.262262262262254%): Data: 25.333333333333336%]:Running loss: 4.350382000207901
[2018-04-17 20:39:03.007546]: [Epoch: 622(62.262262262262254%): Data: 50.66666666666667%]:Running loss: 8.483244627714157
[2018-04-17 20:39:06.526403]: Test set accuracy: 94.33962264150944% ,loss = 5.437980964779854
[2018-04-17 20:39:06.659257]: ====================
[2018-04-17 20:39:06.663768]: Elapsed time since starting training: 1:18:32.828399
[2018-04-17 20:39:06.668280]: Estimated time left: -1 day, 23:56:27.167089
[2018-04-17 20:39:06.675800]: ====================
[2018-04-17 20:39:06.761528]: [Epoch: 623(62.36236236236237%): Data: 0.0%]:Running loss: 0.21751923859119415
[2018-04-17 20:39:08.051959]: [Epoch: 623(62.36236236236237%): Data: 25.333333333333336%]:Running loss: 4.350383147597313
[2018-04-17 20:39:09.345905]: [Epoch: 623(62.36236236236237%): Data: 50.66666666666667%]:Running loss: 8.483245983719826
[2018-04-17 20:39:12.859241]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 20:39:12.978058]: ====================
[2018-04-17 20:39:12.983071]: Elapsed time since starting training: 1:18:39.147702
[2018-04-17 20:39:12.987587]: Estimated time left: -1 day, 23:56:20.847782
[2018-04-17 20:39:12.992596]: ====================
[2018-04-17 20:39:13.064788]: [Epoch: 624(62.46246246246246%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 20:39:14.345193]: [Epoch: 624(62.46246246246246%): Data: 25.333333333333336%]:Running loss: 4.350382551550865
[2018-04-17 20:39:15.609053]: [Epoch: 624(62.46246246246246%): Data: 50.66666666666667%]:Running loss: 8.483244448900223
[2018-04-17 20:39:19.120390]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 20:39:19.350503]: ====================
[2018-04-17 20:39:19.355014]: Elapsed time since starting training: 1:18:45.519645
[2018-04-17 20:39:19.359526]: Estimated time left: -1 day, 23:56:14.475843
[2018-04-17 20:39:19.364540]: ====================
[2018-04-17 20:39:19.434725]: [Epoch: 625(62.56256256256256%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 20:39:20.738693]: [Epoch: 625(62.56256256256256%): Data: 25.333333333333336%]:Running loss: 4.350381836295128
[2018-04-17 20:39:22.006564]: [Epoch: 625(62.56256256256256%): Data: 50.66666666666667%]:Running loss: 8.483243227005005
[2018-04-17 20:39:25.564525]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 20:39:25.682839]: ====================
[2018-04-17 20:39:25.687854]: Elapsed time since starting training: 1:18:51.852485
[2018-04-17 20:39:25.692866]: Estimated time left: -1 day, 23:56:08.142503
[2018-04-17 20:39:25.697378]: ====================
[2018-04-17 20:39:25.770071]: [Epoch: 626(62.66266266266266%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 20:39:27.046967]: [Epoch: 626(62.66266266266266%): Data: 25.333333333333336%]:Running loss: 4.350381165742874
[2018-04-17 20:39:28.363467]: [Epoch: 626(62.66266266266266%): Data: 50.66666666666667%]:Running loss: 8.483244687318802
[2018-04-17 20:39:31.914911]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:39:32.034729]: ====================
[2018-04-17 20:39:32.040745]: Elapsed time since starting training: 1:18:58.205376
[2018-04-17 20:39:32.045257]: Estimated time left: -1 day, 23:56:01.790112
[2018-04-17 20:39:32.049769]: ====================
[2018-04-17 20:39:32.121460]: [Epoch: 627(62.76276276276276%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:39:33.417907]: [Epoch: 627(62.76276276276276%): Data: 25.333333333333336%]:Running loss: 4.350379854440689
[2018-04-17 20:39:34.691794]: [Epoch: 627(62.76276276276276%): Data: 50.66666666666667%]:Running loss: 8.483241826295853
[2018-04-17 20:39:38.343504]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 20:39:38.487387]: ====================
[2018-04-17 20:39:38.492400]: Elapsed time since starting training: 1:19:04.657031
[2018-04-17 20:39:38.496912]: Estimated time left: -1 day, 23:55:55.338958
[2018-04-17 20:39:38.500923]: ====================
[2018-04-17 20:39:38.575621]: [Epoch: 628(62.86286286286287%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 20:39:39.864047]: [Epoch: 628(62.86286286286287%): Data: 25.333333333333336%]:Running loss: 4.35038223862648
[2018-04-17 20:39:41.142948]: [Epoch: 628(62.86286286286287%): Data: 50.66666666666667%]:Running loss: 8.483244761824608
[2018-04-17 20:39:44.663308]: Test set accuracy: 94.33962264150944% ,loss = 5.437973141670227
[2018-04-17 20:39:44.783127]: ====================
[2018-04-17 20:39:44.788141]: Elapsed time since starting training: 1:19:10.952270
[2018-04-17 20:39:44.793154]: Estimated time left: -1 day, 23:55:49.042717
[2018-04-17 20:39:44.797164]: ====================
[2018-04-17 20:39:44.866348]: [Epoch: 629(62.96296296296296%): Data: 0.0%]:Running loss: 0.21751892566680908
[2018-04-17 20:39:46.143745]: [Epoch: 629(62.96296296296296%): Data: 25.333333333333336%]:Running loss: 4.350381687283516
[2018-04-17 20:39:47.409110]: [Epoch: 629(62.96296296296296%): Data: 50.66666666666667%]:Running loss: 8.483243599534035
[2018-04-17 20:39:50.941502]: Test set accuracy: 94.33962264150944% ,loss = 5.437977239489555
[2018-04-17 20:39:51.058314]: ====================
[2018-04-17 20:39:51.062825]: Elapsed time since starting training: 1:19:17.226954
[2018-04-17 20:39:51.067337]: Estimated time left: -1 day, 23:55:42.768534
[2018-04-17 20:39:51.071849]: ====================
[2018-04-17 20:39:51.143540]: [Epoch: 630(63.06306306306306%): Data: 0.0%]:Running loss: 0.21751908957958221
[2018-04-17 20:39:52.412413]: [Epoch: 630(63.06306306306306%): Data: 25.333333333333336%]:Running loss: 4.350381135940552
[2018-04-17 20:39:53.697330]: [Epoch: 630(63.06306306306306%): Data: 50.66666666666667%]:Running loss: 8.483242616057396
[2018-04-17 20:39:57.190618]: Test set accuracy: 94.33962264150944% ,loss = 5.437973141670227
[2018-04-17 20:39:57.315952]: ====================
[2018-04-17 20:39:57.320464]: Elapsed time since starting training: 1:19:23.485095
[2018-04-17 20:39:57.327482]: Estimated time left: -1 day, 23:55:36.507887
[2018-04-17 20:39:57.332496]: ====================
[2018-04-17 20:39:57.405691]: [Epoch: 631(63.16316316316316%): Data: 0.0%]:Running loss: 0.21751892566680908
[2018-04-17 20:39:58.676570]: [Epoch: 631(63.16316316316316%): Data: 25.333333333333336%]:Running loss: 4.3503803461790085
[2018-04-17 20:39:59.977027]: [Epoch: 631(63.16316316316316%): Data: 50.66666666666667%]:Running loss: 8.483241885900497
[2018-04-17 20:40:03.531479]: Test set accuracy: 94.33962264150944% ,loss = 5.437980219721794
[2018-04-17 20:40:03.650797]: ====================
[2018-04-17 20:40:03.655308]: Elapsed time since starting training: 1:19:29.819939
[2018-04-17 20:40:03.659820]: Estimated time left: -1 day, 23:55:30.175549
[2018-04-17 20:40:03.664834]: ====================
[2018-04-17 20:40:03.733517]: [Epoch: 632(63.263263263263255%): Data: 0.0%]:Running loss: 0.21751920878887177
[2018-04-17 20:40:05.045004]: [Epoch: 632(63.263263263263255%): Data: 25.333333333333336%]:Running loss: 4.350379824638367
[2018-04-17 20:40:06.349973]: [Epoch: 632(63.263263263263255%): Data: 50.66666666666667%]:Running loss: 8.483240008354187
[2018-04-17 20:40:09.861310]: Test set accuracy: 94.33962264150944% ,loss = 5.437974631786346
[2018-04-17 20:40:09.983134]: ====================
[2018-04-17 20:40:09.987646]: Elapsed time since starting training: 1:19:36.152277
[2018-04-17 20:40:09.992659]: Estimated time left: -1 day, 23:55:23.842710
[2018-04-17 20:40:09.997171]: ====================
[2018-04-17 20:40:10.067859]: [Epoch: 633(63.36336336336337%): Data: 0.0%]:Running loss: 0.21751898527145386
[2018-04-17 20:40:11.385864]: [Epoch: 633(63.36336336336337%): Data: 25.333333333333336%]:Running loss: 4.350380480289459
[2018-04-17 20:40:12.681809]: [Epoch: 633(63.36336336336337%): Data: 50.66666666666667%]:Running loss: 8.483242973685265
[2018-04-17 20:40:16.177103]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:40:16.296923]: ====================
[2018-04-17 20:40:16.303440]: Elapsed time since starting training: 1:19:42.467569
[2018-04-17 20:40:16.307951]: Estimated time left: -1 day, 23:55:17.527418
[2018-04-17 20:40:16.312463]: ====================
[2018-04-17 20:40:16.379642]: [Epoch: 634(63.46346346346346%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:40:17.645508]: [Epoch: 634(63.46346346346346%): Data: 25.333333333333336%]:Running loss: 4.350378900766373
[2018-04-17 20:40:18.909870]: [Epoch: 634(63.46346346346346%): Data: 50.66666666666667%]:Running loss: 8.483241155743599
[2018-04-17 20:40:22.382103]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:40:22.503927]: ====================
[2018-04-17 20:40:22.508940]: Elapsed time since starting training: 1:19:48.673571
[2018-04-17 20:40:22.513452]: Estimated time left: -1 day, 23:55:11.321917
[2018-04-17 20:40:22.517964]: ====================
[2018-04-17 20:40:22.592162]: [Epoch: 635(63.56356356356356%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:40:23.885600]: [Epoch: 635(63.56356356356356%): Data: 25.333333333333336%]:Running loss: 4.350380599498749
[2018-04-17 20:40:25.179045]: [Epoch: 635(63.56356356356356%): Data: 50.66666666666667%]:Running loss: 8.483241617679596
[2018-04-17 20:40:28.680851]: Test set accuracy: 94.33962264150944% ,loss = 5.4379817098379135
[2018-04-17 20:40:28.795657]: ====================
[2018-04-17 20:40:28.799667]: Elapsed time since starting training: 1:19:54.964298
[2018-04-17 20:40:28.804179]: Estimated time left: -1 day, 23:55:05.031190
[2018-04-17 20:40:28.809192]: ====================
[2018-04-17 20:40:28.883891]: [Epoch: 636(63.66366366366366%): Data: 0.0%]:Running loss: 0.21751926839351654
[2018-04-17 20:40:30.149255]: [Epoch: 636(63.66366366366366%): Data: 25.333333333333336%]:Running loss: 4.350380927324295
[2018-04-17 20:40:31.445702]: [Epoch: 636(63.66366366366366%): Data: 50.66666666666667%]:Running loss: 8.483241394162178
[2018-04-17 20:40:34.981604]: Test set accuracy: 94.33962264150944% ,loss = 5.437976494431496
[2018-04-17 20:40:35.103930]: ====================
[2018-04-17 20:40:35.109445]: Elapsed time since starting training: 1:20:01.273574
[2018-04-17 20:40:35.113956]: Estimated time left: -1 day, 23:54:58.721413
[2018-04-17 20:40:35.118468]: ====================
[2018-04-17 20:40:35.191163]: [Epoch: 637(63.76376376376376%): Data: 0.0%]:Running loss: 0.21751905977725983
[2018-04-17 20:40:36.476580]: [Epoch: 637(63.76376376376376%): Data: 25.333333333333336%]:Running loss: 4.350379645824432
[2018-04-17 20:40:37.780546]: [Epoch: 637(63.76376376376376%): Data: 50.66666666666667%]:Running loss: 8.483239099383354
[2018-04-17 20:40:41.258795]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:40:41.372097]: ====================
[2018-04-17 20:40:41.377110]: Elapsed time since starting training: 1:20:07.541741
[2018-04-17 20:40:41.381622]: Estimated time left: -1 day, 23:54:52.453747
[2018-04-17 20:40:41.386635]: ====================
[2018-04-17 20:40:41.454816]: [Epoch: 638(63.86386386386387%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:40:42.745749]: [Epoch: 638(63.86386386386387%): Data: 25.333333333333336%]:Running loss: 4.350380212068558
[2018-04-17 20:40:44.004095]: [Epoch: 638(63.86386386386387%): Data: 50.66666666666667%]:Running loss: 8.483240634202957
[2018-04-17 20:40:47.518440]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 20:40:47.638760]: ====================
[2018-04-17 20:40:47.644275]: Elapsed time since starting training: 1:20:13.808404
[2018-04-17 20:40:47.649288]: Estimated time left: -1 day, 23:54:46.186081
[2018-04-17 20:40:47.653299]: ====================
[2018-04-17 20:40:47.723485]: [Epoch: 639(63.96396396396396%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 20:40:49.012913]: [Epoch: 639(63.96396396396396%): Data: 25.333333333333336%]:Running loss: 4.350378200411797
[2018-04-17 20:40:50.268752]: [Epoch: 639(63.96396396396396%): Data: 50.66666666666667%]:Running loss: 8.483237534761429
[2018-04-17 20:40:53.952051]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 20:40:54.074878]: ====================
[2018-04-17 20:40:54.079891]: Elapsed time since starting training: 1:20:20.244021
[2018-04-17 20:40:54.084905]: Estimated time left: -1 day, 23:54:39.750464
[2018-04-17 20:40:54.089416]: ====================
[2018-04-17 20:40:54.162612]: [Epoch: 640(64.06406406406407%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 20:40:55.560829]: [Epoch: 640(64.06406406406407%): Data: 25.333333333333336%]:Running loss: 4.3503783494234085
[2018-04-17 20:40:56.851260]: [Epoch: 640(64.06406406406407%): Data: 50.66666666666667%]:Running loss: 8.483239278197289
[2018-04-17 20:41:00.491444]: Test set accuracy: 94.33962264150944% ,loss = 5.437977239489555
[2018-04-17 20:41:00.634324]: ====================
[2018-04-17 20:41:00.640841]: Elapsed time since starting training: 1:20:26.804971
[2018-04-17 20:41:00.646357]: Estimated time left: -1 day, 23:54:33.189515
[2018-04-17 20:41:00.650868]: ====================
[2018-04-17 20:41:00.719557]: [Epoch: 641(64.16416416416416%): Data: 0.0%]:Running loss: 0.21751908957958221
[2018-04-17 20:41:02.017501]: [Epoch: 641(64.16416416416416%): Data: 25.333333333333336%]:Running loss: 4.350378319621086
[2018-04-17 20:41:03.285373]: [Epoch: 641(64.16416416416416%): Data: 50.66666666666667%]:Running loss: 8.483238697052002
[2018-04-17 20:41:07.002256]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:41:07.132603]: ====================
[2018-04-17 20:41:07.137616]: Elapsed time since starting training: 1:20:33.302247
[2018-04-17 20:41:07.143131]: Estimated time left: -1 day, 23:54:26.692238
[2018-04-17 20:41:07.149147]: ====================
[2018-04-17 20:41:07.220838]: [Epoch: 642(64.26426426426426%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:41:08.502244]: [Epoch: 642(64.26426426426426%): Data: 25.333333333333336%]:Running loss: 4.350379303097725
[2018-04-17 20:41:09.790169]: [Epoch: 642(64.26426426426426%): Data: 50.66666666666667%]:Running loss: 8.483238756656647
[2018-04-17 20:41:13.476471]: Test set accuracy: 94.33962264150944% ,loss = 5.437978357076645
[2018-04-17 20:41:13.607821]: ====================
[2018-04-17 20:41:13.612835]: Elapsed time since starting training: 1:20:39.776963
[2018-04-17 20:41:13.618349]: Estimated time left: -1 day, 23:54:20.217522
[2018-04-17 20:41:13.623361]: ====================
[2018-04-17 20:41:13.698061]: [Epoch: 643(64.36436436436436%): Data: 0.0%]:Running loss: 0.2175191342830658
[2018-04-17 20:41:15.120843]: [Epoch: 643(64.36436436436436%): Data: 25.333333333333336%]:Running loss: 4.350379213690758
[2018-04-17 20:41:16.489984]: [Epoch: 643(64.36436436436436%): Data: 50.66666666666667%]:Running loss: 8.48323954641819
[2018-04-17 20:41:20.041427]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 20:41:20.161246]: ====================
[2018-04-17 20:41:20.166260]: Elapsed time since starting training: 1:20:46.330891
[2018-04-17 20:41:20.170772]: Estimated time left: -1 day, 23:54:13.664597
[2018-04-17 20:41:20.176286]: ====================
[2018-04-17 20:41:20.245470]: [Epoch: 644(64.46446446446447%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 20:41:21.544424]: [Epoch: 644(64.46446446446447%): Data: 25.333333333333336%]:Running loss: 4.350378170609474
[2018-04-17 20:41:22.904540]: [Epoch: 644(64.46446446446447%): Data: 50.66666666666667%]:Running loss: 8.483237892389297
[2018-04-17 20:41:26.542724]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 20:41:26.678585]: ====================
[2018-04-17 20:41:26.684601]: Elapsed time since starting training: 1:20:52.849232
[2018-04-17 20:41:26.689615]: Estimated time left: -1 day, 23:54:07.146255
[2018-04-17 20:41:26.694628]: ====================
[2018-04-17 20:41:26.764816]: [Epoch: 645(64.56456456456456%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 20:41:28.081816]: [Epoch: 645(64.56456456456456%): Data: 25.333333333333336%]:Running loss: 4.350379168987274
[2018-04-17 20:41:29.387288]: [Epoch: 645(64.56456456456456%): Data: 50.66666666666667%]:Running loss: 8.483238399028778
[2018-04-17 20:41:33.019947]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 20:41:33.151297]: ====================
[2018-04-17 20:41:33.156310]: Elapsed time since starting training: 1:20:59.320440
[2018-04-17 20:41:33.161323]: Estimated time left: -1 day, 23:54:00.674547
[2018-04-17 20:41:33.166838]: ====================
[2018-04-17 20:41:33.240534]: [Epoch: 646(64.66466466466466%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 20:41:34.556533]: [Epoch: 646(64.66466466466466%): Data: 25.333333333333336%]:Running loss: 4.350378155708313
[2018-04-17 20:41:35.860500]: [Epoch: 646(64.66466466466466%): Data: 50.66666666666667%]:Running loss: 8.483236357569695
[2018-04-17 20:41:39.462077]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 20:41:39.587911]: ====================
[2018-04-17 20:41:39.591922]: Elapsed time since starting training: 1:21:05.756553
[2018-04-17 20:41:39.596435]: Estimated time left: -1 day, 23:53:54.238934
[2018-04-17 20:41:39.601447]: ====================
[2018-04-17 20:41:39.674643]: [Epoch: 647(64.76476476476476%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 20:41:40.923964]: [Epoch: 647(64.76476476476476%): Data: 25.333333333333336%]:Running loss: 4.350378021597862
[2018-04-17 20:41:42.221915]: [Epoch: 647(64.76476476476476%): Data: 50.66666666666667%]:Running loss: 8.483236223459244
[2018-04-17 20:41:45.953337]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:41:46.085187]: ====================
[2018-04-17 20:41:46.092206]: Elapsed time since starting training: 1:21:12.256336
[2018-04-17 20:41:46.098223]: Estimated time left: -1 day, 23:53:47.737146
[2018-04-17 20:41:46.103236]: ====================
[2018-04-17 20:41:46.187961]: [Epoch: 648(64.86486486486487%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:41:47.521005]: [Epoch: 648(64.86486486486487%): Data: 25.333333333333336%]:Running loss: 4.350376754999161
[2018-04-17 20:41:48.831489]: [Epoch: 648(64.86486486486487%): Data: 50.66666666666667%]:Running loss: 8.483236998319626
[2018-04-17 20:41:52.505760]: Test set accuracy: 94.33962264150944% ,loss = 5.437975004315376
[2018-04-17 20:41:52.647136]: ====================
[2018-04-17 20:41:52.651647]: Elapsed time since starting training: 1:21:18.816278
[2018-04-17 20:41:52.657162]: Estimated time left: -1 day, 23:53:41.178207
[2018-04-17 20:41:52.662176]: ====================
[2018-04-17 20:41:52.734869]: [Epoch: 649(64.96496496496496%): Data: 0.0%]:Running loss: 0.21751900017261505
[2018-04-17 20:41:54.059893]: [Epoch: 649(64.96496496496496%): Data: 25.333333333333336%]:Running loss: 4.3503763526678085
[2018-04-17 20:41:55.350825]: [Epoch: 649(64.96496496496496%): Data: 50.66666666666667%]:Running loss: 8.483235001564026
[2018-04-17 20:41:58.977969]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:41:59.117842]: ====================
[2018-04-17 20:41:59.122854]: Elapsed time since starting training: 1:21:25.287485
[2018-04-17 20:41:59.127868]: Estimated time left: -1 day, 23:53:34.707501
[2018-04-17 20:41:59.133383]: ====================
[2018-04-17 20:41:59.203067]: [Epoch: 650(65.06506506506507%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:42:00.523579]: [Epoch: 650(65.06506506506507%): Data: 25.333333333333336%]:Running loss: 4.350378945469856
[2018-04-17 20:42:01.845595]: [Epoch: 650(65.06506506506507%): Data: 50.66666666666667%]:Running loss: 8.483238384127617
[2018-04-17 20:42:05.536408]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:42:05.663747]: ====================
[2018-04-17 20:42:05.668258]: Elapsed time since starting training: 1:21:31.832889
[2018-04-17 20:42:05.675277]: Estimated time left: -1 day, 23:53:28.160092
[2018-04-17 20:42:05.680793]: ====================
[2018-04-17 20:42:05.759001]: [Epoch: 651(65.16516516516516%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:42:07.087532]: [Epoch: 651(65.16516516516516%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 20:42:08.393003]: [Epoch: 651(65.16516516516516%): Data: 50.66666666666667%]:Running loss: 8.483235836029053
[2018-04-17 20:42:12.038697]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:42:12.175561]: ====================
[2018-04-17 20:42:12.180074]: Elapsed time since starting training: 1:21:38.344705
[2018-04-17 20:42:12.185088]: Estimated time left: -1 day, 23:53:21.650281
[2018-04-17 20:42:12.189599]: ====================
[2018-04-17 20:42:12.261791]: [Epoch: 652(65.26526526526526%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:42:13.560243]: [Epoch: 652(65.26526526526526%): Data: 25.333333333333336%]:Running loss: 4.350377678871155
[2018-04-17 20:42:14.818590]: [Epoch: 652(65.26526526526526%): Data: 50.66666666666667%]:Running loss: 8.483238324522972
[2018-04-17 20:42:18.480326]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:42:18.607163]: ====================
[2018-04-17 20:42:18.612677]: Elapsed time since starting training: 1:21:44.777308
[2018-04-17 20:42:18.617691]: Estimated time left: -1 day, 23:53:15.217678
[2018-04-17 20:42:18.622203]: ====================
[2018-04-17 20:42:18.694897]: [Epoch: 653(65.36536536536536%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:42:20.000869]: [Epoch: 653(65.36536536536536%): Data: 25.333333333333336%]:Running loss: 4.35037736594677
[2018-04-17 20:42:21.354468]: [Epoch: 653(65.36536536536536%): Data: 50.66666666666667%]:Running loss: 8.483234480023384
[2018-04-17 20:42:25.112963]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:42:25.243309]: ====================
[2018-04-17 20:42:25.248823]: Elapsed time since starting training: 1:21:51.413454
[2018-04-17 20:42:25.253846]: Estimated time left: -1 day, 23:53:08.581523
[2018-04-17 20:42:25.258349]: ====================
[2018-04-17 20:42:25.335055]: [Epoch: 654(65.46546546546547%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:42:26.679138]: [Epoch: 654(65.46546546546547%): Data: 25.333333333333336%]:Running loss: 4.350377097725868
[2018-04-17 20:42:28.006155]: [Epoch: 654(65.46546546546547%): Data: 50.66666666666667%]:Running loss: 8.483237355947495
[2018-04-17 20:42:31.725551]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:42:31.852890]: ====================
[2018-04-17 20:42:31.857402]: Elapsed time since starting training: 1:21:58.022033
[2018-04-17 20:42:31.862415]: Estimated time left: -1 day, 23:53:01.972954
[2018-04-17 20:42:31.868432]: ====================
[2018-04-17 20:42:31.940123]: [Epoch: 655(65.56556556556556%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:42:33.235065]: [Epoch: 655(65.56556556556556%): Data: 25.333333333333336%]:Running loss: 4.350375175476074
[2018-04-17 20:42:34.533517]: [Epoch: 655(65.56556556556556%): Data: 50.66666666666667%]:Running loss: 8.483234778046608
[2018-04-17 20:42:38.217312]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 20:42:38.336630]: ====================
[2018-04-17 20:42:38.341643]: Elapsed time since starting training: 1:22:04.506274
[2018-04-17 20:42:38.346657]: Estimated time left: -1 day, 23:52:55.488712
[2018-04-17 20:42:38.351670]: ====================
[2018-04-17 20:42:38.425366]: [Epoch: 656(65.66566566566566%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 20:42:39.688224]: [Epoch: 656(65.66566566566566%): Data: 25.333333333333336%]:Running loss: 4.350376799702644
[2018-04-17 20:42:40.996201]: [Epoch: 656(65.66566566566566%): Data: 50.66666666666667%]:Running loss: 8.483236491680145
[2018-04-17 20:42:44.661447]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:42:44.794301]: ====================
[2018-04-17 20:42:44.799314]: Elapsed time since starting training: 1:22:10.963444
[2018-04-17 20:42:44.804829]: Estimated time left: -1 day, 23:52:49.030540
[2018-04-17 20:42:44.809842]: ====================
[2018-04-17 20:42:44.883037]: [Epoch: 657(65.76576576576578%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:42:46.175975]: [Epoch: 657(65.76576576576578%): Data: 25.333333333333336%]:Running loss: 4.3503739684820175
[2018-04-17 20:42:47.483952]: [Epoch: 657(65.76576576576578%): Data: 50.66666666666667%]:Running loss: 8.48323281109333
[2018-04-17 20:42:51.188804]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:42:51.320153]: ====================
[2018-04-17 20:42:51.325167]: Elapsed time since starting training: 1:22:17.489798
[2018-04-17 20:42:51.330179]: Estimated time left: -1 day, 23:52:42.505190
[2018-04-17 20:42:51.335193]: ====================
[2018-04-17 20:42:51.406382]: [Epoch: 658(65.86586586586587%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:42:52.731906]: [Epoch: 658(65.86586586586587%): Data: 25.333333333333336%]:Running loss: 4.3503768891096115
[2018-04-17 20:42:54.038882]: [Epoch: 658(65.86586586586587%): Data: 50.66666666666667%]:Running loss: 8.483234405517578
[2018-04-17 20:42:57.775322]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:42:57.904666]: ====================
[2018-04-17 20:42:57.909679]: Elapsed time since starting training: 1:22:24.074310
[2018-04-17 20:42:57.915195]: Estimated time left: -1 day, 23:52:35.920676
[2018-04-17 20:42:57.920207]: ====================
[2018-04-17 20:42:57.993403]: [Epoch: 659(65.96596596596596%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:42:59.265284]: [Epoch: 659(65.96596596596596%): Data: 25.333333333333336%]:Running loss: 4.350379779934883
[2018-04-17 20:43:00.552206]: [Epoch: 659(65.96596596596596%): Data: 50.66666666666667%]:Running loss: 8.483236104249954
[2018-04-17 20:43:04.185366]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 20:43:04.315713]: ====================
[2018-04-17 20:43:04.322230]: Elapsed time since starting training: 1:22:30.486861
[2018-04-17 20:43:04.328748]: Estimated time left: -1 day, 23:52:29.507123
[2018-04-17 20:43:04.333761]: ====================
[2018-04-17 20:43:04.414476]: [Epoch: 660(66.06606606606607%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 20:43:05.724458]: [Epoch: 660(66.06606606606607%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 20:43:07.029930]: [Epoch: 660(66.06606606606607%): Data: 50.66666666666667%]:Running loss: 8.483231827616692
[2018-04-17 20:43:10.720243]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:43:10.964894]: ====================
[2018-04-17 20:43:10.970408]: Elapsed time since starting training: 1:22:37.134538
[2018-04-17 20:43:10.975421]: Estimated time left: -1 day, 23:52:22.859948
[2018-04-17 20:43:10.980936]: ====================
[2018-04-17 20:43:11.055133]: [Epoch: 661(66.16616616616616%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:43:12.382162]: [Epoch: 661(66.16616616616616%): Data: 25.333333333333336%]:Running loss: 4.350377753376961
[2018-04-17 20:43:13.710193]: [Epoch: 661(66.16616616616616%): Data: 50.66666666666667%]:Running loss: 8.483233898878098
[2018-04-17 20:43:17.400505]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:43:17.522831]: ====================
[2018-04-17 20:43:17.527844]: Elapsed time since starting training: 1:22:43.691973
[2018-04-17 20:43:17.532356]: Estimated time left: -1 day, 23:52:16.303515
[2018-04-17 20:43:17.537369]: ====================
[2018-04-17 20:43:17.608558]: [Epoch: 662(66.26626626626627%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:43:18.909518]: [Epoch: 662(66.26626626626627%): Data: 25.333333333333336%]:Running loss: 4.3503760397434235
[2018-04-17 20:43:20.284674]: [Epoch: 662(66.26626626626627%): Data: 50.66666666666667%]:Running loss: 8.483236193656921
[2018-04-17 20:43:23.952427]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:43:24.074752]: ====================
[2018-04-17 20:43:24.079264]: Elapsed time since starting training: 1:22:50.243895
[2018-04-17 20:43:24.085282]: Estimated time left: -1 day, 23:52:09.750087
[2018-04-17 20:43:24.089792]: ====================
[2018-04-17 20:43:24.161483]: [Epoch: 663(66.36636636636636%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:43:25.454922]: [Epoch: 663(66.36636636636636%): Data: 25.333333333333336%]:Running loss: 4.350375324487686
[2018-04-17 20:43:26.767913]: [Epoch: 663(66.36636636636636%): Data: 50.66666666666667%]:Running loss: 8.483231976628304
[2018-04-17 20:43:30.540445]: Test set accuracy: 94.33962264150944% ,loss = 5.437976494431496
[2018-04-17 20:43:30.680316]: ====================
[2018-04-17 20:43:30.685831]: Elapsed time since starting training: 1:22:56.849961
[2018-04-17 20:43:30.689842]: Estimated time left: -1 day, 23:52:03.145527
[2018-04-17 20:43:30.694855]: ====================
[2018-04-17 20:43:30.765543]: [Epoch: 664(66.46646646646647%): Data: 0.0%]:Running loss: 0.21751905977725983
[2018-04-17 20:43:32.061488]: [Epoch: 664(66.46646646646647%): Data: 25.333333333333336%]:Running loss: 4.350376293063164
[2018-04-17 20:43:33.396037]: [Epoch: 664(66.46646646646647%): Data: 50.66666666666667%]:Running loss: 8.48323604464531
[2018-04-17 20:43:37.152025]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:43:37.277859]: ====================
[2018-04-17 20:43:37.282371]: Elapsed time since starting training: 1:23:03.447002
[2018-04-17 20:43:37.288387]: Estimated time left: -1 day, 23:51:56.546982
[2018-04-17 20:43:37.292899]: ====================
[2018-04-17 20:43:37.365593]: [Epoch: 665(66.56656656656656%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:43:38.729730]: [Epoch: 665(66.56656656656656%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 20:43:40.067778]: [Epoch: 665(66.56656656656656%): Data: 50.66666666666667%]:Running loss: 8.483234226703644
[2018-04-17 20:43:43.819252]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:43:43.961130]: ====================
[2018-04-17 20:43:43.966143]: Elapsed time since starting training: 1:23:10.130774
[2018-04-17 20:43:43.970655]: Estimated time left: -1 day, 23:51:49.864714
[2018-04-17 20:43:43.976671]: ====================
[2018-04-17 20:43:44.047359]: [Epoch: 666(66.66666666666666%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:43:45.374889]: [Epoch: 666(66.66666666666666%): Data: 25.333333333333336%]:Running loss: 4.350376695394516
[2018-04-17 20:43:46.658803]: [Epoch: 666(66.66666666666666%): Data: 50.66666666666667%]:Running loss: 8.483234018087387
[2018-04-17 20:43:50.299483]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 20:43:50.430834]: ====================
[2018-04-17 20:43:50.435345]: Elapsed time since starting training: 1:23:16.599976
[2018-04-17 20:43:50.440358]: Estimated time left: -1 day, 23:51:43.395011
[2018-04-17 20:43:50.445371]: ====================
[2018-04-17 20:43:50.520572]: [Epoch: 667(66.76676676676678%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 20:43:51.806992]: [Epoch: 667(66.76676676676678%): Data: 25.333333333333336%]:Running loss: 4.35037924349308
[2018-04-17 20:43:53.118980]: [Epoch: 667(66.76676676676678%): Data: 50.66666666666667%]:Running loss: 8.483235731720924
[2018-04-17 20:43:56.775202]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:43:56.899533]: ====================
[2018-04-17 20:43:56.905047]: Elapsed time since starting training: 1:23:23.069678
[2018-04-17 20:43:56.910061]: Estimated time left: -1 day, 23:51:36.925308
[2018-04-17 20:43:56.915075]: ====================
[2018-04-17 20:43:56.985763]: [Epoch: 668(66.86686686686687%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:43:58.319308]: [Epoch: 668(66.86686686686687%): Data: 25.333333333333336%]:Running loss: 4.3503774255514145
[2018-04-17 20:43:59.625280]: [Epoch: 668(66.86686686686687%): Data: 50.66666666666667%]:Running loss: 8.483234241604805
[2018-04-17 20:44:03.308575]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:44:03.432404]: ====================
[2018-04-17 20:44:03.437919]: Elapsed time since starting training: 1:23:29.602048
[2018-04-17 20:44:03.442932]: Estimated time left: -1 day, 23:51:30.392437
[2018-04-17 20:44:03.447945]: ====================
[2018-04-17 20:44:03.521140]: [Epoch: 669(66.96696696696696%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:44:04.832126]: [Epoch: 669(66.96696696696696%): Data: 25.333333333333336%]:Running loss: 4.350377231836319
[2018-04-17 20:44:06.133085]: [Epoch: 669(66.96696696696696%): Data: 50.66666666666667%]:Running loss: 8.483233720064163
[2018-04-17 20:44:09.765243]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:44:09.907121]: ====================
[2018-04-17 20:44:09.912635]: Elapsed time since starting training: 1:23:36.076765
[2018-04-17 20:44:09.916645]: Estimated time left: -1 day, 23:51:23.918724
[2018-04-17 20:44:09.922661]: ====================
[2018-04-17 20:44:09.994352]: [Epoch: 670(67.06706706706707%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:44:11.352964]: [Epoch: 670(67.06706706706707%): Data: 25.333333333333336%]:Running loss: 4.350375458598137
[2018-04-17 20:44:12.682500]: [Epoch: 670(67.06706706706707%): Data: 50.66666666666667%]:Running loss: 8.483232229948044
[2018-04-17 20:44:16.464055]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:44:16.603425]: ====================
[2018-04-17 20:44:16.608439]: Elapsed time since starting training: 1:23:42.773070
[2018-04-17 20:44:16.612449]: Estimated time left: -1 day, 23:51:17.222920
[2018-04-17 20:44:16.617463]: ====================
[2018-04-17 20:44:16.685143]: [Epoch: 671(67.16716716716716%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:44:17.979584]: [Epoch: 671(67.16716716716716%): Data: 25.333333333333336%]:Running loss: 4.350374847650528
[2018-04-17 20:44:19.294588]: [Epoch: 671(67.16716716716716%): Data: 50.66666666666667%]:Running loss: 8.483233943581581
[2018-04-17 20:44:22.954314]: Test set accuracy: 94.33962264150944% ,loss = 5.437975376844406
[2018-04-17 20:44:23.094185]: ====================
[2018-04-17 20:44:23.098696]: Elapsed time since starting training: 1:23:49.263327
[2018-04-17 20:44:23.103709]: Estimated time left: -1 day, 23:51:10.731660
[2018-04-17 20:44:23.109725]: ====================
[2018-04-17 20:44:23.178910]: [Epoch: 672(67.26726726726727%): Data: 0.0%]:Running loss: 0.21751901507377625
[2018-04-17 20:44:24.487389]: [Epoch: 672(67.26726726726727%): Data: 25.333333333333336%]:Running loss: 4.35037325322628
[2018-04-17 20:44:25.768796]: [Epoch: 672(67.26726726726727%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 20:44:29.429530]: Test set accuracy: 94.33962264150944% ,loss = 5.437972769141197
[2018-04-17 20:44:29.579930]: ====================
[2018-04-17 20:44:29.587451]: Elapsed time since starting training: 1:23:55.752082
[2018-04-17 20:44:29.592965]: Estimated time left: -1 day, 23:51:04.242404
[2018-04-17 20:44:29.597477]: ====================
[2018-04-17 20:44:29.673178]: [Epoch: 673(67.36736736736736%): Data: 0.0%]:Running loss: 0.2175189107656479
[2018-04-17 20:44:30.995193]: [Epoch: 673(67.36736736736736%): Data: 25.333333333333336%]:Running loss: 4.350373923778534
[2018-04-17 20:44:32.331747]: [Epoch: 673(67.36736736736736%): Data: 50.66666666666667%]:Running loss: 8.483231008052826
[2018-04-17 20:44:35.994486]: Test set accuracy: 94.33962264150944% ,loss = 5.437972769141197
[2018-04-17 20:44:36.126337]: ====================
[2018-04-17 20:44:36.131851]: Elapsed time since starting training: 1:24:02.296482
[2018-04-17 20:44:36.136865]: Estimated time left: -1 day, 23:50:57.698504
[2018-04-17 20:44:36.142379]: ====================
[2018-04-17 20:44:36.213569]: [Epoch: 674(67.46746746746747%): Data: 0.0%]:Running loss: 0.2175189107656479
[2018-04-17 20:44:37.525056]: [Epoch: 674(67.46746746746747%): Data: 25.333333333333336%]:Running loss: 4.3503770381212234
[2018-04-17 20:44:38.816997]: [Epoch: 674(67.46746746746747%): Data: 50.66666666666667%]:Running loss: 8.483233764767647
[2018-04-17 20:44:42.520338]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 20:44:42.678760]: ====================
[2018-04-17 20:44:42.683773]: Elapsed time since starting training: 1:24:08.848404
[2018-04-17 20:44:42.688786]: Estimated time left: -1 day, 23:50:51.146583
[2018-04-17 20:44:42.693800]: ====================
[2018-04-17 20:44:42.767495]: [Epoch: 675(67.56756756756756%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 20:44:44.072465]: [Epoch: 675(67.56756756756756%): Data: 25.333333333333336%]:Running loss: 4.350376382470131
[2018-04-17 20:44:45.411526]: [Epoch: 675(67.56756756756756%): Data: 50.66666666666667%]:Running loss: 8.483231201767921
[2018-04-17 20:44:49.142447]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 20:44:49.281817]: ====================
[2018-04-17 20:44:49.287332]: Elapsed time since starting training: 1:24:15.451461
[2018-04-17 20:44:49.292345]: Estimated time left: -1 day, 23:50:44.543525
[2018-04-17 20:44:49.296857]: ====================
[2018-04-17 20:44:49.372057]: [Epoch: 676(67.66766766766766%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 20:44:50.685549]: [Epoch: 676(67.66766766766766%): Data: 25.333333333333336%]:Running loss: 4.350377082824707
[2018-04-17 20:44:51.992524]: [Epoch: 676(67.66766766766766%): Data: 50.66666666666667%]:Running loss: 8.483231902122498
[2018-04-17 20:44:55.694869]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:44:55.824715]: ====================
[2018-04-17 20:44:55.829728]: Elapsed time since starting training: 1:24:21.993858
[2018-04-17 20:44:55.834741]: Estimated time left: -1 day, 23:50:38.000628
[2018-04-17 20:44:55.840256]: ====================
[2018-04-17 20:44:55.914955]: [Epoch: 677(67.76776776776778%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:44:57.232458]: [Epoch: 677(67.76776776776778%): Data: 25.333333333333336%]:Running loss: 4.350376158952713
[2018-04-17 20:44:58.567507]: [Epoch: 677(67.76776776776778%): Data: 50.66666666666667%]:Running loss: 8.483233213424683
[2018-04-17 20:45:02.337532]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:45:02.480914]: ====================
[2018-04-17 20:45:02.485927]: Elapsed time since starting training: 1:24:28.650558
[2018-04-17 20:45:02.490940]: Estimated time left: -1 day, 23:50:31.344429
[2018-04-17 20:45:02.496454]: ====================
[2018-04-17 20:45:02.567154]: [Epoch: 678(67.86786786786787%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:45:03.860582]: [Epoch: 678(67.86786786786787%): Data: 25.333333333333336%]:Running loss: 4.350374981760979
[2018-04-17 20:45:05.147504]: [Epoch: 678(67.86786786786787%): Data: 50.66666666666667%]:Running loss: 8.48323230445385
[2018-04-17 20:45:08.829294]: Test set accuracy: 94.33962264150944% ,loss = 5.437976121902466
[2018-04-17 20:45:08.960643]: ====================
[2018-04-17 20:45:08.965656]: Elapsed time since starting training: 1:24:35.130287
[2018-04-17 20:45:08.970670]: Estimated time left: -1 day, 23:50:24.865201
[2018-04-17 20:45:08.976185]: ====================
[2018-04-17 20:45:09.046371]: [Epoch: 679(67.96796796796797%): Data: 0.0%]:Running loss: 0.21751904487609863
[2018-04-17 20:45:10.505752]: [Epoch: 679(67.96796796796797%): Data: 25.333333333333336%]:Running loss: 4.350374460220337
[2018-04-17 20:45:11.844311]: [Epoch: 679(67.96796796796797%): Data: 50.66666666666667%]:Running loss: 8.483231723308563
[2018-04-17 20:45:15.409791]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:45:15.559690]: ====================
[2018-04-17 20:45:15.564202]: Elapsed time since starting training: 1:24:41.728833
[2018-04-17 20:45:15.569717]: Estimated time left: -1 day, 23:50:18.266154
[2018-04-17 20:45:15.574730]: ====================
[2018-04-17 20:45:15.645919]: [Epoch: 680(68.06806806806807%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:45:16.939869]: [Epoch: 680(68.06806806806807%): Data: 25.333333333333336%]:Running loss: 4.3503736555576324
[2018-04-17 20:45:18.227283]: [Epoch: 680(68.06806806806807%): Data: 50.66666666666667%]:Running loss: 8.483231365680695
[2018-04-17 20:45:21.794267]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:45:21.927121]: ====================
[2018-04-17 20:45:21.932635]: Elapsed time since starting training: 1:24:48.097266
[2018-04-17 20:45:21.937147]: Estimated time left: -1 day, 23:50:11.898222
[2018-04-17 20:45:21.942662]: ====================
[2018-04-17 20:45:22.013350]: [Epoch: 681(68.16816816816817%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:45:23.282726]: [Epoch: 681(68.16816816816817%): Data: 25.333333333333336%]:Running loss: 4.3503769636154175
[2018-04-17 20:45:24.641839]: [Epoch: 681(68.16816816816817%): Data: 50.66666666666667%]:Running loss: 8.483233392238617
[2018-04-17 20:45:28.288034]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:45:28.435426]: ====================
[2018-04-17 20:45:28.439938]: Elapsed time since starting training: 1:24:54.604569
[2018-04-17 20:45:28.444450]: Estimated time left: -1 day, 23:50:05.391420
[2018-04-17 20:45:28.447960]: ====================
[2018-04-17 20:45:28.516141]: [Epoch: 682(68.26826826826827%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:45:29.787521]: [Epoch: 682(68.26826826826827%): Data: 25.333333333333336%]:Running loss: 4.350376337766647
[2018-04-17 20:45:31.049878]: [Epoch: 682(68.26826826826827%): Data: 50.66666666666667%]:Running loss: 8.483232259750366
[2018-04-17 20:45:34.637417]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:45:34.774784]: ====================
[2018-04-17 20:45:34.780298]: Elapsed time since starting training: 1:25:00.944427
[2018-04-17 20:45:34.785311]: Estimated time left: -1 day, 23:49:59.050058
[2018-04-17 20:45:34.790324]: ====================
[2018-04-17 20:45:34.861513]: [Epoch: 683(68.36836836836837%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:45:36.117854]: [Epoch: 683(68.36836836836837%): Data: 25.333333333333336%]:Running loss: 4.350377053022385
[2018-04-17 20:45:37.382721]: [Epoch: 683(68.36836836836837%): Data: 50.66666666666667%]:Running loss: 8.483231276273727
[2018-04-17 20:45:40.972763]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:45:41.115142]: ====================
[2018-04-17 20:45:41.121160]: Elapsed time since starting training: 1:25:07.285288
[2018-04-17 20:45:41.127675]: Estimated time left: -1 day, 23:49:52.707694
[2018-04-17 20:45:41.133189]: ====================
[2018-04-17 20:45:41.202374]: [Epoch: 684(68.46846846846847%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:45:42.491802]: [Epoch: 684(68.46846846846847%): Data: 25.333333333333336%]:Running loss: 4.350376322865486
[2018-04-17 20:45:43.779225]: [Epoch: 684(68.46846846846847%): Data: 50.66666666666667%]:Running loss: 8.483234152197838
[2018-04-17 20:45:47.342199]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:45:47.472546]: ====================
[2018-04-17 20:45:47.477559]: Elapsed time since starting training: 1:25:13.642190
[2018-04-17 20:45:47.482573]: Estimated time left: -1 day, 23:49:46.353298
[2018-04-17 20:45:47.487085]: ====================
[2018-04-17 20:45:47.559276]: [Epoch: 685(68.56856856856857%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:45:48.814113]: [Epoch: 685(68.56856856856857%): Data: 25.333333333333336%]:Running loss: 4.350374683737755
[2018-04-17 20:45:50.112064]: [Epoch: 685(68.56856856856857%): Data: 50.66666666666667%]:Running loss: 8.48322968184948
[2018-04-17 20:45:53.667518]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:45:53.794356]: ====================
[2018-04-17 20:45:53.799870]: Elapsed time since starting training: 1:25:19.963999
[2018-04-17 20:45:53.804883]: Estimated time left: -1 day, 23:49:40.030486
[2018-04-17 20:45:53.810398]: ====================
[2018-04-17 20:45:53.881086]: [Epoch: 686(68.66866866866866%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:45:55.160989]: [Epoch: 686(68.66866866866866%): Data: 25.333333333333336%]:Running loss: 4.350374191999435
[2018-04-17 20:45:56.434876]: [Epoch: 686(68.66866866866866%): Data: 50.66666666666667%]:Running loss: 8.483232006430626
[2018-04-17 20:45:59.973786]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 20:46:00.102629]: ====================
[2018-04-17 20:46:00.107141]: Elapsed time since starting training: 1:25:26.271772
[2018-04-17 20:46:00.111654]: Estimated time left: -1 day, 23:49:33.723715
[2018-04-17 20:46:00.116165]: ====================
[2018-04-17 20:46:00.188358]: [Epoch: 687(68.76876876876878%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 20:46:01.476782]: [Epoch: 687(68.76876876876878%): Data: 25.333333333333336%]:Running loss: 4.350372269749641
[2018-04-17 20:46:02.742657]: [Epoch: 687(68.76876876876878%): Data: 50.66666666666667%]:Running loss: 8.483229950070381
[2018-04-17 20:46:06.337206]: Test set accuracy: 94.33962264150944% ,loss = 5.4379720240831375
[2018-04-17 20:46:06.474573]: ====================
[2018-04-17 20:46:06.479585]: Elapsed time since starting training: 1:25:32.644216
[2018-04-17 20:46:06.484598]: Estimated time left: -1 day, 23:49:27.350771
[2018-04-17 20:46:06.490113]: ====================
[2018-04-17 20:46:06.562305]: [Epoch: 688(68.86886886886887%): Data: 0.0%]:Running loss: 0.2175188809633255
[2018-04-17 20:46:07.846720]: [Epoch: 688(68.86886886886887%): Data: 25.333333333333336%]:Running loss: 4.350374817848206
[2018-04-17 20:46:09.096543]: [Epoch: 688(68.86886886886887%): Data: 50.66666666666667%]:Running loss: 8.483231291174889
[2018-04-17 20:46:12.738728]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:46:12.870078]: ====================
[2018-04-17 20:46:12.876094]: Elapsed time since starting training: 1:25:39.040725
[2018-04-17 20:46:12.881608]: Estimated time left: -1 day, 23:49:20.953761
[2018-04-17 20:46:12.886120]: ====================
[2018-04-17 20:46:12.955304]: [Epoch: 689(68.96896896896897%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:46:14.255762]: [Epoch: 689(68.96896896896897%): Data: 25.333333333333336%]:Running loss: 4.350375518202782
[2018-04-17 20:46:15.545691]: [Epoch: 689(68.96896896896897%): Data: 50.66666666666667%]:Running loss: 8.483231171965599
[2018-04-17 20:46:19.032964]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:46:19.159802]: ====================
[2018-04-17 20:46:19.165317]: Elapsed time since starting training: 1:25:45.329948
[2018-04-17 20:46:19.170330]: Estimated time left: -1 day, 23:49:14.665541
[2018-04-17 20:46:19.174842]: ====================
[2018-04-17 20:46:19.244027]: [Epoch: 690(69.06906906906907%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:46:20.502371]: [Epoch: 690(69.06906906906907%): Data: 25.333333333333336%]:Running loss: 4.3503755033016205
[2018-04-17 20:46:21.758712]: [Epoch: 690(69.06906906906907%): Data: 50.66666666666667%]:Running loss: 8.483229607343674
[2018-04-17 20:46:25.485622]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:46:25.625494]: ====================
[2018-04-17 20:46:25.631009]: Elapsed time since starting training: 1:25:51.795640
[2018-04-17 20:46:25.636535]: Estimated time left: -1 day, 23:49:08.199347
[2018-04-17 20:46:25.641536]: ====================
[2018-04-17 20:46:25.710726]: [Epoch: 691(69.16916916916917%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:46:26.984615]: [Epoch: 691(69.16916916916917%): Data: 25.333333333333336%]:Running loss: 4.350375980138779
[2018-04-17 20:46:28.236437]: [Epoch: 691(69.16916916916917%): Data: 50.66666666666667%]:Running loss: 8.483231261372566
[2018-04-17 20:46:31.766323]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 20:46:31.892658]: ====================
[2018-04-17 20:46:31.896669]: Elapsed time since starting training: 1:25:58.061300
[2018-04-17 20:46:31.900680]: Estimated time left: -1 day, 23:49:01.934689
[2018-04-17 20:46:31.905192]: ====================
[2018-04-17 20:46:31.977386]: [Epoch: 692(69.26926926926927%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 20:46:33.245255]: [Epoch: 692(69.26926926926927%): Data: 25.333333333333336%]:Running loss: 4.350373610854149
[2018-04-17 20:46:34.542204]: [Epoch: 692(69.26926926926927%): Data: 50.66666666666667%]:Running loss: 8.48323056101799
[2018-04-17 20:46:38.121220]: Test set accuracy: 94.33962264150944% ,loss = 5.437972769141197
[2018-04-17 20:46:38.248559]: ====================
[2018-04-17 20:46:38.253071]: Elapsed time since starting training: 1:26:04.417702
[2018-04-17 20:46:38.258084]: Estimated time left: -1 day, 23:48:55.577786
[2018-04-17 20:46:38.265103]: ====================
[2018-04-17 20:46:38.351332]: [Epoch: 693(69.36936936936937%): Data: 0.0%]:Running loss: 0.2175189107656479
[2018-04-17 20:46:39.624719]: [Epoch: 693(69.36936936936937%): Data: 25.333333333333336%]:Running loss: 4.350374236702919
[2018-04-17 20:46:40.891085]: [Epoch: 693(69.36936936936937%): Data: 50.66666666666667%]:Running loss: 8.48323069512844
[2018-04-17 20:46:44.426987]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:46:44.557334]: ====================
[2018-04-17 20:46:44.562347]: Elapsed time since starting training: 1:26:10.726477
[2018-04-17 20:46:44.566859]: Estimated time left: -1 day, 23:48:49.268510
[2018-04-17 20:46:44.571872]: ====================
[2018-04-17 20:46:44.643563]: [Epoch: 694(69.46946946946947%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:46:45.901407]: [Epoch: 694(69.46946946946947%): Data: 25.333333333333336%]:Running loss: 4.350376829504967
[2018-04-17 20:46:47.187326]: [Epoch: 694(69.46946946946947%): Data: 50.66666666666667%]:Running loss: 8.483233377337456
[2018-04-17 20:46:50.708188]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:46:50.949330]: ====================
[2018-04-17 20:46:50.954343]: Elapsed time since starting training: 1:26:17.118473
[2018-04-17 20:46:50.958354]: Estimated time left: -1 day, 23:48:42.877015
[2018-04-17 20:46:50.963869]: ====================
[2018-04-17 20:46:51.032050]: [Epoch: 695(69.56956956956957%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:46:52.320476]: [Epoch: 695(69.56956956956957%): Data: 25.333333333333336%]:Running loss: 4.35037524998188
[2018-04-17 20:46:53.583835]: [Epoch: 695(69.56956956956957%): Data: 50.66666666666667%]:Running loss: 8.483228996396065
[2018-04-17 20:46:57.235043]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:46:57.381934]: ====================
[2018-04-17 20:46:57.387449]: Elapsed time since starting training: 1:26:23.552080
[2018-04-17 20:46:57.393465]: Estimated time left: -1 day, 23:48:36.442406
[2018-04-17 20:46:57.398980]: ====================
[2018-04-17 20:46:57.481198]: [Epoch: 696(69.66966966966966%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:46:58.765617]: [Epoch: 696(69.66966966966966%): Data: 25.333333333333336%]:Running loss: 4.350373834371567
[2018-04-17 20:47:00.050032]: [Epoch: 696(69.66966966966966%): Data: 50.66666666666667%]:Running loss: 8.483231514692307
[2018-04-17 20:47:03.613507]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 20:47:03.747363]: ====================
[2018-04-17 20:47:03.752376]: Elapsed time since starting training: 1:26:29.917007
[2018-04-17 20:47:03.757891]: Estimated time left: -1 day, 23:48:30.077478
[2018-04-17 20:47:03.763406]: ====================
[2018-04-17 20:47:03.836100]: [Epoch: 697(69.76976976976978%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 20:47:05.110496]: [Epoch: 697(69.76976976976978%): Data: 25.333333333333336%]:Running loss: 4.350372776389122
[2018-04-17 20:47:06.365325]: [Epoch: 697(69.76976976976978%): Data: 50.66666666666667%]:Running loss: 8.483228087425232
[2018-04-17 20:47:09.975925]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:47:10.098752]: ====================
[2018-04-17 20:47:10.103765]: Elapsed time since starting training: 1:26:36.267894
[2018-04-17 20:47:10.108277]: Estimated time left: -1 day, 23:48:23.727092
[2018-04-17 20:47:10.113291]: ====================
[2018-04-17 20:47:10.178464]: [Epoch: 698(69.86986986986987%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:47:11.522036]: [Epoch: 698(69.86986986986987%): Data: 25.333333333333336%]:Running loss: 4.350376531481743
[2018-04-17 20:47:12.801439]: [Epoch: 698(69.86986986986987%): Data: 50.66666666666667%]:Running loss: 8.483231380581856
[2018-04-17 20:47:16.430086]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:47:16.565948]: ====================
[2018-04-17 20:47:16.570961]: Elapsed time since starting training: 1:26:42.735592
[2018-04-17 20:47:16.575975]: Estimated time left: -1 day, 23:48:17.259895
[2018-04-17 20:47:16.581990]: ====================
[2018-04-17 20:47:16.651676]: [Epoch: 699(69.96996996996997%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:47:17.966171]: [Epoch: 699(69.96996996996997%): Data: 25.333333333333336%]:Running loss: 4.350373834371567
[2018-04-17 20:47:19.235547]: [Epoch: 699(69.96996996996997%): Data: 50.66666666666667%]:Running loss: 8.483227238059044
[2018-04-17 20:47:22.842136]: Test set accuracy: 94.33962264150944% ,loss = 5.437973886728287
[2018-04-17 20:47:22.968472]: ====================
[2018-04-17 20:47:22.973485]: Elapsed time since starting training: 1:26:49.138116
[2018-04-17 20:47:22.977997]: Estimated time left: -1 day, 23:48:10.857372
[2018-04-17 20:47:22.983011]: ====================
[2018-04-17 20:47:23.055203]: [Epoch: 700(70.07007007007007%): Data: 0.0%]:Running loss: 0.21751895546913147
[2018-04-17 20:47:24.325079]: [Epoch: 700(70.07007007007007%): Data: 25.333333333333336%]:Running loss: 4.35037337243557
[2018-04-17 20:47:25.612001]: [Epoch: 700(70.07007007007007%): Data: 50.66666666666667%]:Running loss: 8.483230516314507
[2018-04-17 20:47:29.209567]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:47:29.344426]: ====================
[2018-04-17 20:47:29.349940]: Elapsed time since starting training: 1:26:55.514070
[2018-04-17 20:47:29.354453]: Estimated time left: -1 day, 23:48:04.480916
[2018-04-17 20:47:29.358964]: ====================
[2018-04-17 20:47:29.429652]: [Epoch: 701(70.17017017017017%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:47:30.704041]: [Epoch: 701(70.17017017017017%): Data: 25.333333333333336%]:Running loss: 4.3503749668598175
[2018-04-17 20:47:31.984947]: [Epoch: 701(70.17017017017017%): Data: 50.66666666666667%]:Running loss: 8.483230262994766
[2018-04-17 20:47:35.667238]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:47:35.811122]: ====================
[2018-04-17 20:47:35.816645]: Elapsed time since starting training: 1:27:01.981276
[2018-04-17 20:47:35.821649]: Estimated time left: -1 day, 23:47:58.013720
[2018-04-17 20:47:35.827164]: ====================
[2018-04-17 20:47:35.894843]: [Epoch: 702(70.27027027027027%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:47:37.197307]: [Epoch: 702(70.27027027027027%): Data: 25.333333333333336%]:Running loss: 4.350375935435295
[2018-04-17 20:47:38.452143]: [Epoch: 702(70.27027027027027%): Data: 50.66666666666667%]:Running loss: 8.48322942852974
[2018-04-17 20:47:42.060738]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:47:42.195597]: ====================
[2018-04-17 20:47:42.202115]: Elapsed time since starting training: 1:27:08.366244
[2018-04-17 20:47:42.206627]: Estimated time left: -1 day, 23:47:51.628742
[2018-04-17 20:47:42.213645]: ====================
[2018-04-17 20:47:42.284834]: [Epoch: 703(70.37037037037037%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:47:43.575767]: [Epoch: 703(70.37037037037037%): Data: 25.333333333333336%]:Running loss: 4.350373730063438
[2018-04-17 20:47:44.893772]: [Epoch: 703(70.37037037037037%): Data: 50.66666666666667%]:Running loss: 8.48323205113411
[2018-04-17 20:47:48.517407]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 20:47:48.658282]: ====================
[2018-04-17 20:47:48.663295]: Elapsed time since starting training: 1:27:14.827424
[2018-04-17 20:47:48.667807]: Estimated time left: -1 day, 23:47:45.168064
[2018-04-17 20:47:48.671817]: ====================
[2018-04-17 20:47:48.745012]: [Epoch: 704(70.47047047047047%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 20:47:50.041960]: [Epoch: 704(70.47047047047047%): Data: 25.333333333333336%]:Running loss: 4.350372463464737
[2018-04-17 20:47:51.335901]: [Epoch: 704(70.47047047047047%): Data: 50.66666666666667%]:Running loss: 8.483228012919426
[2018-04-17 20:47:54.928955]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:47:55.060805]: ====================
[2018-04-17 20:47:55.066821]: Elapsed time since starting training: 1:27:21.231452
[2018-04-17 20:47:55.071835]: Estimated time left: -1 day, 23:47:38.763534
[2018-04-17 20:47:55.077349]: ====================
[2018-04-17 20:47:55.148037]: [Epoch: 705(70.57057057057057%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:47:56.435962]: [Epoch: 705(70.57057057057057%): Data: 25.333333333333336%]:Running loss: 4.350377157330513
[2018-04-17 20:47:57.760484]: [Epoch: 705(70.57057057057057%): Data: 50.66666666666667%]:Running loss: 8.483231082558632
[2018-04-17 20:48:01.368076]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:48:01.494413]: ====================
[2018-04-17 20:48:01.499426]: Elapsed time since starting training: 1:27:27.664057
[2018-04-17 20:48:01.504941]: Estimated time left: -1 day, 23:47:32.330930
[2018-04-17 20:48:01.509453]: ====================
[2018-04-17 20:48:01.577634]: [Epoch: 706(70.67067067067066%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:48:02.862054]: [Epoch: 706(70.67067067067066%): Data: 25.333333333333336%]:Running loss: 4.350374296307564
[2018-04-17 20:48:04.131430]: [Epoch: 706(70.67067067067066%): Data: 50.66666666666667%]:Running loss: 8.48322719335556
[2018-04-17 20:48:07.713453]: Test set accuracy: 94.33962264150944% ,loss = 5.437974631786346
[2018-04-17 20:48:07.839288]: ====================
[2018-04-17 20:48:07.844301]: Elapsed time since starting training: 1:27:34.008932
[2018-04-17 20:48:07.849315]: Estimated time left: -1 day, 23:47:25.986054
[2018-04-17 20:48:07.854830]: ====================
[2018-04-17 20:48:07.926019]: [Epoch: 707(70.77077077077078%): Data: 0.0%]:Running loss: 0.21751898527145386
[2018-04-17 20:48:09.198402]: [Epoch: 707(70.77077077077078%): Data: 25.333333333333336%]:Running loss: 4.350372537970543
[2018-04-17 20:48:10.426167]: [Epoch: 707(70.77077077077078%): Data: 50.66666666666667%]:Running loss: 8.483230143785477
[2018-04-17 20:48:13.992650]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:48:14.117983]: ====================
[2018-04-17 20:48:14.122996]: Elapsed time since starting training: 1:27:40.287627
[2018-04-17 20:48:14.127508]: Estimated time left: -1 day, 23:47:19.707861
[2018-04-17 20:48:14.132021]: ====================
[2018-04-17 20:48:14.198698]: [Epoch: 708(70.87087087087087%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:48:15.464564]: [Epoch: 708(70.87087087087087%): Data: 25.333333333333336%]:Running loss: 4.350374266505241
[2018-04-17 20:48:16.736445]: [Epoch: 708(70.87087087087087%): Data: 50.66666666666667%]:Running loss: 8.483228638768196
[2018-04-17 20:48:20.331509]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:48:20.458346]: ====================
[2018-04-17 20:48:20.462356]: Elapsed time since starting training: 1:27:46.626987
[2018-04-17 20:48:20.466869]: Estimated time left: -1 day, 23:47:13.368500
[2018-04-17 20:48:20.470880]: ====================
[2018-04-17 20:48:20.541568]: [Epoch: 709(70.97097097097097%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:48:21.801919]: [Epoch: 709(70.97097097097097%): Data: 25.333333333333336%]:Running loss: 4.3503763526678085
[2018-04-17 20:48:23.087337]: [Epoch: 709(70.97097097097097%): Data: 50.66666666666667%]:Running loss: 8.483229324221611
[2018-04-17 20:48:26.661340]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:48:26.797702]: ====================
[2018-04-17 20:48:26.803218]: Elapsed time since starting training: 1:27:52.967849
[2018-04-17 20:48:26.808733]: Estimated time left: -1 day, 23:47:07.027138
[2018-04-17 20:48:26.813745]: ====================
[2018-04-17 20:48:26.884935]: [Epoch: 710(71.07107107107107%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:48:28.169851]: [Epoch: 710(71.07107107107107%): Data: 25.333333333333336%]:Running loss: 4.350373074412346
[2018-04-17 20:48:29.441232]: [Epoch: 710(71.07107107107107%): Data: 50.66666666666667%]:Running loss: 8.483231738209724
[2018-04-17 20:48:32.963598]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 20:48:33.091437]: ====================
[2018-04-17 20:48:33.095448]: Elapsed time since starting training: 1:27:59.259578
[2018-04-17 20:48:33.099459]: Estimated time left: -1 day, 23:47:00.735910
[2018-04-17 20:48:33.103469]: ====================
[2018-04-17 20:48:33.178168]: [Epoch: 711(71.17117117117117%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 20:48:34.418967]: [Epoch: 711(71.17117117117117%): Data: 25.333333333333336%]:Running loss: 4.350372284650803
[2018-04-17 20:48:35.703884]: [Epoch: 711(71.17117117117117%): Data: 50.66666666666667%]:Running loss: 8.483228012919426
[2018-04-17 20:48:39.323007]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:48:39.454357]: ====================
[2018-04-17 20:48:39.459370]: Elapsed time since starting training: 1:28:05.624001
[2018-04-17 20:48:39.464885]: Estimated time left: -1 day, 23:46:54.370985
[2018-04-17 20:48:39.469397]: ====================
[2018-04-17 20:48:39.542090]: [Epoch: 712(71.27127127127127%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:48:40.847059]: [Epoch: 712(71.27127127127127%): Data: 25.333333333333336%]:Running loss: 4.3503758162260056
[2018-04-17 20:48:42.090366]: [Epoch: 712(71.27127127127127%): Data: 50.66666666666667%]:Running loss: 8.48322942852974
[2018-04-17 20:48:45.735057]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:48:45.860892]: ====================
[2018-04-17 20:48:45.865905]: Elapsed time since starting training: 1:28:12.030536
[2018-04-17 20:48:45.870918]: Estimated time left: -1 day, 23:46:47.964451
[2018-04-17 20:48:45.875932]: ====================
[2018-04-17 20:48:45.947622]: [Epoch: 713(71.37137137137137%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:48:47.224517]: [Epoch: 713(71.37137137137137%): Data: 25.333333333333336%]:Running loss: 4.35037437081337
[2018-04-17 20:48:48.508932]: [Epoch: 713(71.37137137137137%): Data: 50.66666666666667%]:Running loss: 8.483227416872978
[2018-04-17 20:48:52.111013]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:48:52.244368]: ====================
[2018-04-17 20:48:52.248879]: Elapsed time since starting training: 1:28:18.413510
[2018-04-17 20:48:52.253392]: Estimated time left: -1 day, 23:46:41.581977
[2018-04-17 20:48:52.258405]: ====================
[2018-04-17 20:48:52.330598]: [Epoch: 714(71.47147147147147%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:48:53.655118]: [Epoch: 714(71.47147147147147%): Data: 25.333333333333336%]:Running loss: 4.350372076034546
[2018-04-17 20:48:54.924496]: [Epoch: 714(71.47147147147147%): Data: 50.66666666666667%]:Running loss: 8.483229830861092
[2018-04-17 20:48:58.531586]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 20:48:58.678977]: ====================
[2018-04-17 20:48:58.685996]: Elapsed time since starting training: 1:28:24.850627
[2018-04-17 20:48:58.691009]: Estimated time left: -1 day, 23:46:35.144360
[2018-04-17 20:48:58.695521]: ====================
[2018-04-17 20:48:58.772225]: [Epoch: 715(71.57157157157157%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 20:49:00.074187]: [Epoch: 715(71.57157157157157%): Data: 25.333333333333336%]:Running loss: 4.350374415516853
[2018-04-17 20:49:01.357600]: [Epoch: 715(71.57157157157157%): Data: 50.66666666666667%]:Running loss: 8.48322893679142
[2018-04-17 20:49:04.967710]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:49:05.113598]: ====================
[2018-04-17 20:49:05.121619]: Elapsed time since starting training: 1:28:31.286250
[2018-04-17 20:49:05.126131]: Estimated time left: -1 day, 23:46:28.709238
[2018-04-17 20:49:05.130643]: ====================
[2018-04-17 20:49:05.200328]: [Epoch: 716(71.67167167167166%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:49:06.489256]: [Epoch: 716(71.67167167167166%): Data: 25.333333333333336%]:Running loss: 4.350376486778259
[2018-04-17 20:49:07.772168]: [Epoch: 716(71.67167167167166%): Data: 50.66666666666667%]:Running loss: 8.483229547739029
[2018-04-17 20:49:11.397306]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 20:49:11.527654]: ====================
[2018-04-17 20:49:11.533168]: Elapsed time since starting training: 1:28:37.697298
[2018-04-17 20:49:11.538182]: Estimated time left: -1 day, 23:46:22.297187
[2018-04-17 20:49:11.543194]: ====================
[2018-04-17 20:49:11.614884]: [Epoch: 717(71.77177177177178%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 20:49:12.904814]: [Epoch: 717(71.77177177177178%): Data: 25.333333333333336%]:Running loss: 4.3503731191158295
[2018-04-17 20:49:14.205774]: [Epoch: 717(71.77177177177178%): Data: 50.66666666666667%]:Running loss: 8.483227282762527
[2018-04-17 20:49:17.798326]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 20:49:17.925666]: ====================
[2018-04-17 20:49:17.931180]: Elapsed time since starting training: 1:28:44.095309
[2018-04-17 20:49:17.936193]: Estimated time left: -1 day, 23:46:15.899176
[2018-04-17 20:49:17.940705]: ====================
[2018-04-17 20:49:18.010391]: [Epoch: 718(71.87187187187187%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 20:49:19.289793]: [Epoch: 718(71.87187187187187%): Data: 25.333333333333336%]:Running loss: 4.350371927022934
[2018-04-17 20:49:20.581227]: [Epoch: 718(71.87187187187187%): Data: 50.66666666666667%]:Running loss: 8.483227729797363
[2018-04-17 20:49:24.216893]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:49:24.356766]: ====================
[2018-04-17 20:49:24.361779]: Elapsed time since starting training: 1:28:50.526410
[2018-04-17 20:49:24.367795]: Estimated time left: -1 day, 23:46:09.468075
[2018-04-17 20:49:24.372307]: ====================
[2018-04-17 20:49:24.442493]: [Epoch: 719(71.97197197197197%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:49:25.759500]: [Epoch: 719(71.97197197197197%): Data: 25.333333333333336%]:Running loss: 4.35037337243557
[2018-04-17 20:49:27.059456]: [Epoch: 719(71.97197197197197%): Data: 50.66666666666667%]:Running loss: 8.483226522803307
[2018-04-17 20:49:30.649503]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:49:30.810431]: ====================
[2018-04-17 20:49:30.815946]: Elapsed time since starting training: 1:28:56.980577
[2018-04-17 20:49:30.821460]: Estimated time left: -1 day, 23:46:03.013909
[2018-04-17 20:49:30.826474]: ====================
[2018-04-17 20:49:30.901172]: [Epoch: 720(72.07207207207207%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:49:32.212659]: [Epoch: 720(72.07207207207207%): Data: 25.333333333333336%]:Running loss: 4.350374519824982
[2018-04-17 20:49:33.496573]: [Epoch: 720(72.07207207207207%): Data: 50.66666666666667%]:Running loss: 8.483227133750916
[2018-04-17 20:49:37.195408]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:49:37.362853]: ====================
[2018-04-17 20:49:37.367867]: Elapsed time since starting training: 1:29:03.532498
[2018-04-17 20:49:37.373382]: Estimated time left: -1 day, 23:45:56.461987
[2018-04-17 20:49:37.378404]: ====================
[2018-04-17 20:49:37.453094]: [Epoch: 721(72.17217217217218%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:49:38.695898]: [Epoch: 721(72.17217217217218%): Data: 25.333333333333336%]:Running loss: 4.350371569395065
[2018-04-17 20:49:39.985327]: [Epoch: 721(72.17217217217218%): Data: 50.66666666666667%]:Running loss: 8.483229205012321
[2018-04-17 20:49:43.512205]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:49:43.654584]: ====================
[2018-04-17 20:49:43.659597]: Elapsed time since starting training: 1:29:09.823727
[2018-04-17 20:49:43.664109]: Estimated time left: -1 day, 23:45:50.171260
[2018-04-17 20:49:43.669122]: ====================
[2018-04-17 20:49:43.738807]: [Epoch: 722(72.27227227227228%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:49:45.029238]: [Epoch: 722(72.27227227227228%): Data: 25.333333333333336%]:Running loss: 4.3503747433424
[2018-04-17 20:49:46.320171]: [Epoch: 722(72.27227227227228%): Data: 50.66666666666667%]:Running loss: 8.483229354023933
[2018-04-17 20:49:49.929775]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:49:50.048591]: ====================
[2018-04-17 20:49:50.054106]: Elapsed time since starting training: 1:29:16.218235
[2018-04-17 20:49:50.058618]: Estimated time left: -1 day, 23:45:43.776751
[2018-04-17 20:49:50.063631]: ====================
[2018-04-17 20:49:50.129807]: [Epoch: 723(72.37237237237237%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:49:51.408206]: [Epoch: 723(72.37237237237237%): Data: 25.333333333333336%]:Running loss: 4.350376278162003
[2018-04-17 20:49:52.706659]: [Epoch: 723(72.37237237237237%): Data: 50.66666666666667%]:Running loss: 8.483229354023933
[2018-04-17 20:49:56.316256]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:49:56.449611]: ====================
[2018-04-17 20:49:56.455628]: Elapsed time since starting training: 1:29:22.620259
[2018-04-17 20:49:56.460641]: Estimated time left: -1 day, 23:45:37.374728
[2018-04-17 20:49:56.466656]: ====================
[2018-04-17 20:49:56.540855]: [Epoch: 724(72.47247247247248%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:49:57.824768]: [Epoch: 724(72.47247247247248%): Data: 25.333333333333336%]:Running loss: 4.350373208522797
[2018-04-17 20:49:59.093141]: [Epoch: 724(72.47247247247248%): Data: 50.66666666666667%]:Running loss: 8.483228281140327
[2018-04-17 20:50:02.796487]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 20:50:02.942376]: ====================
[2018-04-17 20:50:02.947389]: Elapsed time since starting training: 1:29:29.111519
[2018-04-17 20:50:02.952402]: Estimated time left: -1 day, 23:45:30.882967
[2018-04-17 20:50:02.957917]: ====================
[2018-04-17 20:50:03.027101]: [Epoch: 725(72.57257257257257%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 20:50:04.319547]: [Epoch: 725(72.57257257257257%): Data: 25.333333333333336%]:Running loss: 4.350372239947319
[2018-04-17 20:50:05.622000]: [Epoch: 725(72.57257257257257%): Data: 50.66666666666667%]:Running loss: 8.483228027820587
[2018-04-17 20:50:09.318830]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:50:09.441657]: ====================
[2018-04-17 20:50:09.446670]: Elapsed time since starting training: 1:29:35.611301
[2018-04-17 20:50:09.452185]: Estimated time left: -1 day, 23:45:24.383184
[2018-04-17 20:50:09.457198]: ====================
[2018-04-17 20:50:09.530895]: [Epoch: 726(72.67267267267268%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:50:10.846392]: [Epoch: 726(72.67267267267268%): Data: 25.333333333333336%]:Running loss: 4.35037399828434
[2018-04-17 20:50:12.135320]: [Epoch: 726(72.67267267267268%): Data: 50.66666666666667%]:Running loss: 8.483226835727692
[2018-04-17 20:50:15.701301]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:50:15.851701]: ====================
[2018-04-17 20:50:15.857717]: Elapsed time since starting training: 1:29:42.022348
[2018-04-17 20:50:15.862229]: Estimated time left: -1 day, 23:45:17.973140
[2018-04-17 20:50:15.866741]: ====================
[2018-04-17 20:50:15.944949]: [Epoch: 727(72.77277277277278%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:50:17.208308]: [Epoch: 727(72.77277277277278%): Data: 25.333333333333336%]:Running loss: 4.350374206900597
[2018-04-17 20:50:18.521299]: [Epoch: 727(72.77277277277278%): Data: 50.66666666666667%]:Running loss: 8.483227580785751
[2018-04-17 20:50:22.173009]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 20:50:22.311878]: ====================
[2018-04-17 20:50:22.317394]: Elapsed time since starting training: 1:29:48.481523
[2018-04-17 20:50:22.324913]: Estimated time left: -1 day, 23:45:11.510456
[2018-04-17 20:50:22.330930]: ====================
[2018-04-17 20:50:22.401618]: [Epoch: 728(72.87287287287288%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 20:50:23.685531]: [Epoch: 728(72.87287287287288%): Data: 25.333333333333336%]:Running loss: 4.350371107459068
[2018-04-17 20:50:24.950395]: [Epoch: 728(72.87287287287288%): Data: 50.66666666666667%]:Running loss: 8.483225852251053
[2018-04-17 20:50:28.524398]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:50:28.660761]: ====================
[2018-04-17 20:50:28.666276]: Elapsed time since starting training: 1:29:54.830907
[2018-04-17 20:50:28.671289]: Estimated time left: -1 day, 23:45:05.164080
[2018-04-17 20:50:28.676803]: ====================
[2018-04-17 20:50:28.747992]: [Epoch: 729(72.97297297297297%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:50:30.016866]: [Epoch: 729(72.97297297297297%): Data: 25.333333333333336%]:Running loss: 4.350375220179558
[2018-04-17 20:50:31.285740]: [Epoch: 729(72.97297297297297%): Data: 50.66666666666667%]:Running loss: 8.483229473233223
[2018-04-17 20:50:34.840191]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:50:35.074314]: ====================
[2018-04-17 20:50:35.079327]: Elapsed time since starting training: 1:30:01.243457
[2018-04-17 20:50:35.083840]: Estimated time left: -1 day, 23:44:58.751529
[2018-04-17 20:50:35.088853]: ====================
[2018-04-17 20:50:35.159039]: [Epoch: 730(73.07307307307308%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:50:36.416383]: [Epoch: 730(73.07307307307308%): Data: 25.333333333333336%]:Running loss: 4.350374057888985
[2018-04-17 20:50:37.696787]: [Epoch: 730(73.07307307307308%): Data: 50.66666666666667%]:Running loss: 8.483225658535957
[2018-04-17 20:50:41.113879]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 20:50:41.221665]: ====================
[2018-04-17 20:50:41.226679]: Elapsed time since starting training: 1:30:07.391310
[2018-04-17 20:50:41.231692]: Estimated time left: -1 day, 23:44:52.603677
[2018-04-17 20:50:41.237207]: ====================
[2018-04-17 20:50:41.305889]: [Epoch: 731(73.17317317317318%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 20:50:42.584790]: [Epoch: 731(73.17317317317318%): Data: 25.333333333333336%]:Running loss: 4.350372672080994
[2018-04-17 20:50:43.846144]: [Epoch: 731(73.17317317317318%): Data: 50.66666666666667%]:Running loss: 8.483228743076324
[2018-04-17 20:50:47.432179]: Test set accuracy: 94.33962264150944% ,loss = 5.437958613038063
[2018-04-17 20:50:47.551998]: ====================
[2018-04-17 20:50:47.556510]: Elapsed time since starting training: 1:30:13.721141
[2018-04-17 20:50:47.561022]: Estimated time left: -1 day, 23:44:46.274347
[2018-04-17 20:50:47.566537]: ====================
[2018-04-17 20:50:47.643241]: [Epoch: 732(73.27327327327328%): Data: 0.0%]:Running loss: 0.21751834452152252
[2018-04-17 20:50:48.921139]: [Epoch: 732(73.27327327327328%): Data: 25.333333333333336%]:Running loss: 4.350369542837143
[2018-04-17 20:50:50.198034]: [Epoch: 732(73.27327327327328%): Data: 50.66666666666667%]:Running loss: 8.483224838972092
[2018-04-17 20:50:53.803622]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:50:53.941487]: ====================
[2018-04-17 20:50:53.947002]: Elapsed time since starting training: 1:30:20.111132
[2018-04-17 20:50:53.952015]: Estimated time left: -1 day, 23:44:39.883855
[2018-04-17 20:50:53.957028]: ====================
[2018-04-17 20:50:54.035237]: [Epoch: 733(73.37337337337337%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:50:55.285061]: [Epoch: 733(73.37337337337337%): Data: 25.333333333333336%]:Running loss: 4.35037499666214
[2018-04-17 20:50:56.572985]: [Epoch: 733(73.37337337337337%): Data: 50.66666666666667%]:Running loss: 8.483227118849754
[2018-04-17 20:51:00.184087]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:51:00.316940]: ====================
[2018-04-17 20:51:00.322454]: Elapsed time since starting training: 1:30:26.487085
[2018-04-17 20:51:00.327468]: Estimated time left: -1 day, 23:44:33.508403
[2018-04-17 20:51:00.331980]: ====================
[2018-04-17 20:51:00.414700]: [Epoch: 734(73.47347347347348%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:51:01.724683]: [Epoch: 734(73.47347347347348%): Data: 25.333333333333336%]:Running loss: 4.350373730063438
[2018-04-17 20:51:02.998570]: [Epoch: 734(73.47347347347348%): Data: 50.66666666666667%]:Running loss: 8.48322819173336
[2018-04-17 20:51:06.617192]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 20:51:06.755560]: ====================
[2018-04-17 20:51:06.760573]: Elapsed time since starting training: 1:30:32.925204
[2018-04-17 20:51:06.765586]: Estimated time left: -1 day, 23:44:27.069783
[2018-04-17 20:51:06.770600]: ====================
[2018-04-17 20:51:06.842792]: [Epoch: 735(73.57357357357357%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 20:51:08.109660]: [Epoch: 735(73.57357357357357%): Data: 25.333333333333336%]:Running loss: 4.3503701984882355
[2018-04-17 20:51:09.386555]: [Epoch: 735(73.57357357357357%): Data: 50.66666666666667%]:Running loss: 8.483226090669632
[2018-04-17 20:51:13.052804]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:51:13.179140]: ====================
[2018-04-17 20:51:13.183652]: Elapsed time since starting training: 1:30:39.348283
[2018-04-17 20:51:13.188164]: Estimated time left: -1 day, 23:44:20.647205
[2018-04-17 20:51:13.192175]: ====================
[2018-04-17 20:51:13.270385]: [Epoch: 736(73.67367367367368%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:51:14.554798]: [Epoch: 736(73.67367367367368%): Data: 25.333333333333336%]:Running loss: 4.35037599503994
[2018-04-17 20:51:15.855757]: [Epoch: 736(73.67367367367368%): Data: 50.66666666666667%]:Running loss: 8.48322980105877
[2018-04-17 20:51:19.524011]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:51:19.656865]: ====================
[2018-04-17 20:51:19.662379]: Elapsed time since starting training: 1:30:45.827010
[2018-04-17 20:51:19.666891]: Estimated time left: -1 day, 23:44:14.168478
[2018-04-17 20:51:19.671905]: ====================
[2018-04-17 20:51:19.745099]: [Epoch: 737(73.77377377377378%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:51:21.030517]: [Epoch: 737(73.77377377377378%): Data: 25.333333333333336%]:Running loss: 4.350374266505241
[2018-04-17 20:51:22.336489]: [Epoch: 737(73.77377377377378%): Data: 50.66666666666667%]:Running loss: 8.483225733041763
[2018-04-17 20:51:25.892946]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 20:51:26.023794]: ====================
[2018-04-17 20:51:26.028808]: Elapsed time since starting training: 1:30:52.192937
[2018-04-17 20:51:26.034322]: Estimated time left: -1 day, 23:44:07.801047
[2018-04-17 20:51:26.039335]: ====================
[2018-04-17 20:51:26.112530]: [Epoch: 738(73.87387387387388%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 20:51:27.392434]: [Epoch: 738(73.87387387387388%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 20:51:28.688380]: [Epoch: 738(73.87387387387388%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 20:51:32.286447]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:51:32.421305]: ====================
[2018-04-17 20:51:32.426318]: Elapsed time since starting training: 1:30:58.590448
[2018-04-17 20:51:32.430830]: Estimated time left: -1 day, 23:44:01.405040
[2018-04-17 20:51:32.435342]: ====================
[2018-04-17 20:51:32.506030]: [Epoch: 739(73.97397397397397%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:51:33.761873]: [Epoch: 739(73.97397397397397%): Data: 25.333333333333336%]:Running loss: 4.350370898842812
[2018-04-17 20:51:35.034255]: [Epoch: 739(73.97397397397397%): Data: 50.66666666666667%]:Running loss: 8.48322457075119
[2018-04-17 20:51:38.588707]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:51:38.715043]: ====================
[2018-04-17 20:51:38.721560]: Elapsed time since starting training: 1:31:04.886191
[2018-04-17 20:51:38.727576]: Estimated time left: -1 day, 23:43:55.107793
[2018-04-17 20:51:38.732088]: ====================
[2018-04-17 20:51:38.810296]: [Epoch: 740(74.07407407407408%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:51:40.064130]: [Epoch: 740(74.07407407407408%): Data: 25.333333333333336%]:Running loss: 4.350374802947044
[2018-04-17 20:51:41.352556]: [Epoch: 740(74.07407407407408%): Data: 50.66666666666667%]:Running loss: 8.483228042721748
[2018-04-17 20:51:44.992234]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:51:45.120575]: ====================
[2018-04-17 20:51:45.125589]: Elapsed time since starting training: 1:31:11.290220
[2018-04-17 20:51:45.130602]: Estimated time left: -1 day, 23:43:48.705269
[2018-04-17 20:51:45.135616]: ====================
[2018-04-17 20:51:45.207807]: [Epoch: 741(74.17417417417418%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:51:46.476687]: [Epoch: 741(74.17417417417418%): Data: 25.333333333333336%]:Running loss: 4.350372016429901
[2018-04-17 20:51:47.732520]: [Epoch: 741(74.17417417417418%): Data: 50.66666666666667%]:Running loss: 8.48322556912899
[2018-04-17 20:51:51.322571]: Test set accuracy: 94.33962264150944% ,loss = 5.437970906496048
[2018-04-17 20:51:51.446902]: ====================
[2018-04-17 20:51:51.451915]: Elapsed time since starting training: 1:31:17.616546
[2018-04-17 20:51:51.456929]: Estimated time left: -1 day, 23:43:42.378942
[2018-04-17 20:51:51.461441]: ====================
[2018-04-17 20:51:51.534133]: [Epoch: 742(74.27427427427428%): Data: 0.0%]:Running loss: 0.21751883625984192
[2018-04-17 20:51:52.826069]: [Epoch: 742(74.27427427427428%): Data: 25.333333333333336%]:Running loss: 4.350372105836868
[2018-04-17 20:51:54.101460]: [Epoch: 742(74.27427427427428%): Data: 50.66666666666667%]:Running loss: 8.483227044343948
[2018-04-17 20:51:57.735122]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:51:57.885522]: ====================
[2018-04-17 20:51:57.893543]: Elapsed time since starting training: 1:31:24.058174
[2018-04-17 20:51:57.900061]: Estimated time left: -1 day, 23:43:35.935308
[2018-04-17 20:51:57.906077]: ====================
[2018-04-17 20:51:57.997820]: [Epoch: 743(74.37437437437437%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:51:59.289756]: [Epoch: 743(74.37437437437437%): Data: 25.333333333333336%]:Running loss: 4.350374728441238
[2018-04-17 20:52:00.620293]: [Epoch: 743(74.37437437437437%): Data: 50.66666666666667%]:Running loss: 8.48322981595993
[2018-04-17 20:52:04.218361]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:52:04.344196]: ====================
[2018-04-17 20:52:04.348707]: Elapsed time since starting training: 1:31:30.513338
[2018-04-17 20:52:04.353219]: Estimated time left: -1 day, 23:43:29.482150
[2018-04-17 20:52:04.357731]: ====================
[2018-04-17 20:52:04.430425]: [Epoch: 744(74.47447447447448%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:52:05.734392]: [Epoch: 744(74.47447447447448%): Data: 25.333333333333336%]:Running loss: 4.350373104214668
[2018-04-17 20:52:07.009783]: [Epoch: 744(74.47447447447448%): Data: 50.66666666666667%]:Running loss: 8.483226239681244
[2018-04-17 20:52:10.645450]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 20:52:10.785824]: ====================
[2018-04-17 20:52:10.791339]: Elapsed time since starting training: 1:31:36.955970
[2018-04-17 20:52:10.796352]: Estimated time left: -1 day, 23:43:23.039017
[2018-04-17 20:52:10.801365]: ====================
[2018-04-17 20:52:10.872554]: [Epoch: 745(74.57457457457457%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 20:52:12.159476]: [Epoch: 745(74.57457457457457%): Data: 25.333333333333336%]:Running loss: 4.35037125647068
[2018-04-17 20:52:13.467454]: [Epoch: 745(74.57457457457457%): Data: 50.66666666666667%]:Running loss: 8.483226656913757
[2018-04-17 20:52:17.070033]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:52:17.194364]: ====================
[2018-04-17 20:52:17.199377]: Elapsed time since starting training: 1:31:43.364008
[2018-04-17 20:52:17.204391]: Estimated time left: -1 day, 23:43:16.630978
[2018-04-17 20:52:17.209404]: ====================
[2018-04-17 20:52:17.279089]: [Epoch: 746(74.67467467467468%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:52:18.559995]: [Epoch: 746(74.67467467467468%): Data: 25.333333333333336%]:Running loss: 4.350371927022934
[2018-04-17 20:52:19.854437]: [Epoch: 746(74.67467467467468%): Data: 50.66666666666667%]:Running loss: 8.483224853873253
[2018-04-17 20:52:23.536227]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:52:23.682115]: ====================
[2018-04-17 20:52:23.686627]: Elapsed time since starting training: 1:31:49.851258
[2018-04-17 20:52:23.691640]: Estimated time left: -1 day, 23:43:10.143729
[2018-04-17 20:52:23.696152]: ====================
[2018-04-17 20:52:23.770349]: [Epoch: 747(74.77477477477478%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:52:25.017165]: [Epoch: 747(74.77477477477478%): Data: 25.333333333333336%]:Running loss: 4.350373849272728
[2018-04-17 20:52:26.281526]: [Epoch: 747(74.77477477477478%): Data: 50.66666666666667%]:Running loss: 8.483228132128716
[2018-04-17 20:52:29.817429]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 20:52:29.950783]: ====================
[2018-04-17 20:52:29.955296]: Elapsed time since starting training: 1:31:56.119927
[2018-04-17 20:52:29.960309]: Estimated time left: -1 day, 23:43:03.875562
[2018-04-17 20:52:29.965322]: ====================
[2018-04-17 20:52:30.036010]: [Epoch: 748(74.87487487487488%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 20:52:31.338473]: [Epoch: 748(74.87487487487488%): Data: 25.333333333333336%]:Running loss: 4.3503711223602295
[2018-04-17 20:52:32.614365]: [Epoch: 748(74.87487487487488%): Data: 50.66666666666667%]:Running loss: 8.483223617076874
[2018-04-17 20:52:36.239004]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:52:36.373361]: ====================
[2018-04-17 20:52:36.378374]: Elapsed time since starting training: 1:32:02.543005
[2018-04-17 20:52:36.383890]: Estimated time left: -1 day, 23:42:57.451982
[2018-04-17 20:52:36.388902]: ====================
[2018-04-17 20:52:36.460592]: [Epoch: 749(74.97497497497497%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:52:37.726462]: [Epoch: 749(74.97497497497497%): Data: 25.333333333333336%]:Running loss: 4.350374221801758
[2018-04-17 20:52:39.022405]: [Epoch: 749(74.97497497497497%): Data: 50.66666666666667%]:Running loss: 8.483227670192719
[2018-04-17 20:52:42.614456]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:52:42.733773]: ====================
[2018-04-17 20:52:42.738786]: Elapsed time since starting training: 1:32:08.903417
[2018-04-17 20:52:42.743298]: Estimated time left: -1 day, 23:42:51.092071
[2018-04-17 20:52:42.749816]: ====================
[2018-04-17 20:52:42.814989]: [Epoch: 750(75.07507507507508%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:52:44.080353]: [Epoch: 750(75.07507507507508%): Data: 25.333333333333336%]:Running loss: 4.350373327732086
[2018-04-17 20:52:45.367777]: [Epoch: 750(75.07507507507508%): Data: 50.66666666666667%]:Running loss: 8.483226299285889
[2018-04-17 20:52:49.001439]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:52:49.139807]: ====================
[2018-04-17 20:52:49.145322]: Elapsed time since starting training: 1:32:15.309953
[2018-04-17 20:52:49.149833]: Estimated time left: -1 day, 23:42:44.685536
[2018-04-17 20:52:49.154847]: ====================
[2018-04-17 20:52:49.225534]: [Epoch: 751(75.17517517517518%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:52:50.495912]: [Epoch: 751(75.17517517517518%): Data: 25.333333333333336%]:Running loss: 4.350371599197388
[2018-04-17 20:52:51.805394]: [Epoch: 751(75.17517517517518%): Data: 50.66666666666667%]:Running loss: 8.48322680592537
[2018-04-17 20:52:55.520272]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 20:52:55.653627]: ====================
[2018-04-17 20:52:55.659643]: Elapsed time since starting training: 1:32:21.824274
[2018-04-17 20:52:55.665659]: Estimated time left: -1 day, 23:42:38.170212
[2018-04-17 20:52:55.669670]: ====================
[2018-04-17 20:52:55.754896]: [Epoch: 752(75.27527527527528%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 20:52:57.064378]: [Epoch: 752(75.27527527527528%): Data: 25.333333333333336%]:Running loss: 4.350369438529015
[2018-04-17 20:52:58.377870]: [Epoch: 752(75.27527527527528%): Data: 50.66666666666667%]:Running loss: 8.48322294652462
[2018-04-17 20:53:01.903745]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:53:02.044620]: ====================
[2018-04-17 20:53:02.052141]: Elapsed time since starting training: 1:32:28.216271
[2018-04-17 20:53:02.057154]: Estimated time left: -1 day, 23:42:31.778215
[2018-04-17 20:53:02.061666]: ====================
[2018-04-17 20:53:02.130850]: [Epoch: 753(75.37537537537537%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:53:03.389697]: [Epoch: 753(75.37537537537537%): Data: 25.333333333333336%]:Running loss: 4.350373908877373
[2018-04-17 20:53:04.668096]: [Epoch: 753(75.37537537537537%): Data: 50.66666666666667%]:Running loss: 8.483225628733635
[2018-04-17 20:53:08.319305]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 20:53:08.457673]: ====================
[2018-04-17 20:53:08.462185]: Elapsed time since starting training: 1:32:34.626816
[2018-04-17 20:53:08.466697]: Estimated time left: -1 day, 23:42:25.368672
[2018-04-17 20:53:08.471710]: ====================
[2018-04-17 20:53:08.544403]: [Epoch: 754(75.47547547547548%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 20:53:09.926578]: [Epoch: 754(75.47547547547548%): Data: 25.333333333333336%]:Running loss: 4.350371807813644
[2018-04-17 20:53:11.269148]: [Epoch: 754(75.47547547547548%): Data: 50.66666666666667%]:Running loss: 8.483228459954262
[2018-04-17 20:53:14.872229]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 20:53:14.995558]: ====================
[2018-04-17 20:53:14.999567]: Elapsed time since starting training: 1:32:41.164198
[2018-04-17 20:53:15.003578]: Estimated time left: -1 day, 23:42:18.831791
[2018-04-17 20:53:15.011600]: ====================
[2018-04-17 20:53:15.088303]: [Epoch: 755(75.57557557557557%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 20:53:16.414341]: [Epoch: 755(75.57557557557557%): Data: 25.333333333333336%]:Running loss: 4.350370019674301
[2018-04-17 20:53:17.741860]: [Epoch: 755(75.57557557557557%): Data: 50.66666666666667%]:Running loss: 8.483224362134933
[2018-04-17 20:53:21.320876]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:53:21.446710]: ====================
[2018-04-17 20:53:21.451222]: Elapsed time since starting training: 1:32:47.615853
[2018-04-17 20:53:21.455734]: Estimated time left: -1 day, 23:42:12.380136
[2018-04-17 20:53:21.459745]: ====================
[2018-04-17 20:53:21.544471]: [Epoch: 756(75.67567567567568%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:53:22.848939]: [Epoch: 756(75.67567567567568%): Data: 25.333333333333336%]:Running loss: 4.350375771522522
[2018-04-17 20:53:24.150399]: [Epoch: 756(75.67567567567568%): Data: 50.66666666666667%]:Running loss: 8.483227908611298
[2018-04-17 20:53:27.715880]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:53:27.837202]: ====================
[2018-04-17 20:53:27.842216]: Elapsed time since starting training: 1:32:54.006847
[2018-04-17 20:53:27.847731]: Estimated time left: -1 day, 23:42:05.987638
[2018-04-17 20:53:27.853245]: ====================
[2018-04-17 20:53:27.922933]: [Epoch: 757(75.77577577577578%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:53:29.243943]: [Epoch: 757(75.77577577577578%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 20:53:30.545905]: [Epoch: 757(75.77577577577578%): Data: 50.66666666666667%]:Running loss: 8.483226954936981
[2018-04-17 20:53:34.103364]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 20:53:34.219173]: ====================
[2018-04-17 20:53:34.224186]: Elapsed time since starting training: 1:33:00.388315
[2018-04-17 20:53:34.228196]: Estimated time left: -1 day, 23:41:59.607173
[2018-04-17 20:53:34.232709]: ====================
[2018-04-17 20:53:34.306405]: [Epoch: 758(75.87587587587588%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 20:53:35.641955]: [Epoch: 758(75.87587587587588%): Data: 25.333333333333336%]:Running loss: 4.350372955203056
[2018-04-17 20:53:36.945923]: [Epoch: 758(75.87587587587588%): Data: 50.66666666666667%]:Running loss: 8.483227595686913
[2018-04-17 20:53:40.502379]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:53:40.636737]: ====================
[2018-04-17 20:53:40.641249]: Elapsed time since starting training: 1:33:06.805378
[2018-04-17 20:53:40.645259]: Estimated time left: -1 day, 23:41:53.190110
[2018-04-17 20:53:40.650272]: ====================
[2018-04-17 20:53:40.723467]: [Epoch: 759(75.97597597597597%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:53:42.071552]: [Epoch: 759(75.97597597597597%): Data: 25.333333333333336%]:Running loss: 4.350372031331062
[2018-04-17 20:53:43.412617]: [Epoch: 759(75.97597597597597%): Data: 50.66666666666667%]:Running loss: 8.48322381079197
[2018-04-17 20:53:47.003674]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:53:47.121989]: ====================
[2018-04-17 20:53:47.126500]: Elapsed time since starting training: 1:33:13.291131
[2018-04-17 20:53:47.131013]: Estimated time left: -1 day, 23:41:46.704356
[2018-04-17 20:53:47.135525]: ====================
[2018-04-17 20:53:47.207716]: [Epoch: 760(76.07607607607608%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:53:48.495641]: [Epoch: 760(76.07607607607608%): Data: 25.333333333333336%]:Running loss: 4.350371479988098
[2018-04-17 20:53:49.808131]: [Epoch: 760(76.07607607607608%): Data: 50.66666666666667%]:Running loss: 8.483227416872978
[2018-04-17 20:53:53.454326]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:53:53.584673]: ====================
[2018-04-17 20:53:53.588684]: Elapsed time since starting training: 1:33:19.753315
[2018-04-17 20:53:53.593697]: Estimated time left: -1 day, 23:41:40.242160
[2018-04-17 20:53:53.598209]: ====================
[2018-04-17 20:53:53.670902]: [Epoch: 761(76.17617617617618%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:53:55.072128]: [Epoch: 761(76.17617617617618%): Data: 25.333333333333336%]:Running loss: 4.350372925400734
[2018-04-17 20:53:56.389632]: [Epoch: 761(76.17617617617618%): Data: 50.66666666666667%]:Running loss: 8.483225971460342
[2018-04-17 20:54:00.037831]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:54:00.158653]: ====================
[2018-04-17 20:54:00.163666]: Elapsed time since starting training: 1:33:26.328297
[2018-04-17 20:54:00.168180]: Estimated time left: -1 day, 23:41:33.667189
[2018-04-17 20:54:00.172690]: ====================
[2018-04-17 20:54:00.244380]: [Epoch: 762(76.27627627627628%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:54:01.521276]: [Epoch: 762(76.27627627627628%): Data: 25.333333333333336%]:Running loss: 4.3503739684820175
[2018-04-17 20:54:02.856326]: [Epoch: 762(76.27627627627628%): Data: 50.66666666666667%]:Running loss: 8.483226791024208
[2018-04-17 20:54:06.486478]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 20:54:06.736644]: ====================
[2018-04-17 20:54:06.741657]: Elapsed time since starting training: 1:33:32.905787
[2018-04-17 20:54:06.746169]: Estimated time left: -1 day, 23:41:27.089200
[2018-04-17 20:54:06.753188]: ====================
[2018-04-17 20:54:06.824377]: [Epoch: 763(76.37637637637637%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 20:54:08.114808]: [Epoch: 763(76.37637637637637%): Data: 25.333333333333336%]:Running loss: 4.350370675325394
[2018-04-17 20:54:09.379170]: [Epoch: 763(76.37637637637637%): Data: 50.66666666666667%]:Running loss: 8.483225747942924
[2018-04-17 20:54:13.007318]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:54:13.137163]: ====================
[2018-04-17 20:54:13.142176]: Elapsed time since starting training: 1:33:39.306807
[2018-04-17 20:54:13.147189]: Estimated time left: -1 day, 23:41:20.688681
[2018-04-17 20:54:13.152203]: ====================
[2018-04-17 20:54:13.222890]: [Epoch: 764(76.47647647647648%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:54:14.501795]: [Epoch: 764(76.47647647647648%): Data: 25.333333333333336%]:Running loss: 4.3503739684820175
[2018-04-17 20:54:15.832333]: [Epoch: 764(76.47647647647648%): Data: 50.66666666666667%]:Running loss: 8.483223646879196
[2018-04-17 20:54:19.474517]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 20:54:19.608875]: ====================
[2018-04-17 20:54:19.614390]: Elapsed time since starting training: 1:33:45.779021
[2018-04-17 20:54:19.619402]: Estimated time left: -1 day, 23:41:14.215967
[2018-04-17 20:54:19.624416]: ====================
[2018-04-17 20:54:19.695605]: [Epoch: 765(76.57657657657657%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 20:54:20.955957]: [Epoch: 765(76.57657657657657%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 20:54:22.231849]: [Epoch: 765(76.57657657657657%): Data: 50.66666666666667%]:Running loss: 8.483218058943748
[2018-04-17 20:54:25.816380]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 20:54:25.955751]: ====================
[2018-04-17 20:54:25.960264]: Elapsed time since starting training: 1:33:52.124895
[2018-04-17 20:54:25.965777]: Estimated time left: -1 day, 23:41:07.869592
[2018-04-17 20:54:25.970791]: ====================
[2018-04-17 20:54:26.047996]: [Epoch: 766(76.67667667667668%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 20:54:27.324891]: [Epoch: 766(76.67667667667668%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 20:54:28.615824]: [Epoch: 766(76.67667667667668%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 20:54:32.268542]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 20:54:32.398388]: ====================
[2018-04-17 20:54:32.403401]: Elapsed time since starting training: 1:33:58.568032
[2018-04-17 20:54:32.408414]: Estimated time left: -1 day, 23:41:01.427457
[2018-04-17 20:54:32.413427]: ====================
[2018-04-17 20:54:32.484616]: [Epoch: 767(76.77677677677679%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 20:54:33.786578]: [Epoch: 767(76.77677677677679%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 20:54:35.076508]: [Epoch: 767(76.77677677677679%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 20:54:38.737242]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 20:54:38.872101]: ====================
[2018-04-17 20:54:38.877114]: Elapsed time since starting training: 1:34:05.041745
[2018-04-17 20:54:38.882127]: Estimated time left: -1 day, 23:40:54.953744
[2018-04-17 20:54:38.887141]: ====================
[2018-04-17 20:54:38.960335]: [Epoch: 768(76.87687687687688%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 20:54:40.272825]: [Epoch: 768(76.87687687687688%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 20:54:41.579299]: [Epoch: 768(76.87687687687688%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 20:54:45.160822]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 20:54:45.290166]: ====================
[2018-04-17 20:54:45.295681]: Elapsed time since starting training: 1:34:11.459810
[2018-04-17 20:54:45.300192]: Estimated time left: -1 day, 23:40:48.535677
[2018-04-17 20:54:45.305707]: ====================
[2018-04-17 20:54:45.376395]: [Epoch: 769(76.97697697697697%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 20:54:46.639261]: [Epoch: 769(76.97697697697697%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 20:54:47.917151]: [Epoch: 769(76.97697697697697%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 20:54:51.519235]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:54:51.660612]: ====================
[2018-04-17 20:54:51.665625]: Elapsed time since starting training: 1:34:17.830256
[2018-04-17 20:54:51.670137]: Estimated time left: -1 day, 23:40:42.165232
[2018-04-17 20:54:51.674648]: ====================
[2018-04-17 20:54:51.744835]: [Epoch: 770(77.07707707707708%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:54:53.016717]: [Epoch: 770(77.07707707707708%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 20:54:54.297623]: [Epoch: 770(77.07707707707708%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 20:54:57.936799]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:54:58.091712]: ====================
[2018-04-17 20:54:58.096223]: Elapsed time since starting training: 1:34:24.260854
[2018-04-17 20:54:58.101236]: Estimated time left: -1 day, 23:40:35.734133
[2018-04-17 20:54:58.105750]: ====================
[2018-04-17 20:54:58.175935]: [Epoch: 771(77.17717717717719%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:54:59.426260]: [Epoch: 771(77.17717717717719%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 20:55:00.695635]: [Epoch: 771(77.17717717717719%): Data: 50.66666666666667%]:Running loss: 8.483222559094429
[2018-04-17 20:55:04.439089]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 20:55:04.581469]: ====================
[2018-04-17 20:55:04.586481]: Elapsed time since starting training: 1:34:30.751112
[2018-04-17 20:55:04.591494]: Estimated time left: -1 day, 23:40:29.243875
[2018-04-17 20:55:04.597009]: ====================
[2018-04-17 20:55:04.665190]: [Epoch: 772(77.27727727727728%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 20:55:05.934064]: [Epoch: 772(77.27727727727728%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 20:55:07.196421]: [Epoch: 772(77.27727727727728%): Data: 50.66666666666667%]:Running loss: 8.4832231849432
[2018-04-17 20:55:10.751373]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:55:10.889240]: ====================
[2018-04-17 20:55:10.894754]: Elapsed time since starting training: 1:34:37.059385
[2018-04-17 20:55:10.899267]: Estimated time left: -1 day, 23:40:22.936102
[2018-04-17 20:55:10.904280]: ====================
[2018-04-17 20:55:10.975970]: [Epoch: 773(77.37737737737737%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:55:12.255372]: [Epoch: 773(77.37737737737737%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 20:55:13.568364]: [Epoch: 773(77.37737737737737%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 20:55:17.162923]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:55:17.296778]: ====================
[2018-04-17 20:55:17.301289]: Elapsed time since starting training: 1:34:43.465920
[2018-04-17 20:55:17.307305]: Estimated time left: -1 day, 23:40:16.528064
[2018-04-17 20:55:17.312319]: ====================
[2018-04-17 20:55:17.387017]: [Epoch: 774(77.47747747747748%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:55:18.698003]: [Epoch: 774(77.47747747747748%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 20:55:19.954348]: [Epoch: 774(77.47747747747748%): Data: 50.66666666666667%]:Running loss: 8.483224242925644
[2018-04-17 20:55:23.476710]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:55:23.606054]: ====================
[2018-04-17 20:55:23.610565]: Elapsed time since starting training: 1:34:49.775196
[2018-04-17 20:55:23.615579]: Estimated time left: -1 day, 23:40:10.219790
[2018-04-17 20:55:23.620593]: ====================
[2018-04-17 20:55:23.692784]: [Epoch: 775(77.57757757757757%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:55:25.014298]: [Epoch: 775(77.57757757757757%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 20:55:26.298212]: [Epoch: 775(77.57757757757757%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 20:55:29.779475]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:55:29.912328]: ====================
[2018-04-17 20:55:29.917342]: Elapsed time since starting training: 1:34:56.081471
[2018-04-17 20:55:29.921352]: Estimated time left: -1 day, 23:40:03.914017
[2018-04-17 20:55:29.925864]: ====================
[2018-04-17 20:55:29.994546]: [Epoch: 776(77.67767767767768%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:55:31.263420]: [Epoch: 776(77.67767767767768%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 20:55:32.533309]: [Epoch: 776(77.67767767767768%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 20:55:36.025082]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:55:36.148410]: ====================
[2018-04-17 20:55:36.153925]: Elapsed time since starting training: 1:35:02.318054
[2018-04-17 20:55:36.158436]: Estimated time left: -1 day, 23:39:57.676933
[2018-04-17 20:55:36.163450]: ====================
[2018-04-17 20:55:36.234138]: [Epoch: 777(77.77777777777779%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:55:37.485966]: [Epoch: 777(77.77777777777779%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 20:55:38.737795]: [Epoch: 777(77.77777777777779%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 20:55:42.299265]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:55:42.444652]: ====================
[2018-04-17 20:55:42.449164]: Elapsed time since starting training: 1:35:08.613795
[2018-04-17 20:55:42.453676]: Estimated time left: -1 day, 23:39:51.381693
[2018-04-17 20:55:42.458187]: ====================
[2018-04-17 20:55:42.524363]: [Epoch: 778(77.87787787787788%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:55:43.785216]: [Epoch: 778(77.87787787787788%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 20:55:45.047072]: [Epoch: 778(77.87787787787788%): Data: 50.66666666666667%]:Running loss: 8.483227267861366
[2018-04-17 20:55:48.628093]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:55:48.764456]: ====================
[2018-04-17 20:55:48.769470]: Elapsed time since starting training: 1:35:14.934101
[2018-04-17 20:55:48.774986]: Estimated time left: -1 day, 23:39:45.060887
[2018-04-17 20:55:48.779997]: ====================
[2018-04-17 20:55:48.851689]: [Epoch: 779(77.97797797797797%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:55:50.107025]: [Epoch: 779(77.97797797797797%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 20:55:51.401969]: [Epoch: 779(77.97797797797797%): Data: 50.66666666666667%]:Running loss: 8.483226209878922
[2018-04-17 20:55:55.009561]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:55:55.159460]: ====================
[2018-04-17 20:55:55.163972]: Elapsed time since starting training: 1:35:21.328603
[2018-04-17 20:55:55.167983]: Estimated time left: -1 day, 23:39:38.667386
[2018-04-17 20:55:55.171993]: ====================
[2018-04-17 20:55:55.240676]: [Epoch: 780(78.07807807807808%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:55:56.541134]: [Epoch: 780(78.07807807807808%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 20:55:57.836077]: [Epoch: 780(78.07807807807808%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 20:56:01.417600]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:56:01.562486]: ====================
[2018-04-17 20:56:01.566998]: Elapsed time since starting training: 1:35:27.731629
[2018-04-17 20:56:01.571510]: Estimated time left: -1 day, 23:39:32.263859
[2018-04-17 20:56:01.576022]: ====================
[2018-04-17 20:56:01.649717]: [Epoch: 781(78.17817817817819%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:56:02.956191]: [Epoch: 781(78.17817817817819%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 20:56:04.194985]: [Epoch: 781(78.17817817817819%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 20:56:07.753448]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:56:07.895826]: ====================
[2018-04-17 20:56:07.900338]: Elapsed time since starting training: 1:35:34.064467
[2018-04-17 20:56:07.904850]: Estimated time left: -1 day, 23:39:25.930519
[2018-04-17 20:56:07.909362]: ====================
[2018-04-17 20:56:07.979049]: [Epoch: 782(78.27827827827828%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:56:09.249927]: [Epoch: 782(78.27827827827828%): Data: 25.333333333333336%]:Running loss: 4.350372314453125
[2018-04-17 20:56:10.491810]: [Epoch: 782(78.27827827827828%): Data: 50.66666666666667%]:Running loss: 8.483226522803307
[2018-04-17 20:56:14.154048]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:56:14.297430]: ====================
[2018-04-17 20:56:14.304448]: Elapsed time since starting training: 1:35:40.469079
[2018-04-17 20:56:14.308960]: Estimated time left: -1 day, 23:39:19.526409
[2018-04-17 20:56:14.313472]: ====================
[2018-04-17 20:56:14.382656]: [Epoch: 783(78.37837837837837%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:56:15.660053]: [Epoch: 783(78.37837837837837%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 20:56:16.930932]: [Epoch: 783(78.37837837837837%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 20:56:20.509447]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 20:56:20.635282]: ====================
[2018-04-17 20:56:20.640296]: Elapsed time since starting training: 1:35:46.804425
[2018-04-17 20:56:20.645810]: Estimated time left: -1 day, 23:39:13.189559
[2018-04-17 20:56:20.650823]: ====================
[2018-04-17 20:56:20.723015]: [Epoch: 784(78.47847847847848%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 20:56:21.986876]: [Epoch: 784(78.47847847847848%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 20:56:23.267280]: [Epoch: 784(78.47847847847848%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 20:56:26.841284]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 20:56:26.973635]: ====================
[2018-04-17 20:56:26.978147]: Elapsed time since starting training: 1:35:53.142778
[2018-04-17 20:56:26.983161]: Estimated time left: -1 day, 23:39:06.852208
[2018-04-17 20:56:26.988174]: ====================
[2018-04-17 20:56:27.058361]: [Epoch: 785(78.57857857857859%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 20:56:28.341272]: [Epoch: 785(78.57857857857859%): Data: 25.333333333333336%]:Running loss: 4.350373834371567
[2018-04-17 20:56:29.609143]: [Epoch: 785(78.57857857857859%): Data: 50.66666666666667%]:Running loss: 8.483228325843811
[2018-04-17 20:56:33.133013]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:56:33.263359]: ====================
[2018-04-17 20:56:33.268875]: Elapsed time since starting training: 1:35:59.433004
[2018-04-17 20:56:33.273386]: Estimated time left: -1 day, 23:39:00.561983
[2018-04-17 20:56:33.278400]: ====================
[2018-04-17 20:56:33.353099]: [Epoch: 786(78.67867867867868%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:56:34.634506]: [Epoch: 786(78.67867867867868%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 20:56:35.894857]: [Epoch: 786(78.67867867867868%): Data: 50.66666666666667%]:Running loss: 8.483228147029877
[2018-04-17 20:56:39.444796]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 20:56:39.578152]: ====================
[2018-04-17 20:56:39.583666]: Elapsed time since starting training: 1:36:05.747795
[2018-04-17 20:56:39.588679]: Estimated time left: -1 day, 23:38:54.246690
[2018-04-17 20:56:39.594193]: ====================
[2018-04-17 20:56:39.667388]: [Epoch: 787(78.77877877877879%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 20:56:40.975366]: [Epoch: 787(78.77877877877879%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 20:56:42.238725]: [Epoch: 787(78.77877877877879%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 20:56:45.779640]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:56:45.910990]: ====================
[2018-04-17 20:56:45.915502]: Elapsed time since starting training: 1:36:12.080133
[2018-04-17 20:56:45.920014]: Estimated time left: -1 day, 23:38:47.915355
[2018-04-17 20:56:45.925529]: ====================
[2018-04-17 20:56:46.006244]: [Epoch: 788(78.87887887887888%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:56:47.293165]: [Epoch: 788(78.87887887887888%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 20:56:48.580588]: [Epoch: 788(78.87887887887888%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 20:56:52.167626]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:56:52.301984]: ====================
[2018-04-17 20:56:52.308000]: Elapsed time since starting training: 1:36:18.472129
[2018-04-17 20:56:52.313013]: Estimated time left: -1 day, 23:38:41.522858
[2018-04-17 20:56:52.317525]: ====================
[2018-04-17 20:56:52.391724]: [Epoch: 789(78.97897897897897%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:56:53.678142]: [Epoch: 789(78.97897897897897%): Data: 25.333333333333336%]:Running loss: 4.350374400615692
[2018-04-17 20:56:54.937491]: [Epoch: 789(78.97897897897897%): Data: 50.66666666666667%]:Running loss: 8.48323030769825
[2018-04-17 20:56:58.503477]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:56:58.626805]: ====================
[2018-04-17 20:56:58.631818]: Elapsed time since starting training: 1:36:24.796449
[2018-04-17 20:56:58.637332]: Estimated time left: -1 day, 23:38:35.198037
[2018-04-17 20:56:58.643348]: ====================
[2018-04-17 20:56:58.714036]: [Epoch: 790(79.07907907907908%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:57:00.000457]: [Epoch: 790(79.07907907907908%): Data: 25.333333333333336%]:Running loss: 4.35037499666214
[2018-04-17 20:57:01.211678]: [Epoch: 790(79.07907907907908%): Data: 50.66666666666667%]:Running loss: 8.483231753110886
[2018-04-17 20:57:04.603697]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:57:04.736551]: ====================
[2018-04-17 20:57:04.741564]: Elapsed time since starting training: 1:36:30.906195
[2018-04-17 20:57:04.746577]: Estimated time left: -1 day, 23:38:29.089293
[2018-04-17 20:57:04.751089]: ====================
[2018-04-17 20:57:04.822289]: [Epoch: 791(79.17917917917919%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:57:06.081626]: [Epoch: 791(79.17917917917919%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 20:57:07.286831]: [Epoch: 791(79.17917917917919%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 20:57:10.794157]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 20:57:10.928014]: ====================
[2018-04-17 20:57:10.932525]: Elapsed time since starting training: 1:36:37.097156
[2018-04-17 20:57:10.937037]: Estimated time left: -1 day, 23:38:22.898332
[2018-04-17 20:57:10.942050]: ====================
[2018-04-17 20:57:11.010232]: [Epoch: 792(79.27927927927928%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 20:57:12.279607]: [Epoch: 792(79.27927927927928%): Data: 25.333333333333336%]:Running loss: 4.350375294685364
[2018-04-17 20:57:13.541964]: [Epoch: 792(79.27927927927928%): Data: 50.66666666666667%]:Running loss: 8.483232334256172
[2018-04-17 20:57:17.094410]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:57:17.227764]: ====================
[2018-04-17 20:57:17.232777]: Elapsed time since starting training: 1:36:43.397408
[2018-04-17 20:57:17.237791]: Estimated time left: -1 day, 23:38:16.597578
[2018-04-17 20:57:17.242303]: ====================
[2018-04-17 20:57:17.320511]: [Epoch: 793(79.37937937937937%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:57:18.608435]: [Epoch: 793(79.37937937937937%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 20:57:19.873800]: [Epoch: 793(79.37937937937937%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 20:57:23.382630]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 20:57:23.516486]: ====================
[2018-04-17 20:57:23.520998]: Elapsed time since starting training: 1:36:49.685629
[2018-04-17 20:57:23.526512]: Estimated time left: -1 day, 23:38:10.308857
[2018-04-17 20:57:23.531025]: ====================
[2018-04-17 20:57:23.602214]: [Epoch: 794(79.47947947947948%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 20:57:24.875098]: [Epoch: 794(79.47947947947948%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 20:57:26.132441]: [Epoch: 794(79.47947947947948%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 20:57:29.674861]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 20:57:29.807714]: ====================
[2018-04-17 20:57:29.812226]: Elapsed time since starting training: 1:36:55.976857
[2018-04-17 20:57:29.817239]: Estimated time left: -1 day, 23:38:04.018130
[2018-04-17 20:57:29.822253]: ====================
[2018-04-17 20:57:29.893443]: [Epoch: 795(79.57957957957959%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 20:57:31.168833]: [Epoch: 795(79.57957957957959%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 20:57:32.446230]: [Epoch: 795(79.57957957957959%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 20:57:36.050814]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 20:57:36.192692]: ====================
[2018-04-17 20:57:36.197705]: Elapsed time since starting training: 1:37:02.362336
[2018-04-17 20:57:36.202719]: Estimated time left: -1 day, 23:37:57.632650
[2018-04-17 20:57:36.208735]: ====================
[2018-04-17 20:57:36.279422]: [Epoch: 796(79.67967967967968%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 20:57:37.558323]: [Epoch: 796(79.67967967967968%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 20:57:38.833715]: [Epoch: 796(79.67967967967968%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 20:57:42.430779]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 20:57:42.677435]: ====================
[2018-04-17 20:57:42.682949]: Elapsed time since starting training: 1:37:08.847580
[2018-04-17 20:57:42.687963]: Estimated time left: -1 day, 23:37:51.147406
[2018-04-17 20:57:42.692475]: ====================
[2018-04-17 20:57:42.765670]: [Epoch: 797(79.77977977977979%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 20:57:44.046074]: [Epoch: 797(79.77977977977979%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 20:57:45.308932]: [Epoch: 797(79.77977977977979%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 20:57:48.809244]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:57:48.946108]: ====================
[2018-04-17 20:57:48.951122]: Elapsed time since starting training: 1:37:15.115753
[2018-04-17 20:57:48.956135]: Estimated time left: -1 day, 23:37:44.879234
[2018-04-17 20:57:48.961651]: ====================
[2018-04-17 20:57:49.033341]: [Epoch: 798(79.87987987987988%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:57:50.303217]: [Epoch: 798(79.87987987987988%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 20:57:51.568080]: [Epoch: 798(79.87987987987988%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 20:57:55.145092]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:57:55.276942]: ====================
[2018-04-17 20:57:55.281955]: Elapsed time since starting training: 1:37:21.446085
[2018-04-17 20:57:55.287471]: Estimated time left: -1 day, 23:37:38.548400
[2018-04-17 20:57:55.291982]: ====================
[2018-04-17 20:57:55.365678]: [Epoch: 799(79.97997997997997%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:57:56.664130]: [Epoch: 799(79.97997997997997%): Data: 25.333333333333336%]:Running loss: 4.35037037730217
[2018-04-17 20:57:57.981133]: [Epoch: 799(79.97997997997997%): Data: 50.66666666666667%]:Running loss: 8.48322232067585
[2018-04-17 20:58:01.610784]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:58:01.747146]: ====================
[2018-04-17 20:58:01.752661]: Elapsed time since starting training: 1:37:27.916791
[2018-04-17 20:58:01.757675]: Estimated time left: -1 day, 23:37:32.077694
[2018-04-17 20:58:01.762688]: ====================
[2018-04-17 20:58:01.833877]: [Epoch: 800(80.08008008008008%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:58:03.094229]: [Epoch: 800(80.08008008008008%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 20:58:04.362600]: [Epoch: 800(80.08008008008008%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 20:58:07.931090]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:58:08.082994]: ====================
[2018-04-17 20:58:08.088007]: Elapsed time since starting training: 1:37:34.252136
[2018-04-17 20:58:08.092518]: Estimated time left: -1 day, 23:37:25.742851
[2018-04-17 20:58:08.097532]: ====================
[2018-04-17 20:58:08.168220]: [Epoch: 801(80.18018018018019%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:58:09.429574]: [Epoch: 801(80.18018018018019%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 20:58:10.686416]: [Epoch: 801(80.18018018018019%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 20:58:14.222820]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 20:58:14.364196]: ====================
[2018-04-17 20:58:14.369208]: Elapsed time since starting training: 1:37:40.533341
[2018-04-17 20:58:14.374724]: Estimated time left: -1 day, 23:37:19.461148
[2018-04-17 20:58:14.379737]: ====================
[2018-04-17 20:58:14.450424]: [Epoch: 802(80.28028028028028%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 20:58:15.710278]: [Epoch: 802(80.28028028028028%): Data: 25.333333333333336%]:Running loss: 4.350370407104492
[2018-04-17 20:58:16.987675]: [Epoch: 802(80.28028028028028%): Data: 50.66666666666667%]:Running loss: 8.483222633600235
[2018-04-17 20:58:20.610308]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 20:58:20.742158]: ====================
[2018-04-17 20:58:20.747171]: Elapsed time since starting training: 1:37:46.911802
[2018-04-17 20:58:20.752185]: Estimated time left: -1 day, 23:37:13.083184
[2018-04-17 20:58:20.757700]: ====================
[2018-04-17 20:58:20.828889]: [Epoch: 803(80.38038038038037%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 20:58:22.103277]: [Epoch: 803(80.38038038038037%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 20:58:23.479436]: [Epoch: 803(80.38038038038037%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 20:58:27.022357]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 20:58:27.185792]: ====================
[2018-04-17 20:58:27.193312]: Elapsed time since starting training: 1:37:53.357441
[2018-04-17 20:58:27.201333]: Estimated time left: -1 day, 23:37:06.634538
[2018-04-17 20:58:27.206347]: ====================
[2018-04-17 20:58:27.285055]: [Epoch: 804(80.48048048048048%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 20:58:28.603562]: [Epoch: 804(80.48048048048048%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 20:58:29.875953]: [Epoch: 804(80.48048048048048%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 20:58:33.417361]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 20:58:33.548209]: ====================
[2018-04-17 20:58:33.552721]: Elapsed time since starting training: 1:37:59.716851
[2018-04-17 20:58:33.557234]: Estimated time left: -1 day, 23:37:00.278135
[2018-04-17 20:58:33.561745]: ====================
[2018-04-17 20:58:33.632434]: [Epoch: 805(80.58058058058059%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 20:58:34.909830]: [Epoch: 805(80.58058058058059%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 20:58:36.192240]: [Epoch: 805(80.58058058058059%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 20:58:39.745187]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 20:58:39.874030]: ====================
[2018-04-17 20:58:39.879044]: Elapsed time since starting training: 1:38:06.043173
[2018-04-17 20:58:39.884056]: Estimated time left: -1 day, 23:36:53.951313
[2018-04-17 20:58:39.888067]: ====================
[2018-04-17 20:58:39.959257]: [Epoch: 806(80.68068068068068%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 20:58:41.238658]: [Epoch: 806(80.68068068068068%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 20:58:42.479457]: [Epoch: 806(80.68068068068068%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 20:58:46.073013]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 20:58:46.208372]: ====================
[2018-04-17 20:58:46.213386]: Elapsed time since starting training: 1:38:12.378017
[2018-04-17 20:58:46.218399]: Estimated time left: -1 day, 23:36:47.616970
[2018-04-17 20:58:46.223413]: ====================
[2018-04-17 20:58:46.295103]: [Epoch: 807(80.78078078078079%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 20:58:47.561972]: [Epoch: 807(80.78078078078079%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 20:58:48.831848]: [Epoch: 807(80.78078078078079%): Data: 50.66666666666667%]:Running loss: 8.483222529292107
[2018-04-17 20:58:52.365244]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 20:58:52.511131]: ====================
[2018-04-17 20:58:52.515644]: Elapsed time since starting training: 1:38:18.680275
[2018-04-17 20:58:52.520156]: Estimated time left: -1 day, 23:36:41.315213
[2018-04-17 20:58:52.524667]: ====================
[2018-04-17 20:58:52.596860]: [Epoch: 808(80.88088088088088%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 20:58:53.881776]: [Epoch: 808(80.88088088088088%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 20:58:55.146640]: [Epoch: 808(80.88088088088088%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 20:58:58.765261]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:58:58.914659]: ====================
[2018-04-17 20:58:58.919672]: Elapsed time since starting training: 1:38:25.084303
[2018-04-17 20:58:58.926690]: Estimated time left: -1 day, 23:36:34.908679
[2018-04-17 20:58:58.931202]: ====================
[2018-04-17 20:58:59.002392]: [Epoch: 809(80.98098098098097%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:59:00.308866]: [Epoch: 809(80.98098098098097%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 20:59:01.583756]: [Epoch: 809(80.98098098098097%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 20:59:05.113642]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 20:59:05.238473]: ====================
[2018-04-17 20:59:05.242985]: Elapsed time since starting training: 1:38:31.407115
[2018-04-17 20:59:05.246996]: Estimated time left: -1 day, 23:36:28.588373
[2018-04-17 20:59:05.251007]: ====================
[2018-04-17 20:59:05.320190]: [Epoch: 810(81.08108108108108%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 20:59:06.592073]: [Epoch: 810(81.08108108108108%): Data: 25.333333333333336%]:Running loss: 4.350371867418289
[2018-04-17 20:59:07.859443]: [Epoch: 810(81.08108108108108%): Data: 50.66666666666667%]:Running loss: 8.483225226402283
[2018-04-17 20:59:11.449990]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 20:59:11.576327]: ====================
[2018-04-17 20:59:11.581339]: Elapsed time since starting training: 1:38:37.745970
[2018-04-17 20:59:11.586854]: Estimated time left: -1 day, 23:36:22.248515
[2018-04-17 20:59:11.591867]: ====================
[2018-04-17 20:59:11.661061]: [Epoch: 811(81.18118118118119%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 20:59:12.877293]: [Epoch: 811(81.18118118118119%): Data: 25.333333333333336%]:Running loss: 4.350371986627579
[2018-04-17 20:59:14.145165]: [Epoch: 811(81.18118118118119%): Data: 50.66666666666667%]:Running loss: 8.483225911855698
[2018-04-17 20:59:17.644469]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:59:17.774315]: ====================
[2018-04-17 20:59:17.778827]: Elapsed time since starting training: 1:38:43.942957
[2018-04-17 20:59:17.783840]: Estimated time left: -1 day, 23:36:16.052030
[2018-04-17 20:59:17.788352]: ====================
[2018-04-17 20:59:17.860043]: [Epoch: 812(81.28128128128128%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:59:19.113877]: [Epoch: 812(81.28128128128128%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 20:59:20.386761]: [Epoch: 812(81.28128128128128%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 20:59:23.934193]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 20:59:24.071058]: ====================
[2018-04-17 20:59:24.076572]: Elapsed time since starting training: 1:38:50.241203
[2018-04-17 20:59:24.081585]: Estimated time left: -1 day, 23:36:09.753784
[2018-04-17 20:59:24.086599]: ====================
[2018-04-17 20:59:24.157788]: [Epoch: 813(81.38138138138137%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 20:59:25.433681]: [Epoch: 813(81.38138138138137%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 20:59:26.676485]: [Epoch: 813(81.38138138138137%): Data: 50.66666666666667%]:Running loss: 8.483226671814919
[2018-04-17 20:59:30.262019]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 20:59:30.390861]: ====================
[2018-04-17 20:59:30.395875]: Elapsed time since starting training: 1:38:56.560506
[2018-04-17 20:59:30.400387]: Estimated time left: -1 day, 23:36:03.434982
[2018-04-17 20:59:30.404899]: ====================
[2018-04-17 20:59:30.476590]: [Epoch: 814(81.48148148148148%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 20:59:31.738959]: [Epoch: 814(81.48148148148148%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 20:59:32.950668]: [Epoch: 814(81.48148148148148%): Data: 50.66666666666667%]:Running loss: 8.483227223157883
[2018-04-17 20:59:36.502111]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 20:59:36.626943]: ====================
[2018-04-17 20:59:36.631957]: Elapsed time since starting training: 1:39:02.796086
[2018-04-17 20:59:36.636468]: Estimated time left: -1 day, 23:35:57.198901
[2018-04-17 20:59:36.641483]: ====================
[2018-04-17 20:59:36.711668]: [Epoch: 815(81.58158158158159%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 20:59:37.955476]: [Epoch: 815(81.58158158158159%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 20:59:39.211315]: [Epoch: 815(81.58158158158159%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 20:59:42.777297]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 20:59:42.904636]: ====================
[2018-04-17 20:59:42.910151]: Elapsed time since starting training: 1:39:09.074280
[2018-04-17 20:59:42.917670]: Estimated time left: -1 day, 23:35:50.918200
[2018-04-17 20:59:42.922183]: ====================
[2018-04-17 20:59:43.003900]: [Epoch: 816(81.68168168168168%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 20:59:44.293343]: [Epoch: 816(81.68168168168168%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 20:59:45.583775]: [Epoch: 816(81.68168168168168%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 20:59:49.177831]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 20:59:49.318705]: ====================
[2018-04-17 20:59:49.323719]: Elapsed time since starting training: 1:39:15.488350
[2018-04-17 20:59:49.328732]: Estimated time left: -1 day, 23:35:44.506637
[2018-04-17 20:59:49.333745]: ====================
[2018-04-17 20:59:49.404935]: [Epoch: 817(81.78178178178179%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 20:59:50.687345]: [Epoch: 817(81.78178178178179%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 20:59:51.949200]: [Epoch: 817(81.78178178178179%): Data: 50.66666666666667%]:Running loss: 8.483230009675026
[2018-04-17 20:59:55.536238]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 20:59:55.672099]: ====================
[2018-04-17 20:59:55.677614]: Elapsed time since starting training: 1:39:21.841744
[2018-04-17 20:59:55.682628]: Estimated time left: -1 day, 23:35:38.152741
[2018-04-17 20:59:55.687641]: ====================
[2018-04-17 20:59:55.756825]: [Epoch: 818(81.88188188188188%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 20:59:57.060291]: [Epoch: 818(81.88188188188188%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 20:59:58.334178]: [Epoch: 818(81.88188188188188%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 21:00:01.925729]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:00:02.068608]: ====================
[2018-04-17 21:00:02.073621]: Elapsed time since starting training: 1:39:28.238252
[2018-04-17 21:00:02.079637]: Estimated time left: -1 day, 23:35:31.755732
[2018-04-17 21:00:02.084149]: ====================
[2018-04-17 21:00:02.155840]: [Epoch: 819(81.98198198198197%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:00:03.434239]: [Epoch: 819(81.98198198198197%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:00:04.782324]: [Epoch: 819(81.98198198198197%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 21:00:08.373873]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:00:08.489180]: ====================
[2018-04-17 21:00:08.493190]: Elapsed time since starting training: 1:39:34.657821
[2018-04-17 21:00:08.498204]: Estimated time left: -1 day, 23:35:25.337165
[2018-04-17 21:00:08.502716]: ====================
[2018-04-17 21:00:08.574908]: [Epoch: 820(82.08208208208208%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:00:09.892411]: [Epoch: 820(82.08208208208208%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:00:11.154267]: [Epoch: 820(82.08208208208208%): Data: 50.66666666666667%]:Running loss: 8.483231335878372
[2018-04-17 21:00:14.693678]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 21:00:14.816504]: ====================
[2018-04-17 21:00:14.821518]: Elapsed time since starting training: 1:39:40.986149
[2018-04-17 21:00:14.827534]: Estimated time left: -1 day, 23:35:19.008337
[2018-04-17 21:00:14.832547]: ====================
[2018-04-17 21:00:14.903235]: [Epoch: 821(82.18218218218219%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 21:00:16.186647]: [Epoch: 821(82.18218218218219%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 21:00:17.518188]: [Epoch: 821(82.18218218218219%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 21:00:21.098207]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 21:00:21.218026]: ====================
[2018-04-17 21:00:21.223039]: Elapsed time since starting training: 1:39:47.387168
[2018-04-17 21:00:21.228052]: Estimated time left: -1 day, 23:35:12.607317
[2018-04-17 21:00:21.234069]: ====================
[2018-04-17 21:00:21.302751]: [Epoch: 822(82.28228228228228%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 21:00:22.631283]: [Epoch: 822(82.28228228228228%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 21:00:23.933747]: [Epoch: 822(82.28228228228228%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 21:00:27.616539]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 21:00:27.732849]: ====================
[2018-04-17 21:00:27.737862]: Elapsed time since starting training: 1:39:53.902493
[2018-04-17 21:00:27.743376]: Estimated time left: -1 day, 23:35:06.092493
[2018-04-17 21:00:27.747888]: ====================
[2018-04-17 21:00:27.815067]: [Epoch: 823(82.38238238238237%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 21:00:29.098982]: [Epoch: 823(82.38238238238237%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:00:30.383897]: [Epoch: 823(82.38238238238237%): Data: 50.66666666666667%]:Running loss: 8.483234316110611
[2018-04-17 21:00:33.958402]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 21:00:34.070200]: ====================
[2018-04-17 21:00:34.076215]: Elapsed time since starting training: 1:40:00.240345
[2018-04-17 21:00:34.081730]: Estimated time left: -1 day, 23:34:59.753639
[2018-04-17 21:00:34.086744]: ====================
[2018-04-17 21:00:34.156930]: [Epoch: 824(82.48248248248248%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 21:00:35.417783]: [Epoch: 824(82.48248248248248%): Data: 25.333333333333336%]:Running loss: 4.350366294384003
[2018-04-17 21:00:36.695680]: [Epoch: 824(82.48248248248248%): Data: 50.66666666666667%]:Running loss: 8.483214542269707
[2018-04-17 21:00:40.253643]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 21:00:40.369951]: ====================
[2018-04-17 21:00:40.374973]: Elapsed time since starting training: 1:40:06.539604
[2018-04-17 21:00:40.380479]: Estimated time left: -1 day, 23:34:53.455391
[2018-04-17 21:00:40.384991]: ====================
[2018-04-17 21:00:40.455177]: [Epoch: 825(82.58258258258259%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 21:00:41.726057]: [Epoch: 825(82.58258258258259%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 21:00:42.997938]: [Epoch: 825(82.58258258258259%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 21:00:46.536848]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:00:46.653660]: ====================
[2018-04-17 21:00:46.658672]: Elapsed time since starting training: 1:40:12.822802
[2018-04-17 21:00:46.663686]: Estimated time left: -1 day, 23:34:47.171683
[2018-04-17 21:00:46.668699]: ====================
[2018-04-17 21:00:46.738885]: [Epoch: 826(82.68268268268268%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:00:48.026309]: [Epoch: 826(82.68268268268268%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:00:49.307716]: [Epoch: 826(82.68268268268268%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 21:00:52.906786]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:00:53.018584]: ====================
[2018-04-17 21:00:53.024098]: Elapsed time since starting training: 1:40:19.188729
[2018-04-17 21:00:53.028609]: Estimated time left: -1 day, 23:34:40.806760
[2018-04-17 21:00:53.033623]: ====================
[2018-04-17 21:00:53.103810]: [Epoch: 827(82.78278278278279%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:00:54.400758]: [Epoch: 827(82.78278278278279%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:00:55.701717]: [Epoch: 827(82.78278278278279%): Data: 50.66666666666667%]:Running loss: 8.483217224478722
[2018-04-17 21:00:59.363455]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:00:59.474750]: ====================
[2018-04-17 21:00:59.479764]: Elapsed time since starting training: 1:40:25.643893
[2018-04-17 21:00:59.485279]: Estimated time left: -1 day, 23:34:34.350592
[2018-04-17 21:00:59.489289]: ====================
[2018-04-17 21:00:59.560979]: [Epoch: 828(82.88288288288288%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:01:00.861437]: [Epoch: 828(82.88288288288288%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:01:02.120285]: [Epoch: 828(82.88288288288288%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 21:01:05.716847]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:01:05.841179]: ====================
[2018-04-17 21:01:05.846693]: Elapsed time since starting training: 1:40:32.010823
[2018-04-17 21:01:05.851205]: Estimated time left: -1 day, 23:34:27.984164
[2018-04-17 21:01:05.857722]: ====================
[2018-04-17 21:01:05.933925]: [Epoch: 829(82.98298298298297%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:01:07.218841]: [Epoch: 829(82.98298298298297%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:01:08.467662]: [Epoch: 829(82.98298298298297%): Data: 50.66666666666667%]:Running loss: 8.483218565583229
[2018-04-17 21:01:12.033644]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:01:12.159479]: ====================
[2018-04-17 21:01:12.165494]: Elapsed time since starting training: 1:40:38.329636
[2018-04-17 21:01:12.170007]: Estimated time left: -1 day, 23:34:21.665362
[2018-04-17 21:01:12.175522]: ====================
[2018-04-17 21:01:12.248216]: [Epoch: 830(83.08308308308308%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:01:13.530123]: [Epoch: 830(83.08308308308308%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:01:14.806517]: [Epoch: 830(83.08308308308308%): Data: 50.66666666666667%]:Running loss: 8.483217269182205
[2018-04-17 21:01:18.351443]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 21:01:18.469757]: ====================
[2018-04-17 21:01:18.474269]: Elapsed time since starting training: 1:40:44.638900
[2018-04-17 21:01:18.478782]: Estimated time left: -1 day, 23:34:15.357088
[2018-04-17 21:01:18.482793]: ====================
[2018-04-17 21:01:18.552979]: [Epoch: 831(83.18318318318319%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 21:01:19.841405]: [Epoch: 831(83.18318318318319%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 21:01:21.123313]: [Epoch: 831(83.18318318318319%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 21:01:24.753466]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:01:24.870778]: ====================
[2018-04-17 21:01:24.875791]: Elapsed time since starting training: 1:40:51.040422
[2018-04-17 21:01:24.880805]: Estimated time left: -1 day, 23:34:08.954564
[2018-04-17 21:01:24.885316]: ====================
[2018-04-17 21:01:24.953498]: [Epoch: 832(83.28328328328328%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:01:26.273006]: [Epoch: 832(83.28328328328328%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 21:01:27.571960]: [Epoch: 832(83.28328328328328%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 21:01:31.233697]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:01:31.349004]: ====================
[2018-04-17 21:01:31.353516]: Elapsed time since starting training: 1:40:57.518147
[2018-04-17 21:01:31.358529]: Estimated time left: -1 day, 23:34:02.477341
[2018-04-17 21:01:31.363542]: ====================
[2018-04-17 21:01:31.434731]: [Epoch: 833(83.38338338338338%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:01:32.736693]: [Epoch: 833(83.38338338338338%): Data: 25.333333333333336%]:Running loss: 4.350369364023209
[2018-04-17 21:01:34.015594]: [Epoch: 833(83.38338338338338%): Data: 50.66666666666667%]:Running loss: 8.4832204580307
[2018-04-17 21:01:37.636221]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:01:37.755538]: ====================
[2018-04-17 21:01:37.760050]: Elapsed time since starting training: 1:41:03.924681
[2018-04-17 21:01:37.765064]: Estimated time left: -1 day, 23:33:56.070806
[2018-04-17 21:01:37.769576]: ====================
[2018-04-17 21:01:37.842269]: [Epoch: 834(83.48348348348348%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:01:39.151751]: [Epoch: 834(83.48348348348348%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:01:40.418620]: [Epoch: 834(83.48348348348348%): Data: 50.66666666666667%]:Running loss: 8.483220890164375
[2018-04-17 21:01:44.063311]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 21:01:44.179620]: ====================
[2018-04-17 21:01:44.185135]: Elapsed time since starting training: 1:41:10.349766
[2018-04-17 21:01:44.189647]: Estimated time left: -1 day, 23:33:49.645722
[2018-04-17 21:01:44.194159]: ====================
[2018-04-17 21:01:44.267353]: [Epoch: 835(83.58358358358359%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 21:01:45.553776]: [Epoch: 835(83.58358358358359%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 21:01:46.824153]: [Epoch: 835(83.58358358358359%): Data: 50.66666666666667%]:Running loss: 8.483221247792244
[2018-04-17 21:01:50.408683]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 21:01:50.528502]: ====================
[2018-04-17 21:01:50.533516]: Elapsed time since starting training: 1:41:16.697645
[2018-04-17 21:01:50.538528]: Estimated time left: -1 day, 23:33:43.297342
[2018-04-17 21:01:50.543040]: ====================
[2018-04-17 21:01:50.625259]: [Epoch: 836(83.68368368368368%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 21:01:51.929732]: [Epoch: 836(83.68368368368368%): Data: 25.333333333333336%]:Running loss: 4.350369870662689
[2018-04-17 21:01:53.208633]: [Epoch: 836(83.68368368368368%): Data: 50.66666666666667%]:Running loss: 8.483221754431725
[2018-04-17 21:01:56.877892]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:01:57.002224]: ====================
[2018-04-17 21:01:57.007237]: Elapsed time since starting training: 1:41:23.171868
[2018-04-17 21:01:57.012250]: Estimated time left: -1 day, 23:33:36.823620
[2018-04-17 21:01:57.017264]: ====================
[2018-04-17 21:01:57.088954]: [Epoch: 837(83.78378378378379%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:01:58.363342]: [Epoch: 837(83.78378378378379%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:01:59.639235]: [Epoch: 837(83.78378378378379%): Data: 50.66666666666667%]:Running loss: 8.483222469687462
[2018-04-17 21:02:03.195691]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:02:03.319020]: ====================
[2018-04-17 21:02:03.324033]: Elapsed time since starting training: 1:41:29.488664
[2018-04-17 21:02:03.329046]: Estimated time left: -1 day, 23:33:30.506323
[2018-04-17 21:02:03.334563]: ====================
[2018-04-17 21:02:03.408760]: [Epoch: 838(83.88388388388388%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:02:04.670112]: [Epoch: 838(83.88388388388388%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:02:05.963551]: [Epoch: 838(83.88388388388388%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 21:02:09.593203]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:02:09.830835]: ====================
[2018-04-17 21:02:09.836349]: Elapsed time since starting training: 1:41:36.000980
[2018-04-17 21:02:09.841363]: Estimated time left: -1 day, 23:33:23.994507
[2018-04-17 21:02:09.846376]: ====================
[2018-04-17 21:02:09.919570]: [Epoch: 839(83.98398398398398%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:02:11.198471]: [Epoch: 839(83.98398398398398%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:02:12.489403]: [Epoch: 839(83.98398398398398%): Data: 50.66666666666667%]:Running loss: 8.483224600553513
[2018-04-17 21:02:16.060900]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:02:16.184228]: ====================
[2018-04-17 21:02:16.189242]: Elapsed time since starting training: 1:41:42.353372
[2018-04-17 21:02:16.194756]: Estimated time left: -1 day, 23:33:17.641115
[2018-04-17 21:02:16.198767]: ====================
[2018-04-17 21:02:16.265945]: [Epoch: 840(84.08408408408408%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:02:17.568910]: [Epoch: 840(84.08408408408408%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 21:02:18.841795]: [Epoch: 840(84.08408408408408%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 21:02:22.460416]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:02:22.575222]: ====================
[2018-04-17 21:02:22.580235]: Elapsed time since starting training: 1:41:48.744866
[2018-04-17 21:02:22.584747]: Estimated time left: -1 day, 23:33:11.250622
[2018-04-17 21:02:22.589760]: ====================
[2018-04-17 21:02:22.659947]: [Epoch: 841(84.18418418418419%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:02:23.944362]: [Epoch: 841(84.18418418418419%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:02:25.287434]: [Epoch: 841(84.18418418418419%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:02:28.963708]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:02:29.077010]: ====================
[2018-04-17 21:02:29.082023]: Elapsed time since starting training: 1:41:55.246654
[2018-04-17 21:02:29.086535]: Estimated time left: -1 day, 23:33:04.748834
[2018-04-17 21:02:29.091549]: ====================
[2018-04-17 21:02:29.161242]: [Epoch: 842(84.28428428428428%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:02:30.483751]: [Epoch: 842(84.28428428428428%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:02:31.773179]: [Epoch: 842(84.28428428428428%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 21:02:35.371748]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:02:35.491065]: ====================
[2018-04-17 21:02:35.496580]: Elapsed time since starting training: 1:42:01.660709
[2018-04-17 21:02:35.500590]: Estimated time left: -1 day, 23:32:58.334779
[2018-04-17 21:02:35.504600]: ====================
[2018-04-17 21:02:35.572281]: [Epoch: 843(84.38438438438438%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:02:36.858701]: [Epoch: 843(84.38438438438438%): Data: 25.333333333333336%]:Running loss: 4.350372895598412
[2018-04-17 21:02:38.139607]: [Epoch: 843(84.38438438438438%): Data: 50.66666666666667%]:Running loss: 8.483227387070656
[2018-04-17 21:02:41.714613]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:02:41.831424]: ====================
[2018-04-17 21:02:41.836951]: Elapsed time since starting training: 1:42:08.001582
[2018-04-17 21:02:41.841450]: Estimated time left: -1 day, 23:32:51.993919
[2018-04-17 21:02:41.845962]: ====================
[2018-04-17 21:02:41.918656]: [Epoch: 844(84.48448448448448%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:02:43.169985]: [Epoch: 844(84.48448448448448%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:02:44.453396]: [Epoch: 844(84.48448448448448%): Data: 50.66666666666667%]:Running loss: 8.483228206634521
[2018-04-17 21:02:48.088060]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:02:48.225426]: ====================
[2018-04-17 21:02:48.229938]: Elapsed time since starting training: 1:42:14.394569
[2018-04-17 21:02:48.234951]: Estimated time left: -1 day, 23:32:45.600920
[2018-04-17 21:02:48.238961]: ====================
[2018-04-17 21:02:48.310150]: [Epoch: 845(84.58458458458459%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:02:49.579532]: [Epoch: 845(84.58458458458459%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:02:50.848400]: [Epoch: 845(84.58458458458459%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:02:54.482065]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:02:54.595366]: ====================
[2018-04-17 21:02:54.600379]: Elapsed time since starting training: 1:42:20.764509
[2018-04-17 21:02:54.604390]: Estimated time left: -1 day, 23:32:39.230979
[2018-04-17 21:02:54.607899]: ====================
[2018-04-17 21:02:54.680091]: [Epoch: 846(84.68468468468468%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:02:55.945957]: [Epoch: 846(84.68468468468468%): Data: 25.333333333333336%]:Running loss: 4.350374087691307
[2018-04-17 21:02:57.228868]: [Epoch: 846(84.68468468468468%): Data: 50.66666666666667%]:Running loss: 8.483229711651802
[2018-04-17 21:03:00.736696]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 21:03:00.858019]: ====================
[2018-04-17 21:03:00.863032]: Elapsed time since starting training: 1:42:27.027161
[2018-04-17 21:03:00.868045]: Estimated time left: -1 day, 23:32:32.967324
[2018-04-17 21:03:00.873560]: ====================
[2018-04-17 21:03:00.943746]: [Epoch: 847(84.78478478478479%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 21:03:02.179030]: [Epoch: 847(84.78478478478479%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 21:03:03.471627]: [Epoch: 847(84.78478478478479%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 21:03:07.001514]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:03:07.115316]: ====================
[2018-04-17 21:03:07.120330]: Elapsed time since starting training: 1:42:33.284460
[2018-04-17 21:03:07.124842]: Estimated time left: -1 day, 23:32:26.710527
[2018-04-17 21:03:07.129355]: ====================
[2018-04-17 21:03:07.200543]: [Epoch: 848(84.88488488488488%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:03:08.473929]: [Epoch: 848(84.88488488488488%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 21:03:09.749821]: [Epoch: 848(84.88488488488488%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 21:03:13.357414]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:03:13.479740]: ====================
[2018-04-17 21:03:13.485254]: Elapsed time since starting training: 1:42:39.649389
[2018-04-17 21:03:13.489766]: Estimated time left: -1 day, 23:32:20.345603
[2018-04-17 21:03:13.494779]: ====================
[2018-04-17 21:03:13.566470]: [Epoch: 849(84.98498498498499%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:03:14.871440]: [Epoch: 849(84.98498498498499%): Data: 25.333333333333336%]:Running loss: 4.350374862551689
[2018-04-17 21:03:16.156858]: [Epoch: 849(84.98498498498499%): Data: 50.66666666666667%]:Running loss: 8.483231619000435
[2018-04-17 21:03:19.745400]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 21:03:19.862714]: ====================
[2018-04-17 21:03:19.868226]: Elapsed time since starting training: 1:42:46.032356
[2018-04-17 21:03:19.873746]: Estimated time left: -1 day, 23:32:13.961623
[2018-04-17 21:03:19.878754]: ====================
[2018-04-17 21:03:19.944931]: [Epoch: 850(85.08508508508508%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 21:03:21.204780]: [Epoch: 850(85.08508508508508%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 21:03:22.456108]: [Epoch: 850(85.08508508508508%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 21:03:26.081748]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 21:03:26.199059]: ====================
[2018-04-17 21:03:26.204073]: Elapsed time since starting training: 1:42:52.368704
[2018-04-17 21:03:26.209092]: Estimated time left: -1 day, 23:32:07.626277
[2018-04-17 21:03:26.214100]: ====================
[2018-04-17 21:03:26.284286]: [Epoch: 851(85.18518518518519%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 21:03:27.571208]: [Epoch: 851(85.18518518518519%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 21:03:28.851619]: [Epoch: 851(85.18518518518519%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 21:03:32.475255]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:03:32.593570]: ====================
[2018-04-17 21:03:32.598584]: Elapsed time since starting training: 1:42:58.762713
[2018-04-17 21:03:32.602594]: Estimated time left: -1 day, 23:32:01.232775
[2018-04-17 21:03:32.607105]: ====================
[2018-04-17 21:03:32.676290]: [Epoch: 852(85.28528528528528%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:03:33.954689]: [Epoch: 852(85.28528528528528%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:03:35.191478]: [Epoch: 852(85.28528528528528%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:03:38.824136]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 21:03:38.938442]: ====================
[2018-04-17 21:03:38.942953]: Elapsed time since starting training: 1:43:05.107584
[2018-04-17 21:03:38.947966]: Estimated time left: -1 day, 23:31:54.887403
[2018-04-17 21:03:38.952478]: ====================
[2018-04-17 21:03:39.026683]: [Epoch: 853(85.38538538538538%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 21:03:40.297053]: [Epoch: 853(85.38538538538538%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 21:03:41.595505]: [Epoch: 853(85.38538538538538%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 21:03:45.232175]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 21:03:45.336955]: ====================
[2018-04-17 21:03:45.341466]: Elapsed time since starting training: 1:43:11.506097
[2018-04-17 21:03:45.345978]: Estimated time left: -1 day, 23:31:48.489391
[2018-04-17 21:03:45.350490]: ====================
[2018-04-17 21:03:45.422181]: [Epoch: 854(85.4854854854855%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 21:03:46.717625]: [Epoch: 854(85.4854854854855%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 21:03:48.047662]: [Epoch: 854(85.4854854854855%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 21:03:51.571532]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:03:51.679318]: ====================
[2018-04-17 21:03:51.683831]: Elapsed time since starting training: 1:43:17.848462
[2018-04-17 21:03:51.688844]: Estimated time left: -1 day, 23:31:42.146525
[2018-04-17 21:03:51.693356]: ====================
[2018-04-17 21:03:51.760535]: [Epoch: 855(85.58558558558559%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:03:53.045952]: [Epoch: 855(85.58558558558559%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:03:54.298787]: [Epoch: 855(85.58558558558559%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:03:57.831176]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:03:57.951998]: ====================
[2018-04-17 21:03:57.958515]: Elapsed time since starting training: 1:43:24.122645
[2018-04-17 21:03:57.964031]: Estimated time left: -1 day, 23:31:35.871338
[2018-04-17 21:03:57.969043]: ====================
[2018-04-17 21:03:58.035720]: [Epoch: 856(85.68568568568568%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:03:59.274012]: [Epoch: 856(85.68568568568568%): Data: 25.333333333333336%]:Running loss: 4.350376784801483
[2018-04-17 21:04:00.699804]: [Epoch: 856(85.68568568568568%): Data: 50.66666666666667%]:Running loss: 8.483235239982605
[2018-04-17 21:04:04.480857]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 21:04:04.612207]: ====================
[2018-04-17 21:04:04.616719]: Elapsed time since starting training: 1:43:30.781350
[2018-04-17 21:04:04.621232]: Estimated time left: -1 day, 23:31:29.214137
[2018-04-17 21:04:04.625743]: ====================
[2018-04-17 21:04:04.699439]: [Epoch: 857(85.78578578578579%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 21:04:06.029977]: [Epoch: 857(85.78578578578579%): Data: 25.333333333333336%]:Running loss: 4.350377321243286
[2018-04-17 21:04:07.357005]: [Epoch: 857(85.78578578578579%): Data: 50.66666666666667%]:Running loss: 8.483235776424408
[2018-04-17 21:04:11.002699]: Test set accuracy: 94.33962264150944% ,loss = 5.437972396612167
[2018-04-17 21:04:11.121015]: ====================
[2018-04-17 21:04:11.125526]: Elapsed time since starting training: 1:43:37.290157
[2018-04-17 21:04:11.130038]: Estimated time left: -1 day, 23:31:22.705331
[2018-04-17 21:04:11.134048]: ====================
[2018-04-17 21:04:11.206742]: [Epoch: 858(85.88588588588588%): Data: 0.0%]:Running loss: 0.2175188958644867
[2018-04-17 21:04:12.506698]: [Epoch: 858(85.88588588588588%): Data: 25.333333333333336%]:Running loss: 4.350370615720749
[2018-04-17 21:04:13.853278]: [Epoch: 858(85.88588588588588%): Data: 50.66666666666667%]:Running loss: 8.483219727873802
[2018-04-17 21:04:17.380157]: Test set accuracy: 94.33962264150944% ,loss = 5.437959358096123
[2018-04-17 21:04:17.486941]: ====================
[2018-04-17 21:04:17.491453]: Elapsed time since starting training: 1:43:43.656084
[2018-04-17 21:04:17.496466]: Estimated time left: -1 day, 23:31:16.339404
[2018-04-17 21:04:17.500978]: ====================
[2018-04-17 21:04:17.568157]: [Epoch: 859(85.98598598598599%): Data: 0.0%]:Running loss: 0.2175183743238449
[2018-04-17 21:04:18.870620]: [Epoch: 859(85.98598598598599%): Data: 25.333333333333336%]:Running loss: 4.350367844104767
[2018-04-17 21:04:20.139995]: [Epoch: 859(85.98598598598599%): Data: 50.66666666666667%]:Running loss: 8.483217522501945
[2018-04-17 21:04:23.734553]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 21:04:23.834820]: ====================
[2018-04-17 21:04:23.839834]: Elapsed time since starting training: 1:43:50.003963
[2018-04-17 21:04:23.844345]: Estimated time left: -1 day, 23:31:09.991525
[2018-04-17 21:04:23.848356]: ====================
[2018-04-17 21:04:23.918542]: [Epoch: 860(86.08608608608608%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 21:04:25.205464]: [Epoch: 860(86.08608608608608%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 21:04:26.512439]: [Epoch: 860(86.08608608608608%): Data: 50.66666666666667%]:Running loss: 8.483217984437943
[2018-04-17 21:04:30.134069]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:04:30.236844]: ====================
[2018-04-17 21:04:30.241355]: Elapsed time since starting training: 1:43:56.405986
[2018-04-17 21:04:30.245866]: Estimated time left: -1 day, 23:31:03.589503
[2018-04-17 21:04:30.250391]: ====================
[2018-04-17 21:04:30.323573]: [Epoch: 861(86.18618618618619%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:04:31.652106]: [Epoch: 861(86.18618618618619%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 21:04:32.959081]: [Epoch: 861(86.18618618618619%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 21:04:36.497991]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:04:36.602269]: ====================
[2018-04-17 21:04:36.607281]: Elapsed time since starting training: 1:44:02.771912
[2018-04-17 21:04:36.611793]: Estimated time left: -1 day, 23:30:57.223576
[2018-04-17 21:04:36.616306]: ====================
[2018-04-17 21:04:36.688999]: [Epoch: 862(86.28628628628628%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:04:37.952859]: [Epoch: 862(86.28628628628628%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 21:04:39.214714]: [Epoch: 862(86.28628628628628%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 21:04:42.738083]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:04:42.844867]: ====================
[2018-04-17 21:04:42.849379]: Elapsed time since starting training: 1:44:09.013509
[2018-04-17 21:04:42.853892]: Estimated time left: -1 day, 23:30:50.981973
[2018-04-17 21:04:42.858403]: ====================
[2018-04-17 21:04:42.922574]: [Epoch: 863(86.38638638638638%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:04:44.178413]: [Epoch: 863(86.38638638638638%): Data: 25.333333333333336%]:Running loss: 4.350369483232498
[2018-04-17 21:04:45.466338]: [Epoch: 863(86.38638638638638%): Data: 50.66666666666667%]:Running loss: 8.48322057723999
[2018-04-17 21:04:49.030815]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:04:49.136597]: ====================
[2018-04-17 21:04:49.143615]: Elapsed time since starting training: 1:44:15.308246
[2018-04-17 21:04:49.147628]: Estimated time left: -1 day, 23:30:44.687741
[2018-04-17 21:04:49.152138]: ====================
[2018-04-17 21:04:49.225834]: [Epoch: 864(86.48648648648648%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:04:50.518271]: [Epoch: 864(86.48648648648648%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:04:51.820734]: [Epoch: 864(86.48648648648648%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 21:04:55.343100]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 21:04:55.446875]: ====================
[2018-04-17 21:04:55.451388]: Elapsed time since starting training: 1:44:21.616019
[2018-04-17 21:04:55.456401]: Estimated time left: -1 day, 23:30:38.379469
[2018-04-17 21:04:55.461916]: ====================
[2018-04-17 21:04:55.527590]: [Epoch: 865(86.58658658658659%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 21:04:56.859131]: [Epoch: 865(86.58658658658659%): Data: 25.333333333333336%]:Running loss: 4.35037037730217
[2018-04-17 21:04:58.197189]: [Epoch: 865(86.58658658658659%): Data: 50.66666666666667%]:Running loss: 8.48322232067585
[2018-04-17 21:05:01.818318]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:05:01.921091]: ====================
[2018-04-17 21:05:01.925603]: Elapsed time since starting training: 1:44:28.090234
[2018-04-17 21:05:01.930115]: Estimated time left: -1 day, 23:30:31.905756
[2018-04-17 21:05:01.934627]: ====================
[2018-04-17 21:05:02.005825]: [Epoch: 866(86.68668668668668%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:05:03.300258]: [Epoch: 866(86.68668668668668%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:05:04.634305]: [Epoch: 866(86.68668668668668%): Data: 50.66666666666667%]:Running loss: 8.483223035931587
[2018-04-17 21:05:08.219839]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:05:08.329631]: ====================
[2018-04-17 21:05:08.334143]: Elapsed time since starting training: 1:44:34.498774
[2018-04-17 21:05:08.338154]: Estimated time left: -1 day, 23:30:25.497215
[2018-04-17 21:05:08.342666]: ====================
[2018-04-17 21:05:08.407839]: [Epoch: 867(86.78678678678679%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:05:09.705790]: [Epoch: 867(86.78678678678679%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:05:10.971656]: [Epoch: 867(86.78678678678679%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 21:05:14.497531]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:05:14.604315]: ====================
[2018-04-17 21:05:14.608827]: Elapsed time since starting training: 1:44:40.773458
[2018-04-17 21:05:14.613841]: Estimated time left: -1 day, 23:30:19.222029
[2018-04-17 21:05:14.617851]: ====================
[2018-04-17 21:05:14.689040]: [Epoch: 868(86.88688688688688%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:05:15.966437]: [Epoch: 868(86.88688688688688%): Data: 25.333333333333336%]:Running loss: 4.350371316075325
[2018-04-17 21:05:17.278426]: [Epoch: 868(86.88688688688688%): Data: 50.66666666666667%]:Running loss: 8.483224108815193
[2018-04-17 21:05:20.875991]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:05:20.984280]: ====================
[2018-04-17 21:05:20.989794]: Elapsed time since starting training: 1:44:47.154425
[2018-04-17 21:05:20.995309]: Estimated time left: -1 day, 23:30:12.840060
[2018-04-17 21:05:20.999319]: ====================
[2018-04-17 21:05:21.069506]: [Epoch: 869(86.98698698698699%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:05:22.373975]: [Epoch: 869(86.98698698698699%): Data: 25.333333333333336%]:Running loss: 4.350371718406677
[2018-04-17 21:05:23.678945]: [Epoch: 869(86.98698698698699%): Data: 50.66666666666667%]:Running loss: 8.483224600553513
[2018-04-17 21:05:27.213342]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:05:27.337674]: ====================
[2018-04-17 21:05:27.344191]: Elapsed time since starting training: 1:44:53.508320
[2018-04-17 21:05:27.348703]: Estimated time left: -1 day, 23:30:06.486666
[2018-04-17 21:05:27.356724]: ====================
[2018-04-17 21:05:27.423904]: [Epoch: 870(87.08708708708708%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:05:28.720851]: [Epoch: 870(87.08708708708708%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 21:05:30.003261]: [Epoch: 870(87.08708708708708%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 21:05:33.606843]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:05:33.740699]: ====================
[2018-04-17 21:05:33.745713]: Elapsed time since starting training: 1:44:59.909842
[2018-04-17 21:05:33.749723]: Estimated time left: -1 day, 23:30:00.085646
[2018-04-17 21:05:33.753734]: ====================
[2018-04-17 21:05:33.827931]: [Epoch: 871(87.18718718718719%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:05:35.096805]: [Epoch: 871(87.18718718718719%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:05:36.456921]: [Epoch: 871(87.18718718718719%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 21:05:40.049474]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:05:40.171799]: ====================
[2018-04-17 21:05:40.178316]: Elapsed time since starting training: 1:45:06.342446
[2018-04-17 21:05:40.183330]: Estimated time left: -1 day, 23:29:53.652039
[2018-04-17 21:05:40.190850]: ====================
[2018-04-17 21:05:40.262039]: [Epoch: 872(87.28728728728728%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:05:41.554977]: [Epoch: 872(87.28728728728728%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:05:42.854934]: [Epoch: 872(87.28728728728728%): Data: 50.66666666666667%]:Running loss: 8.48322668671608
[2018-04-17 21:05:46.473555]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:05:46.614431]: ====================
[2018-04-17 21:05:46.619443]: Elapsed time since starting training: 1:45:12.784074
[2018-04-17 21:05:46.624959]: Estimated time left: -1 day, 23:29:47.210913
[2018-04-17 21:05:46.629470]: ====================
[2018-04-17 21:05:46.699657]: [Epoch: 873(87.38738738738738%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:05:47.966525]: [Epoch: 873(87.38738738738738%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:05:49.213842]: [Epoch: 873(87.38738738738738%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:05:52.742725]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 21:05:52.856026]: ====================
[2018-04-17 21:05:52.861039]: Elapsed time since starting training: 1:45:19.025170
[2018-04-17 21:05:52.866054]: Estimated time left: -1 day, 23:29:40.969817
[2018-04-17 21:05:52.871067]: ====================
[2018-04-17 21:05:52.941754]: [Epoch: 874(87.4874874874875%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 21:05:54.223663]: [Epoch: 874(87.4874874874875%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 21:05:55.481006]: [Epoch: 874(87.4874874874875%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 21:05:59.041975]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:05:59.157783]: ====================
[2018-04-17 21:05:59.162796]: Elapsed time since starting training: 1:45:25.326925
[2018-04-17 21:05:59.167308]: Estimated time left: -1 day, 23:29:34.668061
[2018-04-17 21:05:59.171820]: ====================
[2018-04-17 21:05:59.238998]: [Epoch: 875(87.58758758758759%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:06:00.534443]: [Epoch: 875(87.58758758758759%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:06:01.791285]: [Epoch: 875(87.58758758758759%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:06:05.378323]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:06:05.512178]: ====================
[2018-04-17 21:06:05.517193]: Elapsed time since starting training: 1:45:31.681824
[2018-04-17 21:06:05.522206]: Estimated time left: -1 day, 23:29:28.313163
[2018-04-17 21:06:05.526717]: ====================
[2018-04-17 21:06:05.598910]: [Epoch: 876(87.68768768768768%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:06:06.895357]: [Epoch: 876(87.68768768768768%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:06:08.150193]: [Epoch: 876(87.68768768768768%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:06:11.701636]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:06:11.827973]: ====================
[2018-04-17 21:06:11.832987]: Elapsed time since starting training: 1:45:37.997618
[2018-04-17 21:06:11.837999]: Estimated time left: -1 day, 23:29:21.997370
[2018-04-17 21:06:11.843514]: ====================
[2018-04-17 21:06:11.914703]: [Epoch: 877(87.78778778778779%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:06:13.171055]: [Epoch: 877(87.78778778778779%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 21:06:14.438414]: [Epoch: 877(87.78778778778779%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 21:06:18.017932]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:06:18.146273]: ====================
[2018-04-17 21:06:18.153292]: Elapsed time since starting training: 1:45:44.317421
[2018-04-17 21:06:18.159308]: Estimated time left: -1 day, 23:29:15.676061
[2018-04-17 21:06:18.165824]: ====================
[2018-04-17 21:06:18.241526]: [Epoch: 878(87.88788788788789%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:06:19.566048]: [Epoch: 878(87.88788788788789%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 21:06:20.825397]: [Epoch: 878(87.88788788788789%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 21:06:24.431987]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:06:24.563837]: ====================
[2018-04-17 21:06:24.568349]: Elapsed time since starting training: 1:45:50.732480
[2018-04-17 21:06:24.573864]: Estimated time left: -1 day, 23:29:09.261505
[2018-04-17 21:06:24.578877]: ====================
[2018-04-17 21:06:24.651570]: [Epoch: 879(87.98798798798799%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:06:25.903399]: [Epoch: 879(87.98798798798799%): Data: 25.333333333333336%]:Running loss: 4.350373163819313
[2018-04-17 21:06:27.173275]: [Epoch: 879(87.98798798798799%): Data: 50.66666666666667%]:Running loss: 8.483228221535683
[2018-04-17 21:06:30.754297]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 21:06:30.868100]: ====================
[2018-04-17 21:06:30.873114]: Elapsed time since starting training: 1:45:57.037745
[2018-04-17 21:06:30.878127]: Estimated time left: -1 day, 23:29:02.957744
[2018-04-17 21:06:30.882137]: ====================
[2018-04-17 21:06:30.955332]: [Epoch: 880(88.08808808808809%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 21:06:32.243256]: [Epoch: 880(88.08808808808809%): Data: 25.333333333333336%]:Running loss: 4.350373387336731
[2018-04-17 21:06:33.511629]: [Epoch: 880(88.08808808808809%): Data: 50.66666666666667%]:Running loss: 8.48322731256485
[2018-04-17 21:06:37.056555]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:06:37.178880]: ====================
[2018-04-17 21:06:37.184395]: Elapsed time since starting training: 1:46:03.349026
[2018-04-17 21:06:37.189408]: Estimated time left: -1 day, 23:28:56.646462
[2018-04-17 21:06:37.194422]: ====================
[2018-04-17 21:06:37.267617]: [Epoch: 881(88.18818818818819%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:06:38.543509]: [Epoch: 881(88.18818818818819%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:06:39.807369]: [Epoch: 881(88.18818818818819%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:06:43.353298]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:06:43.469607]: ====================
[2018-04-17 21:06:43.474621]: Elapsed time since starting training: 1:46:09.638751
[2018-04-17 21:06:43.478631]: Estimated time left: -1 day, 23:28:50.356738
[2018-04-17 21:06:43.484146]: ====================
[2018-04-17 21:06:43.552829]: [Epoch: 882(88.28828828828829%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:06:44.808166]: [Epoch: 882(88.28828828828829%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:06:46.084560]: [Epoch: 882(88.28828828828829%): Data: 50.66666666666667%]:Running loss: 8.48322831094265
[2018-04-17 21:06:49.667588]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:06:49.799940]: ====================
[2018-04-17 21:06:49.804953]: Elapsed time since starting training: 1:46:15.969082
[2018-04-17 21:06:49.808964]: Estimated time left: -1 day, 23:28:44.026405
[2018-04-17 21:06:49.814478]: ====================
[2018-04-17 21:06:49.881657]: [Epoch: 883(88.38838838838838%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:06:51.163064]: [Epoch: 883(88.38838838838838%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:06:52.439960]: [Epoch: 883(88.38838838838838%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:06:55.999925]: Test set accuracy: 94.33962264150944% ,loss = 5.437967926263809
[2018-04-17 21:06:56.111221]: ====================
[2018-04-17 21:06:56.116234]: Elapsed time since starting training: 1:46:22.280865
[2018-04-17 21:06:56.121248]: Estimated time left: -1 day, 23:28:37.714121
[2018-04-17 21:06:56.125760]: ====================
[2018-04-17 21:06:56.195946]: [Epoch: 884(88.48848848848849%): Data: 0.0%]:Running loss: 0.21751871705055237
[2018-04-17 21:06:57.446271]: [Epoch: 884(88.48848848848849%): Data: 25.333333333333336%]:Running loss: 4.350374341011047
[2018-04-17 21:06:58.693087]: [Epoch: 884(88.48848848848849%): Data: 50.66666666666667%]:Running loss: 8.483229964971542
[2018-04-17 21:07:02.210940]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:07:02.331261]: ====================
[2018-04-17 21:07:02.336775]: Elapsed time since starting training: 1:46:28.500905
[2018-04-17 21:07:02.341287]: Estimated time left: -1 day, 23:28:31.494082
[2018-04-17 21:07:02.345799]: ====================
[2018-04-17 21:07:02.413479]: [Epoch: 885(88.58858858858859%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:07:03.658288]: [Epoch: 885(88.58858858858859%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 21:07:04.942203]: [Epoch: 885(88.58858858858859%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 21:07:08.478105]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 21:07:08.596921]: ====================
[2018-04-17 21:07:08.601433]: Elapsed time since starting training: 1:46:34.766064
[2018-04-17 21:07:08.605945]: Estimated time left: -1 day, 23:28:25.229926
[2018-04-17 21:07:08.610457]: ====================
[2018-04-17 21:07:08.685656]: [Epoch: 886(88.68868868868869%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 21:07:09.966061]: [Epoch: 886(88.68868868868869%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 21:07:11.231927]: [Epoch: 886(88.68868868868869%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 21:07:14.888149]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:07:14.998443]: ====================
[2018-04-17 21:07:15.003455]: Elapsed time since starting training: 1:46:41.168086
[2018-04-17 21:07:15.008469]: Estimated time left: -1 day, 23:28:18.827401
[2018-04-17 21:07:15.012981]: ====================
[2018-04-17 21:07:15.090688]: [Epoch: 887(88.78878878878879%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:07:16.398164]: [Epoch: 887(88.78878878878879%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:07:17.744744]: [Epoch: 887(88.78878878878879%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 21:07:21.481180]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:07:21.595985]: ====================
[2018-04-17 21:07:21.601500]: Elapsed time since starting training: 1:46:47.765630
[2018-04-17 21:07:21.606012]: Estimated time left: -1 day, 23:28:12.229357
[2018-04-17 21:07:21.610524]: ====================
[2018-04-17 21:07:21.683217]: [Epoch: 888(88.88888888888889%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:07:23.006736]: [Epoch: 888(88.88888888888889%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:07:24.276111]: [Epoch: 888(88.88888888888889%): Data: 50.66666666666667%]:Running loss: 8.483218029141426
[2018-04-17 21:07:27.844600]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:07:27.962414]: ====================
[2018-04-17 21:07:27.967427]: Elapsed time since starting training: 1:46:54.132058
[2018-04-17 21:07:27.972440]: Estimated time left: -1 day, 23:28:05.862929
[2018-04-17 21:07:27.977453]: ====================
[2018-04-17 21:07:28.053657]: [Epoch: 889(88.988988988989%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:07:29.282924]: [Epoch: 889(88.988988988989%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:07:30.521217]: [Epoch: 889(88.988988988989%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 21:07:34.058122]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:07:34.175935]: ====================
[2018-04-17 21:07:34.181449]: Elapsed time since starting training: 1:47:00.345579
[2018-04-17 21:07:34.185460]: Estimated time left: -1 day, 23:27:59.649909
[2018-04-17 21:07:34.185962]: ====================
[2018-04-17 21:07:34.254144]: [Epoch: 890(89.08908908908909%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:07:35.517001]: [Epoch: 890(89.08908908908909%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:07:36.830494]: [Epoch: 890(89.08908908908909%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 21:07:40.458139]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:07:40.594014]: ====================
[2018-04-17 21:07:40.599516]: Elapsed time since starting training: 1:47:06.764147
[2018-04-17 21:07:40.604528]: Estimated time left: -1 day, 23:27:53.230841
[2018-04-17 21:07:40.610043]: ====================
[2018-04-17 21:07:40.681734]: [Epoch: 891(89.1891891891892%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:07:41.968154]: [Epoch: 891(89.1891891891892%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 21:07:43.228505]: [Epoch: 891(89.1891891891892%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 21:07:46.843117]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:07:46.975469]: ====================
[2018-04-17 21:07:46.980983]: Elapsed time since starting training: 1:47:13.145114
[2018-04-17 21:07:46.985997]: Estimated time left: -1 day, 23:27:46.849372
[2018-04-17 21:07:46.991511]: ====================
[2018-04-17 21:07:47.063203]: [Epoch: 892(89.28928928928929%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:07:48.328567]: [Epoch: 892(89.28928928928929%): Data: 25.333333333333336%]:Running loss: 4.350369229912758
[2018-04-17 21:07:49.600448]: [Epoch: 892(89.28928928928929%): Data: 50.66666666666667%]:Running loss: 8.483219757676125
[2018-04-17 21:07:53.221076]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:07:53.359445]: ====================
[2018-04-17 21:07:53.366463]: Elapsed time since starting training: 1:47:19.531094
[2018-04-17 21:07:53.371978]: Estimated time left: -1 day, 23:27:40.463893
[2018-04-17 21:07:53.376489]: ====================
[2018-04-17 21:07:53.446174]: [Epoch: 893(89.38938938938938%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:07:54.731593]: [Epoch: 893(89.38938938938938%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:07:55.991452]: [Epoch: 893(89.38938938938938%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 21:07:59.516820]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:07:59.635638]: ====================
[2018-04-17 21:07:59.640149]: Elapsed time since starting training: 1:47:25.804780
[2018-04-17 21:07:59.645162]: Estimated time left: -1 day, 23:27:34.190207
[2018-04-17 21:07:59.650676]: ====================
[2018-04-17 21:07:59.718356]: [Epoch: 894(89.4894894894895%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:08:00.957150]: [Epoch: 894(89.4894894894895%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:08:02.231037]: [Epoch: 894(89.4894894894895%): Data: 50.66666666666667%]:Running loss: 8.483221516013145
[2018-04-17 21:08:05.767942]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:08:05.991537]: ====================
[2018-04-17 21:08:05.997052]: Elapsed time since starting training: 1:47:32.161181
[2018-04-17 21:08:06.002065]: Estimated time left: -1 day, 23:27:27.833806
[2018-04-17 21:08:06.006577]: ====================
[2018-04-17 21:08:06.073755]: [Epoch: 895(89.5895895895896%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:08:07.309040]: [Epoch: 895(89.5895895895896%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:08:08.570895]: [Epoch: 895(89.5895895895896%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 21:08:12.085741]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:08:12.207064]: ====================
[2018-04-17 21:08:12.211576]: Elapsed time since starting training: 1:47:38.376207
[2018-04-17 21:08:12.216088]: Estimated time left: -1 day, 23:27:21.619782
[2018-04-17 21:08:12.220600]: ====================
[2018-04-17 21:08:12.291794]: [Epoch: 896(89.68968968968969%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:08:13.547629]: [Epoch: 896(89.68968968968969%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:08:14.853100]: [Epoch: 896(89.68968968968969%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 21:08:18.389001]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:08:18.510324]: ====================
[2018-04-17 21:08:18.515839]: Elapsed time since starting training: 1:47:44.680470
[2018-04-17 21:08:18.520852]: Estimated time left: -1 day, 23:27:15.315018
[2018-04-17 21:08:18.525866]: ====================
[2018-04-17 21:08:18.597557]: [Epoch: 897(89.7897897897898%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:08:19.860916]: [Epoch: 897(89.7897897897898%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:08:21.111742]: [Epoch: 897(89.7897897897898%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 21:08:24.670203]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 21:08:24.790523]: ====================
[2018-04-17 21:08:24.795537]: Elapsed time since starting training: 1:47:50.960168
[2018-04-17 21:08:24.800550]: Estimated time left: -1 day, 23:27:09.034819
[2018-04-17 21:08:24.805062]: ====================
[2018-04-17 21:08:24.878758]: [Epoch: 898(89.88988988988989%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 21:08:26.158661]: [Epoch: 898(89.88988988988989%): Data: 25.333333333333336%]:Running loss: 4.350370228290558
[2018-04-17 21:08:27.425031]: [Epoch: 898(89.88988988988989%): Data: 50.66666666666667%]:Running loss: 8.4832224547863
[2018-04-17 21:08:30.990011]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:08:31.112337]: ====================
[2018-04-17 21:08:31.117852]: Elapsed time since starting training: 1:47:57.281981
[2018-04-17 21:08:31.122363]: Estimated time left: -1 day, 23:27:02.713006
[2018-04-17 21:08:31.127377]: ====================
[2018-04-17 21:08:31.200070]: [Epoch: 899(89.98998998999%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:08:32.462927]: [Epoch: 899(89.98998998999%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:08:33.711748]: [Epoch: 899(89.98998998999%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 21:08:37.251660]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:08:37.365464]: ====================
[2018-04-17 21:08:37.369975]: Elapsed time since starting training: 1:48:03.534606
[2018-04-17 21:08:37.374989]: Estimated time left: -1 day, 23:26:56.460380
[2018-04-17 21:08:37.380002]: ====================
[2018-04-17 21:08:37.443170]: [Epoch: 900(90.09009009009009%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:08:38.705025]: [Epoch: 900(90.09009009009009%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:08:39.961366]: [Epoch: 900(90.09009009009009%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 21:08:43.535369]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:08:43.657694]: ====================
[2018-04-17 21:08:43.663209]: Elapsed time since starting training: 1:48:09.827840
[2018-04-17 21:08:43.668222]: Estimated time left: -1 day, 23:26:50.167147
[2018-04-17 21:08:43.673236]: ====================
[2018-04-17 21:08:43.746431]: [Epoch: 901(90.1901901901902%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:08:45.020317]: [Epoch: 901(90.1901901901902%): Data: 25.333333333333336%]:Running loss: 4.350371539592743
[2018-04-17 21:08:46.286685]: [Epoch: 901(90.1901901901902%): Data: 50.66666666666667%]:Running loss: 8.4832251816988
[2018-04-17 21:08:49.854672]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:08:49.977499]: ====================
[2018-04-17 21:08:49.982512]: Elapsed time since starting training: 1:48:16.146642
[2018-04-17 21:08:49.988026]: Estimated time left: -1 day, 23:26:43.847343
[2018-04-17 21:08:49.993040]: ====================
[2018-04-17 21:08:50.065232]: [Epoch: 902(90.29029029029029%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:08:51.347642]: [Epoch: 902(90.29029029029029%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:08:52.586937]: [Epoch: 902(90.29029029029029%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:08:56.110305]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:08:56.226113]: ====================
[2018-04-17 21:08:56.231628]: Elapsed time since starting training: 1:48:22.396259
[2018-04-17 21:08:56.236642]: Estimated time left: -1 day, 23:26:37.598727
[2018-04-17 21:08:56.241655]: ====================
[2018-04-17 21:08:56.310840]: [Epoch: 903(90.39039039039038%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:08:57.553143]: [Epoch: 903(90.39039039039038%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:08:58.792437]: [Epoch: 903(90.39039039039038%): Data: 50.66666666666667%]:Running loss: 8.483224377036095
[2018-04-17 21:09:02.298260]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:09:02.410558]: ====================
[2018-04-17 21:09:02.415571]: Elapsed time since starting training: 1:48:28.580202
[2018-04-17 21:09:02.422089]: Estimated time left: -1 day, 23:26:31.413280
[2018-04-17 21:09:02.426601]: ====================
[2018-04-17 21:09:02.497790]: [Epoch: 904(90.49049049049049%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:09:03.754632]: [Epoch: 904(90.49049049049049%): Data: 25.333333333333336%]:Running loss: 4.350370794534683
[2018-04-17 21:09:05.023506]: [Epoch: 904(90.49049049049049%): Data: 50.66666666666667%]:Running loss: 8.483223304152489
[2018-04-17 21:09:08.608538]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:09:08.727355]: ====================
[2018-04-17 21:09:08.732368]: Elapsed time since starting training: 1:48:34.896497
[2018-04-17 21:09:08.737381]: Estimated time left: -1 day, 23:26:25.098490
[2018-04-17 21:09:08.742394]: ====================
[2018-04-17 21:09:08.814586]: [Epoch: 905(90.5905905905906%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:09:10.097998]: [Epoch: 905(90.5905905905906%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:09:11.336793]: [Epoch: 905(90.5905905905906%): Data: 50.66666666666667%]:Running loss: 8.483223587274551
[2018-04-17 21:09:14.910796]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:09:15.026604]: ====================
[2018-04-17 21:09:15.031116]: Elapsed time since starting training: 1:48:41.195747
[2018-04-17 21:09:15.036631]: Estimated time left: -1 day, 23:26:18.798738
[2018-04-17 21:09:15.041143]: ====================
[2018-04-17 21:09:15.111830]: [Epoch: 906(90.69069069069069%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:09:16.372182]: [Epoch: 906(90.69069069069069%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:09:17.634038]: [Epoch: 906(90.69069069069069%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 21:09:21.127827]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:09:21.251155]: ====================
[2018-04-17 21:09:21.256168]: Elapsed time since starting training: 1:48:47.420799
[2018-04-17 21:09:21.261683]: Estimated time left: -1 day, 23:26:12.573686
[2018-04-17 21:09:21.267198]: ====================
[2018-04-17 21:09:21.338889]: [Epoch: 907(90.7907907907908%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:09:22.595229]: [Epoch: 907(90.7907907907908%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 21:09:23.862599]: [Epoch: 907(90.7907907907908%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 21:09:27.417050]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:09:27.531855]: ====================
[2018-04-17 21:09:27.537370]: Elapsed time since starting training: 1:48:53.701500
[2018-04-17 21:09:27.542396]: Estimated time left: -1 day, 23:26:06.292973
[2018-04-17 21:09:27.546895]: ====================
[2018-04-17 21:09:27.618084]: [Epoch: 908(90.8908908908909%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:09:28.874926]: [Epoch: 908(90.8908908908909%): Data: 25.333333333333336%]:Running loss: 4.350372314453125
[2018-04-17 21:09:30.135286]: [Epoch: 908(90.8908908908909%): Data: 50.66666666666667%]:Running loss: 8.483226239681244
[2018-04-17 21:09:33.672182]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:09:33.788993]: ====================
[2018-04-17 21:09:33.793505]: Elapsed time since starting training: 1:48:59.958136
[2018-04-17 21:09:33.799020]: Estimated time left: -1 day, 23:26:00.036851
[2018-04-17 21:09:33.804033]: ====================
[2018-04-17 21:09:33.875724]: [Epoch: 909(90.990990990991%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:09:35.129557]: [Epoch: 909(90.990990990991%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:09:36.384895]: [Epoch: 909(90.990990990991%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 21:09:39.950376]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:09:40.056157]: ====================
[2018-04-17 21:09:40.060670]: Elapsed time since starting training: 1:49:06.225301
[2018-04-17 21:09:40.065683]: Estimated time left: -1 day, 23:25:53.769686
[2018-04-17 21:09:40.070195]: ====================
[2018-04-17 21:09:40.138376]: [Epoch: 910(91.09109109109109%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:09:41.483954]: [Epoch: 910(91.09109109109109%): Data: 25.333333333333336%]:Running loss: 4.350373029708862
[2018-04-17 21:09:42.774385]: [Epoch: 910(91.09109109109109%): Data: 50.66666666666667%]:Running loss: 8.483227521181107
[2018-04-17 21:09:46.331844]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:09:46.457679]: ====================
[2018-04-17 21:09:46.463695]: Elapsed time since starting training: 1:49:12.628326
[2018-04-17 21:09:46.468207]: Estimated time left: -1 day, 23:25:47.367162
[2018-04-17 21:09:46.473722]: ====================
[2018-04-17 21:09:46.545413]: [Epoch: 911(91.1911911911912%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:09:47.829327]: [Epoch: 911(91.1911911911912%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:09:49.123267]: [Epoch: 911(91.1911911911912%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:09:52.784000]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 21:09:52.898305]: ====================
[2018-04-17 21:09:52.904321]: Elapsed time since starting training: 1:49:19.068450
[2018-04-17 21:09:52.909334]: Estimated time left: -1 day, 23:25:40.926536
[2018-04-17 21:09:52.915350]: ====================
[2018-04-17 21:09:52.983531]: [Epoch: 912(91.29129129129129%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 21:09:54.294015]: [Epoch: 912(91.29129129129129%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 21:09:55.553865]: [Epoch: 912(91.29129129129129%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 21:09:59.124359]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:09:59.241672]: ====================
[2018-04-17 21:09:59.247186]: Elapsed time since starting training: 1:49:25.411316
[2018-04-17 21:09:59.252200]: Estimated time left: -1 day, 23:25:34.583169
[2018-04-17 21:09:59.257714]: ====================
[2018-04-17 21:09:59.330409]: [Epoch: 913(91.3913913913914%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:10:00.600785]: [Epoch: 913(91.3913913913914%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:10:01.868657]: [Epoch: 913(91.3913913913914%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:10:05.440654]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:10:05.556964]: ====================
[2018-04-17 21:10:05.561977]: Elapsed time since starting training: 1:49:31.726608
[2018-04-17 21:10:05.566991]: Estimated time left: -1 day, 23:25:28.268880
[2018-04-17 21:10:05.571001]: ====================
[2018-04-17 21:10:05.640185]: [Epoch: 914(91.4914914914915%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:10:06.926606]: [Epoch: 914(91.4914914914915%): Data: 25.333333333333336%]:Running loss: 4.350374311208725
[2018-04-17 21:10:08.197986]: [Epoch: 914(91.4914914914915%): Data: 50.66666666666667%]:Running loss: 8.483229652047157
[2018-04-17 21:10:11.853205]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:10:11.975030]: ====================
[2018-04-17 21:10:11.980544]: Elapsed time since starting training: 1:49:38.145175
[2018-04-17 21:10:11.987563]: Estimated time left: -1 day, 23:25:21.847806
[2018-04-17 21:10:11.993078]: ====================
[2018-04-17 21:10:12.058752]: [Epoch: 915(91.5915915915916%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:10:13.348682]: [Epoch: 915(91.5915915915916%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 21:10:14.627081]: [Epoch: 915(91.5915915915916%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 21:10:18.245211]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:10:18.364529]: ====================
[2018-04-17 21:10:18.369040]: Elapsed time since starting training: 1:49:44.533671
[2018-04-17 21:10:18.374053]: Estimated time left: -1 day, 23:25:15.461316
[2018-04-17 21:10:18.378566]: ====================
[2018-04-17 21:10:18.449755]: [Epoch: 916(91.69169169169169%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:10:19.714116]: [Epoch: 916(91.69169169169169%): Data: 25.333333333333336%]:Running loss: 4.350375309586525
[2018-04-17 21:10:21.005550]: [Epoch: 916(91.69169169169169%): Data: 50.66666666666667%]:Running loss: 8.48323206603527
[2018-04-17 21:10:24.583064]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 21:10:24.715415]: ====================
[2018-04-17 21:10:24.720930]: Elapsed time since starting training: 1:49:50.885070
[2018-04-17 21:10:24.725943]: Estimated time left: -1 day, 23:25:09.109927
[2018-04-17 21:10:24.730956]: ====================
[2018-04-17 21:10:24.800642]: [Epoch: 917(91.7917917917918%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 21:10:26.093079]: [Epoch: 917(91.7917917917918%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 21:10:27.344406]: [Epoch: 917(91.7917917917918%): Data: 50.66666666666667%]:Running loss: 8.48323230445385
[2018-04-17 21:10:30.934451]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 21:10:31.056777]: ====================
[2018-04-17 21:10:31.062292]: Elapsed time since starting training: 1:49:57.226421
[2018-04-17 21:10:31.066804]: Estimated time left: -1 day, 23:25:02.769067
[2018-04-17 21:10:31.071817]: ====================
[2018-04-17 21:10:31.144510]: [Epoch: 918(91.8918918918919%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 21:10:32.443965]: [Epoch: 918(91.8918918918919%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 21:10:33.720359]: [Epoch: 918(91.8918918918919%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 21:10:37.274810]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 21:10:37.398641]: ====================
[2018-04-17 21:10:37.404154]: Elapsed time since starting training: 1:50:03.568785
[2018-04-17 21:10:37.409167]: Estimated time left: -1 day, 23:24:56.426202
[2018-04-17 21:10:37.414181]: ====================
[2018-04-17 21:10:37.485872]: [Epoch: 919(91.991991991992%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 21:10:38.751236]: [Epoch: 919(91.991991991992%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 21:10:40.018606]: [Epoch: 919(91.991991991992%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 21:10:43.564033]: Test set accuracy: 94.33962264150944% ,loss = 5.437957867980003
[2018-04-17 21:10:43.677836]: ====================
[2018-04-17 21:10:43.682348]: Elapsed time since starting training: 1:50:09.846979
[2018-04-17 21:10:43.687362]: Estimated time left: -1 day, 23:24:50.148007
[2018-04-17 21:10:43.692876]: ====================
[2018-04-17 21:10:43.763564]: [Epoch: 920(92.09209209209209%): Data: 0.0%]:Running loss: 0.21751831471920013
[2018-04-17 21:10:45.001856]: [Epoch: 920(92.09209209209209%): Data: 25.333333333333336%]:Running loss: 4.350366294384003
[2018-04-17 21:10:46.302816]: [Epoch: 920(92.09209209209209%): Data: 50.66666666666667%]:Running loss: 8.483214274048805
[2018-04-17 21:10:49.823177]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 21:10:49.938483]: ====================
[2018-04-17 21:10:49.943998]: Elapsed time since starting training: 1:50:16.108629
[2018-04-17 21:10:49.948509]: Estimated time left: -1 day, 23:24:43.886860
[2018-04-17 21:10:49.954025]: ====================
[2018-04-17 21:10:50.021704]: [Epoch: 921(92.1921921921922%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 21:10:51.293586]: [Epoch: 921(92.1921921921922%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 21:10:52.546417]: [Epoch: 921(92.1921921921922%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 21:10:56.280847]: Test set accuracy: 94.33962264150944% ,loss = 5.437958985567093
[2018-04-17 21:10:56.401669]: ====================
[2018-04-17 21:10:56.406682]: Elapsed time since starting training: 1:50:22.571313
[2018-04-17 21:10:56.412197]: Estimated time left: -1 day, 23:24:37.423172
[2018-04-17 21:10:56.417210]: ====================
[2018-04-17 21:10:56.487397]: [Epoch: 922(92.29229229229229%): Data: 0.0%]:Running loss: 0.21751835942268372
[2018-04-17 21:10:57.772824]: [Epoch: 922(92.29229229229229%): Data: 25.333333333333336%]:Running loss: 4.350367188453674
[2018-04-17 21:10:59.047704]: [Epoch: 922(92.29229229229229%): Data: 50.66666666666667%]:Running loss: 8.483216017484665
[2018-04-17 21:11:02.675852]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:11:02.824246]: ====================
[2018-04-17 21:11:02.829259]: Elapsed time since starting training: 1:50:28.993390
[2018-04-17 21:11:02.834273]: Estimated time left: -1 day, 23:24:31.001096
[2018-04-17 21:11:02.839286]: ====================
[2018-04-17 21:11:02.908974]: [Epoch: 923(92.3923923923924%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:11:04.196896]: [Epoch: 923(92.3923923923924%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:11:05.481812]: [Epoch: 923(92.3923923923924%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 21:11:09.127507]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:11:09.256851]: ====================
[2018-04-17 21:11:09.261864]: Elapsed time since starting training: 1:50:35.425994
[2018-04-17 21:11:09.266878]: Estimated time left: -1 day, 23:24:24.568993
[2018-04-17 21:11:09.271389]: ====================
[2018-04-17 21:11:09.348093]: [Epoch: 924(92.49249249249249%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:11:10.650055]: [Epoch: 924(92.49249249249249%): Data: 25.333333333333336%]:Running loss: 4.350368455052376
[2018-04-17 21:11:11.961041]: [Epoch: 924(92.49249249249249%): Data: 50.66666666666667%]:Running loss: 8.48321869969368
[2018-04-17 21:11:15.682937]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:11:15.816293]: ====================
[2018-04-17 21:11:15.823311]: Elapsed time since starting training: 1:50:41.987942
[2018-04-17 21:11:15.829327]: Estimated time left: -1 day, 23:24:18.006042
[2018-04-17 21:11:15.834841]: ====================
[2018-04-17 21:11:15.906538]: [Epoch: 925(92.5925925925926%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:11:17.182926]: [Epoch: 925(92.5925925925926%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:11:18.480890]: [Epoch: 925(92.5925925925926%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 21:11:22.073931]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:11:22.200267]: ====================
[2018-04-17 21:11:22.205782]: Elapsed time since starting training: 1:50:48.370413
[2018-04-17 21:11:22.210795]: Estimated time left: -1 day, 23:24:11.624574
[2018-04-17 21:11:22.216310]: ====================
[2018-04-17 21:11:22.286998]: [Epoch: 926(92.69269269269269%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:11:23.571914]: [Epoch: 926(92.69269269269269%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 21:11:24.857833]: [Epoch: 926(92.69269269269269%): Data: 50.66666666666667%]:Running loss: 8.48321895301342
[2018-04-17 21:11:28.482973]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 21:11:28.602791]: ====================
[2018-04-17 21:11:28.608306]: Elapsed time since starting training: 1:50:54.772937
[2018-04-17 21:11:28.613826]: Estimated time left: -1 day, 23:24:05.221543
[2018-04-17 21:11:28.618834]: ====================
[2018-04-17 21:11:28.690524]: [Epoch: 927(92.7927927927928%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 21:11:29.970929]: [Epoch: 927(92.7927927927928%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 21:11:31.249328]: [Epoch: 927(92.7927927927928%): Data: 50.66666666666667%]:Running loss: 8.483217969536781
[2018-04-17 21:11:34.875470]: Test set accuracy: 94.33962264150944% ,loss = 5.437960848212242
[2018-04-17 21:11:34.987770]: ====================
[2018-04-17 21:11:34.991779]: Elapsed time since starting training: 1:51:01.156410
[2018-04-17 21:11:34.996291]: Estimated time left: -1 day, 23:23:58.839078
[2018-04-17 21:11:35.000302]: ====================
[2018-04-17 21:11:35.073998]: [Epoch: 928(92.8928928928929%): Data: 0.0%]:Running loss: 0.21751843392848969
[2018-04-17 21:11:36.366435]: [Epoch: 928(92.8928928928929%): Data: 25.333333333333336%]:Running loss: 4.350368678569794
[2018-04-17 21:11:37.668397]: [Epoch: 928(92.8928928928929%): Data: 50.66666666666667%]:Running loss: 8.483218923211098
[2018-04-17 21:11:41.236383]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:11:41.360213]: ====================
[2018-04-17 21:11:41.365227]: Elapsed time since starting training: 1:51:07.529858
[2018-04-17 21:11:41.369738]: Estimated time left: -1 day, 23:23:52.465631
[2018-04-17 21:11:41.375253]: ====================
[2018-04-17 21:11:41.445440]: [Epoch: 929(92.992992992993%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:11:42.752414]: [Epoch: 929(92.992992992993%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 21:11:44.010267]: [Epoch: 929(92.992992992993%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 21:11:47.613841]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:11:47.725137]: ====================
[2018-04-17 21:11:47.730155]: Elapsed time since starting training: 1:51:13.894786
[2018-04-17 21:11:47.735164]: Estimated time left: -1 day, 23:23:46.100205
[2018-04-17 21:11:47.740177]: ====================
[2018-04-17 21:11:47.811868]: [Epoch: 930(93.09309309309309%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:11:49.082245]: [Epoch: 930(93.09309309309309%): Data: 25.333333333333336%]:Running loss: 4.350369513034821
[2018-04-17 21:11:50.354128]: [Epoch: 930(93.09309309309309%): Data: 50.66666666666667%]:Running loss: 8.483220607042313
[2018-04-17 21:11:53.896069]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:11:54.015386]: ====================
[2018-04-17 21:11:54.020400]: Elapsed time since starting training: 1:51:20.185031
[2018-04-17 21:11:54.025915]: Estimated time left: -1 day, 23:23:39.809454
[2018-04-17 21:11:54.030928]: ====================
[2018-04-17 21:11:54.102117]: [Epoch: 931(93.1931931931932%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:11:55.375503]: [Epoch: 931(93.1931931931932%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:11:56.679971]: [Epoch: 931(93.1931931931932%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 21:12:00.263500]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:12:00.384321]: ====================
[2018-04-17 21:12:00.389335]: Elapsed time since starting training: 1:51:26.553966
[2018-04-17 21:12:00.394348]: Estimated time left: -1 day, 23:23:33.441021
[2018-04-17 21:12:00.399361]: ====================
[2018-04-17 21:12:00.470552]: [Epoch: 932(93.29329329329329%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:12:01.785547]: [Epoch: 932(93.29329329329329%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:12:03.094528]: [Epoch: 932(93.29329329329329%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 21:12:06.757267]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:12:06.888115]: ====================
[2018-04-17 21:12:06.893630]: Elapsed time since starting training: 1:51:33.058261
[2018-04-17 21:12:06.899144]: Estimated time left: -1 day, 23:23:26.936225
[2018-04-17 21:12:06.903656]: ====================
[2018-04-17 21:12:06.975849]: [Epoch: 933(93.3933933933934%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:12:08.273800]: [Epoch: 933(93.3933933933934%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:12:09.550194]: [Epoch: 933(93.3933933933934%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 21:12:13.157786]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:12:13.277605]: ====================
[2018-04-17 21:12:13.282116]: Elapsed time since starting training: 1:51:39.446747
[2018-04-17 21:12:13.287130]: Estimated time left: -1 day, 23:23:20.548741
[2018-04-17 21:12:13.291642]: ====================
[2018-04-17 21:12:13.360826]: [Epoch: 934(93.4934934934935%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:12:14.669807]: [Epoch: 934(93.4934934934935%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:12:15.967758]: [Epoch: 934(93.4934934934935%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 21:12:19.596907]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:12:19.719734]: ====================
[2018-04-17 21:12:19.726753]: Elapsed time since starting training: 1:51:45.890883
[2018-04-17 21:12:19.731265]: Estimated time left: -1 day, 23:23:14.104104
[2018-04-17 21:12:19.736278]: ====================
[2018-04-17 21:12:19.807467]: [Epoch: 935(93.5935935935936%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:12:21.106421]: [Epoch: 935(93.5935935935936%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:12:22.414901]: [Epoch: 935(93.5935935935936%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 21:12:26.002941]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:12:26.133288]: ====================
[2018-04-17 21:12:26.138301]: Elapsed time since starting training: 1:51:52.302932
[2018-04-17 21:12:26.143816]: Estimated time left: -1 day, 23:23:07.692055
[2018-04-17 21:12:26.148830]: ====================
[2018-04-17 21:12:26.220520]: [Epoch: 936(93.69369369369369%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:12:27.520977]: [Epoch: 936(93.69369369369369%): Data: 25.333333333333336%]:Running loss: 4.350371405482292
[2018-04-17 21:12:28.810907]: [Epoch: 936(93.69369369369369%): Data: 50.66666666666667%]:Running loss: 8.483224764466286
[2018-04-17 21:12:32.438553]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:12:32.564889]: ====================
[2018-04-17 21:12:32.569401]: Elapsed time since starting training: 1:51:58.734032
[2018-04-17 21:12:32.574415]: Estimated time left: -1 day, 23:23:01.260954
[2018-04-17 21:12:32.579428]: ====================
[2018-04-17 21:12:32.647609]: [Epoch: 937(93.7937937937938%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:12:33.968622]: [Epoch: 937(93.7937937937938%): Data: 25.333333333333336%]:Running loss: 4.3503719717264175
[2018-04-17 21:12:35.279106]: [Epoch: 937(93.7937937937938%): Data: 50.66666666666667%]:Running loss: 8.483225613832474
[2018-04-17 21:12:38.959392]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:12:39.075200]: ====================
[2018-04-17 21:12:39.080214]: Elapsed time since starting training: 1:52:05.244343
[2018-04-17 21:12:39.085227]: Estimated time left: -1 day, 23:22:54.750142
[2018-04-17 21:12:39.089739]: ====================
[2018-04-17 21:12:39.159925]: [Epoch: 938(93.8938938938939%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:12:40.441834]: [Epoch: 938(93.8938938938939%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:12:41.755334]: [Epoch: 938(93.8938938938939%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 21:12:45.370940]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:12:45.490760]: ====================
[2018-04-17 21:12:45.496273]: Elapsed time since starting training: 1:52:11.660904
[2018-04-17 21:12:45.500786]: Estimated time left: -1 day, 23:22:48.334583
[2018-04-17 21:12:45.505799]: ====================
[2018-04-17 21:12:45.574983]: [Epoch: 939(93.993993993994%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:12:46.835836]: [Epoch: 939(93.993993993994%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:12:48.123259]: [Epoch: 939(93.993993993994%): Data: 50.66666666666667%]:Running loss: 8.483226582407951
[2018-04-17 21:12:51.785998]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:12:51.902809]: ====================
[2018-04-17 21:12:51.907822]: Elapsed time since starting training: 1:52:18.071952
[2018-04-17 21:12:51.912835]: Estimated time left: -1 day, 23:22:41.922534
[2018-04-17 21:12:51.917849]: ====================
[2018-04-17 21:12:51.989038]: [Epoch: 940(94.09409409409409%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:12:53.292504]: [Epoch: 940(94.09409409409409%): Data: 25.333333333333336%]:Running loss: 4.350373029708862
[2018-04-17 21:12:54.561378]: [Epoch: 940(94.09409409409409%): Data: 50.66666666666667%]:Running loss: 8.483227521181107
[2018-04-17 21:12:58.177994]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:12:58.315861]: ====================
[2018-04-17 21:12:58.322880]: Elapsed time since starting training: 1:52:24.487009
[2018-04-17 21:12:58.328896]: Estimated time left: -1 day, 23:22:35.506473
[2018-04-17 21:12:58.334911]: ====================
[2018-04-17 21:12:58.406602]: [Epoch: 941(94.1941941941942%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:12:59.689513]: [Epoch: 941(94.1941941941942%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:13:00.989971]: [Epoch: 941(94.1941941941942%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:13:04.610598]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:13:04.726911]: ====================
[2018-04-17 21:13:04.733425]: Elapsed time since starting training: 1:52:30.898056
[2018-04-17 21:13:04.737937]: Estimated time left: -1 day, 23:22:29.097432
[2018-04-17 21:13:04.743954]: ====================
[2018-04-17 21:13:04.818150]: [Epoch: 942(94.29429429429429%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:13:06.081008]: [Epoch: 942(94.29429429429429%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:13:07.386981]: [Epoch: 942(94.29429429429429%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:13:11.052227]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:13:11.178062]: ====================
[2018-04-17 21:13:11.184077]: Elapsed time since starting training: 1:52:37.348708
[2018-04-17 21:13:11.189090]: Estimated time left: -1 day, 23:22:22.646279
[2018-04-17 21:13:11.193603]: ====================
[2018-04-17 21:13:11.263288]: [Epoch: 943(94.3943943943944%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:13:12.515116]: [Epoch: 943(94.3943943943944%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:13:13.766444]: [Epoch: 943(94.3943943943944%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:13:17.380554]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:13:17.498367]: ====================
[2018-04-17 21:13:17.503380]: Elapsed time since starting training: 1:52:43.667510
[2018-04-17 21:13:17.508394]: Estimated time left: -1 day, 23:22:16.327467
[2018-04-17 21:13:17.514911]: ====================
[2018-04-17 21:13:17.586100]: [Epoch: 944(94.49449449449449%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:13:18.871518]: [Epoch: 944(94.49449449449449%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 21:13:20.142398]: [Epoch: 944(94.49449449449449%): Data: 50.66666666666667%]:Running loss: 8.483230546116829
[2018-04-17 21:13:23.659250]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:13:23.788593]: ====================
[2018-04-17 21:13:23.793105]: Elapsed time since starting training: 1:52:49.957736
[2018-04-17 21:13:23.800625]: Estimated time left: -1 day, 23:22:10.035246
[2018-04-17 21:13:23.805137]: ====================
[2018-04-17 21:13:23.873819]: [Epoch: 945(94.5945945945946%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:13:25.158736]: [Epoch: 945(94.5945945945946%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:13:26.410565]: [Epoch: 945(94.5945945945946%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 21:13:29.724877]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:13:29.835672]: ====================
[2018-04-17 21:13:29.840693]: Elapsed time since starting training: 1:52:56.005324
[2018-04-17 21:13:29.846701]: Estimated time left: -1 day, 23:22:03.989169
[2018-04-17 21:13:29.851715]: ====================
[2018-04-17 21:13:29.923405]: [Epoch: 946(94.69469469469469%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:13:31.176738]: [Epoch: 946(94.69469469469469%): Data: 25.333333333333336%]:Running loss: 4.350375264883041
[2018-04-17 21:13:32.471681]: [Epoch: 946(94.69469469469469%): Data: 50.66666666666667%]:Running loss: 8.483232021331787
[2018-04-17 21:13:36.106847]: Test set accuracy: 94.33962264150944% ,loss = 5.437969416379929
[2018-04-17 21:13:36.227668]: ====================
[2018-04-17 21:13:36.233684]: Elapsed time since starting training: 1:53:02.398315
[2018-04-17 21:13:36.238196]: Estimated time left: -1 day, 23:21:57.597173
[2018-04-17 21:13:36.242708]: ====================
[2018-04-17 21:13:36.314403]: [Epoch: 947(94.7947947947948%): Data: 0.0%]:Running loss: 0.21751877665519714
[2018-04-17 21:13:37.600823]: [Epoch: 947(94.7947947947948%): Data: 25.333333333333336%]:Running loss: 4.350375533103943
[2018-04-17 21:13:38.873707]: [Epoch: 947(94.7947947947948%): Data: 50.66666666666667%]:Running loss: 8.483232289552689
[2018-04-17 21:13:42.411113]: Test set accuracy: 94.33962264150944% ,loss = 5.437970161437988
[2018-04-17 21:13:42.524414]: ====================
[2018-04-17 21:13:42.529428]: Elapsed time since starting training: 1:53:08.694059
[2018-04-17 21:13:42.533940]: Estimated time left: -1 day, 23:21:51.301429
[2018-04-17 21:13:42.538954]: ====================
[2018-04-17 21:13:42.608639]: [Epoch: 948(94.8948948948949%): Data: 0.0%]:Running loss: 0.21751880645751953
[2018-04-17 21:13:43.870494]: [Epoch: 948(94.8948948948949%): Data: 25.333333333333336%]:Running loss: 4.350376129150391
[2018-04-17 21:13:45.146386]: [Epoch: 948(94.8948948948949%): Data: 50.66666666666667%]:Running loss: 8.483233451843262
[2018-04-17 21:13:48.742949]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:13:48.868283]: ====================
[2018-04-17 21:13:48.873296]: Elapsed time since starting training: 1:53:15.037927
[2018-04-17 21:13:48.878811]: Estimated time left: -1 day, 23:21:44.957060
[2018-04-17 21:13:48.883825]: ====================
[2018-04-17 21:13:48.947494]: [Epoch: 949(94.994994994995%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:13:50.272516]: [Epoch: 949(94.994994994995%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:13:51.559940]: [Epoch: 949(94.994994994995%): Data: 50.66666666666667%]:Running loss: 8.483231619000435
[2018-04-17 21:13:55.171543]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 21:13:55.292866]: ====================
[2018-04-17 21:13:55.299884]: Elapsed time since starting training: 1:53:21.464515
[2018-04-17 21:13:55.304898]: Estimated time left: -1 day, 23:21:38.530471
[2018-04-17 21:13:55.309410]: ====================
[2018-04-17 21:13:55.381602]: [Epoch: 950(95.09509509509509%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 21:13:56.672534]: [Epoch: 950(95.09509509509509%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 21:13:57.944421]: [Epoch: 950(95.09509509509509%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 21:14:01.519428]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:14:01.763076]: ====================
[2018-04-17 21:14:01.769092]: Elapsed time since starting training: 1:53:27.933723
[2018-04-17 21:14:01.782126]: Estimated time left: -1 day, 23:21:32.053243
[2018-04-17 21:14:01.787641]: ====================
[2018-04-17 21:14:01.869859]: [Epoch: 951(95.1951951951952%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:14:03.136227]: [Epoch: 951(95.1951951951952%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:14:04.433677]: [Epoch: 951(95.1951951951952%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:14:08.098421]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:14:08.214731]: ====================
[2018-04-17 21:14:08.219744]: Elapsed time since starting training: 1:53:34.384375
[2018-04-17 21:14:08.224757]: Estimated time left: -1 day, 23:21:25.610612
[2018-04-17 21:14:08.229771]: ====================
[2018-04-17 21:14:08.298453]: [Epoch: 952(95.29529529529529%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:14:09.563818]: [Epoch: 952(95.29529529529529%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:14:10.844724]: [Epoch: 952(95.29529529529529%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:14:14.421735]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:14:14.537543]: ====================
[2018-04-17 21:14:14.542556]: Elapsed time since starting training: 1:53:40.707187
[2018-04-17 21:14:14.548071]: Estimated time left: -1 day, 23:21:19.287298
[2018-04-17 21:14:14.553084]: ====================
[2018-04-17 21:14:14.625276]: [Epoch: 953(95.3953953953954%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:14:15.901168]: [Epoch: 953(95.3953953953954%): Data: 25.333333333333336%]:Running loss: 4.350376918911934
[2018-04-17 21:14:17.197115]: [Epoch: 953(95.3953953953954%): Data: 50.66666666666667%]:Running loss: 8.483235374093056
[2018-04-17 21:14:20.729006]: Test set accuracy: 94.33962264150944% ,loss = 5.437971651554108
[2018-04-17 21:14:20.861359]: ====================
[2018-04-17 21:14:20.866371]: Elapsed time since starting training: 1:53:47.031002
[2018-04-17 21:14:20.871384]: Estimated time left: -1 day, 23:21:12.963985
[2018-04-17 21:14:20.876899]: ====================
[2018-04-17 21:14:20.948088]: [Epoch: 954(95.4954954954955%): Data: 0.0%]:Running loss: 0.2175188660621643
[2018-04-17 21:14:22.200418]: [Epoch: 954(95.4954954954955%): Data: 25.333333333333336%]:Running loss: 4.350373387336731
[2018-04-17 21:14:23.481324]: [Epoch: 954(95.4954954954955%): Data: 50.66666666666667%]:Running loss: 8.483222499489784
[2018-04-17 21:14:27.098442]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:14:27.229290]: ====================
[2018-04-17 21:14:27.234311]: Elapsed time since starting training: 1:53:53.398942
[2018-04-17 21:14:27.239818]: Estimated time left: -1 day, 23:21:06.595551
[2018-04-17 21:14:27.245333]: ====================
[2018-04-17 21:14:27.317526]: [Epoch: 955(95.5955955955956%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:14:28.576372]: [Epoch: 955(95.5955955955956%): Data: 25.333333333333336%]:Running loss: 4.350367784500122
[2018-04-17 21:14:29.847251]: [Epoch: 955(95.5955955955956%): Data: 50.66666666666667%]:Running loss: 8.483217179775238
[2018-04-17 21:14:33.432284]: Test set accuracy: 94.33962264150944% ,loss = 5.437959730625153
[2018-04-17 21:14:33.554610]: ====================
[2018-04-17 21:14:33.559622]: Elapsed time since starting training: 1:53:59.724253
[2018-04-17 21:14:33.564636]: Estimated time left: -1 day, 23:21:00.270733
[2018-04-17 21:14:33.569649]: ====================
[2018-04-17 21:14:33.640337]: [Epoch: 956(95.69569569569569%): Data: 0.0%]:Running loss: 0.2175183892250061
[2018-04-17 21:14:34.931771]: [Epoch: 956(95.69569569569569%): Data: 25.333333333333336%]:Running loss: 4.350367873907089
[2018-04-17 21:14:36.233745]: [Epoch: 956(95.69569569569569%): Data: 50.66666666666667%]:Running loss: 8.483217552304268
[2018-04-17 21:14:39.752589]: Test set accuracy: 94.33962264150944% ,loss = 5.437960103154182
[2018-04-17 21:14:39.868899]: ====================
[2018-04-17 21:14:39.873411]: Elapsed time since starting training: 1:54:06.038042
[2018-04-17 21:14:39.878425]: Estimated time left: -1 day, 23:20:53.957447
[2018-04-17 21:14:39.883438]: ====================
[2018-04-17 21:14:39.949613]: [Epoch: 957(95.7957957957958%): Data: 0.0%]:Running loss: 0.2175184041261673
[2018-04-17 21:14:41.195927]: [Epoch: 957(95.7957957957958%): Data: 25.333333333333336%]:Running loss: 4.350368082523346
[2018-04-17 21:14:42.466305]: [Epoch: 957(95.7957957957958%): Data: 50.66666666666667%]:Running loss: 8.483217760920525
[2018-04-17 21:14:45.967615]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:14:46.086432]: ====================
[2018-04-17 21:14:46.090442]: Elapsed time since starting training: 1:54:12.255073
[2018-04-17 21:14:46.094955]: Estimated time left: -1 day, 23:20:47.740414
[2018-04-17 21:14:46.099967]: ====================
[2018-04-17 21:14:46.170655]: [Epoch: 958(95.8958958958959%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:14:47.406441]: [Epoch: 958(95.8958958958959%): Data: 25.333333333333336%]:Running loss: 4.350368976593018
[2018-04-17 21:14:48.592093]: [Epoch: 958(95.8958958958959%): Data: 50.66666666666667%]:Running loss: 8.483219504356384
[2018-04-17 21:14:52.105937]: Test set accuracy: 94.33962264150944% ,loss = 5.437961220741272
[2018-04-17 21:14:52.216230]: ====================
[2018-04-17 21:14:52.221244]: Elapsed time since starting training: 1:54:18.385875
[2018-04-17 21:14:52.225755]: Estimated time left: -1 day, 23:20:41.609614
[2018-04-17 21:14:52.230768]: ====================
[2018-04-17 21:14:52.300454]: [Epoch: 959(95.995995995996%): Data: 0.0%]:Running loss: 0.21751844882965088
[2018-04-17 21:14:53.574842]: [Epoch: 959(95.995995995996%): Data: 25.333333333333336%]:Running loss: 4.350369155406952
[2018-04-17 21:14:54.802608]: [Epoch: 959(95.995995995996%): Data: 50.66666666666667%]:Running loss: 8.483220249414444
[2018-04-17 21:14:58.368088]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:14:58.486403]: ====================
[2018-04-17 21:14:58.491416]: Elapsed time since starting training: 1:54:24.656047
[2018-04-17 21:14:58.496930]: Estimated time left: -1 day, 23:20:35.338439
[2018-04-17 21:14:58.502446]: ====================
[2018-04-17 21:14:58.578146]: [Epoch: 960(96.09609609609609%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:14:59.855543]: [Epoch: 960(96.09609609609609%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:15:01.102860]: [Epoch: 960(96.09609609609609%): Data: 50.66666666666667%]:Running loss: 8.483220860362053
[2018-04-17 21:15:04.640766]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:15:04.760585]: ====================
[2018-04-17 21:15:04.765097]: Elapsed time since starting training: 1:54:30.929728
[2018-04-17 21:15:04.770111]: Estimated time left: -1 day, 23:20:29.065760
[2018-04-17 21:15:04.774627]: ====================
[2018-04-17 21:15:04.840799]: [Epoch: 961(96.1961961961962%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:15:06.073075]: [Epoch: 961(96.1961961961962%): Data: 25.333333333333336%]:Running loss: 4.350369617342949
[2018-04-17 21:15:07.340445]: [Epoch: 961(96.1961961961962%): Data: 50.66666666666667%]:Running loss: 8.483220994472504
[2018-04-17 21:15:10.811675]: Test set accuracy: 94.33962264150944% ,loss = 5.4379623383283615
[2018-04-17 21:15:10.927483]: ====================
[2018-04-17 21:15:10.932496]: Elapsed time since starting training: 1:54:37.097127
[2018-04-17 21:15:10.937008]: Estimated time left: -1 day, 23:20:22.898361
[2018-04-17 21:15:10.941520]: ====================
[2018-04-17 21:15:11.010204]: [Epoch: 962(96.29629629629629%): Data: 0.0%]:Running loss: 0.21751849353313446
[2018-04-17 21:15:12.244485]: [Epoch: 962(96.29629629629629%): Data: 25.333333333333336%]:Running loss: 4.350369930267334
[2018-04-17 21:15:13.484286]: [Epoch: 962(96.29629629629629%): Data: 50.66666666666667%]:Running loss: 8.483221873641014
[2018-04-17 21:15:16.941474]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:15:17.060290]: ====================
[2018-04-17 21:15:17.064802]: Elapsed time since starting training: 1:54:43.229433
[2018-04-17 21:15:17.069815]: Estimated time left: -1 day, 23:20:16.765554
[2018-04-17 21:15:17.074829]: ====================
[2018-04-17 21:15:17.146018]: [Epoch: 963(96.3963963963964%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:15:18.398849]: [Epoch: 963(96.3963963963964%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:15:19.618593]: [Epoch: 963(96.3963963963964%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 21:15:23.037183]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:15:23.147476]: ====================
[2018-04-17 21:15:23.152489]: Elapsed time since starting training: 1:54:49.317120
[2018-04-17 21:15:23.157001]: Estimated time left: -1 day, 23:20:10.678368
[2018-04-17 21:15:23.161514]: ====================
[2018-04-17 21:15:23.228692]: [Epoch: 964(96.49649649649649%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:15:24.431390]: [Epoch: 964(96.49649649649649%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:15:25.691240]: [Epoch: 964(96.49649649649649%): Data: 50.66666666666667%]:Running loss: 8.48322357237339
[2018-04-17 21:15:29.234161]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:15:29.360998]: ====================
[2018-04-17 21:15:29.365510]: Elapsed time since starting training: 1:54:55.529639
[2018-04-17 21:15:29.369521]: Estimated time left: -1 day, 23:20:04.465848
[2018-04-17 21:15:29.374033]: ====================
[2018-04-17 21:15:29.443718]: [Epoch: 965(96.5965965965966%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:15:30.732143]: [Epoch: 965(96.5965965965966%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:15:31.996004]: [Epoch: 965(96.5965965965966%): Data: 50.66666666666667%]:Running loss: 8.48322468996048
[2018-04-17 21:15:35.644205]: Test set accuracy: 94.33962264150944% ,loss = 5.43796494603157
[2018-04-17 21:15:35.761517]: ====================
[2018-04-17 21:15:35.766530]: Elapsed time since starting training: 1:55:01.930659
[2018-04-17 21:15:35.771544]: Estimated time left: -1 day, 23:19:58.063825
[2018-04-17 21:15:35.776557]: ====================
[2018-04-17 21:15:35.846743]: [Epoch: 966(96.69669669669669%): Data: 0.0%]:Running loss: 0.21751859784126282
[2018-04-17 21:15:37.160737]: [Epoch: 966(96.69669669669669%): Data: 25.333333333333336%]:Running loss: 4.350371956825256
[2018-04-17 21:15:38.455179]: [Epoch: 966(96.69669669669669%): Data: 50.66666666666667%]:Running loss: 8.48322531580925
[2018-04-17 21:15:42.110900]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:15:42.246761]: ====================
[2018-04-17 21:15:42.252276]: Elapsed time since starting training: 1:55:08.416405
[2018-04-17 21:15:42.257289]: Estimated time left: -1 day, 23:19:51.578080
[2018-04-17 21:15:42.262303]: ====================
[2018-04-17 21:15:42.334995]: [Epoch: 967(96.7967967967968%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:15:43.639464]: [Epoch: 967(96.7967967967968%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:15:44.922876]: [Epoch: 967(96.7967967967968%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:15:48.529968]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:15:48.651290]: ====================
[2018-04-17 21:15:48.656806]: Elapsed time since starting training: 1:55:14.821437
[2018-04-17 21:15:48.661819]: Estimated time left: -1 day, 23:19:45.173550
[2018-04-17 21:15:48.666832]: ====================
[2018-04-17 21:15:48.739525]: [Epoch: 968(96.8968968968969%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:15:50.082095]: [Epoch: 968(96.8968968968969%): Data: 25.333333333333336%]:Running loss: 4.350372284650803
[2018-04-17 21:15:51.418649]: [Epoch: 968(96.8968968968969%): Data: 50.66666666666667%]:Running loss: 8.483226209878922
[2018-04-17 21:15:55.098935]: Test set accuracy: 94.33962264150944% ,loss = 5.43796569108963
[2018-04-17 21:15:55.225772]: ====================
[2018-04-17 21:15:55.232290]: Elapsed time since starting training: 1:55:21.396419
[2018-04-17 21:15:55.237804]: Estimated time left: -1 day, 23:19:38.597565
[2018-04-17 21:15:55.242316]: ====================
[2018-04-17 21:15:55.329548]: [Epoch: 969(96.996996996997%): Data: 0.0%]:Running loss: 0.2175186276435852
[2018-04-17 21:15:56.598422]: [Epoch: 969(96.996996996997%): Data: 25.333333333333336%]:Running loss: 4.350372552871704
[2018-04-17 21:15:57.871306]: [Epoch: 969(96.996996996997%): Data: 50.66666666666667%]:Running loss: 8.483226478099823
[2018-04-17 21:16:01.511486]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:16:01.649353]: ====================
[2018-04-17 21:16:01.654366]: Elapsed time since starting training: 1:55:27.818997
[2018-04-17 21:16:01.659880]: Estimated time left: -1 day, 23:19:32.175489
[2018-04-17 21:16:01.664893]: ====================
[2018-04-17 21:16:01.736584]: [Epoch: 970(97.09709709709709%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:16:03.057095]: [Epoch: 970(97.09709709709709%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:16:04.317446]: [Epoch: 970(97.09709709709709%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:16:08.052879]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:16:08.175707]: ====================
[2018-04-17 21:16:08.180719]: Elapsed time since starting training: 1:55:34.345350
[2018-04-17 21:16:08.186233]: Estimated time left: -1 day, 23:19:25.649136
[2018-04-17 21:16:08.190746]: ====================
[2018-04-17 21:16:08.259428]: [Epoch: 971(97.1971971971972%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:16:09.553870]: [Epoch: 971(97.1971971971972%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:16:10.876889]: [Epoch: 971(97.1971971971972%): Data: 50.66666666666667%]:Running loss: 8.483228355646133
[2018-04-17 21:16:14.476961]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:16:14.595275]: ====================
[2018-04-17 21:16:14.600790]: Elapsed time since starting training: 1:55:40.764920
[2018-04-17 21:16:14.606807]: Estimated time left: -1 day, 23:19:19.228562
[2018-04-17 21:16:14.611819]: ====================
[2018-04-17 21:16:14.692032]: [Epoch: 972(97.2972972972973%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:16:16.012543]: [Epoch: 972(97.2972972972973%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:16:17.280918]: [Epoch: 972(97.2972972972973%): Data: 50.66666666666667%]:Running loss: 8.48322768509388
[2018-04-17 21:16:20.783233]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:16:20.904555]: ====================
[2018-04-17 21:16:20.909068]: Elapsed time since starting training: 1:55:47.073699
[2018-04-17 21:16:20.913580]: Estimated time left: -1 day, 23:19:12.921789
[2018-04-17 21:16:20.918092]: ====================
[2018-04-17 21:16:20.993793]: [Epoch: 973(97.3973973973974%): Data: 0.0%]:Running loss: 0.217518612742424
[2018-04-17 21:16:22.310795]: [Epoch: 973(97.3973973973974%): Data: 25.333333333333336%]:Running loss: 4.35037225484848
[2018-04-17 21:16:23.566634]: [Epoch: 973(97.3973973973974%): Data: 50.66666666666667%]:Running loss: 8.483225896954536
[2018-04-17 21:16:27.129608]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:16:27.262962]: ====================
[2018-04-17 21:16:27.267474]: Elapsed time since starting training: 1:55:53.432105
[2018-04-17 21:16:27.272989]: Estimated time left: -1 day, 23:19:06.562881
[2018-04-17 21:16:27.278004]: ====================
[2018-04-17 21:16:27.355208]: [Epoch: 974(97.4974974974975%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:16:28.653660]: [Epoch: 974(97.4974974974975%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 21:16:29.940081]: [Epoch: 974(97.4974974974975%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 21:16:33.498042]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:16:33.626383]: ====================
[2018-04-17 21:16:33.633402]: Elapsed time since starting training: 1:55:59.797532
[2018-04-17 21:16:33.639417]: Estimated time left: -1 day, 23:19:00.195952
[2018-04-17 21:16:33.643428]: ====================
[2018-04-17 21:16:33.722639]: [Epoch: 975(97.5975975975976%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:16:35.035630]: [Epoch: 975(97.5975975975976%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 21:16:36.339597]: [Epoch: 975(97.5975975975976%): Data: 50.66666666666667%]:Running loss: 8.48322705924511
[2018-04-17 21:16:39.922624]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 21:16:40.050465]: ====================
[2018-04-17 21:16:40.056480]: Elapsed time since starting training: 1:56:06.221111
[2018-04-17 21:16:40.061494]: Estimated time left: -1 day, 23:18:53.774377
[2018-04-17 21:16:40.066006]: ====================
[2018-04-17 21:16:40.138699]: [Epoch: 976(97.69769769769769%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 21:16:41.398048]: [Epoch: 976(97.69769769769769%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 21:16:42.674943]: [Epoch: 976(97.69769769769769%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 21:16:46.180264]: Test set accuracy: 94.33962264150944% ,loss = 5.4379671812057495
[2018-04-17 21:16:46.310109]: ====================
[2018-04-17 21:16:46.315122]: Elapsed time since starting training: 1:56:12.479753
[2018-04-17 21:16:46.321138]: Estimated time left: -1 day, 23:18:47.514231
[2018-04-17 21:16:46.326653]: ====================
[2018-04-17 21:16:46.398845]: [Epoch: 977(97.7977977977978%): Data: 0.0%]:Running loss: 0.21751868724822998
[2018-04-17 21:16:47.682758]: [Epoch: 977(97.7977977977978%): Data: 25.333333333333336%]:Running loss: 4.3503737449646
[2018-04-17 21:16:48.940603]: [Epoch: 977(97.7977977977978%): Data: 50.66666666666667%]:Running loss: 8.48322880268097
[2018-04-17 21:16:52.493049]: Test set accuracy: 94.33962264150944% ,loss = 5.43796606361866
[2018-04-17 21:16:52.612366]: ====================
[2018-04-17 21:16:52.617881]: Elapsed time since starting training: 1:56:18.782512
[2018-04-17 21:16:52.623397]: Estimated time left: -1 day, 23:18:41.211972
[2018-04-17 21:16:52.628409]: ====================
[2018-04-17 21:16:52.699599]: [Epoch: 978(97.8978978978979%): Data: 0.0%]:Running loss: 0.2175186425447464
[2018-04-17 21:16:53.983011]: [Epoch: 978(97.8978978978979%): Data: 25.333333333333336%]:Running loss: 4.350372850894928
[2018-04-17 21:16:55.262413]: [Epoch: 978(97.8978978978979%): Data: 50.66666666666667%]:Running loss: 8.483227282762527
[2018-04-17 21:16:58.758208]: Test set accuracy: 94.33962264150944% ,loss = 5.43796643614769
[2018-04-17 21:16:58.882539]: ====================
[2018-04-17 21:16:58.888054]: Elapsed time since starting training: 1:56:25.052685
[2018-04-17 21:16:58.893067]: Estimated time left: -1 day, 23:18:34.942302
[2018-04-17 21:16:58.898081]: ====================
[2018-04-17 21:16:58.965760]: [Epoch: 979(97.997997997998%): Data: 0.0%]:Running loss: 0.2175186574459076
[2018-04-17 21:17:00.284767]: [Epoch: 979(97.997997997998%): Data: 25.333333333333336%]:Running loss: 4.350373148918152
[2018-04-17 21:17:01.599263]: [Epoch: 979(97.997997997998%): Data: 50.66666666666667%]:Running loss: 8.483227640390396
[2018-04-17 21:17:05.191314]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:17:05.311132]: ====================
[2018-04-17 21:17:05.316145]: Elapsed time since starting training: 1:56:31.480776
[2018-04-17 21:17:05.323164]: Estimated time left: -1 day, 23:18:28.512205
[2018-04-17 21:17:05.328177]: ====================
[2018-04-17 21:17:05.398364]: [Epoch: 980(98.09809809809809%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:17:06.662225]: [Epoch: 980(98.09809809809809%): Data: 25.333333333333336%]:Running loss: 4.3503740429878235
[2018-04-17 21:17:07.938118]: [Epoch: 980(98.09809809809809%): Data: 50.66666666666667%]:Running loss: 8.483229383826256
[2018-04-17 21:17:11.522147]: Test set accuracy: 94.33962264150944% ,loss = 5.437967553734779
[2018-04-17 21:17:11.650990]: ====================
[2018-04-17 21:17:11.655502]: Elapsed time since starting training: 1:56:37.820133
[2018-04-17 21:17:11.660515]: Estimated time left: -1 day, 23:18:22.174854
[2018-04-17 21:17:11.666030]: ====================
[2018-04-17 21:17:11.737720]: [Epoch: 981(98.1981981981982%): Data: 0.0%]:Running loss: 0.21751870214939117
[2018-04-17 21:17:13.006595]: [Epoch: 981(98.1981981981982%): Data: 25.333333333333336%]:Running loss: 4.350374400615692
[2018-04-17 21:17:14.282988]: [Epoch: 981(98.1981981981982%): Data: 50.66666666666667%]:Running loss: 8.48323030769825
[2018-04-17 21:17:17.818389]: Test set accuracy: 94.33962264150944% ,loss = 5.437968298792839
[2018-04-17 21:17:17.938709]: ====================
[2018-04-17 21:17:17.943221]: Elapsed time since starting training: 1:56:44.107852
[2018-04-17 21:17:17.948234]: Estimated time left: -1 day, 23:18:15.887135
[2018-04-17 21:17:17.953749]: ====================
[2018-04-17 21:17:18.024938]: [Epoch: 982(98.2982982982983%): Data: 0.0%]:Running loss: 0.21751873195171356
[2018-04-17 21:17:19.291807]: [Epoch: 982(98.2982982982983%): Data: 25.333333333333336%]:Running loss: 4.350374639034271
[2018-04-17 21:17:20.584753]: [Epoch: 982(98.2982982982983%): Data: 50.66666666666667%]:Running loss: 8.483230724930763
[2018-04-17 21:17:24.180807]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:17:24.308145]: ====================
[2018-04-17 21:17:24.314663]: Elapsed time since starting training: 1:56:50.479294
[2018-04-17 21:17:24.320678]: Estimated time left: -1 day, 23:18:09.514691
[2018-04-17 21:17:24.325692]: ====================
[2018-04-17 21:17:24.396881]: [Epoch: 983(98.3983983983984%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:17:25.672775]: [Epoch: 983(98.3983983983984%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:17:26.937135]: [Epoch: 983(98.3983983983984%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 21:17:30.548739]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:17:30.672067]: ====================
[2018-04-17 21:17:30.676579]: Elapsed time since starting training: 1:56:56.841210
[2018-04-17 21:17:30.681593]: Estimated time left: -1 day, 23:18:03.153776
[2018-04-17 21:17:30.686606]: ====================
[2018-04-17 21:17:30.757795]: [Epoch: 984(98.49849849849849%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:17:32.078807]: [Epoch: 984(98.49849849849849%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:17:33.359713]: [Epoch: 984(98.49849849849849%): Data: 50.66666666666667%]:Running loss: 8.483231127262115
[2018-04-17 21:17:36.935220]: Test set accuracy: 94.33962264150944% ,loss = 5.437968671321869
[2018-04-17 21:17:37.060554]: ====================
[2018-04-17 21:17:37.066570]: Elapsed time since starting training: 1:57:03.231201
[2018-04-17 21:17:37.072085]: Estimated time left: -1 day, 23:17:56.763786
[2018-04-17 21:17:37.078101]: ====================
[2018-04-17 21:17:37.151297]: [Epoch: 985(98.5985985985986%): Data: 0.0%]:Running loss: 0.21751874685287476
[2018-04-17 21:17:38.441225]: [Epoch: 985(98.5985985985986%): Data: 25.333333333333336%]:Running loss: 4.350374937057495
[2018-04-17 21:17:39.701075]: [Epoch: 985(98.5985985985986%): Data: 50.66666666666667%]:Running loss: 8.483231171965599
[2018-04-17 21:17:43.242993]: Test set accuracy: 94.33962264150944% ,loss = 5.437969788908958
[2018-04-17 21:17:43.377350]: ====================
[2018-04-17 21:17:43.382363]: Elapsed time since starting training: 1:57:09.546493
[2018-04-17 21:17:43.386374]: Estimated time left: -1 day, 23:17:50.449497
[2018-04-17 21:17:43.390385]: ====================
[2018-04-17 21:17:43.461574]: [Epoch: 986(98.69869869869869%): Data: 0.0%]:Running loss: 0.21751879155635834
[2018-04-17 21:17:44.737466]: [Epoch: 986(98.69869869869869%): Data: 25.333333333333336%]:Running loss: 4.350375831127167
[2018-04-17 21:17:45.988794]: [Epoch: 986(98.69869869869869%): Data: 50.66666666666667%]:Running loss: 8.483232870697975
[2018-04-17 21:17:49.586861]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:17:49.716205]: ====================
[2018-04-17 21:17:49.721218]: Elapsed time since starting training: 1:57:15.885849
[2018-04-17 21:17:49.726232]: Estimated time left: -1 day, 23:17:44.109137
[2018-04-17 21:17:49.731245]: ====================
[2018-04-17 21:17:49.805945]: [Epoch: 987(98.7987987987988%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:17:51.100887]: [Epoch: 987(98.7987987987988%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:17:52.411371]: [Epoch: 987(98.7987987987988%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:17:56.036510]: Test set accuracy: 94.33962264150944% ,loss = 5.437970533967018
[2018-04-17 21:17:56.157332]: ====================
[2018-04-17 21:17:56.163348]: Elapsed time since starting training: 1:57:22.327478
[2018-04-17 21:17:56.168362]: Estimated time left: -1 day, 23:17:37.667509
[2018-04-17 21:17:56.173375]: ====================
[2018-04-17 21:17:56.245567]: [Epoch: 988(98.8988988988989%): Data: 0.0%]:Running loss: 0.21751882135868073
[2018-04-17 21:17:57.526472]: [Epoch: 988(98.8988988988989%): Data: 25.333333333333336%]:Running loss: 4.3503764271736145
[2018-04-17 21:17:58.809885]: [Epoch: 988(98.8988988988989%): Data: 50.66666666666667%]:Running loss: 8.483234032988548
[2018-04-17 21:18:02.471121]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:18:02.604482]: ====================
[2018-04-17 21:18:02.609488]: Elapsed time since starting training: 1:57:28.774119
[2018-04-17 21:18:02.615003]: Estimated time left: -1 day, 23:17:31.220366
[2018-04-17 21:18:02.620519]: ====================
[2018-04-17 21:18:02.693712]: [Epoch: 989(98.998998998999%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:18:03.991664]: [Epoch: 989(98.998998998999%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 21:18:05.271065]: [Epoch: 989(98.998998998999%): Data: 50.66666666666667%]:Running loss: 8.48322008550167
[2018-04-17 21:18:08.881676]: Test set accuracy: 94.33962264150944% ,loss = 5.437961593270302
[2018-04-17 21:18:08.997484]: ====================
[2018-04-17 21:18:09.004503]: Elapsed time since starting training: 1:57:35.168633
[2018-04-17 21:18:09.009015]: Estimated time left: -1 day, 23:17:24.826354
[2018-04-17 21:18:09.013527]: ====================
[2018-04-17 21:18:09.082209]: [Epoch: 990(99.09909909909909%): Data: 0.0%]:Running loss: 0.21751846373081207
[2018-04-17 21:18:10.375649]: [Epoch: 990(99.09909909909909%): Data: 25.333333333333336%]:Running loss: 4.3503692746162415
[2018-04-17 21:18:11.675605]: [Epoch: 990(99.09909909909909%): Data: 50.66666666666667%]:Running loss: 8.483220145106316
[2018-04-17 21:18:15.250110]: Test set accuracy: 94.33962264150944% ,loss = 5.437961965799332
[2018-04-17 21:18:15.379955]: ====================
[2018-04-17 21:18:15.384968]: Elapsed time since starting training: 1:57:41.549098
[2018-04-17 21:18:15.389480]: Estimated time left: -1 day, 23:17:18.445889
[2018-04-17 21:18:15.394493]: ====================
[2018-04-17 21:18:15.461672]: [Epoch: 991(99.1991991991992%): Data: 0.0%]:Running loss: 0.21751847863197327
[2018-04-17 21:18:16.737564]: [Epoch: 991(99.1991991991992%): Data: 25.333333333333336%]:Running loss: 4.350369572639465
[2018-04-17 21:18:18.001425]: [Epoch: 991(99.1991991991992%): Data: 50.66666666666667%]:Running loss: 8.483220666646957
[2018-04-17 21:18:21.610522]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:18:21.726832]: ====================
[2018-04-17 21:18:21.731344]: Elapsed time since starting training: 1:57:47.895473
[2018-04-17 21:18:21.735856]: Estimated time left: -1 day, 23:17:12.100015
[2018-04-17 21:18:21.740368]: ====================
[2018-04-17 21:18:21.810555]: [Epoch: 992(99.2992992992993%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:18:23.073914]: [Epoch: 992(99.2992992992993%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:18:24.345795]: [Epoch: 992(99.2992992992993%): Data: 50.66666666666667%]:Running loss: 8.483222410082817
[2018-04-17 21:18:27.882199]: Test set accuracy: 94.33962264150944% ,loss = 5.437963083386421
[2018-04-17 21:18:28.009537]: ====================
[2018-04-17 21:18:28.015553]: Elapsed time since starting training: 1:57:54.179683
[2018-04-17 21:18:28.020566]: Estimated time left: -1 day, 23:17:05.814803
[2018-04-17 21:18:28.026081]: ====================
[2018-04-17 21:18:28.101281]: [Epoch: 993(99.3993993993994%): Data: 0.0%]:Running loss: 0.21751852333545685
[2018-04-17 21:18:29.377174]: [Epoch: 993(99.3993993993994%): Data: 25.333333333333336%]:Running loss: 4.350370466709137
[2018-04-17 21:18:30.669109]: [Epoch: 993(99.3993993993994%): Data: 50.66666666666667%]:Running loss: 8.483222976326942
[2018-04-17 21:18:34.266674]: Test set accuracy: 94.33962264150944% ,loss = 5.437963828444481
[2018-04-17 21:18:34.502302]: ====================
[2018-04-17 21:18:34.507816]: Elapsed time since starting training: 1:58:00.672447
[2018-04-17 21:18:34.513331]: Estimated time left: -1 day, 23:16:59.322038
[2018-04-17 21:18:34.518344]: ====================
[2018-04-17 21:18:34.587027]: [Epoch: 994(99.4994994994995%): Data: 0.0%]:Running loss: 0.21751855313777924
[2018-04-17 21:18:35.852391]: [Epoch: 994(99.4994994994995%): Data: 25.333333333333336%]:Running loss: 4.350371062755585
[2018-04-17 21:18:37.119761]: [Epoch: 994(99.4994994994995%): Data: 50.66666666666667%]:Running loss: 8.48322369158268
[2018-04-17 21:18:40.724847]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:18:40.863215]: ====================
[2018-04-17 21:18:40.867727]: Elapsed time since starting training: 1:58:07.032358
[2018-04-17 21:18:40.872741]: Estimated time left: -1 day, 23:16:52.962628
[2018-04-17 21:18:40.877754]: ====================
[2018-04-17 21:18:40.948943]: [Epoch: 995(99.5995995995996%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:18:42.216814]: [Epoch: 995(99.5995995995996%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:18:43.512259]: [Epoch: 995(99.5995995995996%): Data: 50.66666666666667%]:Running loss: 8.483224004507065
[2018-04-17 21:18:47.030112]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:18:47.155948]: ====================
[2018-04-17 21:18:47.160961]: Elapsed time since starting training: 1:58:13.325592
[2018-04-17 21:18:47.165973]: Estimated time left: -1 day, 23:16:46.669396
[2018-04-17 21:18:47.170988]: ====================
[2018-04-17 21:18:47.243180]: [Epoch: 996(99.69969969969969%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:18:48.531605]: [Epoch: 996(99.69969969969969%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:18:49.821535]: [Epoch: 996(99.69969969969969%): Data: 50.66666666666667%]:Running loss: 8.483222991228104
[2018-04-17 21:18:53.390524]: Test set accuracy: 94.33962264150944% ,loss = 5.437963455915451
[2018-04-17 21:18:53.515858]: ====================
[2018-04-17 21:18:53.520370]: Elapsed time since starting training: 1:58:19.685001
[2018-04-17 21:18:53.525384]: Estimated time left: -1 day, 23:16:40.309985
[2018-04-17 21:18:53.529896]: ====================
[2018-04-17 21:18:53.602088]: [Epoch: 997(99.7997997997998%): Data: 0.0%]:Running loss: 0.21751853823661804
[2018-04-17 21:18:54.907559]: [Epoch: 997(99.7997997997998%): Data: 25.333333333333336%]:Running loss: 4.350370764732361
[2018-04-17 21:18:56.185456]: [Epoch: 997(99.7997997997998%): Data: 50.66666666666667%]:Running loss: 8.48322308063507
[2018-04-17 21:18:59.784526]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:18:59.902340]: ====================
[2018-04-17 21:18:59.906852]: Elapsed time since starting training: 1:58:26.071483
[2018-04-17 21:18:59.912366]: Estimated time left: -1 day, 23:16:33.923003
[2018-04-17 21:18:59.917380]: ====================
[2018-04-17 21:18:59.987065]: [Epoch: 998(99.8998998998999%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:19:01.271481]: [Epoch: 998(99.8998998998999%): Data: 25.333333333333336%]:Running loss: 4.350371360778809
[2018-04-17 21:19:02.549879]: [Epoch: 998(99.8998998998999%): Data: 50.66666666666667%]:Running loss: 8.483224153518677
[2018-04-17 21:19:06.085280]: Test set accuracy: 94.33962264150944% ,loss = 5.437964200973511
[2018-04-17 21:19:06.216630]: ====================
[2018-04-17 21:19:06.221141]: Elapsed time since starting training: 1:58:32.385772
[2018-04-17 21:19:06.226154]: Estimated time left: -1 day, 23:16:27.609215
[2018-04-17 21:19:06.231168]: ====================
[2018-04-17 21:19:06.303360]: [Epoch: 999(100.0%): Data: 0.0%]:Running loss: 0.21751856803894043
[2018-04-17 21:19:07.599312]: [Epoch: 999(100.0%): Data: 25.333333333333336%]:Running loss: 4.3503721207380295
[2018-04-17 21:19:08.865178]: [Epoch: 999(100.0%): Data: 50.66666666666667%]:Running loss: 8.483225762844086
[2018-04-17 21:19:12.468258]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
[2018-04-17 21:19:12.595597]: ====================
[2018-04-17 21:19:12.601613]: Elapsed time since starting training: 1:58:38.766244
[2018-04-17 21:19:12.610136]: Estimated time left: -1 day, 23:16:21.225735
[2018-04-17 21:19:12.614647]: ====================
[2018-04-17 21:19:12.619160]: Elapsed time on training: 1:58:38.783289
[2018-04-17 21:19:13.879511]: Test set accuracy: 94.33962264150944% ,loss = 5.4379653185606
